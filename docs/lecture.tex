% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={ECON5630 Topics in Empirical Industrial Organization},
  pdfauthor={Kohei Kawaguchi},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{ECON5630 Topics in Empirical Industrial Organization}
\author{Kohei Kawaguchi}
\date{Last updated: 2025-03-04}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter{Syllabus}\label{syllabus}

\section{Instructor Information}\label{instructor-information}

\begin{itemize}
\tightlist
\item
  Instructor:

  \begin{itemize}
  \tightlist
  \item
    Name: Kohei Kawaguchi (Sunada).
  \item
    Office hour: LSK6070, by appointment.
  \end{itemize}
\item
  All questions related to the class have to be publicly asked on Discord rather than being privately asked in e-mail. The instructor usually does not reply in the evening, weekends, and holidays.
\end{itemize}

\section{General Information}\label{general-information}

\subsection{Class Time}\label{class-time}

\begin{itemize}
\tightlist
\item
  Date: Mon, Wed.
\item
  Time: 9:00-10:50.
\item
  Venue: G001, CYT Bldg.
\end{itemize}

\subsection{Description}\label{description}

\begin{itemize}
\item
  This is a PhD-level course for empirical industrial organization. This course covers various econometric methods used in industrial organization that is often referred to as the structural estimation approach. These methods have been gradually developed since 1980s in parallel with the modernization of industrial organization based on the game theory and now widely applied in antitrust policy, business strategy, and neighboring fields such as labor economics and international economics.
\item
  This course presumes a good understanding of PhD-level microeconomics and microeconometrics. Participants are expected to understand at least UG-level industrial organization. This course requires participants to write programs mostly in R and sometimes in C++ to implement various econometric methods. In particular, all assignments will involve such a non-trivial programming task. Even though the understanding of these programming languages is not a prerequisite, a sharp learning curve will be required. Some experience in other programming languages will help. Audit without a credit is not admitted for students.
\end{itemize}

\subsection{Expectation and Goals}\label{expectation-and-goals}

\begin{itemize}
\tightlist
\item
  The goal of this course is to learn and practice econometric methods for empirical industrial organization. The lecture covers the econometric methods that have been developed between 80s and 00s to estimate primitive parameters governing imperfect competition among firms, such as production and cost function estimation, demand function estimation, merger simulation, entry and exit analysis, and dynamic decision models. The lecture also covers various new methods to recover model primitives in certain mechanisms such as auction, matching, network, and bargaining. The emphasis is put on the former group of methods, because they are the basis for other new methods. Participants will not only understand the theoretical background of the methods but also become able to implement these methods from scratches by writing their own programs. I will briefly discuss the latter class of new methods through reading recent papers. The participants will become able to understand and use these new methods.
\end{itemize}

\section{Required Environment}\label{required-environment}

\begin{itemize}
\tightlist
\item
  Participants should bring their laptop to the class. We have enough extension codes for students. The laptop should have sufficient RAM (at least \(\ge\) 8GB, \(\ge\) 16GB is recommended) and CPU power (at least Core i5 grade, Core i7 grade is recommended). Participants are fully responsible for their hardware issues. Operating System can be arbitrary.
\item
  Please install the following software by the first lecture. Technical issues related to the installment should be resolved by yourself, because it depends on your local environment. If you had an error, copy and paste the error message on a search engine, and find a solution. This solves 99.9\% of the problems.

  \begin{itemize}
  \tightlist
  \item
    R: \url{https://www.r-project.org/}
  \item
    RStudio: \url{https://www.rstudio.com/}
  \item
    LaTeX:

    \begin{itemize}
    \tightlist
    \item
      MikTex \url{https://miktex.org/}
    \item
      TeXLive \url{https://www.tug.org/texlive/}
    \item
      MacTeX \url{http://www.tug.org/mactex/}
    \end{itemize}
  \end{itemize}
\end{itemize}

\section{Evaluation}\label{evaluation}

\begin{itemize}
\tightlist
\item
  Assignments (90): In total 9 homework are assigned. Each homework involves the implementation of the methods covered in the class. Each homework has 10 points. The working hour for each homework will be around 10-20 hours.
\item
  Presentation (10): Toward the end of the semester, a paper in industrial organization is randomly assigned to each participant. Each participant makes a presentation within 20 pages and records 30 minutes presentation.
\item
  Grading is based on the absolute scores: A+ with more than 90 points, A with more than 85 points, A- with more than 80 points, B+ with more than 70 points, B with more than 60 points, B- with more than 50 points and C otherwise.
\end{itemize}

\section{Academic Integrity}\label{academic-integrity}

Without academic integrity, there is no serious learning. Thus you are expected to hold the highest standard of academic integrity in the course. You are encouraged to study and do homework in groups. However, no cheating, plagiarism will be tolerated. Anyone caught
cheating, plagiarism will fail the course. Please make sure adhere to the HKUST Academic
Honor Code at all time (see \url{http://www.ust.hk/vpaao/integrity/}).

\section{Schedule}\label{schedule}

\begin{itemize}
\tightlist
\item
  Introduction to structural estimation, R and RStudio
\item
  Production function estimation I
\item
  Production function estimation II
\item
  Demand function estimation I
\item
  Demand function estimation II
\item
  Merger Analysis
\item
  Entry and Exit
\item
  Single-Agent Dynamics I
\item
  Single-Agent Dynamics II
\item
  Dynamic Game I
\item
  Dynamic Game II
\item
  Auction
\item
  Recent topics
\item
  Presentations
\end{itemize}

\section{Course Materials}\label{course-materials}

\subsection{Code}\label{code}

\begin{itemize}
\tightlist
\item
  The source file of the lecture note and assignments are available at \url{https://github.com/kohei-kawaguchi/EmpiricalIO}.
\end{itemize}

\subsection{R and RStudio}\label{r-and-rstudio}

\begin{itemize}
\tightlist
\item
  Grolemund, G., 2014, Hands-On Programming with R, O'Reilly.

  \begin{itemize}
  \tightlist
  \item
    Free online version is available: \url{https://rstudio-education.github.io/hopr/}.
  \end{itemize}
\item
  Wickham, H., \& Grolemund, G., 2017, R for Data Science, O'Reilly.

  \begin{itemize}
  \tightlist
  \item
    Free online version is available: \url{https://r4ds.had.co.nz/}.
  \end{itemize}
\item
  Boswell, D., \& Foucher, T., 2011, The Art of Readable Code: Simple and Practical Techniques for Writing Better Code, O'Reilly.
\end{itemize}

\subsection{Handbook Chapters}\label{handbook-chapters}

\begin{itemize}
\tightlist
\item
  Ackerberg, D., Benkard, C., Berry, S., \& Pakes, A. (2007). ``Econometric tools for analyzing market outcomes''. Handbook of econometrics, 6, 4171-4276.
\item
  Athey, S., \& Haile, P. A. (2007). ``Nonparametric approaches to auctions''. Handbook of
  Econometrics, 6, 3847-3965.
\item
  Berry, S., \& Reiss, P. (2007). ``Empirical models of entry and market structure''. Handbook of Industrial Organization, 3, 1845-1886.
\item
  Bresnahan, T. F. (1989). ``Empirical studies of industries with market power''. Handbook of
  Industrial Organization, 2, 1011-1057.
\item
  Hendricks, K., \& Porter, R. H. (2007). ``An empirical perspective on auctions''. Handbook of
  Industrial Organization, 3, 2073-2143.
\item
  Matzkin, R. L. (2007). ``Nonparametric identification''. Handbook of Econometrics, 6, 5307-5368.
\item
  Newey, W. K., \& McFadden, D. (1994). ``Large sample estimation and hypothesis testing''. Handbook of Econometrics, 4, 2111-2245.
\item
  Reiss, P. C., \& Wolak, F. A. (2007). ``Structural econometric modeling: Rationales and examples from industrial organization''. Handbook of Econometrics, 6, 4277-4415.
\end{itemize}

\subsection{Books}\label{books}

\begin{itemize}
\tightlist
\item
  Train, K. E. (2009). Discrete Choice Methods with Simulation, Cambridge university press.
\item
  Davis, P., \& Garces, E. (2010). Quantitative Techniques for Competition and Antitrust Analysis, Princeton University Press.
\item
  Tirole, J. (1988). The Theory of Industrial Organization, The MIT Press.
\end{itemize}

\subsection{Papers}\label{papers}

\begin{itemize}
\tightlist
\item
  The list of important papers are occasionally given during the course.
\end{itemize}

\chapter{Introduction}\label{intro}

\section{What are structural models?}\label{what-are-structural-models}

\begin{itemize}
\tightlist
\item
  An economic model is a mapping from exogenous variables (including shocks and parameters) to endogenous variables.
\item
  This mapping is derived from a solution concept (optimality and equilibrium).
\item
  The structural estimation approach starts from an economic model and derives an econometric model.
\item
  The \textbf{structural-form} of an economic model is the equilibrium condition for the endogenous variables given the exogenous variables.
\item
  The \textbf{reduced-form} of an economic model is the solution of the structural-form for the endogenous variables in terms of the exogenous variables.
\end{itemize}

\section{Example: Linear demand and supply model}\label{example-linear-demand-and-supply-model}

\begin{itemize}
\item
  Consider a linear demand and supply model:
  \begin{align}
      Q_i^d = \alpha + \beta P_i + \gamma X_i + \epsilon_i \\
      Q_i^s = \delta + \theta P_i + \zeta Z_i + \nu_i
  \end{align}
\item
  The parameters of the model are: \(\alpha, \beta, \gamma, \delta, \theta, \zeta\)
\item
  The observed exogenous variables are: \(X_i, Z_i\)
\item
  The unobserved exogenous variables (shocks) are: \(\epsilon_i, \nu_i\) (assume standard deviations of 1 for simplicity and mutually i.i.d.)
\item
  The endogenous variables are: \(P_i, Q_i\)
\item
  The solution concept is the market clearing condition:
  \begin{align}
    &Q_i^d = Q_i^s \\
    &\Leftrightarrow \alpha + \beta P_i + \gamma X_i + \epsilon_i = \delta + \theta P_i + \zeta Z_i + \nu_i
  \end{align}
\item
  So far this is the structural-form of the model.
\item
  The solution is obtained by solving the endogenous variables for the exogenous variables:
  \begin{align}
    P_i = \frac{\alpha - \delta + \gamma X_i - \zeta Z_i + \epsilon_i - \nu_i}{\theta - \beta} \\
    Q_i = \frac{\alpha \theta - \beta \delta + \theta \gamma X_i - \beta \zeta Z_i + \theta \epsilon_i - \beta \nu_i}{\theta - \beta}
  \end{align}
\item
  This is the mapping from the exogenous variables to the endogenous variables in the structural model.
\item
  This is the reduced-form of the model.
\end{itemize}

\section{Ordinary-Least-Squares (OLS) estimation of the demand and supply model}\label{ordinary-least-squares-ols-estimation-of-the-demand-and-supply-model}

\begin{itemize}
\tightlist
\item
  OLS is applied to the reduced-form of the model.
\item
  The reduced-form model is represented by the following equation:
  \begin{align}
    P_i &= \pi_1 + \pi_2 X_i + \pi_3 Z_i + \sigma_1 \varepsilon_i\\
    Q_i &= \pi_4 + \pi_5 X_i + \pi_6 Z_i + \sigma_2 \upsilon_i
  \end{align}
\item
  The parameters of the reduced-form model are: \(\pi_0, \pi_1, \pi_2, \pi_3, \pi_4, \pi_5, \sigma_1, \sigma_2\) are related to the parameters of the structural-form model as follows:
  \begin{align}
    \pi_1 = \frac{\alpha - \delta}{\theta - \beta} \\
    \pi_2 = \frac{\gamma}{\theta - \beta} \\
    \pi_3 = \frac{-\zeta}{\theta - \beta} \\
    \pi_4 = \frac{\alpha \theta - \beta \delta}{\theta - \beta} \\
    \pi_5 = \frac{\theta \gamma}{\theta - \beta} \\
    \pi_6 = \frac{- \beta \zeta}{\theta - \beta} \\
    \sigma_1 = \frac{1}{\theta - \beta} \\
    \sigma_2 = \frac{\sqrt{\theta^2 + \beta^2}}{\theta - \beta}
  \end{align}
\item
  Because the right-hand side of the reduced-form model only includes exogenous variables, the OLS estimators can consistently estimate the reduced-form parameters.
\item
  From the known 6 reduced-form parameters \(\pi_1, \pi_2, \pi_3, \pi_4, \pi_5, \pi_6\), we can recover 6 structural-form parameters \(\alpha, \beta, \gamma, \delta, \theta, \zeta\).
\item
  This is the original idea of OLS in the context of structural estimation.
\item
  You may be concerned that the right-hand side of the reduced-form model may include some endogenous variables --- it's just because you have not fully solved the model.
\end{itemize}

\section{Maximum-Likelihood Estimation (MLE) of the demand and supply model}\label{maximum-likelihood-estimation-mle-of-the-demand-and-supply-model}

\begin{itemize}
\tightlist
\item
  The MLE is not very different from the above approach.
\item
  We derive the reduced-form model.
\item
  Then, under the distributional assumptions on the shocks, we can derive the likelihood function:
  \begin{align}
    L(\alpha, \beta, \gamma, \delta, \theta, \zeta) = \prod_{i=1}^n f(P_i, Q_i | X_i, Z_i)
  \end{align}
\item
  The distributional assumptions on the shocks could be:
  \begin{align}
    \epsilon_i \sim N(0, 1) \\
    \nu_i \sim N(0, 1)
  \end{align}
\item
  If the structural-form parameters could be identified by the OLS estimator, then the MLE estimator should also identify them because you have the same information with a stronger distributional assumption.
\end{itemize}

\section{Simulation-based (Simulated-Likelihood or Simulated-Method-of-Moments) methods}\label{simulation-based-simulated-likelihood-or-simulated-method-of-moments-methods}

\begin{itemize}
\tightlist
\item
  In the current example, the reduced-form model is analytically derived and the likelihood function is also analytically derived.
\item
  However, in many cases, the reduced-form model is not analytically derived and the likelihood function is not analytically derived.
\item
  Even in this case, if we can simulate the endogenous variables solving the equilibrium condition, we can use the simulation-based methods to estimate the parameters.
\item
  For example, by simulating shocks \(\epsilon_i\) and \(\nu_i\) from the distributional assumptions, we can simulate the endogenous variables \(P_i\) and \(Q_i\).
\item
  Then, we can approximate the likelihood function by the empirical distribution of the simulated data.
\item
  Or, we can find parameters that minimize the distance between the observed and simulated endogenous variables.
\end{itemize}

\section{Two-Stage Least Squares (2SLS) estimation of the demand and supply model}\label{two-stage-least-squares-2sls-estimation-of-the-demand-and-supply-model}

\begin{itemize}
\tightlist
\item
  The OLS and ML estimators relied on the reduced-form model.
\item
  The 2SLS estimator is a method to estimate the structural-form parameters of the equation of interest by representing the other equations in the reduced-form.
\item
  Suppose that we are interested in estimating the structural-form parameters of the demand equation.
\item
  The demand equation is:
  \begin{align}
    Q_i = \alpha + \beta P_i + \gamma X_i + \epsilon_i
  \end{align}
\item
  The 2SLS estimator first runs the reduced-form model for the other equation:
  \begin{align}
    P_i = \pi_1 + \pi_2 X_i + \pi_3 Z_i + \sigma_1 \varepsilon_i
  \end{align}
\item
  Then, the 2SLS estimator uses the predicted values of the endogenous variables from the reduced-form model for the supply equation to estimate the structural-form parameters of the demand equation.
\item
  In this estimation, \(Z_i\) is used as an instrument for \(P_i\), which is an exogenous variable excluded from the demand equation.
\item
  Instead, suppose that we are interested in estimating the structural-form parameters of the supply equation.
\item
  The supply equation is:
  \begin{align}
    Q_i = \delta + \theta P_i + \zeta Z_i + \nu_i
  \end{align}
\item
  The 2SLS estimator first runs the reduced-form model for the other equation:
  \begin{align}
    P_i = \pi_1 + \pi_2 X_i + \pi_3 Z_i + \sigma_1 \varepsilon_i
  \end{align}
\item
  Then, the 2SLS estimator uses the predicted values of the endogenous variables from the reduced-form model for the demand equation to estimate the structural-form parameters of the supply equation.
\item
  In this estimation, \(X_i\) is used as an instrument for \(P_i\), which is an exogenous variable excluded from the supply equation.
\end{itemize}

\section{Instrumental-Variables (IV) and Generalized Method of Moments (GMM) estimation of the demand and supply model}\label{instrumental-variables-iv-and-generalized-method-of-moments-gmm-estimation-of-the-demand-and-supply-model}

\begin{itemize}
\tightlist
\item
  The IV and GMM estimators rely on another representation of the economic model.
\item
  It relies on the \textbf{moment condition} of the economic model.
\item
  In the current example, the moment condition is:
  \begin{align}
    & E[\epsilon_i | X_i, Z_i] = 0\\
    & E[\nu_i | X_i, Z_i] = 0
  \end{align}
\item
  The IV and GMM estimators find the parameters that make the empirical-analogue of the moment condition zero.
\item
  To compute the empirical-analogue of the moment condition, this time, we solve the equilibrium condition for the shocks (not for the endogenous variables).
\item
  For example, for the demand equation, we solve the following equation for \(\epsilon_i\):
  \begin{align}
    \epsilon_i &= Q_i - \alpha - \beta P_i - \gamma X_i\\
    \nu_i &= Q_i - \delta - \theta P_i - \zeta Z_i
  \end{align}
\item
  Then, the right-hand side includes only observed variables and the parameters.
\item
  Then, we can compute the implied shock from the data for candidate parameters as:
  \begin{align}
    \hat{\epsilon}_i &= Q_i - \hat{\alpha} - \hat{\beta} P_i - \hat{\gamma} X_i\\
    \hat{\nu}_i &= Q_i - \hat{\delta} - \hat{\theta} P_i - \hat{\zeta} Z_i
  \end{align}
\item
  Then, we can compute the empirical-analogue of the moment condition:
  \begin{align}
    \frac{1}{n} \sum_{i=1}^n \hat{\epsilon}_i A(Z_i, X_i) = 0\\
    \frac{1}{n} \sum_{i=1}^n \hat{\nu}_i B(Z_i, X_i) = 0
  \end{align}
  where \(A(Z_i, X_i)\) and \(B(Z_i, X_i)\) are some known functions of the observed variables and the parameters.
\item
  The IV and GMM estimators find the parameters that make the empirical-analogue of the moment condition zero.
\end{itemize}

\section{General Case}\label{general-case}

\begin{itemize}
\tightlist
\item
  In general, the structural-form model is represented by the following equation:
  \begin{align}
    f(Y_i, X_i, \epsilon_i, \theta) = 0
  \end{align}
  for endogenous variables \(Y_i\), exogenous variables \(X_i\), shocks \(\epsilon_i\), and the parameters \(\theta\).
\item
  The reduced-form model is represented by the following equation:
  \begin{align}
    Y_i = g(X_i, \epsilon_i, \theta) = f_1^{-1}(X_i, \epsilon_i, \theta)
  \end{align}
  for exogenous variables \(X_i\), shocks \(\epsilon_i\), and the parameters \(\theta\).
\item
  We can apply OLS, ML, Simulated-Likelihood to this form.
\item
  The moment condition is:
  \begin{align}
    E[h(Y_i, X_i, \theta) | X_i, \nu_i] = E[f_3^{-1}(Y_i, X_i, \theta) | X_i, \nu_i] = 0
  \end{align}
\item
  We can apply IV and GMM to this form.
\item
  Thus, structural estimation is a general framework to estimate the parameters of the economic model by transforming it in either form and applying the corresponding estimation method.
\end{itemize}

\section{Structural Estimation and Counterfactual Analysis}\label{structural-estimation-and-counterfactual-analysis}

\subsection{Example}\label{example}

\begin{itemize}
\item
  \citet{Igami2017} ``Estimating the Innovator's Dilemma: Structural Analysis of Creative Destruction in the Hard Disk Drive Industry, 1981-1998''
\item
  \textbf{Question}:

  \begin{itemize}
  \tightlist
  \item
    Does the ``Innovator's Dilemma'' \citep{Christensen1997} or the delay of innovation among incumbents exist?
  \item
    Christensen argued that old winners tend to lag behind entrants even when introducing a new technology is not too difficult, with a case study of the HDD industry.
  \end{itemize}
\item
  Apple's smartphones vs.~Nokia's feature phones
\item
  Amazon vs.~Borders
\item
  Kodak's digital cameras
\item
  If it exists, what is the reason for that?
\item
  How do we empirically answer this question?
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{figuretable/Igam2017Fig1} 

}

\caption{Figure 1 of Igam (2017)}\label{fig:unnamed-chunk-2}
\end{figure}

\begin{itemize}
\item
  \textbf{Hypotheses}:
\item
  Identify potentially competing hypotheses to explain the phenomenon.

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Cannibalization: Because of cannibalization, the benefits of introducing a new product are smaller for incumbents than for entrants.
  \item
    Different costs: The incumbents may have higher costs for innovation due to organizational inertia, but at the same time they may have some cost advantage due to accumulated R\&D and better financial access.
  \item
    Preemption: The incumbents have additional incentive for innovation to preempt potential rivals.
  \item
    Institutional environment: The impacts of the three components differ across different institutional contexts such as the rules governing patents and market size.
  \end{enumerate}
\item
  Casual empiricists pick up their favorite factors to make up a story.
\item
  Serious empiricists should try to separate the contributions of each factor from data.
\item
  To do so, the author develops an economic model that explicitly incorporates the above-mentioned factors, while keeping the model parameters flexible enough to let the data tell the sign and size of the effects of each factor on innovation.
\item
  \textbf{Economic model}:
\item
  The time is discrete with finite horizon \(t = 1, \cdots, T\).
\item
  In each year, there is a finite number of firms indexed by \(i\).
\item
  Each firm is in one of the technological states:
  \begin{equation}
  s_{it} \in \{\text{old only, both, new only, potential entrant}\},
  \end{equation}
  where the first two states are for incumbents (stick to the old technology or start using the new technology) and the last two states are for actual and potential entrants (enter with the new technology or stay outside the market).
\item
  In each year:

  \begin{itemize}
  \tightlist
  \item
    Pre-innovation incumbent (\(s_{it} =\) old): exit or innovate by paying a sunk cost \(\kappa^{inc}\) (to be \(s_{i, t + 1} =\) both).
  \item
    Post-innovation incumbent (\(s_{it} =\) both): exit or stay to be both.
  \item
    Potential entrant (\(s_{it} =\) potential entrant): give up entry or enter with the new technology by paying a sunk cost \(\kappa^{net}\) (to be \(s_{i, t + 1} =\) new).
  \item
    Actual entrant (\(s_{it} =\) new): exit or stay to be new.
  \end{itemize}
\item
  Given the industry state \(s_t = \{s_{it}\}_i\), the product market competition opens and the profit of firm \(i\), \(\pi_t(s_{it}, s_{-it})\), is realized for each active firm.
\item
  As the product market competition closes:

  \begin{itemize}
  \tightlist
  \item
    Pre-innovation incumbents draw private cost shocks and make decisions: \(a_t^{pre}\).
  \item
    Observing this, post-innovation incumbents draw private cost shocks and make decisions: \(a_t^{post}\).
  \item
    Observing this, actual entrants draw private cost shocks and make decisions: \(a_t^{act}\).
  \item
    Observing this, potential entrants draw private cost shocks and make decisions: \(a_t^{pot}\).
  \end{itemize}
\item
  This is a dynamic game. The equilibrium is defined by the concept of \textbf{Markov-perfect equilibrium} \citep{Maskin1988}.
\item
  The representation of the competing theories in the model:

  \begin{itemize}
  \tightlist
  \item
    The existence of cannibalization is represented by the assumption that an incumbent maximizes the joint profits of old and new technology products.
  \item
    The size of cannibalization is captured by the shape of profit function.
  \item
    The difference in the cost of innovation is captured by the difference in the sunk costs of innovation.
  \item
    The preemptive incentive for incumbents is embodied in the dynamic optimization problem for each incumbent.
  \end{itemize}
\item
  \textbf{Econometric model}:
\item
  The author then turns the economic model into an econometric model.
\item
  This amounts to specifying which part of the economic model is observed/known and which part is unobserved/unknown.
\item
  The author collects the data set of the HDD industry during 1977-99.
\item
  Based on the data, the author specifies the identities of active firms and their products and the technologies embodied in the products in each year to code their \textbf{state variables}.
\item
  Moreover, by tracking the change in the state, the author codes their \textbf{action variables}.
\item
  Thus, the state and action variables, \(s_t\) and \(a_t\). These are the \textbf{observables}.
\item
  The author does not observe:

  \begin{itemize}
  \tightlist
  \item
    Profit function \(\pi_t(\cdot)\).
  \item
    Sunk cost of innovation for pre-innovation incumbents \(\kappa^{inc}\).
  \item
    Sunk cost of entry for potential entrants \(\kappa^{net}\).
  \item
    Private cost shocks.
  \end{itemize}
\item
  These are the \textbf{unobservables}.
\item
  Among the unobservables, the profit function and sunk costs are the \textbf{parameters of interest} and the private cost shocks are \textbf{nuisance parameters} in the sense only the knowledge about the distribution of the latter is demanded.
\item
  \textbf{Identification}:
\item
  Can we infer the unobservables from the observables and the restrictions on the distribution of observables by the economic theory?
\item
  The profit function is identified from estimating the demand function for each firm's product, and estimating the cost function for each firm from using their price setting behavior.
\item
  The sunk costs of innovation are identified from the conditional probability of innovation across various states. If the cost is low, the probability should be high.
\item
  \textbf{Estimation}:

  \begin{itemize}
  \tightlist
  \item
    The identification established that in principle we can uncover the parameters of interest from observables under the restrictions of economic theory.
  \end{itemize}
\item
  Finally, we apply a statistical method to the econometric model and infer the parameters of interest.
\item
  \textbf{Counterfactual analysis}:

  \begin{itemize}
  \tightlist
  \item
    If we can uncover the parameters of interest, we can conduct \textbf{comparative statics}: study the change in the endogenous variables when the exogenous variables including the model parameters are set differently. In the current framework, this exercise is often called the \textbf{counterfactual analysis}.
  \end{itemize}
\item
  What if there was no cannibalization?:

  \begin{itemize}
  \tightlist
  \item
    An incumbent separately maximizes the profit from old technology and new technology instead of jointly maximizing the profits. Solve the model under this new assumption everything else being equal.
  \end{itemize}
\item
  Free of cannibalization concerns, 8.95 incumbents start producing new HDDs in the first 10 years, compared with 6.30 in the baseline.
\item
  The cumulative numbers of innovators among incumbents and entrants differ only by 2.8 compared with 6.45 in the baseline.
\item
  Thus cannibalization can explain a significant part of the incumbent-entrant innovation gap.
\item
  What if there was no preemption?:

  \begin{itemize}
  \tightlist
  \item
    A potential entrant ignores the incumbents' innovations upon making entry decisions.

    \begin{itemize}
    \tightlist
    \item
      Without the preemptive motives, only 6.02 incumbents would innovate in the first 10 years, compared with 6.30 in the baseline.
    \item
      The cumulative incumbent-entrant innovation gap widens to 8.91 compared with 6.45 in the baseline.
    \end{itemize}
  \end{itemize}
\item
  The sunk cost of entry is smaller for incumbents than for entrants in the baseline.
\item
  \textbf{Interpretations and policy/managerial implications}:
\item
  Despite the cost advantage and the preemptive motives, the speed of innovation is slower among incumbents due to the strong cannibalization effect.
\item
  Incumbents that attempt to avoid the ``innovator's dilemma'' should separate the decision making between old and new sections inside the organization so that they can avoid the concern for cannibalization.
\end{itemize}

\subsection{Recap}\label{recap}

\begin{itemize}
\tightlist
\item
  The structural approach in empirical industrial organization consists of the following components:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Research question.
\item
  Competing hypotheses.
\item
  Economic model.
\item
  Econometric model.
\item
  Identification.
\item
  Data collection.
\item
  Data cleaning.
\item
  Estimation.
\item
  Counterfactual analysis.
\item
  Coding.
\item
  Interpretations and policy/managerial implications.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  The goal of this course is to be familiar with the standard methodology to complete this process.
\item
  The methodology covered in this class is mostly developed to analyze the standard framework of dynamic or oligopoly competition.
\item
  The policy implications are centered around competition policies.
\item
  But the basic idea can be extended to different classes of situations such as auction, matching, voting, contract, marketing, and so on.
\item
  Note that the depth of the research question and the relevance of the policy/managerial implications are the most important parts of the research.
\item
  Focusing on the methodology in this class is to minimize the time allocated to less important issues and maximize the attention and time to the most valuable part in future research.
\item
  Given a research question, what kind of data is necessary to answer the question?
\item
  Given data, what kind of research questions can you address? Which questions can be credibly answered? Which questions can be an over-stretch?
\item
  Given a research question and data, what is the best way to answer the question? What type of problems can you avoid using the method? What is the limitation of your approach? How will you defend against possible referee comments?
\item
  Given a result, what kinds of interpretations can you credibly derive? What kinds of interpretations can be contested by potential opponents? What kinds of contributions can you claim?
\item
  To address these issues is \textbf{necessary} to publish a paper and it is \textbf{necessary} to be familiar with the methodology to do so.
\end{itemize}

\chapter{Production and Cost Function Estimation}\label{production}

\section{Motivations}\label{motivations}

\begin{itemize}
\tightlist
\item
  Estimating \textbf{production and cost functions} of producers is the cornerstone of economic analysis.
\item
  Estimating the functions includes to separate the contribution of observed inputs and the other factors, which is often referred to as the \textbf{productivity}.
\item
  ``What determines productivity?'' \citep{Syverson2011}-type research questions naturally follow.
\item
  The methods covered in this chapter are widely used across different fields.
\item
  Some of them are variants from the standard methods.
\end{itemize}

\subsection{IO}\label{io}

\begin{itemize}
\tightlist
\item
  \citet{Olley1996}:

  \begin{itemize}
  \tightlist
  \item
    How much did the deregulation in the U.S. telecommunication industry, in particular the divestiture of AT\&T in 1984, spurred the productivity growth of the incumbent, facilitated entries, and increased the aggregate productivity?
  \item
    To do so, the authors estimate the plant-level production functions and productivity in the telecommunication industry.
  \end{itemize}
\item
  \citet{Doraszelski2013a}:

  \begin{itemize}
  \tightlist
  \item
    What is the role of R\&D in determining the differences in productivity across firms and the evolution of firm-level productivity over time?
  \item
    To do so, the authors estimate the firm-level production functions and productivity of Spanish manufacturing firms during 1990s in which the transition probability of a productivity is a function of the R\&D activities.
  \end{itemize}
\end{itemize}

\subsection{Development}\label{development}

\begin{itemize}
\tightlist
\item
  \citet{Hsieh2009}:

  \begin{itemize}
  \tightlist
  \item
    How large is the misallocation of inputs across manufacturing firms in China and India compared to the U.S? How will the aggregate productivity of China and India change if the degree of misallocation is reduced to the U.S. level?
  \item
    To do so, the authors measure the revenue productivity of firms, which should be the same across firms within an industry if there were no distortion, and the measurement of the revenue productivity requires to estimate the production function.
  \end{itemize}
\item
  \citet{Gennaioli2013}:

  \begin{itemize}
  \tightlist
  \item
    What are the determinants of regional growth? Do geographic, institutional, cultural, and human capital factors explain the difference across regions?
  \item
    To do so, the authors construct the data set that covers 74\% of the world's surface and 97\% of its GDP and estimate the production function in which the above mentioned factors could affect the productivity.
  \end{itemize}
\end{itemize}

\subsection{Trade}\label{trade}

\begin{itemize}
\tightlist
\item
  \citet{Haskel2007}:

  \begin{itemize}
  \tightlist
  \item
    Are there spillovers from FDI to domestic firms?
  \item
    To do so, the authors estimate the plant-level production function of the U.K. manufacturing firms during 1973 and 1992 and study how the foreign presence in the U.K. affected the productivity.
  \end{itemize}
\item
  \citet{Loecker2011}:

  \begin{itemize}
  \tightlist
  \item
    Does the removal of trade barriers induces efficiency gain for producers?
  \item
    To do so, the author estimate the production functions of Belgian textile industry during 1994-2002 in which the degree of trade protection can affect the productivity level.
  \end{itemize}
\end{itemize}

\subsection{Management}\label{management}

\begin{itemize}
\tightlist
\item
  \citet{Bloom2007}:

  \begin{itemize}
  \tightlist
  \item
    How do management practices affect the firm productivity?
  \item
    To do so, the authors first estimate the production function and productivity of manufacturing firms in developed countries, and then study how the independently measured management practices of the firms affect the estimated productivity.
  \end{itemize}
\item
  \citet{Braguinsky2015}:

  \begin{itemize}
  \tightlist
  \item
    How do changes in ownership affect the productivity and profitability of firms?
  \item
    To do so, the authors estimate the production function for various outputs including the physical output, return on capital and labor, and the utilization rate, price level, using the cotton spinners data in Japan during 1896 and 1920.
  \end{itemize}
\end{itemize}

\subsection{Education}\label{education}

\begin{itemize}
\tightlist
\item
  \citet{Cunha2010}:

  \begin{itemize}
  \tightlist
  \item
    How do childhood and schooling interventions ``produce'' the cognitive and non-cognitive skills of children?
  \item
    To do so, the authors estimate the mapping from childhood and schooling interventions to children's cognitive and non-cognitive skills, the ``production function'' of childhood environment and education.
  \end{itemize}
\end{itemize}

\section{Analyzing Producer Behaviors}\label{analyzing-producer-behaviors}

\begin{itemize}
\item
  There are several levels of parameters that govern the behavior of firms:
\item
  \textbf{Production function}

  \begin{itemize}
  \tightlist
  \item
    Add factor market structure.
  \item
    Add cost minimization.
  \end{itemize}
\item
  \(\rightarrow\) \textbf{Cost function}

  \begin{itemize}
  \tightlist
  \item
    Add product market structure.
  \item
    Add profit maximization.
  \end{itemize}
\item
  \(\rightarrow\) \textbf{Supply function (Pricing function)}

  \begin{itemize}
  \tightlist
  \item
    Combine cost and supply (pricing) functions.
  \end{itemize}
\item
  \(\rightarrow\) \textbf{Profit function}
\item
  Which parameter to identify?
\item
  Primitive enough to be invariant to relevant policy changes.

  \begin{itemize}
  \tightlist
  \item
    e.g.~If you conduct a policy experiment that changes the factor market structure, identifying cost functions is not enough.
  \end{itemize}
\item
  As reduced-form as possible among such specifications.

  \begin{itemize}
  \tightlist
  \item
    A reduced-form parameter usually can be rationalized by a class of underlying structural parameters and institutional assumptions. Thus, the analysis becomes robust to some misspecifications.
  \item
    e.g.~A non-parametric function \(C(q, w)\) can represent a cost function of a producer who is not necessarily minimizing the cost. If we derive a cost function from a production function and a factor market structure, then the cost function cannot represent such a non-optimization behavior.
  \end{itemize}
\end{itemize}

\section{Production Function Estimation}\label{production-function-estimation}

\subsection{Cobb-Douglas Specification as a Benchmark}\label{cobb-douglas-specification-as-a-benchmark}

\begin{itemize}
\tightlist
\item
  Most of the following argument carries over to a general model.
\item
  For firm \(j = 1, \cdots, J\) and time \(t = 1, \cdots, T\), we observe output \(Y_{jt}\), labor \(L_{jt}\), and capital \(K_{jt}\).
\item
  We consider an asymptotic of \(J \to \infty\) for a fixed \(T\).
\item
  Assume Cobb-Douglas production function:
  \begin{equation}
  Y_{jt} = A_{jt}  L_{jt}^{\beta_l} K_{jt}^{\beta_k},
  \end{equation}
  where \(A_{jt}\) is firm \(j\) and time \(t\) specific unobserved heterogeneity in the model.
\item
  Taking the logarithm gives:
  \begin{equation}
  y_{jt} = \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + \epsilon_{jt},
  \end{equation}
  where lowercase symbols represent natural logs of variables and \(\ln(A_{jt}) = \beta_0 + \epsilon_{jt}\).
\item
  This can be regarded as a first-order log-linear approximation of a production function.
\item
  Linear regression model! May OLS work?
\end{itemize}

\subsection{Potential Bias I: Endogeneity}\label{potential-bias-i-endogeneity}

\begin{itemize}
\tightlist
\item
  \(\epsilon_{jt}\) contains everything that cannot be explained by the observed inputs: better capital may be employed, a worker may have obtained better skills, etc.
\item
  When the manager of a firm makes an input choice, she should have some information about the realization of \(\epsilon_{jt}\).
\item
  Thus, the input choice can be correlated with \(\epsilon_{jt}\); for example under static optimization of \(L_{jt}\) given \(K_{jt}\):
  \begin{equation}
  L_{jt} = \Bigg[\frac{p_{jt}}{w_{jt}} \beta_l \exp^{\beta_0 + \epsilon_{jt}} K_{jt}^{\beta_k}\Bigg]^{\frac{1}{1 - \beta_l}}.
  \end{equation}
\item
  In this case, OLS estimator for \(\beta_l\) is \textit{positively} biased, because when \(\epsilon_{jt}\) is high, \(l_{jt}\) is high and thus the increase in output caused by \(\epsilon_{jt}\) is captured as if caused by the increase in labor input.
\item
  The endogeneity problem was already recognized by \citet{Marschak1944}.
\end{itemize}

\subsection{Potential Bias II: Selection}\label{potential-bias-ii-selection}

\begin{itemize}
\tightlist
\item
  Firms freely enter and exit market.
\item
  Therefore, a firm that had low \(\epsilon_{jt}\) is likely to exit.
\item
  However, if firms have high capital \(K_{jt}\), it can stay in the market even if the realization of \(\epsilon_{jt}\) is very low.
\item
  Therefore, conditional on being in the market, there is a \textit{negative} correlation between the capital \(K_{jt}\) and \(\epsilon_{jt}\).
\item
  This problem occurs even if the choice of \(K_{jt}\) itself is not a function of \(\epsilon_{jt}\).
\end{itemize}

\subsection{How to Resolve Endogeneity Bias?}\label{how-to-resolve-endogeneity-bias}

\begin{itemize}
\tightlist
\item
  Temporarily abstract away from entry and exit.
\item
  The data is balanced.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Panel data.
\item
  First-order condition for inputs.
\item
  Instrumental variable.
\item
  Olley-Pakes approach and its followers/critics.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \citet{Griliches1998} is a good survey of the history up to Olley-Pakes approach.
\item
  \citet{Ackerberg2015} also offer a good survey and clarify problems and implicit assumptions in Olley-Pakes approach.
\end{itemize}

\subsection{Panel Data}\label{panel-data}

\begin{itemize}
\tightlist
\item
  Assume that \(\epsilon_{jt} = \mu_j + \eta_{jt}\), where \(\eta_{jt}\) is uncorrelated with input choices up to period \(t\):
  \begin{equation}
  y_{jt} = \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + \mu_j + \eta_{jt}.
  \end{equation}
\item
  Then, by differentiating period \(t\) and \(t - 1\) equations, we get:
  \begin{equation}
  y_{jt} - y_{j, t - 1}= \beta_l (l_{jt} - l_{j, t - 1}) + \beta_k (k_{jt} - k_{j, t - 1}) + (\eta_{jt} - \eta_{j, t - 1}).
  \end{equation}
\item
  Then, because \(\eta_{jt} - \eta_{j, t - 1}\) is uncorrelated either with \(l_{jt} - l_{j, t - 1}\) or \(k_{jt} - k_{j, t - 1}\), we can identify the parameter.
\item
  Problem:

  \begin{itemize}
  \tightlist
  \item
    Restrictive heterogeneity.
  \item
    When there are measurement errors, fixed-effect estimator can generate higher biases than OLS estimator, because measurement errors more likely to survive first-difference and within-transformation.
  \end{itemize}
\end{itemize}

\subsection{First-Order Condition for Inputs}\label{first-order-condition-for-inputs}

\begin{itemize}
\tightlist
\item
  Use the first-order condition for inputs as the moment condition \citep{McElroy1987}.
\item
  Closely related to the cost function estimation literature.
\item
  Need to specify the factor market structure and the nature of the optimization problem for a firm.
\item
  Recently being center of attention again as one of the solutions to the ``collinearity problem'' discussed below.
\end{itemize}

\subsection{Instrumental Variable}\label{productioniv}

\begin{itemize}
\item
  Borrow the idea from the first-order condition approach that the input choices are affected by some exogenous variables.
\item
  If we have instrumental variables that affect inputs but are uncorrelated with errors \(\epsilon_{jt}\), then we can identify the parameter by an instrumental variable method.
\item
  One candidate for the instrumental variables: \textbf{input prices}.
\item
  Input price affect input decision.
\item
  Input price is not correlated with \(\epsilon_{jt}\) if the factor product market is competitive and \(\epsilon_{jt}\) is an idiosyncratic shock to a firm.
\item
  Problems:

  \begin{itemize}
  \tightlist
  \item
    Input prices often lack cross-sectional variation.
  \item
    Cross-sectional variation is often due to unobserved input quality.
  \end{itemize}
\item
  Another candidate for the instrumental variables: \textbf{lagged inputs}.
\item
  If \(\epsilon_{jt}\) does not have auto-correlation, lagged inputs are not correlated with the current shock.
\item
  If there are adjustment costs for inputs, then lagged inputs are correlated with the current inputs.
\item
  Problem:

  \begin{itemize}
  \tightlist
  \item
    If \(\epsilon_{jt}\) has auto-correlation, all lagged inputs are correlated with the errors: For example, if \(\epsilon_{jt}\) is AR(1), \(\epsilon_{jt} = \alpha \epsilon_{j, t - 1} + \nu_{j, t - 1} = \cdots \alpha^l \epsilon_{j, t - l} + \nu_{j, t - 1} + \cdots, \alpha^{l - 1} \nu_{j, t - l}\) for any \(l\).
  \end{itemize}
\end{itemize}

\subsection{Olley-Pakes Approach}\label{olley-pakes-approach}

\begin{itemize}
\tightlist
\item
  Exploit restrictions from the economic theory \citep{Olley1996}.
\item
  Write \(\epsilon_{jt} = \omega_{jt} + \eta_{jt}\), where \(\omega_{jt}\) is an anticipated shock and \(\eta_{jt}\) is an ex-post shock.
\item
  Inputs are correlated with \(\omega_{jt}\) but not with \(\eta_{jt}\)
\item
  The model is written as:
  \begin{equation}
  y_{jt} = \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + \omega_{jt} + \eta_{jt}.
  \end{equation}
\item
  OP use economic theory to derive a valid proxy for the anticipated shock \(\omega_{jt}\).
\end{itemize}

\subsection{Assumption I: Information Set}\label{assumption-i-information-set}

\begin{itemize}
\tightlist
\item
  The firm's information set at \(t\), \(I_{jt}\), includes current and past productivity shocks \(\{\omega_{j\tau}\}_{\tau = 0}^t\) but does not include future productivity shocks \(\{\omega_{j\tau}\}_{\tau = t + 1}^{\infty}\).
\item
  The transitory shocks \(\eta_{jt}\) satisfy \(\mathbb{E}\{\eta_{jt}|I_{jt}\} = 0\).
\end{itemize}

\subsection{Assumption II: First Order Markov}\label{assumption-ii-first-order-markov}

\begin{itemize}
\tightlist
\item
  Productivity shocks evolve according to the distribution:
  \begin{equation}
  p(\omega_{j, t + 1}|I_{jt}) = p(\omega_{j, t + 1}|\omega_{jt}), 
  \end{equation}
  and the distribution is known to firms and stochastically increasing in \(\omega_{jt}\).
\item
  Then:
  \begin{equation}
  \omega_{jt} = \mathbb{E}\{\omega_{jt}|\omega_{j, t - 1}\} + \nu_{jt},
  \end{equation}
  and:
  \begin{equation}
  \mathbb{E}\{\nu_{jt}|I_{j, t - 1}\} = 0,
  \end{equation}
  by construction.
\end{itemize}

\subsection{Assumption III: Timing of Input Choices}\label{assumption-iii-timing-of-input-choices}

\begin{itemize}
\tightlist
\item
  Firms accumulate capital according to:
  \begin{equation}
  k_{jt} = \kappa(k_{j, t - 1}, i_{j, t - 1}),
  \end{equation}
  where investment \(i_{j, t - 1}\) is chosen in period \(t - 1\).
\item
  Labor input \(l_{jt}\) is non-dynamic and chosen at \(t\).
\item
  This assumption characterizes and distinguishes labor and capital.
\item
  Intuitively, it takes a full period for new capital to be ordered, delivered, and installed.
\end{itemize}

\subsection{Assumption IV: Scalar Unobservable}\label{assumption-iv-scalar-unobservable}

\begin{itemize}
\tightlist
\item
  Firms' investment decisions are given by:
  \begin{equation}
  i_{jt} = f_t(k_{jt}, \omega_{jt}).
  \end{equation}
\item
  This assumption places strong implicit restrictions on additional firm-specific unobservables.

  \begin{itemize}
  \tightlist
  \item
    No \textbf{across firm} unobserved heterogeneity in adjustment cost of capital, in demand and labor market conditions, or in other parts of the production function.
  \item
    Okay with \textbf{across time} unobserved heterogeneity.
  \end{itemize}
\end{itemize}

\subsection{Assumption IV: Strict Monotonicity}\label{assumption-iv-strict-monotonicity}

\begin{itemize}
\tightlist
\item
  The investment policy function \(f_t(k_{jt}, \omega_{jt})\) is strictly increasing in \(\omega_{jt}\).
\item
  This holds if the realization of higher \(\omega_{jt}\) implies higher expectation for future productivity (Assumption III) and if the marginal product of capital is increasing in the expectation for future productivity.
\item
  To verify the latter condition in a given game is often not easy.
\end{itemize}

\subsection{Two-step Approach: The First Step}\label{two-step-approach-the-first-step}

\begin{itemize}
\tightlist
\item
  In the following, I suppress the index of \(t\) from unknown functions for notational simplicity.
\item
  Insert \(\omega_{jt} = h(k_{jt}, i_{jt})\) to the original equation to get:
  \begin{equation}
  \begin{split}
  y_{jt} &= \beta_l l_{jt} + \underbrace{\beta_0 + \beta_k k_{jt} + h(k_{jt}, i_{jt})}_{\text{unknown function of $k_{jt}$ and $i_{jt}$}} + \eta_{jt}\\
  & \equiv \beta_l l_{jt} + \phi(k_{jt}, i_{jt}) + \eta_{jt}.
  \end{split}
  \end{equation}
\item
  This is a \textbf{partially linear model}: see \citet{Ichimura2007} for reference.
\item
  Because \(l_{jt}, k_{jt}\) and \(i_{jt}\) are uncorrelated with \(\eta_{jt}\), we can identify \(\beta_l\) and \(\phi(\cdot)\) by exploiting the moment condition:
  \begin{equation}
  \begin{split}
  & \mathbb{E}\{\eta_{jt}|l_{jt}, k_{jt}, i_{jt}\} = 0\\
  & \Leftrightarrow \mathbb{E}\{y_{jt} - \beta_l l_{jt} - \phi(k_{jt}, i_{jt}) |l_{jt}, k_{jt}, i_{jt}\} = 0.
  \end{split}
  \end{equation}
  \textbf{if there is enough variation} in \(l_{jt}, k_{jt}\) and \(i_{jt}\).
\item
  This ``if there is enough variation'' part is actually problematic. Discuss later.
\item
  Let \(\beta_l^0\) and \(\phi^0\) be the identified true parameters.
\end{itemize}

\subsection{Two-step Approach: The Second Step}\label{two-step-approach-the-second-step}

\begin{itemize}
\tightlist
\item
  Note that:
  \begin{equation}
  \omega_{jt} \equiv \phi(k_{jt}, i_{jt}) - \beta_0 - \beta_k k_{jt}.
  \end{equation}
\item
  Therefore, we have:
  \begin{equation}
  \begin{split}
  &y_{jt} - \beta_l^0 l_{jt} \\
  &= \beta_0 + \beta_k k_{jt} + \omega_{jt} + \eta_{jt}\\
  &= \beta_0 + \beta_k k_{jt} + g(\omega_{j, t - 1}) + \nu_{jt} + \eta_{jt}\\
  &= \beta_0 + \beta_k k_{jt} + g[\phi^0(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})] + \nu_{jt} + \eta_{jt}.
  \end{split}
  \end{equation}
\item
  \(\nu_{jt}\) and \(\eta_{jt}\) are independent of the covariates.
\item
  This is a \textbf{multiple-index model} with indices \(\beta_0 + \beta_1 k_{jt}\) and \(\beta_0 + \beta_1 k_{j, t - 1}\) where parameters of two indices are restricted to be the same: see \citet{Ichimura2007} for reference.
\item
  We can identify \(\beta_0, \beta_k\) and \(g\) by exploiting the moment condition:
  \begin{equation}
  \begin{split}
  & \mathbb{E}\{\nu_{jt} + \eta_{jt}|k_{jt}, k_{j, t - 1}, i_{j, t - 1}\} = 0\\
  & \Leftrightarrow \mathbb{E}\{y_{jt} - \beta_l^0 l_{jt} -  \beta_0 - \beta_k k_{jt} - g[\phi^0(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})] |k_{jt}, k_{j, t - 1}, i_{j, t - 1}\} = 0.
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Identification of the Anticipated Shocks}\label{identification-of-the-anticipated-shocks}

\begin{itemize}
\tightlist
\item
  If \(\phi, \beta_0, \beta_k\) are identified, then \(\omega_{jt}\) is also identified by:
  \begin{equation}
  \omega_{jt} \equiv \phi(k_{jt}, i_{jt}) - \beta_0 - \beta_k k_{jt}.
  \end{equation}
\end{itemize}

\subsection{\texorpdfstring{Two-Step Estimation of \citet{Olley1996}.}{Two-Step Estimation of @Olley1996.}}\label{two-step-estimation-of-olley1996.}

\begin{itemize}
\tightlist
\item
  \textbf{First step}: Estimate \(\beta_L\) and \(\phi\) in :
  \begin{equation}
  \begin{split}
  y_{jt} = \beta_l l_{jt} + \phi(k_{jt}, i_{jt}) + \eta_{jt}.
  \end{split}
  \end{equation}
  by approximating \(\phi\) with some basis functions, say, polynomials or splines:
  \begin{equation}
  \begin{split}
  y_{jt} &= \beta_l l_{jt} +  \sum_{p = 1}^P \gamma_p \phi_p(k_{jt}, i_{jt}) +  \left[\phi(k_{jt}, i_{jt}) - \sum_{p = 1}^P \gamma_n \phi_n(k_{jt}, i_{jt})\right] + \eta_{jt}\\
  & = \beta_l l_{jt} +  \sum_{p = 1}^P \gamma_p \phi_p(k_{jt}, i_{jt}) + \tilde{\eta}_{jt}
  \end{split}
  \end{equation}
  where \(P \to \infty\) when the sample size goes to infinity.
\item
  e.g.~second-order polynomial approximation:
  \begin{equation}
  \begin{split}
  & \phi_1(k_{jt}, i_{jt}) = k_{jt}, \phi_2(k_{jt}, i_{jt}) = i_{jt}\\
  & \phi_3(k_{jt}, i_{jt}) = k_{jt}^2, \phi_4(k_{jt}, i_{jt}) = i_{jt}^2\\
  & \phi_5(k_{jt}, i_{jt}) = k_{jt} i_{jt}.
  \end{split}
  \end{equation}
\item
  Once the basis functions are fixed, estimation is the same as the linear model.
\item
  But the inference (the computation of the standard deviation) is difference, because of the approximation error.
\item
  See \citet{Chen2007} for reference.
\item
  Let \(\hat{\beta}_l\) and \(\hat{\phi}\) be the estimates from the first step.
\item
  \textbf{Second step}: Estimate \(\beta_0\), \(\beta_k\), and \(g\) in:
  \begin{equation}
  \begin{split}
  y_{jt} - \hat{\beta}_l l_{jt}& = \beta_0 + \beta_k k_{jt} + g[\hat{\phi}(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})] + \nu_{jt} + \eta_{jt}\\
  &+ [\beta_l - \hat{\beta}_l] l_{jt}\\
  &+ \left\{g[\phi(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})] - g[\hat{\phi}(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})]\right\}\\
  & = \beta_0 + \beta_k k_{jt} + g[\hat{\phi}(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})] + \nu_{jt} + \tilde{\eta}_{jt}
  \end{split}
  \end{equation}
  by approximating \(g\) by some basis functions, say, polynomials or splines.
\end{itemize}

\subsection{From An Economic Models to An Econometric Model}\label{from-an-economic-models-to-an-econometric-model}

\begin{itemize}
\tightlist
\item
  Starting from economic model with some unobserved heterogeneity, we reach some reduced-form model.
\item
  If the resulting model belongs to a class of econometric models whose identification and estimation are established, we can simply apply the existing methods.
\end{itemize}

\subsection{How to Resolve Selection Bias}\label{how-to-resolve-selection-bias}

\begin{itemize}
\tightlist
\item
  Use propensity score to correct selection bias: \citet{Ahn1993}.
\item
  At the beginning of period \(t\), after observing \(\omega_{jt}\), firm \(j\) decides whether to continue the business (\(\chi_{jt} = 1\)) or exit (\(\chi_{jt} = 0)\).
\item
  Assume that the difference between continuation and exit values is strictly increasing in \(\omega_{jt}\).
\item
  Then, there is a threshold \(\underline{\omega}(k_{jt})\) such that:
  \begin{equation}
  \chi_{jt} = 
  \begin{cases}
  1 &\text{   if   } \omega_{jt} \ge \underline{\omega}(k_{jt})\\
  0 &\text{   otherwise.}
  \end{cases}
  \end{equation}
\item
  We can only observe firms that satisfy \(\chi_{jt} = 1\).
\end{itemize}

\subsection{Correction in the First Step}\label{correction-in-the-first-step}

\begin{itemize}
\tightlist
\item
  In the first step, we need no correction because:
  \begin{equation}
  \begin{split}
  &\mathbb{E}\{y_{jt}|l_{jt}, k_{jt}, i_{jt}, \chi_{jt} = 1 \}\\
  &=\beta_l l_{jt} + \phi(k_{jt}, i_{jt}) + \mathbb{E}\{\eta_{jt}|\chi_{jt} = 1\}\\
  &= \beta_l l_{jt} + \phi(k_{jt}, i_{jt}).
  \end{split}
  \end{equation}
\item
  Ex-post shock \(\eta_{jt}\) is independent of continuation/exit decision.
  Therefore, we can identify \(\beta_l\) and \(\phi(\cdot)\) as in the previous case.
\end{itemize}

\subsection{Correction in the Second Step I: The Source of Bias}\label{correction-in-the-second-step-i-the-source-of-bias}

\begin{itemize}
\tightlist
\item
  One the other hand, we need correction in the second step, because:
  \begin{equation}
  \begin{split}
  &\mathbb{E}\{y_{jt} - \beta_l^0 l_{jt}|k_{jt},  k_{j, t - 1}, i_{j, t - 1}, \chi_{jt} = 1\} \\
  &= \beta_0 + \beta_k k_{jt} + g[\phi^0(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})]\\
  & + \mathbb{E}\{\nu_{jt} + \eta_{jt}| k_{jt}, i_{jt}, k_{j, t - 1}, l_{j, t - 1}, \chi_{jt} = 1\}\\
  &= \beta_0 + \beta_k k_{jt} + g[\phi^0(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})]\\
  & + \mathbb{E}\{\nu_{jt}| k_{jt}, k_{j, t - 1}, i_{j, t - 1} , \chi_{jt} = 1\}.
  \end{split}
  \end{equation}
  and
  \begin{equation}
  \mathbb{E}\{\nu_{jt}| k_{jt}, k_{j, t - 1}, i_{j, t - 1}, \chi_{jt} = 1 \} \neq 0,
  \end{equation}
  since anticipated shock matters continuation/exit decision in period \(t\).
\end{itemize}

\subsection{Correction in the Second Step II: Conditional Exit Probability}\label{correction-in-the-second-step-ii-conditional-exit-probability}

\begin{itemize}
\tightlist
\item
  Let's see that the conditional expectation:
  \begin{equation}
  \begin{split}
  &\mathbb{E}\{\omega_{jt}| k_{jt},  k_{j, t - 1}, i_{j, t - 1}, \chi_{jt} = 1 \}\\
  &=\mathbb{E}\{\omega_{jt}| k_{jt}, k_{j, t - 1}, i_{j, t - 1}, \omega_{jt} \ge \underline{\omega}(k_{jt}) \}\\
  &=\int_{\underline{\omega}(k_{jt})} \omega_{jt} \frac{p(\omega_{jt}|\omega_{j, t - 1})}{\int_{\underline{\omega}(k_{jt})} p(\omega|\omega_{j, t - 1}) d\omega } d \omega_{jt}\\
  &\equiv \tilde{g}(\omega_{j, t - 1}, \underline{\omega}(k_{jt})),
  \end{split}
  \end{equation}
  is a function of \(\omega_{j, t - 1}\) and \(\underline{\omega}(k_{jt})\).
\end{itemize}

\subsection{Correction in the Second Step III: Invertibility in Threshold}\label{correction-in-the-second-step-iii-invertibility-in-threshold}

\begin{itemize}
\tightlist
\item
  The propensity of continuation conditional on observed information up to period \(t - 1\):
  \begin{equation}
  \begin{split}
  P_{jt} &\equiv \mathbb{P}\{\chi_{jt} = 1|\mathcal{I}_{j, t - 1}\}\\
  &= \mathbb{P}\{\omega_{jt} \ge \underline{\omega}(k_{jt}) |\mathcal{I}_{j, t - 1}\}\\
  &= \mathbb{P}\{g(\omega_{j, t - 1}) + \nu_{jt} \ge \underline{\omega}[\kappa(k_{j, t - 1}, i_{j, t - 1})]|\mathcal{I}_{j, t - 1} \}\\
  &= \mathbb{P}\{ \chi_{jt} = 1| i_{j, t - 1}, k_{j, t - 1}\}.
  \end{split}
  \end{equation}
\item
  \(\rightarrow\) It suffices to condition on \(i_{j, t - 1}, k_{j, t - 1}\).
\item
  We also have:
  \begin{equation}
  P_{jt} = \mathbb{P}\{\chi_{jt} = 1| \omega_{j, t - 1}, \underline{\omega}(k_{jt})\},
  \end{equation}
  and it is invertible in \(\underline{\omega}(k_{jt})\), that is,
  \begin{equation}
  \underline{\omega}(k_{jt}) \equiv \psi(P_{jt}, \omega_{j, t - 1}).
  \end{equation}
\end{itemize}

\subsection{Correction in the Second Step IV: Controlling the Threshold}\label{correction-in-the-second-step-iv-controlling-the-threshold}

\begin{itemize}
\tightlist
\item
  Now, he have:
  \begin{equation}
  \begin{split}
  &\mathbb{E}\{y_{jt} - \beta_l^0 l_{jt}|k_{jt}, k_{j, t - 1}, i_{j, t - 1}, \chi_{jt} = 1\} \\
  &= \beta_0 + \beta_k k_{jt} + \mathbb{E}\{\omega_{jt}| k_{jt}, k_{j, t - 1}, i_{j, t - 1} , \chi_{jt} = 1\}\\
  &= \beta_0 + \beta_k k_{jt} + \tilde{g}(\omega_{j, t - 1}, \underline{\omega}(k_{jt}))\\
  &= \beta_0 + \beta_k k_{jt} + \tilde{g}(\omega_{j, t - 1}, \psi(P_{jt}, \omega_{j, t - 1}))\\
  &\equiv \beta_0 + \beta_k k_{jt} + \tilde{\tilde{g}}(\omega_{j, t - 1}, P_{jt})\\
  &= \beta_0 + \beta_k k_{jt} + \tilde{\tilde{g}}[\phi^0(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1}), P_{jt}].
  \end{split}
  \end{equation}
\item
  At the end, the only difference is to include \(P_{jt}\) as a covariate.
\item
  \(P_{jt}\) is a \textbf{known} function of \(i_{j, t - 1}\) and \(k_{j, t - 1}\).
\item
  Even if we condition on \(P_{jt} = p\), there are still many combinations of \(i_{j, t - 1}\) and \(k_{j, t - 1}\) that gives \(P_{jt} = p\).
\item
  With this remaining variation, we can identify \(\beta_0\), \(\beta_k\), and \(\tilde{\tilde{g}}\) by the same argument as the case without selection, for each \(P_{jt} = p\).
\end{itemize}

\subsection{\texorpdfstring{Three Step Estimation of \citet{Olley1996}}{Three Step Estimation of @Olley1996}}\label{three-step-estimation-of-olley1996}

\begin{itemize}
\tightlist
\item
  \textbf{Zero step}: Estimate the propensity score:
  \begin{equation}
  P_{jt} = 1\{\chi_{jt} = 1| i_{j, t - 1}, k_{j, t - 1}\},
  \end{equation}
  by a kernel estimator.
\item
  Insert the resulting estimates \(\widehat{P}_{jt}\) into the first and second steps.
\end{itemize}

\subsection{Zero Investment Problem}\label{zero-investment-problem}

\begin{itemize}
\tightlist
\item
  One of the key assumptions in OP method was invertibility between anticipated shock and investment:
  \begin{equation}
  \omega_{jt} = i^{-1}(k_{jt}, i_{jt}) \equiv h(k_{jt}, i_{jt}).
  \end{equation}
\item
  However, in micro data, zero investment is a rule rather than exceptions.
\item
  Then, the invertibility does not hold globally: there are some region of the anticipated shock in which the investment takes value zero.
\end{itemize}

\subsection{Tackle Zero Investment Problem I: Discard Some Data}\label{tackle-zero-investment-problem-i-discard-some-data}

\begin{itemize}
\tightlist
\item
  Discard a data \((j, t)\) such that \(i_{j, t - 1} = 0\).
\item
  Use a data \((j, t)\) such that \(i_{j, t - 1} > 0\).
\item
  Then, invertibility recovers on this selected sample.
\item
  This does not cause bias in the estimator because \(\nu_{jt}\) in :
  \begin{equation}
  \beta_0 + \beta_l k_{jt} + g[\phi^0(k_{j, t - 1}, i_{j, t - 1}) - (\beta_0 + \beta_k k_{j, t - 1})] + \nu_{jt} + \eta_{jt},
  \end{equation}
  is independent of the event up to \(t - 1\), including \(i_{j, t - 1}\).
\item
  However, this causes information loss. The loss is high if the proportion of the sample such that \(i_{j, t - 1} = 0\) is high.
\end{itemize}

\subsection{Tackle Zero Investment Problem II: Use Another Proxy}\label{tackle-zero-investment-problem-ii-use-another-proxy}

\begin{itemize}
\item
  Investment is just a possible proxy for the anticipated shock.
\item
  Intermediate inputs can be used as proxies as well \citep{Levinsohn2003}.
\item
  The problem is that these intermediate inputs are included in the gross production function, whereas investment is excluded.
\item
  Let \(m_{jt}\) be the log material input, and assume that the production function takes the form of:
  \begin{equation}
  y_{jt} = \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + \beta_m m_{jt} + \omega_{jt} + \eta_{jt}.
  \end{equation}
\item
  In addition, assume that the \textbf{optimal policy function} for \(m_{jt}\) is strictly monotonic in the ex-ante shock, and hence is invertible:
  \begin{equation}
  m_{jt} = m(k_{jt}, \omega_{jt}) \Leftrightarrow \omega_{jt} = m^{-1}(m_{jt}, k_{jt}) \equiv h(m_{jt}, k_{jt}). \label{eq:material}
  \end{equation}
\item
  \textbf{First step}:
  \begin{equation}
  \begin{split}
  y_{jt} &= \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + \beta_m m_{jt} + h(m_{jt}, k_{jt}) + \eta_{jt}\\
  &= \beta_l l_{jt} + \phi(m_{jt}, k_{jt}) + \eta_{jt}.
  \end{split}
  \end{equation}
\item
  We can identify \(\beta_l\) and \(\phi\) by exploiting the moment condition (you can include \(i_{jt}\) if it is available):
  \begin{equation}
  \begin{split}
  & \mathbb{E}\{\eta_{jt}|l_{jt}, m_{jt}, k_{jt}, i_{jt}\} = 0\\
  & \Leftrightarrow \mathbb{E}\{y_{jt}  - \beta_l l_{jt} - \phi(m_{jt}, k_{jt}) |l_{jt}, m_{jt}, k_{jt}, i_{jt}\} = 0,
  \end{split}
  \end{equation}
  if \textbf{there is enough variation} in \(l_{jt}, m_{jt}, k_{jt}\).
\item
  \textbf{Second step}:
  \begin{equation}
  \begin{split}
  &y_{jt} - \beta_l^0 l_{jt}\\
  & = \beta_0 + \beta_k k_{jt} + \beta_m m_{jt} + g[\phi^0(m_{j, t - 1}, k_{j, t - 1}) - \beta_0 - \beta_k k_{j, t - 1} - \beta_m m_{j, t - 1}]\\
  & + \nu_{jt} + \eta_{jt}.
  \end{split}
  \end{equation}
\item
  We can identify \(\beta_k\), \(\beta_m\), and \(g\) by exploiting the moment condition:
  \begin{equation}
  \begin{split}
  \mathbb{E}\{\nu_{jt} + \eta_{jt} | k_{jt}, m_{j, t - 1}, k_{j,t - 1}\} = 0.
  \end{split}
  \end{equation}
\item
  Because \(m_{jt}\) is correlated with \(\nu_{jt}\), the moment should not condition on \(m_{jt}\).
\item
  The identification of \(\beta_{m}\) comes from \(\beta_m m_{j, t - 1}\).
\end{itemize}

\subsection{\texorpdfstring{One-step Estimation of \citet{Olley1996} and \citet{Levinsohn2003}}{One-step Estimation of @Olley1996 and @Levinsohn2003}}\label{one-step-estimation-of-olley1996-and-levinsohn2003}

\begin{itemize}
\item
  \citet{Levinsohn2003} can be estimated in the similar two-step method.
\item
  We can jointly estimate the parameters in first and second steps to improve the efficiency \citep{Wooldridge2009}.
\item
  We estimate under the assumptions of \citet{Olley1996}:
  \begin{equation}
  y_{jt} = \beta_0 + \beta_1 l_{jt} + \beta_k k_{jt} + \omega_{jt} + \eta_{jt}.
  \end{equation}
\item
  The first step exploits the following moment:
  \begin{equation}
  \mathbb{E}\{\eta_{jt}|l_{jt}, k_{jt}, i_{jt}\} = 0,
  \end{equation}
  that is:
  \begin{equation}
  \mathbb{E}\{y_{jt} - \beta_1 l_{jt} - \beta_0 - \beta_k k_{jt} - \omega(k_{jt}, i_{jt})|l_{jt}, k_{jt}, i_{jt}\} = 0. \label{eq:opfirst}
  \end{equation}
\item
  We can reinforce the moment condition as:
  \begin{equation}
  \mathbb{E}\{\eta_{jt}|l_{jt}, k_{jt}, i_{jt}, \cdots, l_{j1}, k_{j1}, i_{j1}\} = 0
  \end{equation}
  if we assume that lagged inputs are correlated with the current inputs and \(\eta_{jt}\) is independent.
\item
  The second step exploits the following moment:
  \begin{equation}
  \mathbb{E}\{\nu_{jt}|k_{jt}, i_{j, t - 1}, l_{j, t - 1}\} = 0,
  \end{equation}
  that is:
  \begin{equation}
  \mathbb{E}\{y_{jt} - \beta_0 - \beta_1 l_{jt} - \beta_k k_{jt} - g[\omega(k_{j,t - 1}, i_{j, t - 1})]|k_{jt}, i_{j, t - 1}, l_{j, t - 1}\} = 0. \label{eq:opsecond}
  \end{equation}
\item
  We can reinforce the moment condition as:
  \begin{equation}
  \mathbb{E}\{\nu_{jt}|k_{jt}, i_{j, t - 1}, l_{j, t - 1}, \cdots, k_{j1}, i_{j1}, l_{j1}\} = 0,
  \end{equation}
  if we assume that lagged input are correlated with the current inputs and \(\nu_{jt} + \eta_{jt}\) are independent.
\item
  We can construct a GMM estimator based on equations \eqref{eq:opfirst} and \eqref{eq:opsecond}.
\item
  The one-step estimator can be more efficient but can be computationally heavier than the two-step estimator.
\end{itemize}

\subsection{Scalar Unobservable Problem: Finite-order Markov Process}\label{scalar-unobservable-problem-finite-order-markov-process}

\begin{itemize}
\item
  Borrow the idea of using the first-order condition to resolve the collinearity problem \citep{Gandhi2017a}.
\item
  We have assumed that anticipated shocks follow a first-order Markov process:
  \begin{equation}
  \omega_{jt} = g(\omega_{j, t - 1}) + \nu_{jt}.
  \end{equation}
\item
  However, it may be true that it has more than one lags, for example:
  \begin{equation}
  \omega_{jt} = g(\omega_{j, t - 1}, \omega_{j, t - 2}) + \nu_{jt}.
  \end{equation}
\item
  Then, we need proxies as many as the number of unobservables:
  \begin{equation}
  \begin{pmatrix}
  i_{jt} \\ m_{jt} 
  \end{pmatrix}
  = \Gamma(k_{jt}, \omega_{jt}, \omega_{j, t - 1}),
  \end{equation}
  such that the policy function for the proxies is a bijection in \((\omega_{jt}, \omega_{j, t - 1})\).
\item
  Then, we can have:
  \begin{equation}
  \omega_{jt} = \Gamma_1^{-1}(k_{jt}, i_{jt}, m_{jt}).
  \end{equation}
\item
  The reminder goes as in the standard OP method.
\end{itemize}

\subsection{Scalar Unobservable Problem: Demand and Productivity Shocks}\label{scalar-unobservable-problem-demand-and-productivity-shocks}

\begin{itemize}
\tightlist
\item
  There may be a demand shock \(\mu_{jt}\) that also follows first-order Markov process.
\item
  Then, the policy function depend both on \(\mu_{jt}\) and \(\omega_{jt}\).
\item
  We again need proxies as many as the number of unobservable.
\item
  Suppose that we can observe the price of the firm \(p_{jt}\).
\item
  Inverting the policy function:
  \begin{equation}
  \begin{pmatrix}
  i_{jt}\\ p_{jt}
  \end{pmatrix}
  = \Gamma(k_{jt}, \omega_{jt}, \mu_{jt}).
  \end{equation}
  yields:
  \begin{equation}
  \omega_{jt} = \Gamma_1^{- 1}(k_{jt}, i_{jt}, p_{jt}).
  \end{equation}
\item
  If \(\omega_{jt}\) only depends on \(\omega_{j, t - 1}\) but not on \(\mu_{j, t - 1}\), then the second step of the modified OP method is to estimate:
  \begin{equation}
  \begin{split}
  y_{jt} - \hat{\beta}_l l_{jt} 
  &= \beta_0 + \beta_k k_{jt}\\
  & + g(\omega_{j, t - 1}) + \nu_{jt} + \eta_{jt}\\
  &= \beta_0 + \beta_k k_{jt}\\
  & + g(\hat{\phi}_{j, t - 1} - \beta_0 - \beta_k k_{j, t - 1}) + \nu_{jt} + \eta_{jt}.
  \end{split}
  \end{equation}
\item
  It goes as in the standard OP method.
\item
  If \(\omega_{jt}\) depends both on \(\omega_{j, t - 1}\) and \(\mu_{j, t - 1}\), the second step regression equation will be:
  \begin{equation}
  \begin{split}
  y_{jt} - \hat{\beta}_l l_{jt} 
  &= \beta_0 + \beta_k k_{jt}\\
  & + g(\omega_{j, t - 1}, \mu_{j, t - 1}) + \nu_{jt} + \eta_{jt}\\
  &= \beta_0 + \beta_k k_{jt}\\
  & + g(\hat{\phi}_{j, t - 1} - \beta_0 - \beta_k k_{j, t - 1}, \mu_{j, t - 1}) + \nu_{jt} + \eta_{jt}.
  \end{split}
  \end{equation}
\item
  We still have to control \(\mu_{j, t - 1}\) in the second step.
\item
  Invert the policy function for \(\mu_{j, t - 1}\) to get:
  \begin{equation}
  \mu_{j, t - 1} = \Gamma_2^{- 1}(k_{j, t - 1}, i_{j, t - 1}, p_{j, t - 1}),
  \end{equation}
  and plug it into the second step regression equation to get:
  \begin{equation}
  \begin{split}
  &y_{jt} - \hat{\beta}_l l_{jt}\\
  &= \beta_0 + \beta_k k_{jt}\\
  &+g(\hat{\phi}_{j, t - 1} - \beta_0 - \beta_k k_{j, t - 1}, \Gamma_2^{- 1}(k_{j, t - 1}, i_{j, t - 1}, p_{j, t - 1})) + \nu_{jt} + \eta_{jt}.
  \end{split}
  \end{equation}
\item
  The parameters \(\beta_0\) and \(\beta_k\) \textbf{cannot} be identified only with this observation, because \(\Gamma_2^{-1}\) is \textbf{unknown non-parametric} function: it can mean any function of \((k_{j, t - 1}, i_{j, t - 1}, p_{j, t - 1})\).
\item
  To estimate such a model, we jointly estimate the demand function along with the production function.
\item
  At this point, we do not investigate it further because we have not yet learned how to estimate the demand function.
\item
  For now just keep in mind that:

  \begin{itemize}
  \tightlist
  \item
    There has to be as many proxies as the dimension of the unobservable state variables.
  \item
    It is okay that the unobservable state variable includes a demand shock.
  \item
    It can be problematic when the unobservable demand shock affect the evolution of the anticipated productivity shock.
  \end{itemize}
\end{itemize}

\subsection{Collinearity Problem}\label{collinearity-problem}

\begin{itemize}
\tightlist
\item
  The collinearity problem is formally pointed out by \citet{Ackerberg2015}.
\item
  This paper is finally published in 2015, but has been circulated since 2005.
\item
  We assumed that \(k_{jt}\) and \(\omega_{jt}\) are state variables.
\item
  Then the policy function for labor input should take the form of:
  \begin{equation}
  l_{jt} = l(k_{jt}, \omega_{jt}).
  \end{equation}
\item
  However, because \(\omega_{jt} = h(i_{jt}, k_{jt})\), we have:
  \begin{equation}
  l_{jt} = l[k_{jt}, h(i_{jt}, k_{jt})] = \tilde{l}(i_{jt}, k_{jt}).
  \end{equation}
\item
  Therefore, in the first stage, we encounter a multicollinearity problem:
  \begin{equation}
  \begin{split}
  y_{jt} &= \beta_0 + \beta_l \tilde{l}(i_{jt}, k_{jt}) + \phi(i_{jt}, k_{jt}) + \eta_{jt}\\
  &\equiv \tilde{\phi}(i_{jt}, k_{jt}).
  \end{split}
  \end{equation}
\item
  Thus, \(\beta_l\) cannot be identified in the first step.
\item
  The second step becomes:
  \begin{equation}
  y_{jt} = \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + g[\tilde{\phi}(i_{j, t - 1}, k_{j, t - 1}) - \beta_0 - \beta_l l_{j, t - 1} - \beta_k k_{jt}] + \nu_{jt} + \eta_{jt}
  \end{equation}
\item
  Because \(l_{jt}\) is correlated with \(\nu_{jt}\), moment can only condition on \(l_{j, t - 1}\).
\item
  However, conditioning on \(k_{j, t - 1}\) and \(i_{j, t - 1}\), again there is no remaining variation in \(l_{j, t - 1}\).
\item
  Therefore, \(\beta_l\) cannot be identified either in the second step.
\item
  \textbf{\(\beta_l\) cannot be identified!}
\end{itemize}

\subsection{Tackle Collinearity Problem: Peculiar Assumptions}\label{tackle-collinearity-problem-peculiar-assumptions}

\begin{itemize}
\tightlist
\item
  To make Olley-Pakes/Levinsohn-Petrin approach workable, we need peculiar data generating process for \(l_{jt}\).
\item
  Consider Levinsohn-Petrin framework.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  There is an optimization error in \(l_{jt}\).

  \begin{itemize}
  \tightlist
  \item
    If it is not i.i.d over time, it becomes a state variable and enters to the policy for \(m_{jt}\), violating the scalar unobserved heterogeneity assumption of \(m_{jt}\).
  \item
    If there is an optimization error for \(m_{jt}\), this again violates the scalar unobserved heterogeneity assumption.
  \end{itemize}
\item
  \(k_{jt}\) is realized, \(\omega_{jt}\) is observed, \(m_{jt}\) and \(i_{jt}\) are determined, a new i.i.d. unexpected shock is observed, \(l_{jt}\) is determined, and \(\eta_{jt}\) is observed.

  \begin{itemize}
  \tightlist
  \item
    If it is not i.i.d over time, it becomes a state variable and enters to the policy for \(m_{jt}\), violating the scalar unobserved heterogeneity assumption.
  \end{itemize}
\item
  \(k_{jt}\) is realized, an unexpected shock is observed, \(l_{jt}\) is determined, \(\omega_{jt}\) is observed, \(m_{jt}\) and \(i_{jt}\) are determined, and \(\eta_{jt}\) is observed (\citet{Ackerberg2016} recommends this assumption).

  \begin{itemize}
  \tightlist
  \item
    In this case, the unexpected shock can be serially correlated, because it suffices to know \(k_{jt}\), \(i_{jt}\), \(l_{jt}\) to decide \(m_{jt}\). It does not have to predict the future unexpected shock based on the realization of the current shock because \(m_{jt}\) is a static decision.
  \item
    This changes the optimal policy function of \(m_{jt}\) \eqref{eq:material} to:
    \begin{equation}
     m_{jt} = m(k_{jt}, \omega_{jt}, l_{jt}).
     \end{equation}
  \item
    The first step:
    \begin{equation}
     \begin{split}
     y_{jt} &= \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + h(k_{jt}, m_{jt}, l_{jt}) + \eta_{jt}\\
     &= \psi(k_{jt}, m_{jt}, l_{jt}) + \eta_{jt}.\\
     \Rightarrow & \mathbb{E}\{y_{jt} - \psi(k_{jt}, m_{jt}, l_{jt})|k_{jt}, m_{jt}, l_{jt}\} = 0.
     \end{split}
     \end{equation}
  \item
    The second step:
    \begin{equation}
     \begin{split}
     y_{jt} &= \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + g[\psi(k_{j, t - 1}, m_{j, t - 1}, l_{j, t - 1}) - \beta_0 - \beta_l l_{j, t - 1} - \beta_k k_{j, t - 1}] + \nu_{jt} + \eta_{jt}\\
     \Rightarrow & \mathbb{E}\{y_{jt} - \beta_0 - \beta_l l_{jt} - \beta_k k_{jt} - g[\psi(k_{j, t - 1}, m_{j, t - 1}, l_{j, t - 1}) - \beta_0 - \beta_l l_{j, t - 1} - \beta_k k_{j, t - 1}]|k_{j, t - 1}, i_{j, t - 1}, l_{j, t - 1}, m_{j, t - 1}\}
     \end{split}
     \end{equation}
  \item
    \(m_{jt}\) has to be excluded from the production function, i.e., it has to be a value-added production function. Otherwise, \(\beta_m m_{jt}\) and \(\beta_m m_{j, t - 1}\) appear in the second step. Because \(m_{jt}\) is correlated with \(\nu_{jt}\), the only hope is to vary \(m_{j, t - 1}\). But there is no additional variation in \(m_{j, t - 1}\) conditional on \(k_{j, t - 1}\), \(i_{j, t - 1}\), and \(l_{j, t - 1}\).
  \end{itemize}
\end{enumerate}

\subsection{Tackle Collinearity Problem: Share Regression}\label{tackle-collinearity-problem-share-regression}

\begin{itemize}
\item
  How to avoid the peculiar assumptions on shocks and timing of decisions?
\item
  How to identify gross production function avoiding the third assumption by \citet{Ackerberg2015}?
\item
  Return to the old literature using the first-order condition.
\item
  Let \(w_t\) be wage and \(p_t\) be the product price.
\item
  Assume that the factor market is competitive.
\item
  Then, the first-order condition for profit maximization with respect to \(L_{jt}\) is:
  \begin{equation}
  \begin{split}
  &P_t F_L(L_{jt}, K_{jt})e^{\omega_{jt}} \mathbb{E} e^{\eta_{jt}} = w_t\\
  &\Leftrightarrow \frac{P_t F_L(L_{jt}, K_{jt})e^{\omega_{jt}} \mathbb{E} e^{\eta_{jt}}}{F(L_{jt}, K_{jt}) } = \frac{w_t}{F(L_{jt}, K_{jt}) }\\
  &\Leftrightarrow \frac{F_L(L_{jt}, K_{jt}) L_{jt}\mathbb{E} e^{\eta_{jt}}}{F(L_{jt}, K_{jt})  e^{\eta_{jt}}} = \frac{w_t L_{jt}}{P_t \underbrace{F(L_{jt}, K_{jt}) e^{\omega_{jt}} e^{\eta_{jt}}}_{Y_{jt}} },
  \end{split}
  \end{equation}
  where the right hand side is expenditure share to the labor, which is observed.
\item
  Furthermore, on the left hand side, we only have \(\eta_{jt}\), which is independent of inputs.
\item
  Let \(s_{jt}\) be the log of expenditure share to the labor, and take a log of the previous equation gives:
  \begin{equation}
  \begin{split}
  s_{jt} &= \log [F_L(L_{jt}, K_{jt}) L_{jt} \mathbb{E} e^{\eta_{jt}} / F(L_{jt}, K_{jt})] - \eta_{jt}\\
  & = \log(\beta_l) + \ln \mathbb{E} e^{\eta_{jt}} - \eta_{jt}.
  \end{split}
  \end{equation}
\item
  Remember that the coefficient in the Cobb-Douglas function is equal to the expenditure share.
\item
  In general, share regression provides additional variation to identify the elasticity of anticipated production with respect to the labor.
  Then we can follow the standard OP method to recover other parameters.
\end{itemize}

\section{Cost Function Estimation}\label{cost-function-estimation}

\subsection{Cost Function: Duality}\label{cost-function-duality}

\begin{itemize}
\item
  Given a function \(y = F(x)\) such that:

  \begin{itemize}
  \tightlist
  \item
    Add factor market structure.
  \item
    Add cost minimization.
  \end{itemize}
\item
  \(\rightarrow\) There exists a unique \textbf{cost function} \(c = C(y, p)\):

  \begin{itemize}
  \tightlist
  \item
    \textbf{Positivity}: positive for positive input prices and a positive.
  \item
    \textbf{Homogeneity}: homogeneous of degree one in the input prices.
  \item
    \textbf{Monotonicity}: increasing in the input prices and in the level of output.
  \item
    \textbf{Concavity}: concave in the input prices.
  \end{itemize}
\item
  Given a function \(c = C(y, p)\) such that:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Positivity}: positive for positive input prices and a positive.
  \item
    \textbf{Homogeneity}: homogeneous of degree one in the input prices.
  \item
    \textbf{Monotonicity}: increasing in the input prices and in the level of output.
  \item
    \textbf{Concavity}: concave in the input prices.
  \end{itemize}
\item
  \(\rightarrow\) There exists a unique production function \(F(x)\) that yields \(C(y, p)\) as a solution to the cost minimization problem:
  \begin{equation}
  C(y, p) = \min_{x} p'x \text{   s.t.   } F(x) \ge y.
  \end{equation}
\item
  If the latter condition holds, the function \(C\) is said to be \textbf{integrable}.
\item
  It is rare that you can find a closed-form cost function of a production function.
\item
  It makes sense to start from cost function.
\item
  The duality ensures that there is a one-to-one mapping between a class of cost function and a class of production function.
\item
  If you accept competitive factor markets and cost minimization, identifying a cost function is equivalent to identifying a production function.
\item
  We used this idea in the last slides to identify the parameters regarding static decision variables.
\item
  See \citet{Jorgenson1986} for the literature in this topic up to the mid 80s.
\end{itemize}

\subsection{Translog Cost Function}\label{translog-cost-function}

\begin{itemize}
\tightlist
\item
  One of the popular specifications:
  \begin{equation}
  \begin{split}
  \ln c &= \alpha_0 + \alpha_p' \ln p + \alpha_y \ln y + \frac{1}{2} \ln p' B_{pp} \ln p\\
  & + \ln p' \beta_{py} \ln y + \frac{1}{2}\beta_{yy}(\ln y)^2.
  \end{split}
  \end{equation}
\item
  It assumes that the first and second order elasticities are constant.
\item
  A second-order (log) Taylor approximation of a general cost function.
\end{itemize}

\subsection{Translog Cost Function: Integrability}\label{translog-cost-function-integrability}

\begin{itemize}
\tightlist
\item
  Translog cost function is known to be integrable if the following conditions hold:
\item
  \textbf{Homogeneity}: the cost shares and the cost flexibility are homogeneity of degree zero: \(B_{pp}1 = 0\), \(\beta_{py}'1 = 0\).
\item
  \textbf{Cost exhaustion}: the sum of cost shares is equal to unity: \(\alpha_p'1 = 1\), \(B_{pp}'1 = 0\), \(\beta_{py}'1 = 0\).
\item
  \textbf{Symmetry}: the matrix of share elasticities, biases of scale, and the cost flexibility elasticity is symmetric:
  \begin{equation}
  \begin{pmatrix}
  B_{pp} & \beta_{py}\\
  \beta_{py}' & \beta_{yy}
  \end{pmatrix}
  =
  \begin{pmatrix}
  B_{pp} & \beta_{py}\\
  \beta_{py}' & \beta_{yy}
  \end{pmatrix}'.
  \end{equation}
\item
  \textbf{Monotonicity}: The matrix of share elasticities \(B_{pp} + vv' - diag(v)\) is positive semi-definite.
\end{itemize}

\subsection{Two Approaches}\label{two-approaches}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cost data approach.

  \begin{itemize}
  \tightlist
  \item
    Use accounting cost data.
  \item
    It does not depend on behavioral assumption.
  \item
    One can impose restrictions of assuming cost minimization.
  \item
    The accounting cost data may not represent economic cost.
  \end{itemize}
\item
  Revealed preference approach.

  \begin{itemize}
  \tightlist
  \item
    Assume decision problem for firms.
  \item
    Assume profit maximization.
  \item
    Reveal the costs from firm's equilibrium strategy.
  \item
    It depends on structural assumptions.
  \item
    It reveals the cost as perceived by firms.
  \end{itemize}
\end{enumerate}

\subsection{Cost Data Approach}\label{cost-data-approach}

\begin{itemize}
\tightlist
\item
  Estimating a cost function using cost data from accounting data.
\item
  \citet{McElroy1987} is one of the most flexible and robust frameworks.
\item
  The approach is somewhat getting less popular in IO researchers.
\item
  Recently, the approach is not popular among IO researchers.
\item
  I \textit{conjecture} one of the reasons for this is that IO researchers believe cost data taken from accounting information does not capture all the costs firms face.
\item
  However, it is good to know the classical literature because it sometimes gives a new insight.
\item
  cf. \citet{Byrne2015} : Propose a novel method to combine accounting cost data to estimate demand and cost function jointly without using instrumental variable approach.
\end{itemize}

\subsection{Revealed Preference Approach}\label{revealed-preference-approach}

\begin{itemize}
\tightlist
\item
  Another approach is to \textbf{reveal} the marginal cost from firm's price/quantity setting behavior assuming it is maximizing profit.

  \begin{itemize}
  \tightlist
  \item
    Originates at \citet{rosseEstimatingCostFunction1970}.
  \item
    A parameter affects economic agent's action.
  \item
    Therefore, economic agent's action \textbf{reveals} the information about the parameter.
  \item
    See \citet{Bresnahan1981} and \citet{Bresnahan1989} for reference.
  \end{itemize}
\item
  We have shown that the assumption on the factor market and cost function minimization gives restriction on the cost parameters.
\item
  We may further assume the product market structure and profit maximization to identify cost parameters.
\item
  Example: In a competitive market, the equilibrium price is equal to the marginal cost. Therefore, the marginal cost is identified from prices.
\item
  What if the competition is imperfect?
\end{itemize}

\subsection{Single-product Monopolist}\label{single-product-monopolist}

\begin{itemize}
\item
  This approach requires researcher to specify the decision problem of a firm.
\item
  Assume that the firm is a single-product monopolist.
\item
  Let \(D(p)\) be the demand function.
\item
  Let \(C(q)\) be the cost function.
\item
  Temporarily, assume that we \textbf{know} the demand function.
\item
  We learn how to estimate demand functions in coming weeks.
\item
  The only unknown parameter is the cost function.
\item
  The monopolist solves:
  \begin{equation}
  \max_{p} D(p)p - C(D(p)).
  \end{equation}
\item
  The first-order condition w.r.t. \(p\) for profit maximization is:
  \begin{equation}
  \begin{split}
  &D(p) + pD'(p) - C'(D(p)) D'(p) = 0.\\
  &\Leftrightarrow C'(D(p)) = \underbrace{\frac{D(p) + pD'(p)}{D'(p)}}_{\text{$p$ is observed and $D(p)$ is known.}}
  \end{split}
  \end{equation}
\item
  This identifies the marginal cost \textit{at the equilibrium quantity}.
\item
  To trace out the entire marginal cost function, you need a demand shifter \(Z\) that changes the equilibrium: \(D(p, Z)\).
  \begin{equation}
  C'(D(p, z)) = \frac{D(p, z) + pD'(p, z)}{D'(p, z)}
  \end{equation}
\item
  This identifies the marginal cost function \textit{at the equilibrium quantity when $Z = z$}.
\item
  If the equilibrium quantities cover the domain of the marginal cost function when the demand shifter \(Z\) moves around, then it identifies the entire marginal cost function.
\end{itemize}

\subsection{Unobserved Heterogeneity in the Cost Function}\label{unobserved-heterogeneity-in-the-cost-function}

\begin{itemize}
\item
  Previously we did not consider any unobserved heterogeneity in the cost function.
\item
  Now suppose that the cost function is given by:
  \begin{equation}
  C(q) = \tilde{C}(q) + q \epsilon + \mu,
  \end{equation}
  and \(\epsilon\) and \(\mu\) are not observed.
\item
  Moreover, because it includes anticipated shocks, it is likely to be correlated with input decisions and hence the output.
\item
  The first-order condition w.r.t. \(p\) for profit maximization is:
  \begin{equation}
  \begin{split}
  &D(p, z) + pD'(p, z) - [\tilde{C}'(D(p, z)) + \epsilon]D'(p, z) = 0.\\
  &\Leftrightarrow \tilde{C}'(D(p, z))  = \frac{D(p, z) + pD'(p, z)}{D'(p,z)} - \epsilon.
  \end{split}
  \end{equation}
\item
  Take the expectation conditional on \(Z = z\):
  \begin{equation}
  \tilde{C}'(D(p, z)) = \frac{D(p, z) + pD'(p, z)}{D'(p, z)} - \mathbb{E}\{\epsilon|Z = z\}.
  \end{equation}
\item
  If \(Z\) and \(\epsilon\) is independent, then the last term becomes zero and we can follow the same argument as before to trace out the marginal cost function.
\end{itemize}

\subsection{Multi-product Monopolist Case}\label{multi-product-monopolist-case}

\begin{itemize}
\item
  Demand for good \(j\) is \(D_j(p)\) given a price vector \(p\).
\item
  Cost for producing a vector of good \(q\) is \(C(q)\).
\item
  Demand function is \textbf{known} but cost function is not known.
\item
  The monopolist solves:
  \begin{equation}
  \max_{p} \sum_{j = 1}^J p_j D_j(p) - C(D_1(p), \cdots, D_J(p)).
  \end{equation}
\item
  The first-order condition w.r.t. \(p_i\) for profit maximization is:
  \begin{equation}
  \begin{split}
  &D_i(p) +  \sum_{j = 1}^J p_j \frac{\partial D_j(p)}{\partial p_i} = \sum_{j = 1}^J \frac{\partial C(D_1(p), \cdots, D_J(p))}{\partial q_j} \frac{\partial D_j(p)}{\partial p_i}.\\
  &= 
  \begin{pmatrix}
  \frac{\partial D_1(p)}{\partial p_i} & \cdots & \frac{\partial D_J(p)}{\partial p_i}
  \end{pmatrix}
  \begin{pmatrix}
  \frac{\partial C(D_1(p), \cdots, D_J(p))}{\partial q_1}\\
  \vdots\\
  \frac{\partial C(D_1(p), \cdots, D_J(p))}{\partial q_J}
  \end{pmatrix}
  \end{split}
  \end{equation}
\item
  Summing up, the first-order condition w.r.t. \(p\) is summarized as:
  \begin{equation}
  \begin{split}
  &\begin{pmatrix}
   D_1(p) + \sum_{j = 1}^J p_j \frac{\partial D_j(p)}{\partial p_1}\\
   \vdots\\
   D_J(p) + \sum_{j = 1}^J p_j \frac{\partial D_j(p)}{\partial p_J}
  \end{pmatrix} 
  =
  \begin{pmatrix}
  \frac{\partial D_1(p)}{\partial p_1} & \cdots & \frac{\partial D_J(p)}{\partial p_1}\\
  \vdots\\
  \frac{\partial D_1(p)}{\partial p_J} & \cdots & \frac{\partial D_J(p)}{\partial p_J}
  \end{pmatrix}
  \begin{pmatrix}
  \frac{\partial C(D_1(p), \cdots, D_J(p))}{\partial q_1}\\
  \vdots\\
  \frac{\partial C(D_1(p), \cdots, D_J(p))}{\partial q_J}
  \end{pmatrix}\\
  &\Leftrightarrow
  \begin{pmatrix}
  \frac{\partial C(D_1(p), \cdots, D_J(p))}{\partial q_1}\\
  \vdots\\
  \frac{\partial C(D_1(p), \cdots, D_J(p))}{\partial q_J}
  \end{pmatrix} = 
  \underbrace{\begin{pmatrix}
  \frac{\partial D_1(p)}{\partial p_1} & \cdots & \frac{\partial D_J(p)}{\partial p_1}\\
  \vdots\\
  \frac{\partial D_1(p)}{\partial p_J} & \cdots & \frac{\partial D_J(p)}{\partial p_J}
  \end{pmatrix}^{-1}  
  \begin{pmatrix}
   D_1(p) + \sum_{j = 1}^J p_j \frac{\partial D_j(p)}{\partial p_1}\\
   \vdots\\
   D_J(p) + \sum_{j = 1}^J p_j \frac{\partial D_j(p)}{\partial p_J}
  \end{pmatrix}.}_{\text{$p$ is observed and $D(p)$s are known.}}
  \end{split}
  \end{equation}
\item
  Hence, the cost function is identified.
\item
  Including unobserved heterogeneity in the cost function causes the same problem as in the previous case.
\end{itemize}

\subsection{Oligopoly}\label{oligopoly}

\begin{itemize}
\item
  There are firm \(j = 1, \cdots, J\) and they sell product \(j = 1, \cdots, J\), that is, firm = product (for simplicity).
\item
  Consider a price setting game. When the price vector is \(p\), demand for product \(j\) is given by \(D_j(p)\).
\item
  The cost function for firm \(j\) is \(C_j(q_j)\).
\item
  Given other firms' price \(p_{-j}\), firm \(j\) solves:
  \begin{equation}
  \max_{p_j} D_j(p) p_j - C_j(D_j(p)).
  \end{equation}
\item
  The first-order condition w.r.t. \(p_j\) for profit maximization is:
  \begin{equation}
  \begin{split}
  &D_j(p) + \frac{\partial D_j(p)}{\partial p_j} p_j = \frac{\partial C_j(D_j(p))}{\partial q_j} \frac{\partial D_j(p)}{\partial p_j}.\\
  &\frac{\partial C_j(D_j(p))}{\partial q_j} = \underbrace{\frac{\partial D_j(p)}{\partial p_j}^{-1}[D_j(p) + \frac{\partial D_j(p)}{\partial p_j} p_j ]}_{\text{$p$ is observed and $D_j(p)$ is known}}.
  \end{split}
  \end{equation}
\item
  In Nash equilibrium, these equations jointly hold for all firms \(j = 1, \cdots, J\).{]}
\item
  Including unobserved heterogeneity in the cost function causes the same problem as in the previous case.
\end{itemize}

\chapter{Demand Function Estimation}\label{demand}

\section{Motivations}\label{motivations-1}

\begin{itemize}
\item
  From the demand function and utility maximization assumption, we can reveal the preference of the decision maker.
\item
  Thus, estimating demand function is necessary for \textbf{evaluating the consumer welfare}.
\item
  In IO, estimating the \textbf{price elasticity of demand} is especially important, because it determines the \textbf{market power} of a monopolist and the size of the dead-weight loss.
\item
  In macroeconomics, estimating demand is important to determine the \textbf{price level}, because the price level is the minimum expenditure for a consumer to achieve the certain level of utility.
\item
  In marketing, estimating demand is necessary to design the optimal pricing, advertising, and all the other marketing interventions.
\item
  In principle, the theory can be applied to whatever decisions other than the consumer choice.
\item
  \citet{Nevo2000c}:

  \begin{itemize}
  \tightlist
  \item
    How do the hypothetical mergers in the ready-to-eat cereal industry affect the market price, markup, and consumer surplus?
  \item
    To do so, the authors estimate the demand for ready-to-eat cereals and the cost functions for each product. Then, the authors conduct counterfactual simulations of mergers to quantify the effects.
  \end{itemize}
\item
  \citet{Chung2002}:

  \begin{itemize}
  \tightlist
  \item
    To what extent do firms go abroad to access technology available in other locations?
  \item
    To study this issue, the authors estimate firms' locational choices when going abroad.
  \end{itemize}
\item
  \citet{Rysman2004}:

  \begin{itemize}
  \tightlist
  \item
    In Yellow pages, how do consumers evaluate the advertisement on it, and how do advertisers value consumer usage?
  \item
    To study this, the author simultaneously estimates the consumer demand for usage of a directory, advertiser demand for advertising, and a publisher's first-order condition.
  \end{itemize}
\item
  \citet{Gentzkow2004}:

  \begin{itemize}
  \tightlist
  \item
    Are online and print newspapers substitutes or complements?
  \item
    To study this, the author estimates a demand function in which online and print newspapers can be either substitutes or complements.
  \end{itemize}
\item
  \citet{Bayer2007}:

  \begin{itemize}
  \tightlist
  \item
    What are people's preferences for schools and neighborhoods? How is this capitalized into housing prices?
  \item
    To do so, the authors estimate the discrete choice of residents over locations. To deal with the endogeneity between the neighborhood and the unobserved attributes of the location, the authors use the discontinuity at the school attendance zone.
  \end{itemize}
\item
  \citet{Archak2011}:

  \begin{itemize}
  \tightlist
  \item
    How does the information embedded in product reviews affect consumer choice?
  \item
    To study this, the authors estimate the discrete choice model of consumers in which the text information from the product reviews is included as the product attributes.
  \end{itemize}
\item
  \citet{Holmes2011}:

  \begin{itemize}
  \tightlist
  \item
    Wal-Mart maintains high store density. How large is the economy of density and the sales cannibalization?
  \item
    To study this, the author first estimates the demand function across neighborhood Wal-Mart to capture the sales cannibalization, and then estimates the cost structure from their entry and exit behaviors.
  \end{itemize}
\item
  \citet{Handbury2014}:

  \begin{itemize}
  \tightlist
  \item
    Urban and rural areas differ in available products. How does the price difference change if the heterogeneity in the product availability is incorporated?
  \item
    To do so, the authors estimate the demand function at each location, and then construct the spatial price index based on the available products at each location.
  \end{itemize}
\end{itemize}

\section{Analyzing Consumer Behaviors}\label{analyzing-consumer-behaviors}

\begin{itemize}
\item
  \textbf{Alternative set}.
\item
  \textbf{Utility function}.

  \begin{itemize}
  \tightlist
  \item
    Add system of \textbf{choice sets}.
  \item
    Add utility maximization.
  \end{itemize}
\item
  \(\rightarrow\) \textbf{Demand function}.
\item
  In the case of producer behavior, there was a chance to directly observe the output of the most primitive function, the production function.
\item
  In the case of consumer behavior, we never directly observe the output of the most primitive function, the utility function.
\item
  We can at most identify demand functions.
\item
  \textbf{Revealed preference theory}:

  \begin{itemize}
  \tightlist
  \item
    \citet{Samuelson1938}, \citet{Houthakker1950}, \citet{Richter1966}, \citet{Afriat1967}, \citet{Varian1982}.
  \item
    If the demand function is derived from a preference by maximizing the preference, the demand function should satisfy some restrictions.
  \item
    If the assumption is true, we can recover part of the preference from the demand function.
  \end{itemize}
\end{itemize}

\section{Continuous Choice}\label{continuous-choice}

\begin{itemize}
\tightlist
\item
  The alternative set \(\mathcal{X}\) is a subset of \(\mathbb{R}^J\).
\item
  The utility function \(u\) is rational, monotone, and continuous on \(\mathcal{X}\).
\item
  The choice sets are given by a system of \textbf{linear budget sets}:
  \[
  \mathcal{B}(p, w) = \{q \in \mathcal{X}: p \cdot q \le w\}.
  \]
\item
  If choice sets are non-linear, the following duality approach needs to be modified.
\end{itemize}

\subsection{Duality between Utility and Expenditure Functions}\label{duality-between-utility-and-expenditure-functions}

\begin{itemize}
\tightlist
\item
  It is rather a special case that we can derive a closed-form solution to a utility maximization problem.
\item
  We can use the first-order conditions as moment conditions for identification.
  \begin{equation}
  \frac{\partial u(q)}{\partial q_i} = \lambda p_i, i = 1, \cdots, J.
  \end{equation}
\item
  The derivation of a demand function from the identified utility function in general requires numerical simulation, which can be troublesome.
\item
  As well as the duality between production and cost functions, we have the same duality theorem for utility and expenditure functions.
\item
  There is a one-to-one mapping between a class of utility functions and a class of expenditure functions.
\item
  Therefore, it is okay to start from an expenditure function.
\item
  It is rare that we can recover the utility function associated with an expenditure function in closed form. But it is not often required for analysis.
\item
  Moreover, we can easily derive other important functions from the expenditure functions.
\item
  Let \(p\) be the price vector and \(u\) be the target utility level.
\item
  Let \(u(q)\) be a utility function.
\item
  An expenditure function associated with the utility function is defined by:
  \begin{equation}
  e(u, p) = \min_{q} p \cdot q, \text{ subject to } u(q) \ge u.
  \end{equation}
\item
  Let \(x\) be the total expenditure such that:
  \begin{equation}
  x = e(u, p).
  \end{equation}
\item
  We can start the analysis by specifying this function instead of the utility function.
\end{itemize}

\subsection{Deriving Other Functions}\label{deriving-other-functions}

\begin{itemize}
\tightlist
\item
  It is easy to derive other functions from an expenditure function.
\item
  \textbf{Indirect utility function}: invert the expenditure function to get:
  \begin{equation}
  u = e^{-1}(p, x) \equiv v(p, x).
  \end{equation}
\item
  \textbf{Hicksian demand function}: apply Shepard's lemma:
  \begin{equation}
  q_i = \frac{\partial e(u, p)}{\partial p_i} \equiv h_i(u, p).
  \end{equation}
\item
  \textbf{Marshallian demand function}: insert Hicksian demand function to the expenditure function:
  \begin{equation}
  q_i = h_i(v(p, x), p) \equiv d_i(p, x).
  \end{equation}
\end{itemize}

\subsection{Starting from an Indirect Utility Function}\label{starting-from-an-indirect-utility-function}

\begin{itemize}
\tightlist
\item
  It is almost equivalent to start from an indirect utility function.
\item
  An indirect utility function with the utility function is defined by:
  \begin{equation}
  v(p, x) \equiv \max_{q} u(q), \text{ subject to } p'q \le x.
  \end{equation}
\item
  We can derive the Marshallian demand function by Roy's identity:
  \begin{equation}
  q_i = \frac{- \partial v(p, x)/\partial p_i}{\partial v(p, x)/\partial x} \equiv d_i(p, x).
  \end{equation}
\end{itemize}

\subsection{Expenditure Share Equation}\label{expenditure-share-equation}

\begin{itemize}
\tightlist
\item
  Let's start from an expenditure function \(e(p, x)\).
\item
  By Shepard's lemma, we have:
  \begin{equation}
  \frac{\partial \ln e(u, p)}{\partial \ln p_i} = \frac{\partial e(u, p)}{\partial p_i} \frac{p_i}{e(u, p)} = \frac{p_i q_i}{x} \equiv w_i.
  \end{equation}
\item
  We call this an expenditure share equation.
\item
  The estimation is based on the share equations.
\end{itemize}

\subsection{Almost Ideal Demand System (AIDS)}\label{almost-ideal-demand-system-aids}

\begin{itemize}
\tightlist
\item
  Based on \citet{Deaton1980}.
\item
  See \citet{AngusDeaton1980} for further reference.
\item
  Consider an expenditure function that satisfies the following useful conditions:

  \begin{itemize}
  \tightlist
  \item
    It allows aggregation (this motivation is less important in recent days).
  \item
    It gives an arbitrary first-order approximation to any demand system.
  \item
    It can satisfy the restrictions of utility maximization.
  \item
    It can be used to test the restrictions of utility maximization.
  \end{itemize}
\end{itemize}

\subsection{PIGLOG Class}\label{piglog-class}

\begin{itemize}
\tightlist
\item
  PIGLOG (price-independent generalized logarithmic) class \citep{Muellbauer1976}.
  \begin{equation}
  \ln e(u, p) = (1 - u) \ln a(p) + u\ln b(p),
  \end{equation}
  where \(a(p)\) and \(b(p)\) are arbitrary linear homogeneous concave functions.
\item
  Consider households that differ in total income.
\item
  The PIGLOG form ensures that the aggregate demand can be written in the same form where the total income is replaced with the sum of household total income.
\item
  The derivatives should be given free parameters for the model to be an arbitrary first-order approximation to any demand system.
\item
  In AIDS, we specify \(a(p)\) and \(b(p)\) as:
  \begin{equation}
  \begin{split}
  \ln a(p) &\equiv a_0 + \sum_{k} \alpha_k \ln p_k + \frac{1}{2}\sum_{k} \sum_{j} \gamma_{kj}^* \ln p_k \ln p_j\\
  \ln b(p) &\equiv \ln a(p) + \beta_0  \prod_{k} p_k^{\beta_k}.
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Derive the Share Equation I}\label{derive-the-share-equation-i}

\begin{itemize}
\tightlist
\item
  By Roy's identity, we can derive the associated share equation:
  \begin{equation}
  w_i \equiv \frac{\partial \ln e(u, p)}{\partial \ln p_i} = \alpha_i + \sum_{j} \gamma_{ij} \log p_j + \beta_i u \beta_0 \prod_{k} p_k^{\beta_k},
  \end{equation}
  where
  \begin{equation}
  \gamma_{ij} = \frac{1}{2}(\gamma_{ij}^* + \gamma_{ji}^*).
  \end{equation}
\end{itemize}

\subsection{Derive the Share Equation II}\label{derive-the-share-equation-ii}

\begin{itemize}
\tightlist
\item
  Insert the indirect utility function \(u = v(p, x)\) to get:
  \begin{equation}
  w_i = \alpha_i + \sum_{j} \gamma_{ij} \ln p_j + \beta_i \ln \frac{x}{P},
  \end{equation}
  where
  \begin{equation}
  \ln P \equiv  \alpha_0 + \sum_{k} \alpha_k \ln p_k + \frac{1}{2} \sum_{j} \sum_{k} \gamma_{kj} \ln p_k \ln p_j.
  \end{equation}
\item
  \(P\) is a price index associated with the given preference.
\item
  With the specification of \citet{RichardStone1954}, it becomes \(\ln P = \sum_{j} x_j \ln p_j\).
\item
  It can be used as an approximation.
\end{itemize}

\subsection{Specify the Detail II}\label{specify-the-detail-ii}

\begin{itemize}
\tightlist
\item
  It can satisfy the restrictions of utility maximization.
\item
  It can be used to test the restrictions of utility maximization.

  \begin{itemize}
  \tightlist
  \item
    \(\sum_{j} x_j = 1\):
    \begin{equation}
    \sum_{j} \alpha_j = 1, \sum_{j} \gamma_{jk} = 0, \sum_{j} \beta_j = 0.
    \end{equation}
  \item
    \(e(u, p)\) is linear homogeneous in \(p\):
    \begin{equation}
    \sum_{j} \gamma_{ij} = 0.
    \end{equation}
  \item
    Symmetry:
    \begin{equation}
    \gamma_{ij} = \gamma_{ji}.
    \end{equation}
  \end{itemize}
\end{itemize}

\subsection{Estimation}\label{estimation}

\begin{itemize}
\tightlist
\item
  We can estimate parameters based on the share equations.
\item
  If we use aggregate data, the aggregate error term is correlated with the price vector.
\item
  Therefore, we need at least as many instrumental variables as the dimension of the price vector.
\item
  With valid instrumental variables, we can estimate the model with GMM.
\item
  If we use household-level data, the household-specific errors controlling for aggregate errors will not be correlated with the price vector if the price is determined in a competitive market.
\end{itemize}

\subsection{From Product Space Approach to Characteristics Space Approach}\label{from-product-space-approach-to-characteristics-space-approach}

\begin{itemize}
\tightlist
\item
  The framework up to here is called the \textbf{product space approach} because the utility has been defined over a product space.
\item
  When there are \(J\) goods, there are \(J^2\) parameters for prices.
\item
  One way to resolve this issue is to introduce a priori knowledge about the preference.
\item
  For example, we can introduce a priori segmentation with separability.
\item
  It is hard to evaluate the effect of introducing new product.
\item
  Again, we have to a priori decide which segment/product is similar to the new product.
\item
  This leads us to the \textbf{characteristics space approach} \citep{Lancaster1966, Muth1966}:

  \begin{itemize}
  \tightlist
  \item
    Consumption is an activity in which goods are inputs and in which the output is a collection of characteristics.
  \item
    Utility ranks collections of characteristics and only ranks collections of goods indirectly through the characteristics that they possess.
  \item
    There are \(k = 1, \cdots, K\) activities.
  \item
    The activity \(y\) requires consuming \(x = A y\) products.
  \item
    The activity \(y\) generates \(z = B y\) characteristics.
  \item
    The budget constraint is \(p \cdot x \le 1\).
  \item
    The utility is defined over the characteristics \(u(z)\).
  \item
    The consumer's problem is:
    \[
      \max_y u(z)
      \]
    subject to
    \[
      p \cdot x \le 1, x = Ay, z = By, x, y, z \ge 0.
      \]
  \end{itemize}
\item
  Then, only the dimension of characteristics matters, and the value of new products can be evaluated by their contribution to the production of characteristics.
\item
  The early applications include \citet{Rosen1974}, \citet{Muellbauer1974}, and \citet{Gorman1980}.
\item
  The nonparametric analysis based on the revealed preference is in \citet{Blow2008}.
\end{itemize}

\subsection{From Continuous Choice Approach to Discrete Choice Approach}\label{from-continuous-choice-approach-to-discrete-choice-approach}

\begin{itemize}
\tightlist
\item
  The aggregate demand is a collection of choices across consumers and within consumers over time.
\item
  It makes sense to model individual choices and then aggregate rather than directly modeling the aggregate demand.
\item
  The resulting aggregate demand will satisfy restrictions that are consistent with the underlying consumer choice model.
\item
  If there is an interaction across choices, the aggregation is not trivial.
\item
  This is especially true when aggregating choices within consumers.
\item
  For now, assume that each choice is independent.
\end{itemize}

\section{Discrete Choice}\label{discrete-choice}

\subsection{Discrete Choice Approach}\label{discrete-choice-approach}

\begin{itemize}
\tightlist
\item
  Let \(u(q, z_i)\) be the utility of a consumer over \(J + 1\) dimensional consumption bundle \(q\) characterized by consumer characteristics \(z_i\).
\item
  The consumer solves:
  \begin{equation}
  V(p, y_i, z_i) = \max_{q}u(q, z_i), \text{   s.t.   } p'q \le y_i.
  \end{equation}
\item
  Alternative \(0\) is an \textbf{outside good}.
\item
  Normalize \(p_0 = 1\).
\item
  We call alternatives \(j = 1, \cdots, J\) \textbf{inside goods}.
\item
  The choice space is restricted on:
  \begin{equation}
  \begin{split}
  Q = \{q:& q_0 \in [0, M], q_j \in \{0, 1\}, j = 1, \cdots, J,\\
  & q_j q_k = 0, \forall j \neq k, j, k > 0, M < \infty\}.
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Discrete Choice Approach}\label{discrete-choice-approach-1}

\begin{itemize}
\tightlist
\item
  The budget constraint reduces to:
  \begin{equation}
  \begin{cases}
  q_0 + p_j q_j = y &\text{   if   } q_j = 1, j > 0\\
  q_0 = y &\text{   otherwise}.
  \end{cases}
  \end{equation}
\item
  Hence,
  \begin{equation}
  q_0 = y - \sum_{j = 1}^J p_j q_j.
  \end{equation}
\end{itemize}

\subsection{Discrete Choice Approach}\label{discrete-choice-approach-2}

\begin{itemize}
\tightlist
\item
  The utility maximization problem can be written as:
  \begin{equation}
  V(p, y_i, z_i) = \max_{j = 0, 1, \cdots, J}  v_j(p_j, y_i, z_i),
  \end{equation}
  where
  \begin{equation}
  \begin{split}
  &v_j(p_j, y_i, z_i)\\
  & =
  \begin{cases}
  u(y_i - p_j, 0, \cdots, \underbrace{1}_{q_j}, \cdots, 0, z_i) &\text{   if  }j > 0,\\
  u(y_i, 0, \cdots, 0, z_i) &\text{   if   }j = 0,
  \end{cases}
  \end{split}
  \end{equation}
  is called the \textbf{choice-specific indirect utility}.
\end{itemize}

\subsection{Characteristics Space Approach}\label{characteristics-space-approach}

\begin{itemize}
\item
  Preference is defined over the characteristics of alternatives, \(x_j\):
\item
  Car: vehicle, engine power, model-year, car maker, etc.
\item
  PC: CPU power, number of cores, memory, HDD volume, etc.
\item
  The choice-specific indirect utility is a function of the characteristics of the alternative:
  \begin{equation}
  \begin{split}
  v_j(p_j, y_i, z_i) &= u(y_i - p_j, 0, \cdots, \underbrace{1}_{q_j}, \cdots, 0, z_i)\\
  &= u^*(y_i - p_j, x_j, z_i)\\
  &\equiv v(p_j, x_j, y_i, z_i).
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Weak Separability and Income Effect}\label{weak-separability-and-income-effect}

\begin{itemize}
\tightlist
\item
  We usually focus on a particular product category such as cars, PCs, cereals, detergents, and so on.
\item
  Assume that the preference is separable between the category in question (\textbf{inside goods}) and other categories (\textbf{outside goods}).
\item
  \(u(q) = u[q_I, v(q_O)]\):

  \begin{itemize}
  \tightlist
  \item
    \(q_I\): the consumption vector of inside goods.
  \item
    \(q_O\): the consumption vector of outside goods.
  \item
    Increasing in \(v_O = v(q_O)\).
  \end{itemize}
\item
  \(p = (p_I, p_O)\):

  \begin{itemize}
  \tightlist
  \item
    \(p_I\): the price vector of inside goods.
  \item
    \(p_O\): the price vector of outside goods.
  \end{itemize}
\item
  When \(y_O\) is left for the outside goods, the conditional demand for the outside goods \(q_O(y_O, p_O)\) exists.
\item
  Inserting this into the utility function gives:
  \begin{equation}
  u\{q_I, v[q_O(y_O, p_O)]\} \equiv \tilde{u}(q_I, y_O; p_O).
  \end{equation}
\end{itemize}

\subsection{Weak Separability and Income Effect}\label{weak-separability-and-income-effect-1}

\begin{itemize}
\tightlist
\item
  Thus, how the preference for the outside good is modeled determines how the individual income affects the choice.
  \begin{equation}
  \begin{split}
  &u(y_i - p_j, x_j, z_i) = \tilde{u}(x_j, z_i) + \alpha(y_i - p_j).\\
  &u(y_i - p_j, x_j, z_i) = \tilde{u}(x_j, z_i) + \alpha \ln (y_i - p_j).
  \end{split}
  \end{equation}
\item
  In the first example, the income level does not affect the choice because the term \(\alpha y_i\) is common and constant across choices (there is no income effect).
\item
  We often do not observe the income of a consumer, \(y_i\).
\item
  Remember that the price of a product enters because we consider the \textbf{indirect} utility function here.
\end{itemize}

\subsection{Utility Function Normalization}\label{utility-function-normalization}

\begin{itemize}
\tightlist
\item
  The \textbf{location} of utility function is often normalized by setting:
  \begin{equation}
  u(y^*, 0, \cdots, 0, z) = 0,
  \end{equation}
  for a certain choice of \(y^*\) for any consumer segment \(z_i\).
\end{itemize}

\subsection{Aggregation of the Individual Demand}\label{aggregation-of-the-individual-demand}

\begin{itemize}
\tightlist
\item
  Let \(q(p, x, y_i, z_i) = \{q_j(p, x, y_i, z_i)\}_{j = 0, \cdots, J}\) be the demand function of consumer \(i\), that is:
  \begin{equation}
  q_j(p, x, y_i, z_i) = 1 \Leftrightarrow j = \text{argmax}_{j = 0, 1, \cdots, J}  v(p_j, x_j, y_i, z_i).
  \end{equation}
\item
  Let \(f(y, z)\) be the joint distribution of the income and other consumer characteristics.
\item
  The aggregate demand for good \(j\) is:
  \begin{equation}
  \sigma_j(p, x) \equiv N \int  q_j(p, x, y, z) f(y, z) dy dz,
  \end{equation}
  where \(N\) is the population.
\end{itemize}

\subsection{Horizontal Product Differentiation}\label{horizontal-product-differentiation}

\begin{itemize}
\tightlist
\item
  \textbf{horizontal product differentiation}: consumers do not agree on the ranking of the choices.
\item
  There are two convenience stores \(j = 1, 2\) on a street \([0, 1]\).
\item
  Let \(z_i\) be the location of consumer \(i\) and \(x_j\) be the location of the choice on a street \([0, 1]\) with \(x_1 < x_2\).
\item
  A consumer has a preference such that:
  \begin{equation}
  v_{ij} \equiv v(p_j, x_j, y_i, z_i) \equiv s - t |z_i - x_j| - p_j.
  \end{equation}
\end{itemize}

\subsection{Horizontal Product Differentiation}\label{horizontal-product-differentiation-1}

\begin{itemize}
\tightlist
\item
  Suppose that the prices are low enough that entire consumers on the street are willing to buy either from the stores.
\item
  Consumer \(i\) buys from store \(1\) if and only if:
  \begin{equation}
  \begin{split}
  &v(p_1, x_1, y_i, z_i) \ge v(p_2, x_2, y_i, z_i)\\
  &\Leftrightarrow s - t |z_i - x_1| - p_1 \ge s - t |z_i - x_2|- p_2\\
  &\Leftrightarrow z_i \le \frac{p_2 - p_1}{2 t} + \frac{x_1 + x_2}{2} \equiv \overline{z}_1(p_1, p_2).
  \end{split}
  \end{equation}
\item
  Let \(f(z_i)\) be \(U[0, 1]\). Then, the aggregate demand for store 1 is:
  \begin{equation}
  \begin{split}
  \sigma_1(p, x) = N \int_{0}^{\overline{z}_1(p_1, p_2)} d z_i = N\overline{z}_1(p_1, p_2).
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Vertical Product Differentiation}\label{vertical-product-differentiation}

\begin{itemize}
\tightlist
\item
  \textbf{Vertical product differentiation}: Consumers agree on the ranking of the choices. Consumers can have different willingness to pay.
\item
  \citet{Bresnahan1987} analyzed automobile demand with this framework.
\item
  There are \(J\) goods and consumer \(i\) has a utility such as:
  \begin{equation}
  v_{ij} \equiv v(p_j, x_j, y_i, z_i) = z_i x_j - p_j,
  \end{equation}
  where \(x_j\) is a quality of product \(j\) and \(z_i\) is the consumer's willingness to pay for the quality with \(x_j < x_{j + 1}\).
\item
  Consumers' problem is:
  \begin{equation}
  \max\{0, z_i x_1 - p_1, \cdots, z_i x_J - p_J \}.
  \end{equation}
\end{itemize}

\subsection{Vertical Product Differentiation}\label{vertical-product-differentiation-1}

\begin{itemize}
\tightlist
\item
  Consumer \(i\) prefers good \(j + 1\) to good \(j\) if and only if:
  \begin{equation}
  \begin{split}
  &v(p_{j + 1}, x_{j + 1}, y_i, z_i) \ge v(p_j, x_j, y_i, z_i)\\
  &\Leftrightarrow z_i x_{j + 1} - p_{j + 1} \ge z_i x_j - p_j\\
  &\Leftrightarrow z_i \ge \frac{p_{j + 1} - p_j}{x_{j + 1} - x_j} \equiv \Delta_j.
  \end{split}
  \end{equation}
\item
  So consumer \(i\) purchases good \(j\) if and only if \(z_i \in [\Delta_{j - 1}, \Delta_j)\) and buys nothing if:
  \begin{equation}
  z_i \le \Delta_0 \equiv \min\{p_1/x_1, \cdots p_J/x_j\}.
  \end{equation}
\item
  Letting \(F(z)\) be the distribution function of \(z\), the aggregate demand for good \(j\) is:
  \begin{equation}
  \sigma_j(p, x, z) = N[F(\Delta_{j}) - F(\Delta_{j - 1})].
  \end{equation}
\end{itemize}

\subsection{Econometric Models}\label{econometric-models}

\begin{itemize}
\tightlist
\item
  So far there was no econometrics.
\item
  Next we define what are observable and unobservable, and what are known and unknown.
\item
  Then consider how to identify and estimate the model.
\end{itemize}

\subsection{Multinomial Logit Model: Preference Shock}\label{multinomial-logit-model-preference-shock}

\begin{itemize}
\tightlist
\item
  This originates at \citet{Mcfadden1974}.
\item
  See \citet{Train2009} for reference.
\item
  Suppose that there is some unobservable component in consumer characteristics.
\item
  In reality, consumers choice change somewhat randomly.
\item
  Let's capture such a \textbf{preference shock} by consider the following model:
  \begin{equation}
  v(p_j, x_j, y_i, z_i) + \epsilon_{ij},
  \end{equation}
  with some random vector:
  \begin{equation}
  \epsilon_i \equiv (\epsilon_{i0}, \cdots, \epsilon_{iJ})' \sim G.
  \end{equation}
\item
  At this point, \(G\) can be any distribution and the shocks can be dependent across \(j\) within \(i\).
\item
  \(p, x, y_i, z_i\) are \textbf{observed} but \(\epsilon_{ij}\) are \textbf{unobserved}.
\item
  When the realization of the preference shock is given, the consumer choice is:
  \[
  q_j(p, x, y_i, z_i, \epsilon_{i}) \equiv 1\{j = \text{argmax}_{k = 0, \cdots, J} v(p_k, x_k, y_i, z_i) + \epsilon_{ik}\}
  \]
  for \(k = 0, \cdots, J\).
\item
  The \textbf{choice probability} as observed by econometrician is:
  \[
  \sigma_j(p, x, y_i, z_i) \equiv \int q_j(p, x, y_i, z_i, \epsilon_{i}) dG(\epsilon_i).
  \]
\end{itemize}

\subsection{Multinomial Logit Model: Distributional Assumption}\label{multinomial-logit-model-distributional-assumption}

\begin{itemize}
\item
  Now assume the followings:
\item
  \(\epsilon_{ij}\) are independent across \(j\): \(G(\epsilon_i) = \prod_{j = 0, \cdots, J} G_j(\epsilon_{ij})\).
\item
  \(\epsilon_{ij}\) are identical across \(j\): \(G_j(\epsilon_{ij}) = \overline{G}(\epsilon_{ij})\).
\item
  \(\overline{G}\) is a type-I extreme value.
\item
  \(\rightarrow\) The density \(g(\epsilon_{ij}) = \exp[-\exp(-\epsilon_{ij}) - \epsilon_{ij}]\).
\item
  This is called the (homoskedastic) \textbf{multinomial logit model}.
\item
  Setting the variance of \(\epsilon_{ij}\) at 1 for some \(j\) is a \textbf{scale} normalization.
\item
  By dropping some of the assumptions, we can have heteroskedastic multinomial logit model, generalized extreme value model, and so on.
\item
  Another popular distribution assumption is to assume a multivariate normal distribution of \(\epsilon_i\). This case is called the \textbf{multinomial probit model}.
\end{itemize}

\subsection{Multinomial Logit Model: Choice Probability}\label{multinomial-logit-model-choice-probability}

\begin{itemize}
\tightlist
\item
  The \textbf{choice probability} of consumer \(i\) of good \(j\) is:
  \begin{equation}
  \begin{split}
  \sigma_j(p, x, y_i, z_i) & \equiv \mathbb{P}\{j = \text{argmax}_{k = 0, 1, \cdots, J} v(p_k, x_k, y_i, z_i) + \epsilon_{ik}  \}\\
  &=\mathbb{P}\{v(p_j, x_j, y_i, z_i) -  v(p_k, x_k, y_i, z_i) \ge \epsilon_{ik} - \epsilon_{ij}, \forall k \neq j\}\\
  & = \text{...after some algebra: leave as an exercise...}\\
  &= \frac{\exp[v(p_j, x_j, y_i, z_i) ]}{\sum_{k = 0}^J \exp[v(p_k, x_k, y_i, z_i)] }.
  \end{split}
  \end{equation}
\item
  For example, if:
  \begin{equation}
  v(p_k, x_k, y_i, z_i) = \beta_i'x_k + \alpha_i (y_i - p_k),
  \end{equation}
\end{itemize}

\begin{equation}
\begin{pmatrix}
\beta_i \\
\alpha_i
\end{pmatrix}
= 
\begin{pmatrix}
\beta_0 \\
\alpha_0
\end{pmatrix}
+
\begin{pmatrix}
\Gamma\\
\pi'
\end{pmatrix}
 z_i.
\end{equation}
- Then, we have:
\begin{equation}
\begin{split}
\sigma_{j}(p, x, y_i, z_i) &= \frac{\exp[\beta_i'x_j + \alpha_i (y_i - p_j) ]}{\sum_{k = 0}^J \exp[\beta_i'x_k + \alpha_i (y_i - p_k) ]}\\
&= \frac{\exp[\beta_i'x_j - \alpha_i p_j]}{\sum_{k = 0}^J \exp[\beta_i'x_k - \alpha_i p_k]}
\end{split}
\end{equation}
- If we normalize the characteristics vector so that \(w_0 = 0\) holds for the outside option, it becomes:
\[
\sigma_{j}(p, x, y_i, z_i) = \frac{\exp[\beta_i'x_j - \alpha_i p_j]}{1 + \sum_{k = 1}^J \exp[\beta_i'x_k - \alpha_i p_k]}
\]

\subsection{Multinomial Logit Model: Inclusive Value}\label{multinomial-logit-model-inclusive-value}

\begin{itemize}
\tightlist
\item
  The expected utility for consumer \(i\) before the preference shocks are drawn under multinomial logit model is given by:
  \begin{equation}
  \begin{split}
  &\mathbb{E}\{\max_{j = 0, \cdots, J} v(p_j, x_j, y_i, z_i) + \epsilon_{ij}\} \\
  &= \text{   ...after some algebra: leave as an exercise...}\\
  &= \ln \Bigg\{\sum_{j = 0}^J \exp[v(p_j, x_j, y_i, z_i)] \Bigg\} + constant.
  \end{split} 
  \end{equation}
\item
  This is sometimes called the \textbf{inclusive value} of the choice set.
\end{itemize}

\subsection{Maximum Likelihood Estimation of Multinomial Logit Model}\label{maximum-likelihood-estimation-of-multinomial-logit-model}

\begin{itemize}
\tightlist
\item
  Suppose we observe a sequence of income \(y_i\), consumer characteristics \(z_i\), choice \(q_{i}\), product characteristics \(x_j\) and price \(p_j\).
\item
  \(q_i = (q_{i0}, \cdots, q_{iJ})'\) and \(q_{ij} = 1\) if \(j\) is chosen and \(0\) otherwise.
\item
  The parameter of interest is the mean indirect utility function \(v\).
\item
  Then the log likelihood of \(\{q_i\}_{i = 1}^N\) conditional on \(\{y_i, z_i\}_{i = 1}^N\) and \(\{x_j,p_j\}_{j = 1}^J\) is:
  \begin{equation}
  \begin{split}
  l(v; q, y, z, w) &= \sum_{i = 1}^N \ln \mathbb{P}\{q_i = q(p, x, y_i, z_i)|p, x, y_i, z_i\}\\
  & = \sum_{i = 1}^N \log \Bigg\{ \prod_{j = 0}^{J} \sigma_{j}(p, x, y_i, z_i)^{q_{ij}} \Bigg\}\\
  &= \sum_{i = 1}^N \sum_{j = 0}^J \log \sigma_{j}(p, x, y_i, z_i)^{q_{ij}}.
  \end{split}
  \end{equation}
\item
  We can estimate the parameters by finding parameters that maximize the log likelihood.
\end{itemize}

\subsection{Nonlinear Least Square Estimation of Multinomial Logit Model}\label{nonlinear-least-square-estimation-of-multinomial-logit-model}

\begin{itemize}
\item
  The multinomial logit model can be estimated by nonlinear least square method as well.
\item
  Suppose that the share of product \(j\) among consumers with characteristics \(z\) and income \(y\) was:
  \begin{equation}
  \sigma_j(p, x, y, z).
  \end{equation}
\item
  Note that:
  \begin{equation}
  \begin{split}
  \ln \sigma_{j}(p, x, y, z)  &= \ln \Bigg\{ \frac{\exp[v(p_j, x_j, y, z) ]}{\sum_{k = 0}^J \exp[v(p_k, x_k, y, z)] }  \Bigg\}\\
  &= v(p_j, x_j, y, z) - \ln\Bigg\{ \sum_{k = 0}^J \exp[v(p_k, x_k, y, z)]  \Bigg\}.
  \end{split}
  \end{equation}
\item
  Moreover, because of the location normalization of the utility function,
  \begin{equation}
  \sigma_{0}(p, x, y, z) = \frac{1}{\sum_{k = 0}^J \exp[v(p_j, x_k, y, z)] }.
  \end{equation}
\item
  Hence,
  \begin{equation}
  \ln \sigma_{j}(p, x, y, z) - \ln \sigma_{0}(p, x, y, z) = v(p, x_j, y, z).
  \end{equation}
\item
  The left-hand variables are observed in the data.
\item
  Let \(s_j(y, z)\) be the share of product \(j\) among consumers with characteristics \(z\) and income \(y\) \textbf{in the data}.
\item
  This can be calculated from the consumer-level data.
\item
  More importantly, if there is the total sales data for each demographic, we can use this approach.
\item
  Then, we can estimate the parameter by NLLS such that:
  \begin{equation}
  \min \sum_{(y, z)} \sum_{j = 1}^J \{\ln[s_{j}(y, z)/s_{0}(y, z)] - v(p_j, x_j, y, z)\}^2.
  \end{equation}
\item
  If \(v\) is linear in parameter, it is the ordinal least squares:
  \begin{equation}
  v(p_j, x_j, y_m) = \beta_i' x_j - \alpha_i p_j.
  \end{equation}
\end{itemize}

\begin{equation}
\ln[s_{j}(y, z)/s_{0}(y, z)] = \beta_i' x_j - \alpha_i p_j.
\end{equation}

\subsection{IIA Problem}\label{iia-problem}

\begin{itemize}
\tightlist
\item
  Multinomial logit problem is intuitive and easy to implement.
\item
  However, there are several problems in the model.
\item
  The most important problem is the \textbf{independence of irrelevant alternatives (IIA)} problem.
\item
  Notice that:
  \begin{equation}
  \frac{\sigma_j(p, x, y, z)}{\sigma_{k}(p, x, y, z)} = \frac{\exp[v(p_j, x_j, y, z)]}{\exp[v(p_k, x_k, y, z)]}.
  \end{equation}
\item
  The ratio of choice probabilities between two alternatives depend only on the mean indirect utility of these two alternatives and \textbf{independent of irrelevant alternatives (IIA)}.
\item
  Why is this a problem?
\end{itemize}

\subsection{Blue Bus and Red Bus Problem}\label{blue-bus-and-red-bus-problem}

\begin{itemize}
\tightlist
\item
  Suppose that you can go to a town by bus or by train.
\item
  Half of commuters use a bus and the other half use a train.
\item
  The existing bus was blue. Now, the county introduced a red bus, which is identical to the existing blue bus.
\item
  No one take care of the color of bus. So the mean indirect utility of blue bus and red bus are equal.
\item
  What is the new share across blue bus, red bus, and train?
\item
  IIA \(\to\) share of blue bus = share of train.
\item
  Buses are identical \(\to\) share of blue bus = share of red bus.
\item
  Therefore, shares have to be 1/3, respectively.
\item
  But shouldn't it be that train keeps half share and bus have half share in total?
\end{itemize}

\subsection{Restrictive Price Elasticity}\label{restrictive-price-elasticity}

\begin{itemize}
\tightlist
\item
  IIA property restrict price elasticities in an unfavorable manner.
\item
  This is a serious problem because the main purpose for us to estimate demand functions is to identify the price elasticity.
\item
  Let \(v(p_j, x_j, y, z) = \beta_z'x_j - \alpha_z p_j\). Then, we have:
  \begin{equation}
  e_{jk} =
  \begin{cases}
  -\alpha p_{j} (1 - \sigma_j(p, x, y, z)) &\text{   if   } k = j\\
  \alpha p_{k} \sigma_k(p_k, x_k, y, z) &\text{   if   } k \neq j.
  \end{cases}
  \end{equation}
\item
  The price elasticity is completely determined by the existing choice probabilities of the relevant alternatives.
\item
  Suppose that there are coca cola, Pepsi cola, and a coffee.
\item
  The shares were 1/2, 1/6, 1/3, respectively.
\item
  Suppose that the price of coca cola increased.
\item
  We expect that they instead purchase Pepsi cola because Pepsi cola is more similar to coca cola than coffee.
\item
  However, according to the previous result, twice more consumers substitute to coffee rather than to Pepsi cola.
\end{itemize}

\subsection{Monotonic Inclusive Value}\label{monotonic-inclusive-value}

\begin{itemize}
\tightlist
\item
  Suppose that there is a good whose mean indirect utility is \(v\).
\item
  The inclusive value for this choice set is \(\ln[1 + \exp(v)]\).
\item
  Suppose that we put \(J\) same goods on the shelf and consumer can choose any of them.
\item
  The inclusive value is \(\ln[1 + J \exp(v)]\).
\item
  We just added the same goods. But the expected utility of consumer increases monotonically in the number of alternatives.
\end{itemize}

\subsection{The Source of the Problem}\label{the-source-of-the-problem}

\begin{itemize}
\tightlist
\item
  \textbf{The source of the problem is that there is no correlation in the preference shock across products}.
\item
  When the preference shock to coca cola is high, the preference shock to Pepsi cola should be high, while the preference shock to coffee should be relatively independent.
\item
  Because the expected value of the maximum of the preference shocks increases according to the number of alternatives, the inclusive value becomes increasing in the number of alternatives.
\item
  However, the preference shocks should be the same for the same good. Then, the the expected value of the maximum of the preference shock should not increase even if we add the same products on the shelf.
\end{itemize}

\subsection{Correlation in Preference Shocks}\label{correlation-in-preference-shocks}

\begin{itemize}
\tightlist
\item
  Therefore, the preference shock should be such that: preference shocks between two alternative should be more correlated when they are closer in the characteristics space.
\item
  So we have to allow the covariance matrix of the preference shock to be free parameters.
\item
  If we allow flexible covariance matrix, the curse of dimensionality in the number of alternatives comes back: The dimensionality of the covariance matrix is \(J^2\).
\item
  Another way is to remove \(\epsilon_{ij}\): it is called a \textbf{pure characteristics model} \citep{Berry2007}.
\item
  But the pure characteristics model is computationally not straightforward.
\item
  We explore the way of introducing mild correlation across similar products in the preference shocks.
\end{itemize}

\subsection{Observed and Unobserved Consumer Heterogeneity}\label{observed-and-unobserved-consumer-heterogeneity}

\begin{itemize}
\tightlist
\item
  Consider beverage demand and let \(x_j = \text{carbonated}_j\) and \(z_i = \text{teenager}_i\).
\item
  Suppose that the mean indirect utility is:
  \begin{equation}
  v(p_j, x_j, y_i, z_i) = \beta_i (\text{carbonated})_j - \alpha_i p_j,
  \end{equation}
\end{itemize}

\begin{equation}
\beta_i = 0.1 + 0.2 \cdot (\text{teenager})_i.
\end{equation}

\begin{itemize}
\item
  The mean utility of a carbonated drink for a teenager is 0.3 but only 0.1 for others.
\item
  When coca cola was not available, teenager will substitute more to Pepsi cola than non-teenagers.
\item
  IIA holds at the market-segment level but not at the market level.
\item
  How to avoid IIA at the market-segment level?: Introduce unobserved consumer heterogeneity.
\item
  Suppose that the mean indirect utility is:
  \begin{equation}
  \beta_i = 0.1 + 0.2 \cdot (\text{teenager})_i + \nu_i.
  \end{equation}
\item
  Consumers with high \(\nu_i\) values carbonated drinks more than those with low \(\nu_i\) values.
\item
  When coca cola was not available, consumers with high \(\nu_i\) will substitute more to Pepsi cola than those with low \(\nu_i\) values.
\item
  IIA holds at the market-segment-\(\nu\) level but not at the market-segment level.
\item
  In the above example, ``\(0.2 \cdot (\text{carbonated})_i\)'' captures the consumer heterogeneity by observed characteristics and ``\(\nu_i\)'' by unobserved characteristics.
\end{itemize}

\subsection{Mixed Logit Model}\label{mixed-logit-model}

\begin{itemize}
\tightlist
\item
  Suppose that the mean indirect utility is:
  \begin{equation}
  v(p_j, x_j, y_i, z_i, \beta_i, \alpha_i) = \beta_i' x_j - \alpha_i p_j,
  \end{equation}
  with
  \begin{equation}
  (\beta_i, \alpha_i) \sim f(\beta_i, \alpha_i|y_i, z_i).
  \end{equation}
\item
  If \(\epsilon_{ij}\) is drawn i.i.d. from type-I extreme value distribution, the choice probability of good \(j\) by consumer \(i\) conditional on \(p, x, y_i, z_i\) is:
  \begin{equation}
  \sigma_{j}(p, x, y_i, z_i) = \int_{\beta_i, \alpha_i} \frac{\exp[v(p_j, x_j, y_i, z_i, \beta_i, \alpha_i)]}{\sum_{k = 0}^J \exp[v(p_j, x_j, y_i, z_i, \beta_i, \alpha_i)]} f(\beta_i, \alpha_i|y_i, z_i) d\beta_i d\alpha_i.
  \end{equation}
\item
  This is called the \textbf{mixed-logit model}.
\item
  If the distribution of \(\epsilon_{ij}\) is different, it is no longer mixed logit.
\item
  Conditional on \((\beta_i, \alpha_i)\) the choice probability is written in the same way with the multinomial logit model.
\item
  \(\beta_i, \alpha_i\) are marginal out, because econometrician does not observe them.
\end{itemize}

\subsection{Mixed Logit Model : Parametric Assumptions}\label{mixed-logit-model-parametric-assumptions}

\begin{itemize}
\tightlist
\item
  It is often assumed that:
  \begin{equation}
  v(p_j, x_j, y_i, z_i, \beta_i, \alpha_i) = \beta_i' x_j - \alpha_i p_j.
  \end{equation}
\item
  \citet{Mcfadden2000} showed that any discrete choice models that are consistent with the random utility maximization can be arbitrarily closely approximated by this class of mixed-logit model.
\item
  The distribution of \(\beta_i\) and \(\alpha_i\) is often assumed to be:
  \begin{equation}
  \begin{split}
  &\beta_i = \beta_0 + \Gamma z_i + \Sigma \nu_i,\\
  &\alpha_i = \alpha_0 + \pi' z_i + \omega \upsilon_i,
  \end{split}
  \end{equation}
  where \(\nu_i\) and \(\upsilon_i\) are i.i.d. standard normal random vectors.
\end{itemize}

\subsection{Mixed Logit Model: IIA}\label{mixed-logit-model-iia}

\begin{itemize}
\tightlist
\item
  There is no IIA at the market-segment level:
  \begin{equation}
  \frac{\sigma_{j}(p, x, y, z)}{\sigma_{l}(p, x, y_i, z_i)} = \frac{\int_{\beta_i, \alpha_i} \frac{\exp[v(p_j, x_j, y_i, z_i, \beta_i, \alpha_i)]}{\sum_{k = 0}^J \exp[v(p_k, x_k, y_i, z_i, \beta_i, \alpha_i)]} f(\beta_i, \alpha_i|x, y_i) d\beta_i d\alpha_i}{\int_{\beta_i, \alpha_i} \frac{\exp[v(p_l, x_l, y_i, z_i, \beta_i, \alpha_i)]}{\sum_{k = 0}^J \exp[v(p_k, x_k, y_i, z_i, \beta_i, \alpha_i)]} f(\beta_i, \alpha_i|x, y_i) d\beta_i d\alpha_i}.
  \end{equation}
\item
  The share ratio depends on the price and characteristics of all the other products.
\end{itemize}

\subsection{Mixed Logit Moel: Price Elasticities}\label{mixed-logit-moel-price-elasticities}

\begin{itemize}
\tightlist
\item
  Let:
  \begin{equation}
  v(p_j, x_j, y_i, z_i, \beta_i, \alpha_i) = \beta_i' x_j - \alpha_i p_j.
  \end{equation}
\item
  The price elasticities of the choice probabilities conditional on \(p, x, y_i, z_i\) is:
  \begin{equation}
  e_{jk} = 
  \begin{cases}
  -\frac{p_j}{\sigma_j} \int \alpha_i \sigma_{ij}(1 - \sigma_{ij})f(\beta_i, \alpha_i|y_i, z_i) d\beta_i d\alpha_i &\text{   if   } j = k\\
  \frac{p_k}{\sigma_j} \int \alpha_i \sigma_{ij} \sigma_{ik} f(\beta_i, \alpha_i|y_i, z_i) d\beta_i d\alpha_i &\text{   otherwise},
  \end{cases} 
  \end{equation}
  where
  \begin{equation}
  \sigma_{ij} = \frac{\exp(\beta_i'x_j - \alpha_i p_j)}{\sum_{k = 0}^J \exp(\beta_i'x_k - \alpha_i p_k)}.
  \end{equation}
\item
  The price elasticity depends on the density of unobserved consumer types.
\end{itemize}

\subsection{Simulated Maximum Likelihood Estimation of the Mixed Logit Model}\label{simulated-maximum-likelihood-estimation-of-the-mixed-logit-model}

\begin{itemize}
\tightlist
\item
  The choice probability of the mixed logit model is an integration of the multinomial logit choice probability.
\item
  This is not derived analytically in general.
\item
  We can use simulation to evaluate the choice probability:
\item
  Draw \(R\) values of \(\beta\) and \(\alpha\), \(\{\beta^r, \alpha^r \}_{r = 1}^R\).
\item
  Compute the multinomial choice probabilities associated with \((\beta^r, \alpha^r)\) for each \(r = 1, \cdots, R\).
\item
  Approximate the choice probability with the mean of the simulated multinomial choice share:
  \begin{equation}
  \sigma_{j}(p, x, y_i, z_i) \approx \hat{\sigma}_{j}(p, x, y_i, z_i) \equiv \frac{1}{R} \sum_{r = 1}^R  \frac{\exp[v(p_j, x_j, y_i, z_i, \beta^r, \alpha^r)]}{\sum_{k = 0}^J \exp[v(p_k, x_k, y_i, z_i, \beta^r, \alpha^r)]}.
  \end{equation}
\item
  This is one of the numerical integration: \textbf{Monte Carlo integration}.
\item
  Another approach is to use \textbf{quadrature}. See \citet{Judd1998} for reference.
\end{itemize}

\subsection{Simulated Maximum Likelihood Estimation of the Mixed Logit Model}\label{simulated-maximum-likelihood-estimation-of-the-mixed-logit-model-1}

\begin{itemize}
\item
  There are \(t = 1, \cdots, T\) markets and there \(i = 1, \cdots, N\) consumers in each market.
\item
  Let \(\mathcal{J}_t\) be the set of products that are available in market \(t\).
\item
  Suppose that we observe income \(y_{it}\), characteristics \(z_{it}\), and choice \(q_{it}\) for each consumer in a market.
\item
  Suppose that we observe product characteristics \(x_{jt}\) and price \(p_{jt}\) of each product in each market.
\item
  The simulated conditional log likelihood is:
  \begin{equation}
  \begin{split}
  &\sum_{i = 1}^N \sum_{t = 1}^T \ln \mathbb{P}\{q_{it} = q(p_t, x_t, y_{it}, z_{it})|p_t, x_t, y_{it}, z_{it}\} \\
  &\approx \sum_{i = 1}^N \sum_{t = 1}^T \ln \Bigg\{ \prod_{j \in \mathcal{J}_t \cup \{0\}} \hat{\sigma}_{j}(p_t, x_t, y_{it}, z_{it})^{q_{itj}} \Bigg\}.
  \end{split}
  \end{equation}
\item
  We find parameters that maximize the simulated conditional log likelihood.
\end{itemize}

\subsection{Simulated Non-linear Least Square Estimation of the Mixed Logit Model}\label{simulated-non-linear-least-square-estimation-of-the-mixed-logit-model}

\begin{itemize}
\tightlist
\item
  Suppose that we only know the sales or share at the market-segment level.
\item
  That is, we only observe the share of product \(j\) in market \(t\) among consumers of characteristics \(z\) and income \(y\), \(s_{jt}(y, z)\).
\item
  Then we can estimate the parameter by:
  \begin{equation}
  \min \sum_{t = 1}^T \sum_{j \in \mathcal{J}_t \cup \{0\}} \sum_{(y, z) \in \mathcal{Y} \times \mathcal{Z}} \{s_{jt}(y, z) - \hat{\sigma}_{j}(p_t, x_t, y, z)\}^2.
  \end{equation}
\end{itemize}

\subsection{Numerical Integration with Quadrature}\label{numerical-integration-with-quadrature}

\begin{itemize}
\tightlist
\item
  Refer to Section 7 of \citet{Judd1998}.
\item
  Gauss-Hermite Quadrature uses the following approximation:
  \begin{equation}
  \int_{-\infty}^\infty f(x) e^{-x^2} dx \approx \sum_{i = 1}^n \omega_i f(x_i) + \frac{n\! \sqrt{\pi}}{2^n} \frac{f^{(2n)}(\xi)}{(2n)\!}
  \end{equation}
  for some \(\xi \in (-\infty, \infty)\).
\item
  \(x_i\) are the roots of the Hermite polynomial and \(w_i\) are the weights.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pracma}\SpecialCharTok{::}\FunctionTok{gaussHermite}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $x
## [1] -2.020183e+00 -9.585725e-01  8.881784e-16  9.585725e-01  2.020183e+00
## 
## $w
## [1] 0.01995324 0.39361932 0.94530872 0.39361932 0.01995324
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pracma}\SpecialCharTok{::}\FunctionTok{gaussHermite}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $x
##  [1] -3.4361591 -2.5327317 -1.7566836 -1.0366108 -0.3429013  0.3429013
##  [7]  1.0366108  1.7566836  2.5327317  3.4361591
## 
## $w
##  [1] 7.640433e-06 1.343646e-03 3.387439e-02 2.401386e-01 6.108626e-01
##  [6] 6.108626e-01 2.401386e-01 3.387439e-02 1.343646e-03 7.640433e-06
\end{verbatim}

\begin{itemize}
\tightlist
\item
  In general, when \(Y\) follows a normal distribution of mean \(\mu\) and standard deviation \(\sigma\), we have:
  \begin{equation}
  \begin{split}
  \mathbb{E}\{f(Y)\} &= (2 \pi \sigma^2)^{-1/2} \int_{-\infty}^\infty f(y) e^{-\frac{(y - \mu)^2}{2\sigma^2}} dy \\
  &=(2 \pi \sigma^2)^{-1/2} \int_{-\infty}^\infty f(\mu + \sqrt{2} \sigma z) e^{- z^2} \sqrt{2} \sigma dz \\
  &=\pi^{-1/2} \int_{-\infty}^\infty f(\mu + \sqrt{2} \sigma z) e^{- z^2} dz \\
  &\approx \pi^{-1/2} \sum_{i = 1}^n \omega_i f(\mu + \sqrt{2} \sigma z_i).
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Nested Logit Model: A Special Case of Mixed Logit Model}\label{nested-logit-model-a-special-case-of-mixed-logit-model}

\begin{itemize}
\tightlist
\item
  Let \(w_{j1}, \cdots, w_{jG}\) be the indicator of product category, i.e., \(w_{jg}\) takes value 1 if good \(j\) belong to category \(g\) and 0 otherwise.
\item
  e.g., car category = \{Sports, Luxury, Large, Midsize, Small\}.
\item
  We have:
  \begin{equation}
  v(p, x_j, y_i, z_i) = \beta'x_j - \alpha_i p_j + \sum_{g = 0}^G \zeta_{ig} w_{jg} + \epsilon_{ij}.
  \end{equation}
\item
  If \(\zeta_{ig}\) takes high value, the consumer attaches higher value to the category.
\item
  When a product in category \(g\) was not available, consumers with high \(\zeta_{ig}\) will substitute more to the other products in the same category than consumers with low \(\zeta_{ig}\).
\end{itemize}

\subsection{Nested Logit Model: Distributional Assumption}\label{nested-logit-model-distributional-assumption}

\begin{itemize}
\tightlist
\item
  Let
  \begin{equation}
  \varepsilon_{ij} \equiv \sum_{g = 0}^G \zeta_{ig} w_{jg} + \epsilon_{ij}.
  \end{equation}
\item
  Under certain distributional assumption on \(\zeta_{ig}\) and \(\epsilon_{ij}\), the term \(\varepsilon_{ij}\) have a cumulative distribution \citep{Cardell1997}:
  \begin{equation}
  F(\varepsilon_i) = \exp\Bigg\{- \sum_{g = 0}^G \Bigg(\sum_{j \in \text{   category   } g} \exp[-\varepsilon_{ij}/\lambda_g] \Bigg)^{\lambda_g}  \Bigg\}.
  \end{equation}
\end{itemize}

\subsection{Nested Logit Model: Choice Probability}\label{nested-logit-model-choice-probability}

\begin{itemize}
\tightlist
\item
  Under this distributional assumption, the choice probability is:
  \begin{equation}
  \sigma_{j}(p, x, y_i, z_i) = \frac{\exp[v(p, x_j, y_i, z_i)/\lambda_g] \Bigg(\sum_{k \in \text{   category   } g} \exp[v(p, x_k, y_i, z_i)/\lambda_g]\Bigg)^{\lambda_g - 1}}{\sum_{g = 0}^G \Bigg(\sum_{k \in \text{   category   } g} \exp[v(p, x_k, y_i, z_i)/\lambda_g]\Bigg)^{\lambda_g}},
  \end{equation}
  if good \(j\) belongs to category \(g\).
\item
  The higher \(\lambda_g \in [0, 1]\) implies lower correlation within category \(g\).
\item
  \(\lambda_g = 0\) for all \(g\) coincides with the multinomial logit model.
\end{itemize}

\subsection{Nested Logit Model: Decomposition of the Choice Probability}\label{nested-logit-model-decomposition-of-the-choice-probability}

\begin{itemize}
\tightlist
\item
  The choice probability can be decomposed into two parts:
  \begin{equation}
  \begin{split}
  &\sigma_{j}(p, x, y_i, z_i)\\
  &= \frac{\exp[v(p, x_j, y_i, z_i)/\lambda_g]}{\sum_{k \in \text{   category   } g} \exp[v(p, x_k, y_i, z_i)/\lambda_g]} \frac{\left(\sum_{k \in \text{   category   } g} \exp[v(p, x_k, y_i, z_i)/\lambda_g]\right)^{\lambda_g}}{\sum_{g = 0}^G \Bigg(\sum_{k \in \text{   category   } g} \exp[v(p, x_k, y_i, z_i)/\lambda_g]\Bigg)^{\lambda_g}}.
  \end{split}
  \end{equation}
\item
  Letting:
  \[
  I_{g}(p, x, y_i, z_i) \equiv \log \sum_{k \in \text{   category   } g} \exp[v(p, x_k, y_i, z_i)/\lambda_g],
  \]
  we have:
  \begin{equation}
  \sigma_{j}(p, x, y_i, z_i) = \frac{\exp[v(p, x_j, y_i, z_i)/\lambda_g]}{\sum_{k \in \text{   category   } g} \exp[v(p, x_k, y_i, z_i)/\lambda_g]} \frac{\exp[\lambda_g I_{g}(p, x, y_i, z_i)]}{\sum_{g = 0}^G \exp[\lambda_g I_{g}(p, x, y_i, z_i)]}.
  \end{equation}
\item
  The second first term can be interpreted as the probability of choosing product \(j\) conditional on choosing category \(g\) and the second term as the probability of choosing category \(g\).
\end{itemize}

\subsection{Nested Logit Mode: Outside, Inside-Category, and Category-specific Shares}\label{nested-logit-mode-outside-inside-category-and-category-specific-shares}

\begin{itemize}
\tightlist
\item
  With the outside good as the only member of group zero and \(\delta_0 = 0\) and \(I_0 = 1\), we have:
  \begin{equation}
  \sigma_{0}(p, x, y_i, z_i) = \frac{1}{\sum_{g = 0}^G \exp[\lambda_g I_{g}(p, x, y_i, z_i)]}.
  \end{equation}
\item
  Moreover, the inside-category share of good \(j\) is
  \begin{equation}
  \begin{split}
  \sigma_{j|g}(p, x, y_i, z_i) 
  &\equiv \frac{\sigma_{j}(p, x, y_i, z_i)}{\sum_{k \in \text{   category   } g} \sigma_{k}(p, x, y_i, z_i)}\\
  &= \frac{v(p, x_j, y_i, z_i)/\lambda_g}{\sum_{k \in \text{   category   } g} v(p, x_k, y_i, z_i)/\lambda_g},
  \end{split}
  \end{equation}
  and the share of category \(g\) is
  \begin{equation}
  \begin{split}
  \sigma_g(p, x, y_i, z_i) 
  &\equiv \frac{\sum_{j \in \text{   category   } g} \sigma_{j}(p, x, y_i, z_i)}{\sum_{g = 0}^G \sum_{j \in \text{   category   } g} \sigma_{j}(p, x, y_i, z_i)}\\
  &= \frac{\exp[\lambda_g I_{g}(p, x, y_i, z_i)]}{\sum_{g = 0}^G \exp[\lambda_g I_{g}(p, x, y_i, z_i)]}.
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Nonlinear Least Square Estimation of Nested Logit Model}\label{nonlinear-least-square-estimation-of-nested-logit-model}

\begin{itemize}
\tightlist
\item
  We can estimate the parameters of nested logit model by maximum likelihood estimation.
\item
  In addition, we can also use the nonlinear least square estimation following \citet{berryEstimatingDiscreteChoiceModels1994}.
\item
  We have
  \begin{equation}
  \begin{split}
  \ln \sigma_{j}(p, x, y_i, z_i) - \ln \sigma_{0}(p, x, y_i, z_i) = \frac{v(p, x_j, y_i, z_i)}{\lambda_g} - (1 - \lambda_g) I_g(p, x, y_i, z_i).
  \end{split}
  \end{equation}
\item
  Moreover,
  \begin{equation}
  \begin{split}
  I_g(p, x, y_i, z_i) = \frac{\ln s_g(p, x, y_i, z_i) - \ln s_0(p, x, y_i, z_i)}{\lambda_g}.
  \end{split}
  \end{equation}
\item
  Inserting this to the former and arranging it, we get
  \begin{equation}
  \begin{split}
  \ln \sigma_{j}(p, x, y_i, z_i) - \ln \sigma_{0}(p, x, y_i, z_i) = v(p, x_j, y_i, z_i) + (1 - \lambda_g) \ln s_{j|g}(p, x, y_i, z_i).
  \end{split}
  \end{equation}
\item
  Replacing shares with data, we can estimate the parameters a non-linear least square estimation.
\item
  If \(v\) is linear in parameters, we can use the linear least square estimation.
\item
  We need instruments for i) price \(p_j\) and ii) inside-category share \(s_{j|g}\), respectively.
\item
  If \(\lambda_g\) is heterogeneous across categories, we need instruments for each of them.
\item
  The number of goods in each category is often used as such instruments.
\item
  This requires variations in the available goods across markets, and the entry and exit to be exogenous.
\item
  These variations are implicitly required in the maximum likelihood estimation, too.
\item
  This also means that mixed-logit model also requires these variations for its identification.
\end{itemize}

\subsection{Discrete Choice Model with Unobserved Fixed Effects}\label{discrete-choice-model-with-unobserved-fixed-effects}

\begin{itemize}
\tightlist
\item
  We have assumed that good \(j\) is characterized by a vector of observed characteristics \(x_j\).
\item
  Can econometrician observe all the relevant characteristics of the products in the choice set? Maybe no. For example, econometrician may not observe brand values that are created by advertisement and recognized by consumers.
\item
  Such unobserved product characteristics is likely to be correlated with the price.
\item
  This can cause \textbf{endogeneity problems}.
\item
  In the following, we consider the situation where only market-segment level share data is available.
\item
  Because we can construct the market-share level data from individual choice level data, all the arguments should go through with the individual choice level data.
\end{itemize}

\subsection{Unobserved Fixed Effects in Multinomial Logit Model}\label{unobserved-fixed-effects-in-multinomial-logit-model}

\begin{itemize}
\tightlist
\item
  To fix the idea, let's revisit the multinomial logit model.
\item
  For now, we do not consider either observed or unobserved consumer heterogeneity.
\item
  Including observed heterogeneity is straightforward.
\item
  We discuss how to include unobserved heterogeneity in the subsequent sections.
\item
  Suppose that the indirect utility function of good \(j\) for consumer \(i\) in market \(t\) is:
  \begin{equation}
  \beta' x_{jt}  - \alpha p_{jt} + \xi_{jt} + \epsilon_{ijt},
  \end{equation}
\item
  \(\epsilon_{ijt}\) is i.i.d. Type-I extreme value.
\item
  \(\xi_{jt}\) is the \emph{unobserved product-market-specific fixed effect} of product \(j\) in market \(t\), which can be correlated with \(p_{jt}\).
\item
  We hold the assumption that \(x_{jt}\) is uncorrelated with \(\xi_{jt}\).
\item
  The choice probability of good \(j\) for this consumer and hence the choice share in this market is:
\end{itemize}

\begin{equation}
\sigma_j(p_t, x_t, \xi_t) = \frac{\exp(\beta' x_j - \alpha p_{jt} + \xi_{jt})}{1 + \sum_{k = 1}^J\exp(\beta' x_k - \alpha p_{kt} +  \xi_{kt} ) }.
\end{equation}
- How to deal with the endogeneity between \(p_{jt}\) and \(\xi_{jt}\)?

\subsection{Instrumental Variables and Inversion}\label{instrumental-variables-and-inversion}

\begin{itemize}
\tightlist
\item
  Suppose that we have a vector of instrumental variables \(w_{jt}\) such that:
  \begin{equation}
  \mathbb{E}\{\xi_{jt}|w_{jt}\} = 0.
  \end{equation}
\item
  In a liner model, we \textbf{invert} the model for the unobserved fixed effects:
  \begin{equation}
  \xi_{jt} = y_{jt} - \beta'x_{jt},
  \end{equation}
\item
  Notice that the unobserved fixed effect is written as a function of parameters and data.
\item
  Then we exploit the moment condition by:
  \begin{equation}
  \begin{split}
  &\mathbb{E}\{\xi_{jt}|w_{jt}\} = 0,\\
  &\Rightarrow \mathbb{E}\{ \xi_{jt} w_{jt}\} = 0,\\
  &\Leftrightarrow \mathbb{E}\{(y_{jt} - \beta'x_{jt}) w_{jt} \} = 0
  \end{split}
  \end{equation}
\item
  We can estimate \(\beta\) by finding the value that makes the sample analogue of the above expectation zero.
\end{itemize}

\subsection{Inversion in Multinomial Logit Model}\label{inversion-in-multinomial-logit-model}

\begin{itemize}
\tightlist
\item
  Can we invert the multinomial model for \(\xi_{jt}\)?
\item
  We have:
  \begin{equation}
  \begin{split}
  &\ln [\sigma_{jt}(p_t, x_t, \xi_t) / \sigma_{0t}(p_t, x_t, \xi_t)] = \beta' x_j - \alpha p_{jt} + \xi_{jt}\\
  &\Leftrightarrow \xi_{jt} = \ln [\sigma_j(p_t, x_t, \xi_t) / \sigma_0(p_t, x_t, \xi_t)] - [\beta' x_j - \alpha p_{jt}].
  \end{split}
  \end{equation}
\item
  Therefore, the moment condition can be written as:
  \begin{equation}
  \begin{split}
  &\mathbb{E}\{\xi_{jt}|w_{jt}\} = 0,\\
  &\Rightarrow \mathbb{E}\{\xi_{jt} w_{jt}\} = 0,\\
  &\Leftrightarrow \mathbb{E}\{(\ln [\sigma_{jt}(p_t, x_t, \xi_t) / \sigma_{0t}(p_t, x_t, \xi_t)] - [\beta' x_j - \alpha p_{jt}]) w_{jt}  \} = 0.
  \end{split}
  \end{equation}
\item
  We can evaluate the sample analogue of the expectation by replacing the theoretical choice probability \(\sigma\)
  with the observed share \(s\).
\item
  At the end, it is no different from the linear model where the dependent variable is \(\ln s_{jt}/s_{0t}\).
\end{itemize}

\subsection{Market-invariant Product-specific Fixed Effects}\label{market-invariant-product-specific-fixed-effects}

\begin{itemize}
\tightlist
\item
  Furthermore, if you can assume \(\xi_{jt} = \xi_j\), then
  \begin{equation}
  \ln [\sigma_j(p_t, x_t, \xi_t) / \sigma_0(p_t, x_t, \xi_t)] = \beta' x_{jt} - \alpha p_{jt} + \xi_{j}.
  \end{equation}
\item
  This is nothing but a linear regression on \(x_j\) and \(p_{jt}\) with product-specific unobserved fixed effect.
\item
  This can be estimated by a within-estimator.
\item
  This specification is a good starting point: we better start with the simplest specification and use the estimate as the initial guess for the following specifications.
\end{itemize}

\subsection{Unobserved Consumer Heterogeneity and Unobserved Fixed Effects in Mixed-logit Model}\label{unobserved-consumer-heterogeneity-and-unobserved-fixed-effects-in-mixed-logit-model}

\begin{itemize}
\tightlist
\item
  So far we abstracted away from the unobserved consumer heterogeneity.
\item
  Next, suppose that the indirect utility function of good \(j\) for consumer \(i\) in market \(t\) is:
  \begin{equation}
  \beta_i' x_{jt}  - \alpha_i p_{jt} + \xi_{jt} + \epsilon_{ijt},
  \end{equation}
  where \(\epsilon_{ik}\) is i.i.d. Type-I extreme value.
\item
  The coefficient are drawn according to:
  \begin{equation}
  \begin{split}
  &\beta_{it} = \beta_0 + \Sigma \nu_{it},\\
  &\alpha_{it} = \alpha_0 + \Omega \upsilon_{it},
  \end{split}
  \end{equation}
\item
  \(\nu_i\) are i.i.d. standard normal random variables.
\item
  Then the indirect utility of good \(j\) for consumer \(i\) in market \(t\) is written as:
  \begin{equation}
  \underbrace{\beta_0' x_{jt} - \alpha_0 p_{jt} + \xi_{jt}}_{\text{(conditional) mean}} + \underbrace{\nu_{it}' \Sigma x_{jt} - \upsilon_{it}' \Omega p_{jt}}_{\text{deviation from the mean}} 
  \end{equation}
\item
  We refer to \(\beta_0, \alpha_0\) as \textbf{linear parameters} and \(\Sigma, \Omega\) as \textbf{non-linear parameters}, because of the reason I explain in the subsequent section.
\item
  Let \(\theta_1\) be the linear parameters and \(\theta_2\) the non-linear parameters and let \(\theta = (\theta_1', \theta_2')'\).
\end{itemize}

\subsection{Unobserved Fixed Effects in Mixed-logit Model}\label{unobserved-fixed-effects-in-mixed-logit-model}

\begin{itemize}
\tightlist
\item
  The choice share of good \(j\) in market \(t\) is:
  \begin{equation}
  \begin{split}
  &\sigma_{j}(p_t, x_t, \xi_t; \theta)\\
  &= \int \frac{\exp[\beta_0' x_{jt} - \alpha_0 p_{jt} + \xi_{jt} + \nu_{it}' \Sigma x_{jt} - \upsilon_{it}' \Omega p_{jt}]}{1 + \sum_{k \in \mathcal{J}_t} \exp[\exp[\beta_0' x_{kt} - \alpha_0 p_{kt} + \xi_{kt} + \nu_{it}' \Sigma x_{kt} - \upsilon_{it}' \Omega p_{kt}]]} f(\nu, \upsilon) d \nu d \upsilon.
  \end{split}
  \end{equation}
\item
  How can we represent \(\xi_{jt}\) as a function of parameters of interest to exploit the moment condition?
\end{itemize}

\subsection{\texorpdfstring{Representing \(\xi_{jt}\) as a Function of Parameters of Interest}{Representing \textbackslash xi\_\{jt\} as a Function of Parameters of Interest}}\label{representing-xi_jt-as-a-function-of-parameters-of-interest}

\begin{itemize}
\tightlist
\item
  Let \(s_{jt}\) be the share of product \(j\) in market \(t\).
\item
  The following system of equations implicitly determines \(\xi_{jt}\) as a function of parameters of interest:
  \begin{equation}
  s_{jt} = \sigma_j(p_t, x_t, \xi_t; \theta).
  \end{equation}
\item
  Let \(\xi_{jt}(\theta)\) is the solution to the system of equations above given parameter \(\theta\).
\item
  If it exists, it is the unobserved heterogeneity as a function of parameters and data.
\item
  Does this solution exist?
\item
  Is it unique?
\item
  Is there efficient method to find the solution?
\end{itemize}

\subsection{Summarizing the Conditional Mean Term}\label{summarizing-the-conditional-mean-term}

\begin{itemize}
\tightlist
\item
  Now, let \(\delta_{jt}\) be the conditional mean term in the indirect utility:
  \begin{equation}
  \delta_{jt} \equiv \beta_0' x_{jt} - \alpha_0 p_{jt} + \xi_{jt}.
  \end{equation}
\item
  I call it the average utility of the product in the market.
\item
  Then, the choice share of product \(j\) in market \(t\) is written as:
  \begin{equation}
  \begin{split}
  &\sigma_{jt}(\delta_t, \theta_2) \\
  &\equiv \int \frac{\exp\Bigg(\delta_{jt} + \nu' \Sigma x_{jt} - \upsilon' \Omega p_{jt}\Bigg)}{1 + \sum_{k \in \mathcal{J}_t} \exp\Bigg(\delta_{kt} + \nu' \Sigma x_{kt} - \upsilon' \Omega p_{kt}\Bigg)} f(\nu, \upsilon) d\nu d\upsilon,
  \end{split}
  \end{equation}
  for \(j = 1, \cdots, J, t = 1, \cdots, T\).
\end{itemize}

\subsection{\texorpdfstring{Contraction Mapping for \(\delta_t\).}{Contraction Mapping for \textbackslash delta\_t.}}\label{contraction-mapping-for-delta_t.}

\begin{itemize}
\tightlist
\item
  Now, fix \(\theta_2\) and define an operator \(T\) such that:
  \begin{equation}
  T_t(\delta_t) = \delta_t + \ln \underbrace{s_{t}}_{\text{data}} - \ln \underbrace{\sigma_{t}(\delta_t, \theta_2)}_{\text{model}},
  \end{equation}
  where \(\delta_t = (\delta_{1t}, \cdots, \delta_{Jt})'\), \(s_t = (s_{1t}, \cdots, s_{Jt})'\) and \(\sigma_t = (\sigma_{1t}, \cdots, \sigma_{Jt})'\).
\item
  Let \(\delta_t^{(0)} = (\delta_{1t}^{(0)}, \cdots, \delta_{Jt}^{(0)})'\) be an arbitrary starting vector of average utility of products in a market.
\item
  Using the operator above, we update \(\delta_{t}^{(r)}\) by:
  \begin{equation}
  \delta_{t}^{(r + 1)} = T_t(\delta_{t}^{(r)}) = \delta_t^{(r)} + \ln s_{t} - \ln \sigma_{t}(\delta_t^{(r)}, \theta_2),
  \end{equation}
  for \(r = 0, 1, \cdots\).
\item
  \citet{berryAutomobilePricesMarket1995} proved that \(T_t\) as specified above is a \textbf{contraction mapping with modulus less than one}.
\item
  This means that:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(T_t\) has a unique fixed point;
  \item
    For arbitrary \(\delta_t^{(r)}\), \(\lim_{r \to \infty} T_t^r(\delta_t^{(0)})\) is the unique fixed point.
  \end{enumerate}
\item
  The fixed point of \(T_t\) is \(\delta_t^*\) such that \(\delta_t^* = T_t(\delta_t^*)\), i.e.,
  \begin{equation}
  \begin{split}
  &\delta_t^* = \delta_t^* + \ln s_{t} - \ln \sigma_{t}(\delta_t^*, \theta_2),\\
  &\Leftrightarrow s_{t} = \sigma_{t}(\delta_t^*, \theta_2).
  \end{split}
  \end{equation}
\item
  So, the fixed point \(\delta_t^*\) is the conditional mean indirect utility that solves the equality given non-linear parameter \(\theta_2\).
\item
  Moreover, the solution is unique.
\item
  Moreover, it can be found by iterating the operator.
\item
  Let \(\delta_t(\theta_2)\) be the solution to this equation, i.e., the limit of this operation.
\item
  The above result is useful because it ensures the inversion and provides the algorithm to find the solution.
\item
  The invertibility itself holds under more general settings \citep{Berry2013}.
\end{itemize}

\subsection{\texorpdfstring{Solving for \(\xi_{jt}(\theta)\)}{Solving for \textbackslash xi\_\{jt\}(\textbackslash theta)}}\label{solving-for-xi_jttheta}

\begin{itemize}
\tightlist
\item
  We defined the average utility as:
  \begin{equation}
  \delta_{jt} =  \beta_0' x_{jt} - \alpha_0 p_{jt} + \xi_{jt}.
  \end{equation}
\item
  Hence, if we set:
  \begin{equation}
  \xi_{jt}(\theta) \equiv \delta_{jt}(\theta_2) - \Bigg[\beta_0' x_{jt} - \alpha_0 p_{jt} \Bigg],
  \end{equation}
  the \(\xi_{jt}(\theta)\) solves the equality:
  \begin{equation}
  s_{jt} = \sigma_{j}(p_t, x, \xi_t; \theta).
  \end{equation}
\end{itemize}

\subsection{\texorpdfstring{Solving for \(\xi_{jt}(\theta)\): Summary}{Solving for \textbackslash xi\_\{jt\}(\textbackslash theta): Summary}}\label{solving-for-xi_jttheta-summary}

\begin{itemize}
\tightlist
\item
  In summary, \(\xi_{jt}\) that solves the equality exists and unique, and can be computed by:
\item
  Fix \(\theta = \{\theta_1, \theta_2\}\).
\item
  Fix arbitrary starting value \(\delta_t^{(0)}\) for \(t = 1, \cdots, T\).
\item
  Let \(\delta_t(\theta_2)\) be the limit of \(T_t^r(\delta_t^{(0)})\) for \(r = 0, 1, \cdots\) for each \(t = 1, \cdots, T\).
\item
  Stop the iteration if \(|\delta_t(\theta_2)^{(r + 1)} - \delta_t(\theta_2)^{(r)}|\) is below a threshold.
\item
  Let \(\xi_{jt}(\theta)\) be such that:
  \begin{equation}
  \xi_{jt}(\theta) = \delta_{jt}(\theta_2) - \beta_0' x_{jt} - \alpha_0 p_{jt}.
  \end{equation}
\item
  Then we can evaluate the moment at \(\theta\) by:
  \begin{equation}
  \mathbb{E}\{\xi_{jt}(\theta)|w_{jt}\} = 0.
  \end{equation}
\item
  We run this algorithm every time we evaluate the moment condition at a parameter value.
\end{itemize}

\subsection{GMM Objective Function}\label{gmm-objective-function}

\begin{itemize}
\tightlist
\item
  Find \(\theta\) that solves:
  \begin{equation}
  \min_{\theta} \xi(\theta)' W \Phi^{-1} W' \xi(\theta),
  \end{equation}
  where \(\Phi\) is a weight matrix,
  \begin{equation}
  \xi(\theta) = 
  \begin{pmatrix}
  \xi_{11}(\theta)\\
  \vdots\\
  \xi_{J_1 1}(\theta)\\
  \vdots\\
  \xi_{1T} \\
  \vdots\\
  \xi_{J_T T}
  \end{pmatrix},
  W = 
  \begin{pmatrix}
  w_{11}' \\
  \vdots \\
  w_{J_11}' \\
  \vdots \\
  w_{1T}' \\
  \vdots \\
  w_{J_TT}' \\
  \end{pmatrix}.
  \end{equation}
\item
  There are \(J \to \infty\) and \(T \to \infty\) asymptotics. Either is fine to consistently estimate the parameters.
\item
  \(w_{jt} = (x_{jt}', w_{jt}^*)'\) where \(w_{jt}^*\) is an excluded instrument that is relevant to \(p_{jt}\).
\end{itemize}

\subsection{Estimating Linear Parameters}\label{estimating-linear-parameters}

\begin{itemize}
\tightlist
\item
  The first-order condition for \(\theta_1\) is:
  \begin{equation}
  \theta_1 = (X_1'W \Phi^{-1} W'X_1)^{-1} X_1' W \Phi^{-1} W' \delta(\theta_2),
  \end{equation}
  where
  \begin{equation}
  X_1 = 
  \begin{pmatrix}
  x_{11}' & - p_{11}\\
  \vdots & \vdots \\
  x_{J_1 1}' & - p_{J_1 1}\\
  \vdots & \vdots \\
  x_{1T}' & - p_{1T}\\
  \vdots & \vdots \\
  x_{J_T T} & - p_{J_T T}
  \end{pmatrix},
  \delta(\theta_2) =
  \begin{pmatrix}
  \delta_1(\theta_2)\\
  \vdots\\
  \delta_T(\theta_2)
  \end{pmatrix}
  \end{equation}.
\item
  If \(\theta_2\) is given, the optimal \(\theta_1\) is computed by the above formula.
\item
  \(\rightarrow\) We only have to search over \(\theta_2\).
\item
  This is the reason why we called \(\theta_1\) linear parameters and \(\theta_2\) non-linear parameters.
\end{itemize}

\subsection{BLP Algorithm}\label{blp-algorithm}

\begin{itemize}
\tightlist
\item
  Find \(\theta_2\) that maximizes the GMM objective function.
\item
  To do so:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pick up \(\theta_2\).
\item
  Compute \(\delta(\theta_2)\) by the fixed-point algorithm.
\item
  Compute associated \(\theta_1\) by the formula:
  \begin{equation}
  \theta_1 = (X_1'W \Phi^{-1} W'X_1)^{-1} X_1' W \Phi^{-1} W' \delta(\theta_2),
  \end{equation}
\item
  Compute \(\xi(\theta)\) from the above \(\delta(\theta_2)\) and \(\theta_1\).
\item
  Evaluate the GMM objective function with the \(\xi(\theta)\).
\end{enumerate}

\subsection{Mathematical Program with Equilibrium Constraints (MPEC)}\label{mathematical-program-with-equilibrium-constraints-mpec}

\begin{itemize}
\tightlist
\item
  In the BLP algorithm, for each parameter \(\theta\), find \(\xi(\theta)\) that solve:
  \begin{equation}
  s = \sigma(p, x, \xi; \theta)
  \end{equation}
  by the fixed-point algorithm and then evaluate the GMM objective function.
\item
  This inner loop takes time if the stopping criterion is tight.
\item
  If the stopping criterion is loose, the loop may stop earlier but the error may be unacceptably large.
\item
  \citet{Dube2012} suggest to minimize the GMM objective function with the above equation as the constraints.
  \begin{equation}
  \min_{\theta} \xi(\theta)' W \Phi^{-1} W' \xi(\theta) \text{   s.t.   } s = \sigma(p, x, \xi; \theta).
  \end{equation}
\item
  To enjoy the benefit of this approach, we have to analytically derive the gradient and hessian of the objective function and the constraints, which are anyway needed if we estimate the standard error with the plug-in method.
\item
  If the problem is of small scale, BLP algorithm will be fast enough and easier to implement.
\item
  If the problem is of large scale, you may better use the MPEC approach.
\end{itemize}

\subsection{Control Function Approach}\label{control-function-approach}

\begin{itemize}
\tightlist
\item
  The BLP method requires a share data. It does not work when each consumer face different choice set.
\item
  How to deal with the endogeneity between the price and unobserved fixed effect in such a case?
\item
  The equilibrium price vector in a market is determined by product characteristics, and productivity and demand conditions.
\item
  It will depends on the unobserved product characteristics \(\xi_{jt}\).
\item
  Suppose that the equilibrium price vector in a market is determined by:
  \begin{equation}
  p_{t} = P(x_t, w_t, \xi_t),
  \end{equation}
  where \(w_t\) is a vector of variables that affect the price but are excluded from the indirect utility function.
\item
  If we can estimate it and it is invertible in \(\xi_t\), then, we can have a proxy for \(\xi_t\) such as:
  \begin{equation}
  \hat{\xi}_t = \hat{P}^{-1}(x_t, z_t).
  \end{equation}
\item
  If we insert this into the previous models, \(\xi_{jt}\) is no longer \textbf{unobserved} product characteristics.
\end{itemize}

\subsection{Control Function Approach}\label{control-function-approach-1}

\begin{itemize}
\tightlist
\item
  For example, suppose that \(\xi_{jt}\) is decomposed into anticipated shock \(\nu_{jt}\) and ex-post shock \(\eta_{jt}\) as
  \begin{equation}
  \xi_{jt} = \rho \nu_{jt} + \eta_{jt}.
  \end{equation}
\item
  Then, the equilibrium price should only depend on the anticpated shock as
  \begin{equation}
  p_{jt} = \beta x_{jt} + \gamma w_{jt} + \nu_{jt}.
  \end{equation}
\item
  \(p_{jt}\) and \(\xi_{jt}\) are correlated due to ex-ante shock \(\nu_{jt}\).
\item
  In the first stage, regress \(p_{jt}\) on \(x_{jt}\) and \(w_{jt}\) to obtain \(\hat{\beta}\) and \(\hat{\gamma}\).
\item
  Then, construct \(\hat{\nu}_{jt} = p_{jt} - \hat{\beta} x_{jt} - \hat{\gamma} w_{jt}\).
\item
  Then, we have \(\xi_{jt} = \rho \hat{\nu}_{jt} + \eta_{jt}\).
\item
  In the second stage, insert this into the choice probability.
\item
  \(\eta_{jt}\) is an unobserved \textbf{random} shock.
\item
  We integrate \(\eta_{jt}\) to calculate the likelihood.
\item
  The instrument \(w_{jt}\) is necessary, because, otherwise, \(\nu_{jt}\) has no variation conditional on \(p_{jt}\) and \(x_{jt}\) and \(\rho\) cannot be identified.
\end{itemize}

\subsection{Instrumental Variables}\label{instrumental-variables}

\begin{itemize}
\tightlist
\item
  The remaining problem is how to choose the excluded instrumental variable \(w_{jt}^*\) for each product/market.
\item
  \textbf{Cost shifters}:

  \begin{itemize}
  \tightlist
  \item
    These are traditional instruments that directly affect costs but not demand.
  \end{itemize}
\item
  \textbf{Hausman-type IV} \citep{Hausman1994}:

  \begin{itemize}
  \tightlist
  \item
    Assumes that demand shocks are independent across markets, whereas cost shocks are correlated.
  \item
    The correlation in cost shocks will be true if the products are produced by the same manufacturer.
  \item
    Then, the prices of the same product in other markets \(p_{j, -t}\) will be valid instruments for the price of the product in a given market, \(p_{jt}\).
  \end{itemize}
\item
  \textbf{BLP-type IV} \citep{berryAutomobilePricesMarket1995}:

  \begin{itemize}
  \tightlist
  \item
    In oligopoly, the price of a good in a market depends on the market structure, i.e., what types of products are available in the market.
  \item
    For example, if there are similar products in the market, the price will tend to be lower.
  \item
    Then, the product characteristics of other products in the market will be valid instruments for the price of goods in a given market, \(p_{jt}\).
  \item
    If there are multi-product firms, whether the other good is owned by the same company will also affect the price.
  \item
    Specifically, \citet{berryAutomobilePricesMarket1995} use:
  \end{itemize}
\end{itemize}

\begin{equation}
\sum_{k \neq j \in \mathcal{J}_t \cap \mathcal{F}_{f}} x_{kt},
\end{equation}

\begin{equation}
\sum_{k \neq j \in \mathcal{J}_t \setminus \mathcal{F}_{f}} x_{kt}.
\end{equation}
where \(f\) is the firm that owns product \(j\) and \(\mathcal{F}_{f}\) is the set of products firm \(f\) owns.

\begin{itemize}
\tightlist
\item
  \textbf{Differentiation IV} \citep{Gandhi2015a}:

  \begin{itemize}
  \tightlist
  \item
    Let \(d_{jkt} = d(x_{jt}, x_{kt})\) be some distance between product characteristics.
  \item
    They showed that under certain conditions, the optimal BLP-type IV is a function \(d_{-jt}\{d_{jkt}\}_{k \neq j \in \mathcal{J}_t}\).
  \item
    They suggest using the moments of \(d_{-jt}\) as the excluded instrumental variables.
  \end{itemize}
\item
  \textbf{Weak instruments problem of BLP-type IV}:

  \begin{itemize}
  \tightlist
  \item
    \citet{Armstrong2016b} argued that estimates based on BLP-type IV may be inconsistent when \(J \times \infty\) asymptotics is considered because then the market approaches the competitive market and the correlation between the markup and the product characteristics of rivals disappears.
  \item
    Specifically, the estimator is inconsistent if all of the following conditions are met:
  \end{itemize}

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(J \to \infty\) but \(T\) is fixed
  \item
    The demand/cost functions are such that the correlation between markups and characteristics of other products decreases quickly enough as \(J \to \infty\)
  \item
    There are no cost instruments or other sources of identification
  \end{enumerate}
\end{itemize}

\subsection{PyBLP}\label{pyblp}

\begin{itemize}
\tightlist
\item
  \citet{conlonBestPracticesDifferentiated2020} summarized the best practices for the BLP method and implemented them in a Python package \href{https://pyblp.readthedocs.io/}{\texttt{PyBLP}}.
\item
  From R, we can use \href{https://rstudio.github.io/reticulate/}{\texttt{reticulate}} to call Python functions.
\end{itemize}

\chapter{Merger Analysis}\label{merger}

\section{Motivations}\label{motivations-2}

\begin{itemize}
\tightlist
\item
  Measuring the market power of firms and predicting the possible consequence of horizontal merger cases is one of the primary goal of empirical industrial organization.
\item
  This is important for antitrust authority to review merger cases.
\item
  To do so, we integrate the product/cost function estimation and demand function estimation techniques.
\item
  We introduce the last piece of parameters that characterize the market competition, \textbf{conduct parameter}, and discuss its identification.
\item
  Then, we conduct the first kind of \textbf{counterfactual analysis}, the \textbf{merger simularion}.
\item
  In this exercise, we predict the market response when the ownership structure of product is changed due to a hypothetical merger.
\item
  Every market institution needs its own model for merger simulation:
\item
  \citet{Gowrisankaran2015}:

  \begin{itemize}
  \tightlist
  \item
    In the U.S. hospitals and managed care organizations (MGO) negotiate the hospital prices and the coinsurance rates.
  \item
    What if hospitals are merged? How much do the hospital prices and the coinsurance rates increase?
  \end{itemize}
\item
  \citet{Smith2004}:

  \begin{itemize}
  \tightlist
  \item
    Sometimes the same service is sold through multiple stores such as in the supermarket industry.
  \item
    How does this multi-store nature affect the merger effects?
  \end{itemize}
\item
  \citet{Ivaldi2005} reviews the cases in the European Commission.
\end{itemize}

\section{Identification of Conduct}\label{identification-of-conduct}

\subsection{Identification of Conduct}\label{identification-of-conduct-1}

\begin{itemize}
\tightlist
\item
  So far we have been concerned with the two types of parameters:

  \begin{itemize}
  \tightlist
  \item
    Production and/or cost function.
  \item
    Demand function.
  \end{itemize}
\item
  To identify the marginal cost by the revealed preference approach, we have assumed that firms are engaging in a price competition.
\item
  The mode of competition is another parameter of interest.
\item
  Can we infer the mode of competition instead of assuming it?
\end{itemize}

\subsection{Marginal Revenue Function}\label{marginal-revenue-function}

\begin{itemize}
\tightlist
\item
  To be specific, consider firms producing homogeneous product.
\item
  Under what conditions can we distinguish across Bertrand competition, Cournot competition, and collusion? \citep{Bresnahan1982a}.
\item
  Consider the following marginal revenue function:
  \begin{equation}
  MR(Q) \equiv \lambda Q P'(Q) + P(Q),
  \end{equation}
  where \(Q\) is the aggregate quantity, \(P(Q)\) is the inverse demand function.
\item
  This formula nests Bertrand, Cournot, and collusion:
\item
  Bertrand:

  \begin{itemize}
  \tightlist
  \item
    In Bertrand, a firm cannot change the market price.
  \item
    If a firm increases the production by one unit, whose revenue increases by \(P(Q)\).
  \item
    Therefore, \(\lambda = 0\).
  \end{itemize}
\item
  Cournot:

  \begin{itemize}
  \tightlist
  \item
    In Cournot, the marginal revenue of firm \(f\) is:
    \[
      q_f P'(Q) + P(Q).
      \]
  \item
    Therefore, \(\lambda = s_f\), the quantity share of the firm \(f\).
  \end{itemize}
\item
  Collusion:

  \begin{itemize}
  \tightlist
  \item
    Under collusion, firms behave like a single monopoly.
  \item
    Then, the marginal revenue is:
    \[
      QP'(Q) + P(Q).
      \]
  \item
    Therefore, \(\lambda = 1\).
  \end{itemize}
\item
  The identification of the mode of competition in this context is equivalent to the identification of \(\lambda\), the \textbf{conduct parameter}.
\end{itemize}

\subsection{First-Order Condition}\label{first-order-condition}

\begin{itemize}
\tightlist
\item
  Let \(MC(q_f)\) be the marginal cost of firm \(f\).
\item
  Given the previous general marginal revenue function, the first-order condition for profit maximization for firm \(f\) is written as:
  \begin{equation}
  \lambda Q P'(Q) + P(Q) = MC(q_f).
  \end{equation}
\item
  The system of equations for \(f = 1, \cdots, F\) determine the market equilibrium.
\end{itemize}

\subsection{Linear Model}\label{linear-model}

\begin{itemize}
\tightlist
\item
  To be simple, consider a linear inverse demand function:
  \begin{equation}
  P^D(Q) = \frac{\alpha_0}{\alpha_1} + \frac{1}{\alpha_1}Q + \frac{\alpha_2}{\alpha_1} X + \frac{1}{\alpha_1}u^D,
  \end{equation}
  where \(X_t\) is a vector of observed demand sifters.
\item
  Consider a linear marginal cost function:
  \begin{equation}
  MC(q_{f}) = \beta_0 + \beta_1 q_{f} + \beta_2 W + u^S,
  \end{equation}
  where \(W\) is a vector of observed cost sifters.
\end{itemize}

\subsection{Pricing Equation}\label{pricing-equation}

\begin{itemize}
\tightlist
\item
  Inserting the inverse demand function and marginal cost function to the optimality condition:
  \begin{equation}
  \frac{\lambda}{\alpha_1} Q + P^S(Q) = \beta_0 + \beta_1 q_f + \beta_2 W + u^S
  \end{equation}
\item
  Summing them up and dividing by the number of firms \(N\):
  \begin{equation}
  \frac{\lambda}{\alpha_1} Q + P^S(Q) = \beta_0 + \frac{\beta_1}{N} Q + \beta_2 W_t + u^S,
  \end{equation}
\item
  This determines the aggregate pricing equation:
  \begin{equation}
  \begin{split}
  P^S(Q) &= \beta_0 + (\frac{\beta_1}{N} - \frac{\lambda}{\alpha_1})Q + \beta_2 W + u^S\\
  &= \beta_0 + \gamma Q + \beta_2 W + u^S.
  \end{split}
  \end{equation}
\item
  The key parameter is:
  \begin{equation}
  \gamma \equiv \frac{\beta_1}{N} - \frac{\lambda}{\alpha_1}.
  \end{equation}
\end{itemize}

\subsection{Identification of Inverse Demand Function and Pricing Equation}\label{identification-of-inverse-demand-function-and-pricing-equation}

\begin{itemize}
\tightlist
\item
  We have two systems of \textbf{reduced-form} equations:
  \begin{equation}
  \begin{split}
  &P^D(Q) = \frac{\alpha_0}{\alpha_1} + \frac{1}{\alpha_1}Q + \frac{\alpha_2}{\alpha_1} X + \frac{1}{\alpha_1}u^D,\\
  &P^S(Q) = \beta_0 + \gamma Q + \beta_2 W + u^S.
  \end{split}
  \end{equation}
\item
  If we observe a \textbf{demand shifter} \(X\), then it can be used as an instrument for \(Q\) in the pricing equation to identify the parameters in the pricing equation.
\item
  If we observe a \textbf{cost shifter} \(W_t\), then it can be used as an instrument for \(Q\) in the inverse demand function to identify the parameters in the pricing equation.
\item
  Thus, we can identify the \textbf{reduced-form parameters} \((\alpha_0, \alpha_1, \alpha_2)\) and \((\beta_0, \gamma, \beta_2)\) if we observe a demand shifter \(X\) and a cost shifter \(W\).
\item
  However, this is not enough to separately identify the \textbf{structural-form parameters} \(\beta_1\) and \(\lambda\) in \(\gamma\).
\end{itemize}

\subsection{The Conduct Parameter is Unidentified}\label{the-conduct-parameter-is-unidentified}

\begin{itemize}
\tightlist
\item
  Even if the demand function and pricing equation (supply function) are identified, we still cannot identify the conduct parameter \(\lambda\).
\item
  The price at a quantity may be high either because of the high marginal cost or because of the high markup.
\item
  Remember that the identification of \(\gamma\) and \(\alpha_1\) do not determine the value of \(\lambda\) and \(\beta_1\) in:
  \begin{equation}
  \gamma = \frac{\beta_1}{N} - \frac{\lambda}{\alpha_1}.
  \end{equation}
\item
  \(\beta_1\) is the derivative of the marginal cost.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{figuretable/demandshift} 

}

\caption{Figure 6.2 of Davis (2006)}\label{fig:unnamed-chunk-4}
\end{figure}

\subsection{Identification of the Conduct Parameter: When Cost Data is Available}\label{identification-of-the-conduct-parameter-when-cost-data-is-available}

\begin{itemize}
\tightlist
\item
  If there is reliable cost data, we can directly identify the marginal cost function:
  \begin{equation}
  MC(q_f) = \beta_0 + \beta_1 q_f + \beta_2 W + u^S,
  \end{equation}
  and so \(\beta_1\).
\item
  Then, in a combination with the identification of inverse demand function and pricing equation, \(\lambda\) is identified as:
  \begin{equation}
  \lambda = \alpha_1 \left(\frac{\beta_1}{N} - \gamma\right).
  \end{equation}
\end{itemize}

\subsection{Identification of the Conduct Parameter: When Cost Data is Not Available}\label{identification-of-the-conduct-parameter-when-cost-data-is-not-available}

\begin{itemize}
\tightlist
\item
  Remember the first-order condition:
  \begin{equation}
  \lambda Q P^{D\prime}(Q) + P^S(Q) = MC(q_f),
  \end{equation}
  where we can identify \(P^D(Q)\) and \(P^S(Q)\) if we have demand and cost shifters.
\item
  It is clear from this expression that we need a variation in \(P^{D\prime}(Q)\) with a fixed \(Q\) to identify \(\lambda\), i.e., something that rotates the inverse demand function.
\item
  Intuition: If demand becomes more elastic, prices will decrease and quantity will increase in a market with a high degree of market power.
\end{itemize}

\subsection{Identification of the Conduct Parameter: Demand Rotater is Available}\label{identification-of-the-conduct-parameter-demand-rotater-is-available}

\begin{itemize}
\item
  Let's formalize the idea.
\item
  To identify the conduct parameter, we needed a demand rotater:
  \begin{equation}
  P^D(Q) = \frac{\alpha_0}{\alpha_1} + \frac{1}{\alpha_1}Q + \frac{\alpha_2}{\alpha_1} X + \frac{\alpha_3}{\alpha_1} Q \underbrace{Z}_{\text{demand rotater}} +  \frac{1}{\alpha_1}u^D.
  \end{equation}
\item
  Inserting this into the first-order condition yields:
  \begin{equation}
  \frac{\lambda}{\alpha} Q_t (1 + \alpha Z_t)+ P^S(Q) = \beta_0 + \frac{\beta_1}{N} Q + \beta_2 W + u^s,
  \end{equation}
\item
  This determines the pricing equation:
  \begin{equation}
  \begin{split}
  P^S(Q) &= \beta_0 - \frac{\lambda}{\alpha_1} Q(1 + \alpha_3 Z_t) + \frac{\beta_1}{N} Q_t + \beta_2 W + u^S\\
  &\equiv \beta_0 + \gamma_1 Q + \gamma_2 Z Q + \beta_2 W + u^S,
  \end{split}
  \end{equation}
  where:
  \begin{equation}
  \gamma_1 \equiv \frac{\beta_1}{N} - \frac{\lambda}{\alpha_1}, \gamma_2 \equiv - \frac{\lambda \alpha_3}{\alpha_1}.
  \end{equation}
  \#\#\# Identification of the Conduct Parameters: Demand Rotater is Available
\item
  If we have cost shifters \(W\), it can be used as instruments for \(Q\) in the inverse demand function to identify the demand parameters \((\alpha_0, \alpha_1, \alpha_2, \alpha_3)\).
\item
  If we have demand shifters \(X\), it can be used as instruments for \(Q\) in the pricing equation to identify the supply parameters \((\beta_0, \gamma_1, \gamma_2, \beta_2)\).
\item
  Now we can identify the \textbf{reduced-form} parameters \(\alpha_1, \alpha_3\) and \(\gamma_2\).
\item
  Then, we can not identify the conduct parameter:
  \begin{equation}
  \lambda = - \frac{\gamma_2 \alpha_1}{\alpha_3}.
  \end{equation}
\end{itemize}

\subsection{Identification of Conduct in Differentiated Product Market}\label{identification-of-conduct-in-differentiated-product-market}

\begin{itemize}
\item
  Consider the identification of conduct when there are two differentiated substitutable products and companies compete in price \citep{Nevo1998}.
\item
  Are the prices determined independently or jointly?
\item
  The general first-order condition is:
  \begin{equation}
  \begin{split}
  &(p_1 - c_1) \frac{\partial Q_1(p)}{\partial p_1} + Q_1^S(p) + \Delta_{12}(p_2 - c_2) \frac{\partial Q_2 (p)}{\partial p_1} = 0\\
  &\Delta_{21}(p_1 - c_1)\frac{\partial Q_1(p)}{\partial p_2} + Q_2^S(p) + (p_2 - c_2) \frac{\partial Q_2 (p)}{\partial p_2} = 0,
  \end{split}
  \end{equation}
  where
\item
  \(\Delta_{12} = \Delta_{21} = 0\) if prices are determined independently.
\item
  \(\Delta_{12} = \Delta_{21} = 1\) if price are determined jointly.
\item
  Under what conditions can we identify \(\Delta_{12}\) and \(\Delta_{21}\)?
\item
  We will have to rotate \(\frac{\partial Q_1(p)}{\partial p_2}\) and \(\frac{\partial Q_2 (p)}{\partial p_1}\) while keeping the other variables at the same values.
\item
  \citet{Miller2017} infers \(\Delta\) after the MillerCoors, a joint venture of SABMiller PLC and Molson Coors Brewing, is formed.

  \begin{itemize}
  \tightlist
  \item
    The unobserved year-specific and region-specific cost shocks are identified from the outsiders and the unobserved product-specific cost shocks are assumed to be the same before and after the merger.
  \end{itemize}
\end{itemize}

\section{Merger Simulation}\label{merger-simulation}

\subsection{Unilateral and Coordinated Effects of a Horizontal Merger}\label{unilateral-and-coordinated-effects-of-a-horizontal-merger}

\begin{itemize}
\tightlist
\item
  There are two effects associated with a merge episode:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Unilateral effect}:

  \begin{itemize}
  \tightlist
  \item
    The new merged firm usually have a unilateral incentive to raise prices above their pre-merger level.
  \item
    This unilateral effect may lead to the other firms to have an unilateral incentive to raise price, and the reaction continues to reach the new equilibrium.
  \item
    The latter chain reaction is sometimes called the \textbf{multi-lateral effect}.
  \item
    In economic theory, it is the price change when the same mode of competition (say, the Bertrand-Nash equilibrium) is played.
  \item
    \(\Delta\) is either 0 or 1: firms internalize the profits from owned product but do not internalize the other products.
  \end{itemize}
\item
  \textbf{Coordinated effect}:

  \begin{itemize}
  \tightlist
  \item
    After the merger, the mode of competition may change.
  \item
    For example, the tacit collusion becomes easier and it can happen.
  \item
    This effect, caused by the change in the mode of competition, is called the coordinated effect of a merger.
  \item
    In this case, the conduct parameters \(\Delta\) may take positive values for products owned by the rival firms.
  \end{itemize}
\end{enumerate}

\subsection{Merger Simulation}\label{merger-simulation-1}

\begin{itemize}
\tightlist
\item
  In merger simulation, we compute the equilibrium under different ownership structure.
\item
  This amounts to run a counterfactual simulation hypothetically changing the conduct parameter \(\Delta\).
\item
  The idea stems back to \citet{Farrell1990}, \citet{Werden1994}, \citet{Hausman1994}.
\item
  Before running the simulation, you have to be very careful about the model assumptions:

  \begin{itemize}
  \tightlist
  \item
    In music industry, firms compete not in price but in advertisement.
  \item
    If technological diffusion is important, firms may set dynamic pricing.
  \end{itemize}
\item
  This is the first \textbf{counterfactual analysis} we study in this lecture.
\item
  The results are valid only if the modeling assumptions are correct.
\end{itemize}

\subsection{Quantifying the Unilateral Effect}\label{quantifying-the-unilateral-effect}

\begin{itemize}
\tightlist
\item
  See \citet{Nevo2000c} and \citet{Nevo2001}.
\item
  There are \(J\) products, \(\mathcal{J} = \{1, \cdots, J\}\).
\item
  We can have multiple markets but we suppress the market index.
\item
  Firm \(f\) produces a set of products which we denote \(\mathcal{J}_f \subset \mathcal{J}\).
\item
  Let \(mc_j\) be the constant marginal cost of producing good \(j\).
\item
  Thus assuming a separable cost function.

  \begin{itemize}
  \tightlist
  \item
    We can relax this assumption for the estimation.
  \item
    However, once you admit that the costs can be non-separable, you will start to wonder what happens to the cost function if two firms merged and started to produce the two products that were previously produced by separate firms.
  \end{itemize}
\item
  Let \(D_j(p)\) be the demand for product \(j\) when the price vector is \(p\).
\item
  The problem for firm \(f\) given the price of other firms \(p_{-f}\) is:
  \begin{equation}
  \max_{p_f} \sum_{j \in \mathcal{J}_f} \Pi_j(p_f, p_{-f}) = \sum_{j \in \mathcal{J}_f} (p_j - mc_j) D_j(p_f, p_{-f}),
  \end{equation}
  where \(p_f = \{p_j\}_{j \in \mathcal{J}_f}\), \(p_{-f} = \{p_j\}_{j \in \mathcal{J} \setminus \mathcal{J}_f}\).
\end{itemize}

\subsection{Pre-Merger Equilibrium}\label{pre-merger-equilibrium}

\begin{itemize}
\tightlist
\item
  The first-order condition for firm \(f\) is:
  \begin{equation}
  D_k(p) + \sum_{j \in \mathcal{J}_f} (p_j - mc_j) \frac{\partial D_j(p)}{\partial p_k} = 0, \forall k \in \mathcal{J}_f.
  \end{equation}
\item
  Let \(\Delta_{jk}^{pre}\) takes 1 if same firm produces \(j\) and \(k\) and 0 otherwise before the merger.
\item
  The first-order condition can be written as:
  \begin{equation}
  D_k(p) + \sum_{j \in \mathcal{J}} \Delta_{jk}^{pre}(p_j - mc_j) \frac{\partial D_j(p)}{\partial p_k} = 0, \forall k \in \mathcal{J}_f.
  \end{equation}
\item
  In terms of the product share:
  \begin{equation}
  s_k(p) + \sum_{j \in \mathcal{J}} \Delta_{jk}^{pre}(p_j - mc_j) \frac{\partial s_j(p)}{\partial p_k} = 0, \forall k \in \mathcal{J}_f.
  \end{equation}
\item
  Let \(\Delta^{pre}\) be a \(J \times J\) matrix whose \((j, k)\)-element is \(\Delta_{jk}\).
\item
  At the end of the day, performing a merger simulation is to recompute the equilibrium with different ownership structure encoded in \(\Delta\).
\end{itemize}

\subsection{Post-Merger Equilibrium}\label{post-merger-equilibrium}

\begin{itemize}
\tightlist
\item
  Let \(\Omega^{pre}(p)\) is a matrix whose \((j, k)\)-element is:
\end{itemize}

\begin{equation}
- \frac{\partial s_{j}(p)}{\partial p_k} \Delta_{jk}^{pre}.
\end{equation}

\begin{itemize}
\item
  Then, by the first-order condition, the marginal cost should be:
  \begin{equation}
  mc = p - \Omega^{pre}(p)^{-1} s(p).
  \end{equation}
\item
  If the ownership structure \(\Delta^{pre}\) is changed to \(\Delta^{post}\), and \(\Omega^{pre}\) changed to \(\Omega^{post}\), the post-merger price is determined by solving the non-linear equation:
  \begin{equation}
  p^{post} = mc + \Omega^{post}(p^{post})^{-1}s(p^{post}).
  \end{equation}
\item
  The post-merger share is given by:
  \begin{equation}
  s^{post} = s(p^{post}).
  \end{equation}
\end{itemize}

\subsection{Consumer Surplus}\label{consumer-surplus}

\begin{itemize}
\tightlist
\item
  Suppose that the demand function is based on the mixed-logit model such that the indirect utility is:
  \begin{equation}
  u_{ijt} = x_{jt} \beta_i + \alpha_i p_{jt} + \xi_{j} + \xi_t + \Delta \xi_{jt} + \epsilon_{ijt},
  \end{equation}
  with \(\epsilon_{ijt}\) is drawn from i.i.d. Type-I extreme value distribution and the consumer-level heterogeneity:
\end{itemize}

\begin{equation}
\begin{pmatrix}
\alpha_i \\
\beta_i
\end{pmatrix}
= 
\begin{pmatrix}
\alpha\\
\beta
\end{pmatrix}
+ \Pi z_i + \Sigma \nu_i, \nu_i \sim N(0, I_{K + 1}).
\end{equation}

\begin{itemize}
\tightlist
\item
  Then, the compensated variation due to the price change for consumer \(i\) is:
  \begin{equation}
  CV_{it} = \frac{\ln (\sum_{j = 0}^J \exp(V_{ijt}^{post}) ) - \ln (\sum_{j = 0}^J \exp(V_{ijt}^{pre})) }{\alpha_i},
  \end{equation}
  where \(V_{ijt}^{post}\) and \(V_{ijt}^{pre}\) are indirect utility for consumer \(i\) to purchase good \(j\) at the prices after and before the merger.
\item
  This formula holds only if the price enters linearly in the indirect utility (no income effect).
\item
  For general case, see \citet{Small1981} and \citet{Mcfadden1995}.
\end{itemize}

\subsection{Quantifying the Coordinated Effect}\label{quantifying-the-coordinated-effect}

\begin{itemize}
\tightlist
\item
  The repeated-game theory suggests that a collusion is sustainable if and only if it it incentive compatible: the collusion profit is no less than the deviation profit for each member of the collusion.
\item
  The theory provides a check list that affects the incentive compatibility such as the market share, cost asymmetry, and demand dynamics.
\item
  But it is often hard to judge the coordinated effects from these qualitative information, because mergers simultaneously change many factors and the factors may encourage or hinder collusion.
\item
  \citet{Miller2017} \textbf{retrospectively} studies the coordinated effect of a merger.
\item
  Is \textbf{prospective} analysis of coordinated effects possible as well as the analysis of unilateral effects?
\item
  If we can identify the demand and cost functions, we can calculate the collusion profits and deviation profits.
\item
  If we specify the collusion strategy, we can write down the incentive compatibility.
\item
  We can check how the incentive compatibility change when a hypothetical merger happens.
\item
  The problem is the identification of conduct: to identify the cost function, we need to know the conduct.
\item
  Thus, the stated strategy will work only if we have a data during which we are sure that there was no collusion, or there was a particular type of collusion.
\item
  \citet{Igami2018} use the detailed information of vitamin C cartel case and apply this approach.
\end{itemize}

\chapter{Entry and Exit}\label{entryexit}

\section{Motivations}\label{motivations-3}

\begin{itemize}
\tightlist
\item
  By studying the entry decisions of firms, we can identify the profit function including the entry cost of firms.
\item
  A profit function is the reduced-form parameter of the underlying demand function, cost function, and conduct parameters.
\item
  The profit function can be identified without assuming a particular conduct.
\item
  The parameter is informative enough to answer questions regarding the market structure and producer surplus.
\item
  In the last chapter, we discussed the identification of conduct, in which we learned that the exogenous change in the number of firms in a market gives some information about the conduct.
\item
  In the entry/exit analysis, we study the relationship between the market size, which exogenously changes the equilibrium number of firms, and the change in the market structure to infer the conduct.
\item
  Entry and exit is not all about firms.
\item
  The decision of launching a product is a sort of entry decision and the decision of abolishing a product is a sort of exit decision.
\item
  The framework in this chapter can be applied to a wider class of problems.
\item
  This chapter is mostly based on \citet{berryIdentificationModelsOligopoly2006}.
\end{itemize}

\subsection{Entry Cost, Mode of Competition, and Market Structure}\label{entry-cost-mode-of-competition-and-market-structure}

\begin{itemize}
\tightlist
\item
  Fixed and sunk entry costs and mode of competition are key determinants for market structure \citep{suttonChapter35Market2007}.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{figuretable/entrycost} 

}

\caption{Figure 1 of Sutton (2007)}\label{fig:unnamed-chunk-5}
\end{figure}

\begin{itemize}
\tightlist
\item
  The tougher the mode of competition, the less firms can earn enough profit to compensate the entry cost.
\item
  Therefore, the tougher the mode of competition, the number of firms in the market in the equilibrium cannot grow when the market size increases.
\end{itemize}

\subsection{Exogenous and Endogenous Entry Cost}\label{exogenous-and-endogenous-entry-cost}

\begin{itemize}
\tightlist
\item
  \textbf{Exogenous fixed and sunk entry cost}:
\item
  The cost of entry is the same across modes of entry.
\item
  \textbf{Endogenous fixed and sunk entry cost}:
\item
  The cost differs across modes of entry.
\item
  For example, firms decide the quality of the product upon entering the market and the the cost of entry is increasing in the quality choice.
\item
  If endogenous fixed and sunk entry cost is relevant, the entry cost to compete with the incumbent and have a positive profit will increase as the the number of incumbent firms increases.
\item
  Therefore, the equilibrium firm number will be small and firm size will be large when endogenous fixed and sunk entry cost is relevant.
\end{itemize}

\section{Monopoly Entry}\label{monopoly-entry}

\subsection{Variable Profits and Fixed Costs}\label{variable-profits-and-fixed-costs}

\begin{itemize}
\item
  Consider a cross-section of markets, with one potential entrant in each market.
\item
  Profits in market \(i\) are given by:
  \[
  \pi(x_i, F_i) \equiv v(x_i) - F_i.
  \]
\item
  \(v(x)\) is deterministic and \(F\) is random.
\item
  Typically, \(v(x)\) is interpreted as the variable profits and \(F\) as the fixed costs.
\item
  The potential entrant will enter market \(i\) if and only if:
  \[
  F_i \le v(x_i).
  \]
\item
  The parameters of interest are \(v\) and the distribution of \(F\), \(\Phi\).
\item
  In general, \(F\) in a market can be correlated with \(x\).
\end{itemize}

\subsection{Non-Identification}\label{non-identification}

\begin{itemize}
\tightlist
\item
  Assume that \(F\) is independent of \(x\).
\item
  Notice that a monotonic transformation of both sides of:
  \[
  F_i \le v(x_i).
  \]
  will not change the entry probability.
\item
  Therefore, without further restrictions, \(v\) and \(\Psi\) are at best identified only up to a monotonic transformation.
\end{itemize}

\subsection{Restrictions for Identification.}\label{restrictions-for-identification.}

\begin{itemize}
\tightlist
\item
  Keep assuming that \(F\) is independent of \(x\).
\item
  Let \(p(x)\) is the observed entry probability at \(x\).
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(v\) is known: Because \(v\) is the variable profit function, we can identify it directly from the demand function and cost function.

  \begin{itemize}
  \tightlist
  \item
    Let \(z = v(x)\). Then \(\Psi\) is identified at \(z\) by:
    \[
     \Psi(z)  = \mathbb{P}\{F \le z\} = \mathbb{P}\{F \le v[v^{-1}(z)]\} = p[v^{- 1}(z)].
     \]
  \end{itemize}
\item
  \(\Psi\) is known: Normalize the distribution of \(F\).

  \begin{itemize}
  \tightlist
  \item
    Then, \(v\) is identified at \(x\) by:
    \[
     v(x) = \Psi^{-1}[p(x)].
     \]
  \end{itemize}
\item
  Impose shape restrictions on \(v\) \citep{matzkinNonparametricDistributionFreeEstimation1992}:

  \begin{itemize}
  \tightlist
  \item
    \(v(x)\) is homogeneous of degree 1 and there exists \(x_0\) such that \(v(x_0) = 1\). Then the functions \(v\) and \(\Psi\) are identified.
  \item
    Homogeneous of degree 1: \(v(z \cdot x) = z v(x)\).
  \item
    Let \(p(z, x_0)\) be the probability of entry at \(z\) and \(x_0\).
  \item
    Then, \(\Psi\) is identified at \(z\) by:
    \[
     \Psi(z) = \mathbb{P}\{F \le z\} = \mathbb{P}\{F \le z v(x_0)\} = p(z, x_0).
     \]
  \item
    Then, \(v\) is identified by the second argument.
  \end{itemize}
\end{enumerate}

\subsection{Homogeneous of Degree 1 Variable Profits}\label{homogeneous-of-degree-1-variable-profits}

\begin{itemize}
\tightlist
\item
  Sufficient condition for the variable profit function to satisfy the stated condition:

  \begin{itemize}
  \tightlist
  \item
    Demand is proportional to the population.
  \item
    Marginal cost is constant.
  \item
    Then, the variable profit is the market size \(z\) times the per-capita profit.
  \item
    We can normalize \(v\) at a market of size \(z = 1\) by choosing arbitrary \(x_0\).
  \end{itemize}
\end{itemize}

\section{Complete-Information Homogeneous Oligopoly Entry}\label{complete-information-homogeneous-oligopoly-entry}

\subsection{Variable and Fixed Costs}\label{variable-and-fixed-costs}

\begin{itemize}
\tightlist
\item
  \citet{bresnahanEntryCompetitionConcentrated1991} pioneered the analysis of oligopoly entry models.
\item
  We observe a cross-section of markets in which we observe the number of homogeneous firms and other market-specific characteristics.
\item
  Let \(y_m\) be the number of firms in market \(m\).
\item
  Let \(v_{y_m}(x_m)\) is the variable profit per firm in a market with number of firms \(y_m\) and the market characteristics \(x_m\).
\item
  Let \(F_m\) be the market-specific fixed costs that are i.i.d. across markets with unknown distribution \(\Psi\).
\item
  If there are \(y_m\) firms in market \(m\), the profit per firm in the market is:
  \[
  \pi(y_m, x_m, F_m) \equiv v_{y_m}(x_m) - F_m.
  \]
\end{itemize}

\subsection{Equilibrium Condition}\label{equilibrium-condition}

\begin{itemize}
\item
  The unique Nash equilibrium in the number of firms in market \(m\) is determined by the following equilibrium condition:
  \[
  v_{y_m}(x_m) \ge F_m.
  \]
  \[
  v_{y_m + 1}(x_m) < F_m.
  \]
\item
  Under this equilibrium, the probability of observing \(y\) firms in a market of type \(x\) is:
  \[
  \mathbb{P}\{y = 0|x\} = 1 - \Psi[v_1(x)].
  \]
  \[
  \mathbb{P}\{y = 1|x\} = \Psi[v_1(x)] - \Psi[v_2(x)].
  \]
  \[
  \mathbb{P}\{y = 2|x\} = \Psi[v_2(x)] - \Psi[v_3(x)].
  \]
  \[
  \cdots
  \]
\item
  In other words, the probability of observing at least \(y\) firms in a market of type \(x\) is:
  \[
  \mathbb{P}\{y \ge 1|x\} = \Psi[v_1(x)].
  \]
  \[
  \mathbb{P}\{y \ge 2|x\} = \Psi[v_2(x)].
  \]
  \[
  \mathbb{P}\{y \ge 3|x\} = \Psi[v_3(x)].
  \]
  \[
  \cdots
  \]
\end{itemize}

\subsection{Identification under a Shape Restriction}\label{identification-under-a-shape-restriction}

\begin{itemize}
\tightlist
\item
  The identification argument for each \(y\) is the same as the monopoly entry case.
\item
  For example, assume \(v_y(x) = z v_y(\tilde{x})\) and \(v_1(\tilde{x}_0) = 1\).
\item
  Let \(P_y(z, \tilde{x})\) be the observed probability that the number of firms is no less than \(y\) in market of type \(z,  \tilde{x}\).
\item
  Then \(\Psi\) is identified at \(z\) by:
  \[
  \Psi(z) = \mathbb{P}\{F \le z\} = \mathbb{P}\{F \le z v_1(\tilde{x}_0)\} = P_1(z, \tilde{x}_0).
  \]
\item
  Then, the identification of \(v_y\) follows from:
  \[
  v_y(\tilde{x}) = \frac{\Psi^{-1}[P_y(z, \tilde{x})]}{z}.
  \]
\end{itemize}

\subsection{Log Likelihood Function}\label{log-likelihood-function}

\begin{itemize}
\tightlist
\item
  The log likelihood of observing \(\{y_m\}_{m = 1}^M\) given \(\{x_m\}_{m = 1}^M\) is:
  \[
  l(v, \Psi|\{y_m\}_{m = 1}^M,  \{x_m\}_{m = 1}^M) = \sum_{m = 1}^M \log\{\Psi[v_{y_m}(x_m)] - \Psi[v_{y_m + 1}(x_m)]\}.
  \]
\item
  This is a \textbf{ordered} model in \(y_m\).
\item
  If \(\Psi\) is a normal distribution, it is called an \textbf{ordered probit model}.
\end{itemize}

\section{Complete-Information Heterogeneous Oligopoly Entry}\label{complete-information-heterogeneous-oligopoly-entry}

\subsection{Bivartiate Game with Heterogeneous Profits}\label{bivartiate-game-with-heterogeneous-profits}

\begin{itemize}
\tightlist
\item
  We observe a cross-section of markets in which there are two potential entrants.
\item
  Let the profit of firm \(i\) in market \(m\) be:
  \[
  \begin{split}
  \pi_{im}(x_{im}, y_{jm}, f_{im}) & \equiv v(y_{jm}, x_{im}) - f_{im}\\
  &=v_{0i}(x_{im}) + y_{jm} v_{1i}(x_{im}) - f_{im}.
  \end{split}
  \]
\item
  \(y_{im}\) and \(y_{jm}\) are the indicators of entry of firm \(i\) and \(j\) in market \(m\).
\item
  \(x_{im}\) and \(x_{jm}\) are firm \(i\) and \(j\)'s characteristics in market \(m\).
\item
  \(f_{im}\) and \(f_{jm}\) are the fixed costs of firm \(i\) and \(j\) in market \(m\).
\item
  The second equation is without loss of generality because \(y_{jm}\) is a binary variable.
\item
  The competitive effect of firm \(j\) on \(i\) and the effect o firm \(i\) on \(j\) are asymmetric.
\item
  The parameters of interest are \(v_{0i}, v_{0j}, v_{1i}, v_{1j}\) and the joint distribution of \(f_{im}, f_{jm}\) conditional on \(x_{im}\) and \(x_{jm}\).
\item
  Firms \textbf{observe} both \(f_{im}, f_{jm}\) when they make decisions, but econometrician does not.
\end{itemize}

\subsection{Sampling Assumption and Observations}\label{sampling-assumption-and-observations}

\begin{itemize}
\tightlist
\item
  We have a random sample of observations on markets where every observation is an observable realization of an equilibrium game played between firm \(i\) and \(j\).
\item
  Thus, we can observe:

  \begin{itemize}
  \tightlist
  \item
    \(\mathbb{P}\{0, 0|x\}\): the probability that a market of type \(x\) has no firm.
  \item
    \(\mathbb{P}\{1, 0|x\}\): the probability that a market of type \(x\) has firm \(i\) but not firm \(j\).
  \item
    \(\mathbb{P}\{0, 1|x\}\): the probability that a market of type \(x\) has firm \(j\) but not firm \(i\).
  \item
    \(\mathbb{P}\{1, 1|x\}\): the probability that a market of type \(x\) has both firms.
  \end{itemize}
\end{itemize}

\subsection{Identification Assuming Pure-Strategy Equilibrium}\label{identification-assuming-pure-strategy-equilibrium}

\begin{itemize}
\item
  \citet{tamerIncompleteSimultaneousDiscrete2003} considers the identification when there are only two potential entrants and the pure-strategy Nash equilibrium is assumed.
\item
  Assume that the data is from a pure-strategy equilibrium.
\item
  Then, the probabilities \(\mathbb{P}\{0, 0|x\}\) and \(\mathbb{P}\{1, 1|x\}\) are written as:
  \[
  \mathbb{P}\{0, 0|x\} = \mathbb{P}\{f_{im} \ge v_{0i}(x_{im}), f_{jm} \ge v_{0j}(x_{jm})|x_{im}, x_{jm}\}.
  \]
  \[
  \mathbb{P}\{1, 1|x\} = \mathbb{P}\{f_{im} \le v_{0i}(x_{im}) + v_{1i}(x_{im}), f_{jm} \le v_{0j}(x_{jm}) + v_{1j}(x_{jm})|x_{im}, x_{jm}\}.
  \]
\item
  Assume that \((f_{im}, f_{jm})\) are distributed independently of \((x_{im}, x_{jm})\) with a joint distribution \(F\).
\item
  Assume that \(v_{0i}(x_{im}) = z_{im} v_0(\tilde{x}_{im})\) and \(v_{0j}(x_{jm}) = z_{jm} v_0(\tilde{x}_{jm})\).
\item
  Assume that \(v_{0i}(\tilde{x}_0) = v_{0j}(\tilde{x}_0) = 1\).
\item
  Assume that \(v_{1i}\) and \(v_{1j}\) are non-positive.
\item
  Assume that \(z_{im}| z_{jm}, \tilde{x}_{im}, \tilde{x}_{jm}\) has a distribution with support on \(\mathbb{R}\) and similar for \(z_{jm}\).
\item
  Then, \(F\) is identified by:
  \[
  \begin{split}
  \mathbb{P}\{f_{im} \ge z_{im}, f_{jm} \ge z_{jm}\} &= \mathbb{P}\{ f_{im} \ge z_{im} v_0(\tilde{x}_{0}), f_{jm} \ge z_{jm} v_0(\tilde{x}_{0})\}\\
  &= \mathbb{P}\{0, 0|z_{im}, \tilde{x}_0, z_{jm}, \tilde{x}_0\}.
  \end{split}
  \]
\item
  Then, push \(z_{jm} \to - \infty\) to get:
  \[
  \begin{split}
  \mathbb{P}\{f_{im} \ge z_{im} v_0(\tilde{x}_{im})\} &= \lim_{z_{jm} \to - \infty} \mathbb{P}\{f_{im} \ge z_{im} v_0(x_{im}), f_{jm} \ge z_{jm} v_0(x_{jm})\}\\
  &= \lim_{z_{jm} \to - \infty} \mathbb{P}\{0, 0|z_{im}, \tilde{x}_{im}, z_{jm}, \tilde{x}_{jm}\}
  \end{split}
  \]
\item
  Hence, \(v_{0}\) is identified by:
  \[
  v_0(\tilde{x}_{im}) = \frac{F^{-1}[\lim_{z_{jm} \to - \infty} \mathbb{P}\{0, 0|z_{im}, \tilde{x}_{im}, z_{jm}, \tilde{x}_{jm}\}]}{z_{im}}.
  \]
\item
  The identification of \(v_{1i}\) and \(v_{1j}\) are similar.
\end{itemize}

\subsection{Heterogeneous Independent Fixed Costs}\label{heterogeneous-independent-fixed-costs}

\begin{itemize}
\tightlist
\item
  \citet{berryEstimationModelEntry1992} considers several extensions to the homogeneous oligopoly models.
\item
  Assume that the fixed costs are heterogeneous and independent across firms.

  \begin{itemize}
  \tightlist
  \item
    c.f. In homogeneous oligopoly model, the fixed costs were perfectly correlated across firms in a market.
  \end{itemize}
\item
  Assume that the characteristics can be firm-specific (that can include market-specific characteristics).
\item
  Assume that the variable profit function is homogeneous:
  \[
  \pi_{y}(x_m, F_{im}) = v_y(x_{im}) - F_{im}.
  \]
\item
  Assume that \(F\) is independent of \(x\).
\item
  Suppose that we observe the \textbf{number of potential entrants} in each market.
\item
  For example, in the airline industry, market is a city pair.
\item
  The potential entrants into an airline city pair were those with some service out of at least one of the endpoints of the city pair.
\item
  The variation in the number of potential entrants can be used to identify the model.
\item
  Define:
  \[
  \mu(x) = \mathbb{P}\{F_{im} < v_1(x)\}.
  \]
  \[
  \delta(x) = \mathbb{P}\{F_{im} < v_2(x)\}.
  \]
\item
  Suppose that we \textbf{know} that there only two potential entrants into a market.
\item
  Among such markets, we have:
  \[
  \mathbb{P}\{0, 0|x_1, x_2\} = [1 - \mu(x_1)] [1 - \mu(x_2)].
  \]
  \[
  \mathbb{P}\{1, 1|x_1, x_2\} = \delta(x_1) \delta(x_2).
  \]
\item
  If we set \(x_1 = x_2 = x\), then we have:
  \[
  \mathbb{P}\{0, 0|x, x\} = [1 - \mu(x)]^2.
  \]
  \[
  \mathbb{P}\{1, 1|x, x\} = \delta(x)^2.
  \]
\item
  They identify \(\mu\) and \(\delta\) at \(x\).
\item
  Under shape restrictions, we can identify \(v\) and \(\Psi\) as well.
\end{itemize}

\subsection{Heterogenous and Market-Level Correlated Fixed Costs}\label{heterogenous-and-market-level-correlated-fixed-costs}

\begin{itemize}
\item
  Let \(\epsilon_m\) be the market-specific shock that affects the entry into market \(m\).
\item
  Conditional on \(\epsilon_m\), \(F_{im}\) are still independent across firms in a market.
\item
  Let \(\mu\) be:
  \[
  \mu(x, \epsilon_m) = \mathbb{P}\{F_{im} < v_1(x, \epsilon_m)\}.
  \]
\item
  When there is a market in which we \textbf{know} that there are only two potential entrants, the probability of observing \((0, 0)\) becomes:
  \[
  \mathbb{P}\{0, 0|x_1, x_2\} = \int [1 - \mu(x_1, \epsilon_m)] [1 - \mu(x_2, \epsilon_m)] d \Gamma(\epsilon_m).
  \]
\item
  Specifically, assume that:
  \[
  \epsilon_m 
  = 
  \begin{cases}
  0 & \text{   with probability   } \lambda \\
  1 & \text{   with probability   } 1 - \lambda.
  \end{cases}
  \]
\item
  Then, we in a market in which we \textbf{know} that there are only two potential entrants, the probability of observing \((0, 0)\) becomes:
  \[
  \mathbb{P}\{0, 0|x_1, x_2\} = \lambda [1 - \mu(x_1, 0)] [1 - \mu(x_2, 0)] + (1 - \lambda) [1 - \mu(x_1, 1)] [1 - \mu(x_2, 1)].
  \]
\item
  In general, in a market in which we \textbf{know} that there are only \(K\) potential entrants such that \(x_1 = \cdots x_K = x\), the probability of observing \((0, 0)\) becomes:
  \[
  \mathbb{P}\{0, 0|x, \cdots x\} = \lambda [1 - \mu(x, 0)]^K + (1 - \lambda) [1 - \mu(x, 1)]^K.
  \]
\item
  If there markets with \(K = 1, \cdots, \overline{K}\), we can construct \(\overline{K}\) equations with three unknowns \(\lambda\), \(\mu(x, 0)\), and \(\mu(x, 1)\).
\item
  Thus, the knowledge and the variation in the number of potential entrants help the identification.
\end{itemize}

\subsection{Inference Based On a Unique Prediction}\label{inference-based-on-a-unique-prediction}

\begin{itemize}
\tightlist
\item
  \citet{berryEstimationModelEntry1992} develops a more general model built on the ideas above.
\item
  The key for his analysis is that he ensures that \textbf{there is a unique number of equilibrium entrants}.
\item
  This enables him to calculate the likelihood of observing a sequence of number of entrants, but at the cost of the generality of the underlying model.
\end{itemize}

\subsection{Entry in the Airline Industry: One-shot Game}\label{entry-in-the-airline-industry-one-shot-game}

\begin{itemize}
\tightlist
\item
  Based on \citet{berryEstimationModelEntry1992}.
\item
  A market = a city pair market at a single point in time.
\item
  Consider a one-shot entry game that yields a network structure.
\item
  At the beginning of the period, each firm takes its overall network structure as given and decides whether to operate in a given city pair \textbf{independently} across markets.
\end{itemize}

\subsection{Entry in the Airline Industry: Profit Function}\label{entry-in-the-airline-industry-profit-function}

\begin{itemize}
\tightlist
\item
  There are \(K_m\) potential entrants in market \(m\).
\item
  Let \(y_m\) be a strategy profile.
\item
  \(y_m = (y_{1m}, \cdots, y_{K_m m})'\), \(y_{im} \in \{0, 1\}\).
\item
  The profit function for firm \(i\) in market \(m\):
  \begin{equation}
  \pi_{im}(y_m, f_{im}) = v_m\left(N_{m}\right) - f_{im}.
  \end{equation}
\item
  \(N_{m} = \sum_{i = 1}^{K_m} y_{im}\).
\item
  \(v_m\) is strictly decreasing in \(N_m\).
\end{itemize}

\subsection{Entry in the Airline Industry: Profit Function}\label{entry-in-the-airline-industry-profit-function-1}

\begin{itemize}
\tightlist
\item
  The common term is assumed to be:
  \[
  v_m(N) = x_m' \beta + h(\delta, N_m) + \rho u_{m}, 
  \]
\item
  \(x_m\) is the observed market characteristics, \(h(\cdot)\) is a function that is decreasing in \(N_m\), say, \(- \delta \ln (N_m)\).
\item
  \(u_m\) is the market characteristics that is observed by firms but not by econometrician.
\item
  The firm-specific term:
  \[
  f_{im} = z_{im}' \alpha + \sigma u_{im},
  \]
\item
  \(z_{im}\) is the observed firm characteristics.
\item
  A scale normalization: \(\sigma = \sqrt{1 - \rho^2}\) \(\Rightarrow var(\rho u_m + \sigma u_{im}) = 1\).
\end{itemize}

\subsection{Entry in the Airline Industry: Likelihood Function}\label{entry-in-the-airline-industry-likelihood-function}

\begin{itemize}
\tightlist
\item
  The observed part:
  \[
  r_{im}(N) = x_m' \beta - \delta \ln (N_m) + z_{im}' \alpha. 
  \]
\item
  The unobserved part:
  \[
  \epsilon_{im} = \sqrt{1 - \rho^2} u_{im} + \rho u_{m}.
  \]
\end{itemize}

\subsection{Is the Equilibrium Number of Firms Unique?}\label{is-the-equilibrium-number-of-firms-unique}

\begin{itemize}
\tightlist
\item
  Either of the following conditions are sufficient:
\item
  No firm-level unobserved heterogeneity: \(\rho = 1\).
\item
  No market-level unobserved heterogeneity: \(\rho = 0\).
\item
  The order of entry is predetermined, for example, the most profitable firms enter first.
\item
  The incumbent firms enter first.
\item
  Under either of the above assumptions, simulate the equilibrium number of firms in each market and match with the data.
\end{itemize}

\section{Multiple Prediction}\label{multiple-prediction}

\begin{itemize}
\tightlist
\item
  If we further generalize the model, we will suffer from the problem of \textbf{multiple prediction}.
\item
  First, even in \citet{berryEstimationModelEntry1992}'s framework, the identity of entrants were not uniquely predicted.
\item
  Second, if we allows for the asymmetric competitive effects, we will not have the unique number of equilibrium entrants.
\item
  Third, the uniqueness of the equilibria may not hold once we allow for the mixed-strategy Nash equilibria.
\item
  If we do not have the unique prediction on the endogenous variables, we cannot write down the likelihood function.
\end{itemize}

\subsection{Multiple Equilibria in Bivariate Game with Heterogenous Profits}\label{multiple-equilibria-in-bivariate-game-with-heterogenous-profits}

\begin{itemize}
\tightlist
\item
  Return to \citet{tamerIncompleteSimultaneousDiscrete2003}'s bivariate game with heterogeneous profits.
\item
  Consider the pure-strategy Nash equilibrium when \(f_{im}, f_{jm}\) are realized.
\item
  \((0, 0)\) is a pure-strategy Nash equilibrium if:
  \[
  f_{im} \ge v_{0i}(x_{im});
  \]
  \[
  f_{jm} \ge v_{0j}(x_{jm}).
  \]
\item
  \((1, 1)\) is a pure-strategy Nash equilibrium if:
  \[
  f_{im} \le v_{0i}(x_{im}) + v_{1i}(x_{im});
  \]
  \[
  f_{jm} \le v_{0j}(x_{jm}) + v_{1j}(x_{jm}).
  \]
\item
  \((0, 1)\) is a pure-strategy Nash equilibrium if:
  \[
  f_{im} \ge v_{0i}(x_{im}) + v_{1i}(x_{im});
  \]
  \[
  f_{jm} \le v_{0j}(x_{jm}).
  \]
\item
  \((1, 0)\) is a pure-strategy Nash equilibrium if:
  \[
  f_{im} \le v_{0i}(x_{im});
  \]
  \[
  f_{jm} \ge v_{0j}(x_{jm}) + v_{1j}(x_{jm}).
  \]
\item
  In a certain region of \(f_{im}, f_{jm}\), there are multiple equilibria.
\end{itemize}

\subsection{Multiple Prediction in Bivariate Game with Heterogenous Profits}\label{multiple-prediction-in-bivariate-game-with-heterogenous-profits}

\begin{itemize}
\tightlist
\item
  In the orange region, we have multiple pure-strategy equilibria.
\item
  If we allow for mixed-strategy equilibria, the region of \(f_{im}, f_{jm}\) on which there are multiple equilibria will increase.

  \begin{figure}
  \includegraphics[width=0.8\linewidth]{figuretable/bivariateentry} \end{figure}
\item
  In this example, we can write the likelihood of the number of equilibrium entrants:

  \begin{itemize}
  \tightlist
  \item
    \(2\): green area.
  \item
    \(1\): yellow, orange, and red areas.
  \item
    \(0\): blue area.
  \end{itemize}
\item
  However, we cannot write the likelihood of the strategy profile.

  \begin{itemize}
  \tightlist
  \item
    \((1, 1)\): green area.
  \item
    \((0, 1)\): \(\ge\) red area, \(\le\) orange and red area.
  \item
    \((1, 0)\): \(\ge\) yellow area, \(\le\) orange and yellow area.
  \item
    \((0, 0)\): blue area.
  \end{itemize}
\end{itemize}

\subsection{Inference Based on Moment Inequalities}\label{inference-based-on-moment-inequalities}

\begin{itemize}
\tightlist
\item
  According to the theory, we have:
  \[
  \mathbb{P}\{0, 0|x\} = \mathbb{P}\{f_{i} \ge v_{0i}(x_{i}), f_{j} \ge v_{0j}(x_{j})\} \equiv H(0, 0|x).
  \]
\end{itemize}

\[
\mathbb{P}\{1, 1|x\} = \mathbb{P}\{f_{i} \le v_{0i}(x_{i}) + v_{1i}(x_{i}), f_{j} \le v_{0j}(x_{j}) + v_{1j}(x_{j}) \} \equiv H(1, 1|x).
\]

\[
\mathbb{P}\{0, 1|x\} \ge \mathbb{P}\{f_{i} \ge v_{0i}, v_{0j} \ge f_{j} \ge v_{0j} + v_{1j}\} + \mathbb{P}\{f_{i} \ge v_{0i} + v_{1i}, f_{j} \le v_{0j} + v_{1j}\} \equiv \underline{H}(0, 1|x).
\]

\[
\mathbb{P}\{0, 1|x\} \le \underline{H}(0, 1|x) + \mathbb{P}\{v_{0i} + v_{1i} \le f_{i} \le v_{0i}, v_{0j} + v_{1j} \le f_{j} \le v_{0j}\} \equiv \overline{H}(0, 1|x).
\]

\[
\mathbb{P}\{1, 0|x\} \ge \mathbb{P}\{f_{j} \ge v_{0j}, f_{i} \le v_{0i}\} + \mathbb{P}\{ v_{0j} + v_{1j} \le f_{j} \le v_{0j}, f_{i} \le v_{0i} + v_{1i}\} \equiv \underline{H}(1, 0|x).
\]

\[
\mathbb{P}\{1, 0|x\} \le \underline{H}(0, 1|x) + \mathbb{P}\{v_{0i} + v_{1i} \le f_{i} \le v_{0i}, v_{0j} + v_{1j} \le f_{j} \le v_{0j}\} \equiv \overline{H}(1, 0|x).
\]

\begin{itemize}
\tightlist
\item
  The parameters should satisfy the moment conditions:
  \[
  \mathbb{P}\{0, 0|x\} - H(0, 0|x) = 0;
  \]
  \[
  \mathbb{P}\{1, 1|x\} - H(1, 1|x) = 0;
  \]
  \[
  \min\left\{\mathbb{P}\{0, 1|x\} - \underline{H}(0, 1|x), 0\right\} = 0;
  \]
  \[
  \max\left\{\mathbb{P}\{0, 1|x\} - \overline{H}(0, 1|x), 0\right\} = 0;
  \]
  \[
  \min\left\{\mathbb{P}\{1, 0|x\} - \underline{H}(1, 0|x), 0\right\} = 0;
  \]
  \[
  \max\left\{\mathbb{P}\{1, 0|x\} - \overline{H}(1, 0|x), 0\right\} = 0;
  \]
\item
  We can estimate the parameters with the GMM method using the above modified moment conditions.
\item
  Inference based on the moment inequalities are found in \citet{andrewsInferenceParametersDefined2010}.
\item
  \citet{cilibertoMarketStructureMultiple2009} study the entry exit of airlines when there are heterogeneous competitive effects using the above approach.
\end{itemize}

\section{Incompelete-Information Heterogenous Oligopoly Entry}\label{incompelete-information-heterogenous-oligopoly-entry}

\subsection{Bivariate Case}\label{bivariate-case}

\begin{itemize}
\tightlist
\item
  There are two potential entrants.
\item
  Let the profit of firm \(i\) in market \(m\) be:
  \[
  \begin{split}
  \pi_{im}(x_{im}, y_{jm}, f_{im}) & \equiv v(y_{jm}, x_{im}) - f_{im}\\
  &=v_{0i}(x_{im}) + y_{jm} v_{1i}(x_{im}) - f_{im}.
  \end{split}
  \]
\item
  \(y_{im}\) and \(y_{jm}\) are the indicators of entry of firm \(i\) and \(j\) in market \(m\).
\item
  \(x_{im}\) and \(x_{jm}\) are firm \(i\) and \(j\)'s characteristics in market \(m\).
\item
  \(f_{im}\) and \(f_{jm}\) are the fixed costs of firm \(i\) and \(j\) in market \(m\).
\item
  The second equation is without loss of generality because \(y_{jm}\) is a binary variable.
\item
  The competitive effect of firm \(j\) on \(i\) and the effect of firm \(i\) on \(j\) are asymmetric.
\item
  The parameters of interest are \(v_{0i}, v_{0j}, v_{1i}, v_{1j}\) and the joint distribution of \(f_{im}, f_{jm}\) conditional on \(x_{im}\) and \(x_{jm}\).
\item
  Firm \(i\) \textbf{observe} both \(f_{im}\) but \textbf{not} \(f_{jm}\) when it makes decision.
\item
  Firm \(j\) \textbf{observe} both \(f_{jm}\) but \textbf{not} \(f_{im}\) when it makes decision.
\item
  Econometrican does not observe either of them.
\item
  The joint distribution of \(f_{im}, f_{jm}\) is \(F\) (independent of \(x\)).
\end{itemize}

\subsection{The Equilibrium Strategy and Belief}\label{the-equilibrium-strategy-and-belief}

\begin{itemize}
\tightlist
\item
  The equilibrium strategy becomes a step function that decreases in a threshold:
  \[
  y_{im} = 1\{f_{im} \le t_{im}\}.
  \]
  \[
  y_{jm} = 1\{f_{jm} \le t_{jm}\}.
  \]
\item
  Suppose that firm \(i\) believes that \(f_{jm}\) has a distribution of \(G_{jm}^{im}\) and firm \(j\) believes that \(f_{im}\) has a distribution of \(G_{im}^{jm}\).
\item
  Usually, we assume a common and objective prior: \(G_{jm}^{im}(\epsilon_{jm}) = F(\epsilon_{jm}|\epsilon_{im})\) and \(G_{im}^{jm}(\epsilon_{im}) = F(\epsilon_{im}|\epsilon_{jm})\).
\item
  When firm \(j\) follows strategy \(t_{jm}\), the expected payoff for firm \(i\) to enter is:
  \[
  [v_{0i}(x_{im}) - f_{im}][1 - G_{jm}^{im}(t_{jm})] + [v_{0i}(x_{im}) + v_{1i}(x_{im}) - f_{im})] G_{jm}^{im}(t_{jm}).
  \]
\item
  Thus, the threshold \(t_{im}\) is determined by:
  \[
  [v_{0i}(x_{im}) - t_{im}][1 - G_{jm}^{im}(t_{jm})] + [v_{0i}(x_{im}) + v_{1i}(x_{im}) - t_{im})] G_{jm}^{im}(t_{jm}) = 0.
  \]
\item
  In the same way, the threshold \(t_{jm}\) is determined by:
  \[
  [v_{0j}(x_{jm}) - t_{jm}][1 - G_{im}^{jm}(t_{im})] + [v_{0j}(x_{jm}) + v_{1j}(x_{jm}) - t_{jm})] G_{im}^{jm}(t_{im}) = 0.
  \]
\item
  This system of equations can have multiple solution.
\end{itemize}

\subsection{Equilibrium Selection and Likelihood}\label{equilibrium-selection-and-likelihood}

\begin{itemize}
\tightlist
\item
  If we specify the equilibrium selection rule \(\mathbb{P}(t_{im}, t_{jm}|x_{im}, x_{jm}, f_{im}, f_{jm})\), then we can specify the likelihood of observing \((0, 0)\), \((0, 1)\), \((1, 0)\), and \((1, 1)\).
\item
  If we do not, we will only have bounds on the likelihood of observing \((0, 0)\), \((0, 1)\), \((1, 0)\), and \((1, 1)\).
\item
  Another way is to assume that \textbf{the same equilibrium \(t_{im}^*(x_{im}, x_{jm}), t_{jm}^*(x_{im}, x_{jm})\) holds across markets}.
\item
  Then, the across market relative frequency of entries conditional on \(x_{im}, x_{jm}\) gives the estimates of the entry probabilities:
  \[
  \widehat{G}_{im}(x_{im}, x_{jm}) \approx G_{im}^{jm}[t^*_{im}(x_{im}, x_{jm})],
  \]
  \[
  \widehat{G}_{jm}(x_{im}, x_{jm}) \approx G_{jm}^{im}[t_{jm}^*(x_{im}, x_{jm})],
  \]
  for each \(x_{im}, x_{jm}\).
\item
  The estimated distribution has to solve:
  \[
  \widehat{G}_{im}(x_{im}, x_{jm}) = \mathbb{P}\{[v_{0i}(x_{im}) - f_{im}][1 - \widehat{G}_{jm}(x_{im}, x_{jm})] + [v_{0i}(x_{im}) + v_{1i}(x_{im}) - f_{im}] \widehat{G}_{jm}(x_{im}, x_{jm}) > 0\}.
  \]
  \[
  \widehat{G}_{jm}(x_{im}, x_{jm}) = \mathbb{P}\{[v_{0j}(x_{jm}) - f_{jm}][1 - \widehat{G}_{im}(x_{im}, x_{jm})] + [v_{0j}(x_{jm}) + v_{1j}(x_{jm}) - f_{jm}] \widehat{G}_{im}(x_{im}, x_{jm}) > 0\}.
  \]
\item
  We find parameters \(v_{0i}, v_{0j}, v_{1i}, v_{1j}, F\) that solve this system of equations.
\item
  The ``same equilibrium'' assumption is hardly justified, but is often used in the empirical studies.
\end{itemize}

\chapter{Dynamic Decision Model}\label{dynamics}

\section{Motivations}\label{motivations-4}

\begin{itemize}
\tightlist
\item
  The model is \textbf{dynamic} if there is an \textbf{endogenous state variable}, a state variable that is affected by an action of a player in the past.
\item
  There are many cases where the decision makers have to take into account the dynamic effects of their actions.
\item
  \textbf{Payoff linkages}:

  \begin{itemize}
  \tightlist
  \item
    Storable good: Next week's demand for a detergent depends on how many bottles consumers purchase and consume this week. The latter depends on this week's price and the price schedule of the detergent. The stock of the detergent consumers hold is an endogenous state variable.
  \item
    Learning by doing: The productivity of a firm next year can be higher if the firm produced more this year because the firm can learn from the experience. The cumulative production level is an endogenous state variable.
  \end{itemize}
\item
  \textbf{Information linkages}:

  \begin{itemize}
  \tightlist
  \item
    Uncertainty about the quality: If a consumer is uncertain about the quality of a product but can learn from experiencing the product, next season's demand for the product depends on how many consumers purchase and experience the product this season. The latter depends on this season's price and the price schedule of the product.
  \end{itemize}
\item
  \textbf{Strategic linkages}:

  \begin{itemize}
  \tightlist
  \item
    Tacit collusion: If a firm deviates from the collusive price, the price war will start. Then, the history of the prices is the endogenous state variable.
  \end{itemize}
\end{itemize}

\section{Single-Agent Model}\label{single-agent-model}

\subsection{Setting}\label{setting}

\begin{itemize}
\tightlist
\item
  This model originates at \citet{rustOptimalReplacementGMC1987}, while the setting and the notation follows \citet{pesendorferAsymptoticLeastSquares2008}.
\item
  We start from a simple set-up:
\item
  Single agent.
\item
  Infinite-horizon discrete time.

  \begin{itemize}
  \tightlist
  \item
    Time is \(t = 1, 2, \cdots, \infty\).
  \end{itemize}
\item
  Finitely many choices.

  \begin{itemize}
  \tightlist
  \item
    There are \(K + 1\) actions \(A = \{0, 1, \cdots, K\}\).
  \end{itemize}
\item
  Finite state space.

  \begin{itemize}
  \tightlist
  \item
    There are \(L\) states \(S = \{1, \cdots, L\}\).
  \end{itemize}
\item
  Markovian state transition.
\end{itemize}

\subsection{Timing of the Model}\label{timing-of-the-model}

\begin{itemize}
\tightlist
\item
  At period \(t\):
\item
  State \(s_t \in S\) is publicly observed.
\item
  Choice-specific profitability shocks \(\epsilon_t \in \mathbb{R}^{K + 1}\) are realized according to \(F(\cdot|s_t)\) and privately observed.
\item
  Choice \(a_t \in A\) is made.
\item
  State evolves according to a transition probability:
  \begin{equation}
  g(a, s, s') := \mathbb{P}\{s_{t + 1} = s'|s_t = s, a_t = a\},
  \end{equation}
\item
  Thus, the transition law only depends on today's state and action, but not on the past history.
\end{itemize}

\begin{equation}
G := 
\begin{pmatrix}
g(0, 1, 1) & \cdots & g(0, 1, L)\\
\vdots & & \vdots \\
g(K, 1, 1) & \cdots & g(K, 1, L)\\
& \vdots & \\
g(0, L, 1) & \cdots & g(0, L, L)\\
\vdots & & \vdots \\
g(K, L, 1) & \cdots & g(K, L, L)\\
\end{pmatrix}.
\end{equation}

\subsection{Period Payoff}\label{period-payoff}

\begin{itemize}
\tightlist
\item
  When the state is \(s_t\), action is \(a_t\), and the profitability shocks are \(\epsilon_t\), the period payoff is:
  \begin{equation}
  \pi(a_t, s_t) + \sum_{k = 1}^K \epsilon_{tk} 1\{a_t = k\},
  \end{equation}
\item
  \(\pi(a_t, s_t)\) is the mean \textbf{choice-specific period payoff}.
\item
  \(\epsilon_t\) is assumed to be i.i.d. across times and is drawn from \(F\).
\item
  Let:
  \[
  \epsilon_{t a_t} := \sum_{k = 1}^K \epsilon_{tk} 1\{a_t = k\},
  \]
  be the choice-specific profitability shock.
\item
  Let \(\Pi\) summarize the choice-specific period payoffs at each state:
  \begin{equation}
  \Pi =
  \begin{pmatrix}
  \pi(0, 1)\\
  \vdots \\
  \pi(K, 1)\\
  \vdots \\
  \pi(0, L)\\
  \vdots \\
  \pi(K, L)\\
  \end{pmatrix}.
  \end{equation}
\item
  The \textbf{payoff} is the discounted sum of future payoffs with discount factor \(\beta < 1\).
\item
  \(\Pi\) is one of the parameters of interest.
\end{itemize}

\subsection{Markovian Framework}\label{markovian-framework}

\begin{itemize}
\tightlist
\item
  The strategy is in general a mapping from the \textbf{entire} history to the action set.
\item
  We restrict the set of possible strategies to \textbf{Markovian strategies} \(a(\epsilon_t, s_t)\) that only depends on the latest realization of states \(\epsilon_t, s_t\), i.e., the behavior does not depend on the past states, conditional on today's states.
\item
  The Markovian strategy is introduced by \citet{maskinTheoryDynamicOligopoly1988}. But their model is slightly different from the current mode. They considered an oligopoly model in which only one firm can move at one time and his/her action depends only on the rival's latest move. The current single-agent model can be regarded as a version of \citet{maskinTheoryDynamicOligopoly1988}'s model such that the rival is replaced with the nature.
\end{itemize}

\subsection{Belief}\label{belief}

\begin{itemize}
\tightlist
\item
  When a player makes a decision, s/he should have some belief about the future \(\epsilon_t, s_t\), and \(a_t\).
\item
  We usually assume the \textbf{rational expectation}: the play knows the equilibrium distribution of these future variables and use it as his/her belief.
\item
  The distribution of \(\epsilon_t\) and \(s_t\) is believed to follow \(F\) and \(G\).
\item
  Let \(\sigma(a|s)\) be the player's belief about the possibility of taking \(a\) when the realized state is \(s\), which may or may not coincide with the equilibrium probability.
\item
  Let \(\sigma\) stack them up as:
  \begin{equation}
  \sigma = 
  \begin{pmatrix}
  \sigma(0|1)\\
  \vdots\\
  \sigma(K|1)\\
  \vdots\\ 
  \sigma(0|L)\\
  \vdots\\ 
  \sigma(K|L)
  \end{pmatrix}.
  \end{equation}
\end{itemize}

\subsection{Decision Problem}\label{decision-problem}

\begin{itemize}
\tightlist
\item
  The agent chooses strategy \(a(\cdot, \cdot)\) such that:
  \begin{equation}
  \begin{split}
  \max_{a(\cdot, \cdot)} & \pi[a(\epsilon_0, s_0), s_0] + \epsilon_{0 a(\epsilon_0, s_0)}\\
  &+ \mathbb{E}\Bigg\{ \sum_{t = 1}^\infty \beta^t \Bigg[\pi(a(\epsilon_t, s_t), s_t) + \epsilon_{t a(\epsilon_t, s_t)}\Bigg]\Bigg|s_0, a(\epsilon_0, s_0)\Bigg\}
  \end{split}
  \end{equation}
\item
  The expectation is taken with respect to his/her belief.
\end{itemize}

\subsection{Value Function and Ex-ante Value Function}\label{value-function-and-ex-ante-value-function}

\begin{itemize}
\tightlist
\item
  When the belief about the future behavior is \(\sigma\), then the value function associated with the belief is defined as:
  \begin{equation}
  \begin{split}
  &V(\sigma, s_0, \epsilon_0)\\
  &= \sum_{a \in A} \sigma(a|s_0) \Bigg\{\pi(a, s_0) + \epsilon_{0a} + \mathbb{E}\Bigg[ \sum_{t = 1}^\infty \beta^t \sum_{a \in A}\sigma(a|s_t)\Bigg(\pi(a, s_t) + \epsilon_{ta}\Bigg)\Bigg|s_0, a\Bigg] \Bigg\}.
  \end{split}
  \end{equation}
\item
  It has the recursive structure as:
  \begin{equation}
  \begin{split}
  &V(\sigma, s_0, \epsilon_0)\\
  & = \sum_{a \in A} \sigma(a|s_0) \Bigg\{\pi(a, s_0) + \epsilon_{0a} + \beta \mathbb{E}\Bigg[V(\sigma, s_1, \epsilon_1)\Bigg|s_0, a\Bigg]\Bigg\}\\
  & = \sum_{a \in A} \sigma(a|s_0) \Bigg\{\pi(a, s_0) + \epsilon_{0a} + \beta \sum_{s_1 \in S} V(\sigma, s_1, \epsilon_1)g(a, s_0, s_1)\Bigg\}.
  \end{split}
  \end{equation}
\item
  \(V(\sigma, s, \epsilon)\) is the value function after the profitablity shock \(\epsilon\) is realized.
\item
  On the other hand, we define the \textbf{ex-ante value function} under belief \(\sigma\) as:
  \begin{equation}
  V(\sigma, s) = \mathbb{E}\{V(\sigma, s, \epsilon)|s\}.
  \end{equation}
\end{itemize}

\subsection{Choice-specific Value Function}\label{choice-specific-value-function}

\begin{itemize}
\tightlist
\item
  When the current state and profitability shocks are \(s\) and \(\epsilon\) and the belief about the future behavior is \(\sigma\), we define the \textbf{choice-specific} value function for an agent in a period as follows:
  \begin{equation}
  \begin{split}
  V(\sigma, a, s, \epsilon) &= \pi(a , s) + \epsilon_a + \beta \sum_{s' \in S} V(\sigma, s') g(a, s, s')\\
   &= \underbrace{\pi(a , s) + \beta \sum_{s' \in S} V(\sigma, s') g(a, s, s')}_{v(\sigma, a, s)} + \epsilon_a.
  \end{split}
  \end{equation}
\item
  We call \(v(\sigma, a, s)\) be the \textbf{choice-specific} mean value function with belief \(\sigma\).
\item
  \(V(\sigma, s, \epsilon)\), \(V(\sigma, s)\), \(V(\sigma, a, s, \epsilon)\), and \(v(\sigma, a, s)\) are all different, abusing the notation.
\end{itemize}

\subsection{Optimality Condition}\label{optimality-condition}

\begin{itemize}
\tightlist
\item
  When the state and profitability shocks are \(s\) and \(\epsilon\), \(a\) is the optimal choice if and only if:
  \begin{equation}
  v(\sigma, a, s) + \epsilon_{a} \ge v(\sigma, a', s) + \epsilon_{a'}, \forall a' \in A.
  \end{equation}
\item
  This condition looks similar to the optimality condition in the static discrete choice model.
\item
  The only difference from the static discrete choice model is that the mean indirect utility is the sum of the choice-specific mean profit and the discounted continuation value.
\item
  Thus, as long as the mean choice-specific value function for given parameters can be computed, the following simulation and estimation procedure will be similar to the static discrete choice model.
\end{itemize}

\subsection{Optimal Conditional Choice Probability}\label{optimal-conditional-choice-probability}

\begin{itemize}
\tightlist
\item
  From the previous optimality condition, we can define the \textbf{optimal conditional choice probability} with belief \(\sigma\) as:
  \begin{equation}
  \begin{split}
  p(a|s) &:= \mathbb{P}\{v(\sigma, a, s) + \epsilon_{a} \ge v(\sigma, a', s) + \epsilon_{a'}, \forall a' \in A\}\\
  &= \int \prod_{a' \neq a} 1\{v(\sigma, a, s) + \epsilon_{a} \ge v(\sigma, a', s) + \epsilon_{a'}\} dF\\
  &:= \Psi(\sigma, a, s).
  \end{split}
  \end{equation}
\item
  \(\Psi(\sigma, a, s)\) maps the tuple of action, state and belief to the optimal conditional choice probability of the action given the state and the belief.
\end{itemize}

\subsection{Optimality Condition}\label{optimality-condition-1}

\begin{itemize}
\tightlist
\item
  Let \(p\) and \(\Psi\) be:
  \begin{equation}
  p = 
  \begin{pmatrix}
  p(0|1)\\
  \vdots\\
  p(K|1)\\
  \vdots\\
  p(0|L)\\
  \vdots\\
  p(K|L)
  \end{pmatrix},
  \end{equation}
\end{itemize}

\begin{equation}
\Psi(\sigma) = 
\begin{pmatrix}
\Psi(\sigma, 0, 1)\\
\vdots\\
\Psi(\sigma, K, 1)\\
\vdots\\
\Psi(\sigma, 0, L)\\
\vdots\\
\Psi(\sigma, K, L)
\end{pmatrix}.
\end{equation}
- The optimality condition with respect to the conditional choice probabilities given the belief is written as:
\begin{equation}
p = \Psi(\sigma).
\end{equation}
- The rational expectation hypothesis requires that the belief about the future behavior coincides with the optimal conditional choice probability, i.e.:
\begin{equation}
p = \Psi(p).
\end{equation}
- The optimal conditional choice probability under the rational expectation hypothesis is characterized as a fixed point of mapping \(\Psi\).

\subsection{Mapping from a Conditional Choice Probability to an Ex-ante Value Function}\label{mapping-from-a-conditional-choice-probability-to-an-ex-ante-value-function}

\begin{itemize}
\tightlist
\item
  Inserting \(\sigma = p\), we obtain a mapping from an optimal conditional choice probability to an ex-ante value function such as:
  \begin{equation}
  \begin{split}
  V(s) &= \mathbb{E}\{V(s, \epsilon)|s\}\\
  &= \mathbb{E}\left[ \sum_{t = 0}^\infty \beta^t \sum_{a \in A}p(a|s_t)\left[\pi(a, s_t) + \epsilon_{ta}\right]\Bigg|s_0, a\right]\\
  &:= \varphi(p, s).
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Mapping from an Ex-ante Value Function to an Optimal Conditional Choice Probability}\label{mapping-from-an-ex-ante-value-function-to-an-optimal-conditional-choice-probability}

\begin{itemize}
\tightlist
\item
  On the other hand, we can derive a mapping from an ex-ante value function to an optimal conditional choice probability such as:
  \begin{equation}
  \begin{split}
  p(a|s) = \mathbb{P}\Bigg\{&\pi(a , s) + \beta \sum_{s' \in S} V(s') g(a, s, s') + \epsilon_a \ge\\
  &\pi(a' , s) + \beta \sum_{s' \in S} V(s') g(a', s, s') + \epsilon_{a'}, \forall a' \in A \Bigg\}\\
  &:= \Lambda(V, a, s).
  \end{split}
  \end{equation}
\end{itemize}

\subsection{The Optimality Conditions}\label{the-optimality-conditions}

\begin{itemize}
\tightlist
\item
  Composing these two mappings, we can write down the optimality condition as the fixed-point for ex-ante value functions:
  \begin{equation}
  V = \varphi(p) = \varphi[\Lambda(V)] := \Phi(V).
  \end{equation}
\item
  Or as the fixed-point for the optimal conditional choice probabilities:
  \[
  p = \Lambda(V) = \Lambda[\varphi(p)] := \Psi(p).
  \]
\end{itemize}

\subsection{Fixed-point Algorithm}\label{fixed-point-algorithm}

\begin{itemize}
\tightlist
\item
  If \(\epsilon\) is drawn from an i.i.d. type-I extreme value distribution, we can derive the mapping from the ex-ante value function to the conditional choice probability in the closed form:
  \begin{equation}
  \begin{split}
  \Lambda(V, a, s) &= \mathbb{P}\{\pi(a , s) + \beta \sum_{s' \in S} V(s') g(a, s, s') + \epsilon_{a} \ge\\
   & \pi(a' , s) + \beta \sum_{s' \in S} V(s') g(a', s, s') + \epsilon_{a'}, \forall a' \in A\}\\
  &=\frac{\exp[\pi(a , s) + \beta \sum_{s' \in S} V(s') g(a, s, s')]}{\sum_{a' \in A} \exp[\pi(a' , s) + \beta \sum_{s' \in S} V(s') g(a', s, s')]}.
  \end{split}
  \end{equation}
\item
  Moreover, we can also derive the mapping from the ex-ante value function to the ex-ante value function as follows:
  \begin{equation}
  \begin{split}
  \Phi(V) &= \mathbb{E}\{\max_{a \in A} \pi(a , s) + \beta \sum_{s' \in S} V(s') g(a, s, s') + \epsilon_{a}\} \\
  &=\log \Bigg\{\sum_{a \in A} \exp[\pi(a , s) + \beta \sum_{s' \in S} V(s') g(a, s, s')] \Bigg\} + \gamma,
  \end{split}
  \end{equation}
  where \(\gamma\) is Euler's constant.
\item
  \(\Phi\) is shown to be a contraction mapping as long as \(\beta < 1\).
\item
  Thus, we can solve the model by starting from an arbitrary ex-ante value function \(V\) and by iterating the mapping \(\Phi\) until the change in the ex-ante value functions is below a certain threshold.
\item
  \citet{rustOptimalReplacementGMC1987} gives the result for more general distributional assumption for \(\epsilon\).
\end{itemize}

\section{Identification}\label{identification}

\subsection{Unidentification Result}\label{unidentification-result}

\begin{itemize}
\tightlist
\item
  The identification of the single-agent dynamic decision model is studied in \citet{magnacIdentifyingDynamicDiscrete2002}.
\item
  The model primitives are \((\Pi, F, \beta, G)\).
\item
  The transition probability \(G\) is directly identified from the data because \(a, s, s'\) are observed by econometrician.
\item
  In the same manner, we can directly identify the optimal conditional choice probability \(p\) because \(a\) and \(s\) are observed by econometrician.
\item
  It is known that the model is in general not identified.
\item
  The discount factor \(\beta\) is hard to identify.

  \begin{itemize}
  \tightlist
  \item
    It determines the weights between the current and future profits.
  \item
    Suppose that a firm makes a large investment.
  \item
    This may be because the firm overweights the future (high \(\beta\)) or because the investment cost is low (\(\pi\) is such that the investment cost is low).
  \item
    We cannot distinguish between these two possibilities.
  \item
    To identify it, you need some instruments that changes the future return to the investment but does not affect today's payoff.
  \end{itemize}
\end{itemize}

\subsection{\texorpdfstring{Identification when \(\beta\) and \(F\) is Known}{Identification when \textbackslash beta and F is Known}}\label{identification-when-beta-and-f-is-known}

\begin{itemize}
\tightlist
\item
  We often fix \(\beta\) and assume the distribution \(F\) and only consider the identification of \(\Pi\).
\item
  Note that the optimal conditional choice probability is directly identified from the data because \(s\) and \(a\) are observed.
\item
  Then the optimality condition under the rational expectation hypothesis gives the following \(KL\) system of equations:
  \[
  p = \Psi(p).
  \]
\item
  On the other hand, the dimension of parameter \(\Pi\) is in general \((K + 1)L\) (the mean profit at a state and an action).
\item
  One possible restriction is to assume that \(\pi(0, s)\) are known for any \(s\). For example, assume that \(a = 0\) means that the firm is inactive and so \(\pi(0, s) = 0\).
\end{itemize}

\subsection{Crucial Assumptions for the Argument}\label{crucial-assumptions-for-the-argument}

\begin{itemize}
\tightlist
\item
  The following assumptions are crucial for the above argument.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Conditional i.i.d. Unobservable}: The profit shocks that are unobservable to econometrician are i.i.d. conditional on the observable state.
\item
  \textbf{Conditional Independence of Future Observable State}:
  \begin{equation}
  \mathbb{P}\{s_{t + 1}|s_t, a_t, \epsilon_t\} = \mathbb{P}\{s_{t + 1}|s_t, a_t\}.
  \end{equation}
\end{enumerate}

\begin{itemize}
\tightlist
\item
  If the first assumption is violated, the choice probability cannot be written as a function only of the observable state of the period. If \(\epsilon_t\) is serially correlated, to integrate over \(\epsilon_{t + 1}\) we have to condition on \(\epsilon_t\). Then, we may not be able to identify the optimal conditional choice probability from the data.
\item
  If the second assumption is violated, for the same reason, we may not be able to identify the state transition law.
\item
  \citet{kasaharaNonparametricIdentificationFinite2009} proves the identification when the first assumption is violated: there is a player-specific fixed effect that has a finite-mixture structure.
\end{itemize}

\section{Estimation by Nested Fixed-point Algorithm}\label{estimation-by-nested-fixed-point-algorithm}

\subsection{Nested Fixed-Point Algorithm}\label{nested-fixed-point-algorithm}

\begin{itemize}
\tightlist
\item
  A straightforward way of estimating the single-agent dynamic model is to solve the optimal conditional choice probability by a fixed-point algorithm for each parameter and evaluate the likelihood function using the optimal conditional choice probability.
\item
  Because a fixed-point algorithm is nested in the parameter search, \citet{rustOptimalReplacementGMC1987} named it the \textbf{nested fixed-point algorithm}.
\end{itemize}

\subsection{Solving for the Ex-ante Value Function}\label{solving-for-the-ex-ante-value-function}

\begin{itemize}
\tightlist
\item
  Let \(\theta_1\) be the parameters that determine \(\Pi\), \(\theta_2\) be the parameters that determine \(G\), and \(\theta = (\theta_1', \theta_2')'\).
\item
  The ex-ante value function is a fixed point of a contraction mapping \(\Phi^\theta\) such that:
  \begin{equation}
  \begin{split}
  \Phi^\theta(p) &=\log \Bigg\{\sum_{a \in A} \exp[\pi^{\theta_1}(a , s) + \beta \sum_{s' \in S} V(s') g^{\theta_2}(a, s, s')] \Bigg\} + \gamma,
  \end{split}
  \end{equation}
\item
  Let \(V^{\theta (0)}\) be an arbitrary initial function and define \(V^{\theta (r + 1)}\) by:
  \[
  V^{\theta (r + 1)} = \Phi^{\theta}(V^{\theta (r)}).
  \]
\item
  We iterate this until \(|V^{\theta (r + 1)} - V^{\theta (r)}|\) is below a certain threshold.
\item
  Let \(V^{^\theta (\ast)}\) be the solution to the fixed-point algorithm.
\item
  Then, we can derive the optimal choice probability by:
  \begin{equation}
  \begin{split}
  p^{\theta (\ast)} = \Lambda\left[V^{\theta (\ast)}\right].
  \end{split}
  \end{equation}
\item
  These are the ex-ante value function and optimal conditional choice probabilities under parameters \(\theta\).
\end{itemize}

\subsection{Estimation by Nested Fixed-Point Algorithm}\label{estimation-by-nested-fixed-point-algorithm-1}

\begin{itemize}
\tightlist
\item
  The previous algorithm allows us to derive the optimal choice probability given parameters.
\item
  Then it is straight forward to evaluate the likelihood function given observations \(\{a_t, s_t\}_{t = 1}^T\) by:
  \begin{equation}
  \begin{split}
  &L(\theta; \{a_t, s_t\}_{t = 1}^T) =\prod_{t = 1}^T \prod_{a_t = 0}^1 p^{\theta (\ast)}(a_t|s_t)^{a_t} g^{\theta_2} (s_{t + 1}|s_t, a_t).
  \end{split}
  \end{equation}
  and so the log likelihood function is:
  \begin{equation}
  \begin{split}
  &l(\theta; \{a_t, s_t\}_{t = 1}^T)\\
  &=\sum_{t = 1}^T \sum_{a_t = 0}^1 a_t \log [p^{\theta (\ast)}(a_t|s_t)] + \sum_{t = 1}^T \log [g^{\theta_2} (s_{t + 1}|s_t, a_t)].
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Full and Partial Likelihood}\label{full-and-partial-likelihood}

\begin{itemize}
\tightlist
\item
  We can find \(\theta\) that maximizes the full log likelihood \(l(\theta; \{a_t, s_t\}_{t = 1}^T)\) to estimate the model.
\item
  However, the convergence takes longer as the number of parameters are larger.
\item
  Parameters that govern the state transition is estimated by finding \(\theta_2\) that maximizes the partial likelihood:
  \begin{equation}
  \hat{\theta}_2 = \text{argmax}_{\theta_2} \sum_{t = 1}^T \log g^{\theta_2}(s_{t + 1}|s_t, a_t).
  \end{equation}
\item
  Then we can estimate \(\theta_1\) by finding \(\theta_1\) that maximizes the partial likelihood:
  \begin{equation}
  \hat{\theta}_1 = \text{argmax}_{\theta_1} \sum_{t = 1}^T \sum_{a_t = 0}^1 a_t \log [p^{(\theta_1, \hat{\theta}_2) (\ast)}(a_t|s_t)].
  \end{equation}
\item
  This causes some efficiency loss but speeds up the computation, because we can estimate \(\theta_2\) without solving the fixed-point.
\end{itemize}

\section{Estimation by Conditional Choice Probability (CCP) Approach}\label{estimation-by-conditional-choice-probability-ccp-approach}

\subsection{CCP Approach}\label{ccp-approach}

\begin{itemize}
\tightlist
\item
  \textbf{Conditional Choice Probability (CCP)} approach suggested by \citet{hotzConditionalChoiceProbabilities1993} significantly reduces the computation time at the cost of some efficiency.
\item
  This approach can be applied to many other settings.
\item
  The idea is:

  \begin{itemize}
  \tightlist
  \item
    We can identify the optimal conditional choice probability \(p^\theta\) directly from the data. This is a reduced-form parameter (cf.~\(\theta\) is the structural parameters) of the model.
  \item
    The optimality condition \(p^\theta = \Psi^\theta(p^\theta)\) can be regarded as a moment condition.
  \end{itemize}
\item
  In the nested fixed-point algorithm, we find \(p^\theta\) that solves the optimality condition given \(\theta\) to compute the likelihood.
\item
  In CCP approach, we find \(\theta\) that solves the optimality condition given \(p^\theta\) that is identified directly from the data.
\end{itemize}

\subsection{First Step: Estimating CCP}\label{first-step-estimating-ccp}

\begin{itemize}
\tightlist
\item
  The first step of the CCP approach is to estimate the conditional choice probability and transition probability.
\item
  If everything is discrete, it is nothing but the empirical distribution:
  \begin{equation}
  \begin{split}
  &\hat{p}(a|s) = \frac{\sum_{i = 1}^N \sum_{t = 1}^T 1\{a_{it} = a, s_{it} = s\}}{\sum_{i = 1}^N \sum_{t = 1} 1\{s_{it} = s\}},\\
  &\hat{g}(s'|s, a) = \frac{\sum_{i = 1}^N \sum_{t = 1}^T 1\{s_{i, t + 1} = s', s_{it} = s, a_{it} = a\}}{\sum_{i = 1}^N \sum_{t = 1} 1\{s_{it} = s, a_{it} = a\}}.
  \end{split}
  \end{equation}
\item
  We can of course use a parametric model.
\item
  For example, we may estimate the conditional choice probability with a multinomial logit models:
  \begin{equation}
  \begin{split}
  &\hat{p}(a|s) = \frac{\exp[\hat{\beta} a + \hat{\gamma} s)]}{\sum_{a' \in A} \exp[\hat{\beta} a' + \hat{\gamma} s)]}.
  \end{split}
  \end{equation}
\end{itemize}

\subsection{First Step: Estimating CCP}\label{first-step-estimating-ccp-1}

\begin{itemize}
\tightlist
\item
  What is the estimated CCP \(\hat{p}\)?
\item
  This is the optimal conditional choice probability \textbf{at a particular equilibrium} under a true parameter.
\item
  If parameter changes, then the equilibrium changes. Then, the conditional choice probability also changes.
\item
  The reduced-form parameter \(\hat{p}\) embodies the information about behaviors under the actual equilibrium but does not tell anything about behaviors under hypothetical equilibria.
\item
  Therefore, \(\hat{p}\) is not sufficient to make counterfactual prediction.
\end{itemize}

\subsection{Second Step: Estimating Structural Parameters}\label{second-step-estimating-structural-parameters}

\begin{itemize}
\tightlist
\item
  Among structural parameters \(\theta\), parameters in the transition probability \(\theta_2\) is already identified from the data in the first step.
\item
  How do we identify \(\theta_1\), parameters in the profit function \(\pi\)?
\item
  If we fix \(\theta_1\), in theory, we can compute:
  \begin{equation}
  \begin{split}
  \hat{V}^{(\theta_1, \hat{\theta}_2)}(s) = \varphi^{(\theta_1, \hat{\theta}_2)}(\hat{p}, s) = \mathbb{E}\Bigg[ \sum_{t = 0}^\infty \beta^t \sum_{a \in A}\hat{p}(a|s_t)\Bigg(\pi^{\theta_1}(a, s_t) + \epsilon_{ta}\Bigg)\Bigg|s\Bigg],\\
  \end{split}
  \end{equation}
  although the expectation may not have a closed form solution.
\end{itemize}

\subsection{Second Step: Estimating Structural Parameters}\label{second-step-estimating-structural-parameters-1}

\begin{itemize}
\tightlist
\item
  In addition, if we fix \(\theta_1\), in theory, we can compute:
  \begin{equation}
  \begin{split}
  &\Lambda^{(\theta_1, \hat{\theta}_2)}(\hat{V}^{(\theta_1, \hat{\theta}_2)}, a, s)\\
  &:= \mathbb{P}\Bigg\{\pi^{\theta_1}(a , s) + \beta \sum_{s' \in S} \hat{V}^{(\theta_1, \hat{\theta}_2)}(s') g^{\hat{\theta}_2}(a, s, s') + \epsilon_a\\
  &\ge \pi^{\theta_1}(a' , s) + \beta \sum_{s' \in S} \hat{V}^{(\theta_1, \hat{\theta}_2)}(s') g^{\hat{\theta}_2}(a', s, s') + \epsilon_{a'}, \forall a' \in A \Bigg\}
  \end{split}
  \end{equation}
\item
  Combining these two mappings, we can compute:
  \begin{equation}
  \Psi^{(\theta_1, \hat{\theta_2})}(\hat{p}) = \Lambda^{(\theta_1, \hat{\theta}_2)}[\varphi^{(\theta_1, \hat{\theta}_2)}(\hat{p})].
  \end{equation}
\item
  Then, we can find \(\theta_1\) that minimizes the distance between \(\hat{p}\) and \(\Psi^{(\theta_1, \hat{\theta_2})}(\hat{p})\) to find \(\theta_1\) that is consistent with the observed conditional choice probabilities.
\end{itemize}

\subsection{Type-I Extreme Value Distribution}\label{type-i-extreme-value-distribution}

\begin{itemize}
\tightlist
\item
  \(\Lambda\) and \(\varphi\) do no have closed form expressions in general.
\item
  Exception is the case where the profitability shocks \(\epsilon_{ta}\) is drawn from i.i.d. type-I extreme value distribution.
\item
  First, we know that \(\Lambda\) can be written as:
  \begin{equation}
  \begin{split}
  &\Lambda^{(\theta_1, \hat{\theta}_2)}(\hat{V}^{(\theta_1, \hat{\theta}_2)}, a, s)\\
  &:= \mathbb{P}\Bigg\{\pi^{\theta_1}(a , s) + \beta \sum_{s' \in S} \hat{V}^{(\theta_1, \hat{\theta}_2)}(s') g^{\hat{\theta}_2}(a, s, s') + \epsilon_a \ge\\
  &\pi^{\theta_1}(a' , s) + \beta \sum_{s' \in S} \hat{V}^{(\theta_1, \hat{\theta}_2)}(s') g^{\hat{\theta}_2}(a', s, s') + \epsilon_{a'}, \forall a' \in A \Bigg\}\\
  &=\frac{\exp\Big[\pi^{\theta_1}(a , s) + \beta \sum_{s' \in S}\hat{V}^{(\theta_1, \hat{\theta}_2)}(s') g^{\hat{\theta}_2}(a, s, s')\Big]}{\sum_{a' = 0}^K \exp\Big[\pi^{\theta_1}(a' , s) + \beta \sum_{s' \in S} \hat{V}^{(\theta_1, \hat{\theta}_2)}(s') g^{\hat{\theta}_2}(a', s, s') \Big]}.
  \end{split}
  \end{equation}
\item
  Second, we can show that \(\varphi\) has a closed form solution:
  \begin{equation}
  \begin{split}
  &\varphi^{(\theta_1, \hat{\theta}_2)}(p, s)\\
  &:= \mathbb{E}\{V(s, \epsilon)|s\}\\
  &= \mathbb{E}\Bigg[ \sum_{t = 0}^\infty \beta^t \sum_{a \in A}\hat{p}(a|s_t)\Bigg(\pi^{\theta_1}(a, s_t) + \epsilon_{ta}\Bigg)\Bigg|s\Bigg]\\
  &=\mathbb{E}\Bigg[\sum_{a \in A}\hat{p}(a|s)\Bigg(\pi^{\theta_1}(a, s) + \epsilon_{a} + \beta \sum_{s' \in S} \mathbb{E}\{\hat{V}^{(\theta_1, \hat{\theta}_2)}(s, \epsilon)|s'\} g^{\hat{\theta}_2}(a, s, s')  \Bigg)\Bigg|s\Bigg]\\
  &=\mathbb{E}\Bigg[\sum_{a \in A}\hat{p}(a|s)\Bigg(\pi^{\theta_1}(a, s) + \epsilon_{a} + \beta \sum_{s' \in S} \varphi^{(\theta_1, \hat{\theta}_2)}(\hat{p}, s') g^{\hat{\theta}_2}(a, s, s')  \Bigg)\Bigg|s\Bigg]\\
  &=\sum_{a \in A}\hat{p}(a|s)\Bigg(\pi^{\theta_1}(a, s) + \mathbb{E}[\epsilon_{a}|s, a] + \beta \sum_{s' \in S} \varphi^{(\theta_1, \hat{\theta}_2)}(\hat{p}, s') g^{\hat{\theta}_2}(a, s, s')  \Bigg)
  \end{split}
  \end{equation}
\item
  We need closed form expression of \(\mathbb{E}[\epsilon_{a}|s, a]\): the expected value of choice\(-a\) specific profitability shock \textbf{conditional on that state is \(s\) and \(a\) is optimal} (\(\neq\) unconditional mean of \(\epsilon_a\)).
\end{itemize}

\subsection{Type-I Extreme Value Distribution}\label{type-i-extreme-value-distribution-1}

\begin{itemize}
\tightlist
\item
  If \(\epsilon_a\) is drawn from i.i.d. type-I extreme value distribution, it can be shown that:
  \begin{equation}
  \begin{split}
  \mathbb{E}[\epsilon_{a}|s, a] &= \hat{p}(a|s)^{-1} \int \epsilon_a 1\Bigg\{\pi^{\theta_1}(a , s) + \beta \sum_{s' \in S} \hat{V}^{(\theta_1, \hat{\theta}_2)}(s') g^{\hat{\theta}_2}(a, s, s') + \epsilon_a \ge\\
  &\pi^{\theta_1}(a' , s) + \beta \sum_{s' \in S} \hat{V}^{(\theta_1, \hat{\theta}_2)}(s') g^{\hat{\theta}_2}(a', s, s') + \epsilon_{a'}, \forall a' \in A \Bigg\}dF(e)\\
  &= \gamma - \ln \hat{p}(a|s),
  \end{split}
  \end{equation}
  where \(\gamma\) is Euler's constant:
  \begin{equation}
  \gamma := \lim_{n \to \infty} \Bigg(\sum_{k = 1}^n \frac{1}{k} - \ln(n) \Bigg) \approx 0.57721...
  \end{equation}
\end{itemize}

\subsection{Type-I Extreme Value Distribution}\label{type-i-extreme-value-distribution-2}

\begin{itemize}
\tightlist
\item
  Inserting this into the previous expression, we get:
  \begin{equation}
  \begin{split}
  \varphi^{(\theta_1, \hat{\theta}_2)}(\hat{p}, s) = \sum_{a \in A}\hat{p}(a|s)\Bigg(\pi^{\theta_1}(a, s) + \gamma - \ln \hat{p}(a|s) + \beta \sum_{s' \in S} \varphi^{(\theta_1, \hat{\theta}_2)}(\hat{p}, s') g^{\hat{\theta}_2}(a, s, s')  \Bigg).
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Type-I Extreme Value Distribution}\label{type-i-extreme-value-distribution-3}

\begin{itemize}
\tightlist
\item
  Write the continuation value in a matrix form:
  \begin{equation}
  \begin{split}
  & \sum_{s' \in S} \varphi^{(\theta_1, \hat{\theta}_2)}(p, s') g^{\hat{\theta}_2}(a, s, s')\\
  & = [g^{\hat{\theta}_2}(a, s, 1), \cdots, g^{\hat{\theta}_2}(a, s, L)] 
  \underbrace{\begin{bmatrix}
  \varphi^{(\theta_1, \hat{\theta}_2)}(p, 1)\\
  \vdots\\
  \varphi^{(\theta_1, \hat{\theta}_2)}(p, L).
  \end{bmatrix}}_{:= \varphi^{(\theta_1, \hat{\theta}_2)}(p)}
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Type-I Extreme Value Distribution}\label{type-i-extreme-value-distribution-4}

\begin{itemize}
\tightlist
\item
  Write the ex-ante value function in a matrix form:
\end{itemize}

\begin{equation}
\begin{split}
&\varphi^{(\theta_1, \hat{\theta}_2)}(p, s)\\
&=\underbrace{[p(0|s), \cdots, p(K|s)]}_{:= p(s)'} \\
&\times\begin{bmatrix}
\underbrace{\begin{bmatrix}
\pi^{\theta_1}(0, s)\\
\vdots\\
\pi^{\theta_1}(K, s)
\end{bmatrix}}_{:= \pi^{\theta_1}(s)}
+ \gamma
-
\underbrace{\begin{bmatrix}
\ln p(0|s)\\
\vdots\\
\ln p(K|s)
\end{bmatrix}}_{:= \ln p(s)}
+\beta
\underbrace{\begin{bmatrix}
g^{\hat{\theta}_2}(0, s, 1), \cdots, g^{\hat{\theta}_2}(0, s, L)\\
\vdots\\
g^{\hat{\theta}_2}(K, s, 1), \cdots, g^{\hat{\theta}_2}(K, s, L)
\end{bmatrix}}_{:= G^{\hat{\theta}_2}(s)}
\varphi^{(\theta_1, \hat{\theta}_2)}(p)
\end{bmatrix}\\
&=p(s)'[\pi^{\theta_1}(s) + \gamma - \ln p(s)] + \beta p(s)' G^{\hat{\theta}_2}(s)  \varphi^{(\theta_1, \hat{\theta}_2)}(p)
\end{split}
\end{equation}

\begin{itemize}
\item
  Stacking up for \(s\), we get:
  \begin{equation}
  \begin{split}
  &\varphi^{(\theta_1, \hat{\theta}_2)}(p) =
  \begin{bmatrix}
  p(1)'[\pi^{\theta_1}(1) + \gamma - \ln p(1)]\\
  \vdots\\
  p(L)'[\pi^{\theta_1}(L) + \gamma - \ln p(L)]
  \end{bmatrix}
  +\beta
  \begin{bmatrix}
  p(1)' G^{\hat{\theta}_2}(1)\\
  \vdots\\
  p(L)' G^{\hat{\theta}_2}(L)
  \end{bmatrix}
  \varphi^{(\theta_1, \hat{\theta}_2)}(p)\\
  &\Leftrightarrow\\
  &\varphi^{(\theta_1, \hat{\theta}_2)}(p) = 
  \begin{bmatrix}
  I -
  \beta
  \begin{bmatrix}
  p(1)' G^{\hat{\theta}_2}(1)\\
  \vdots\\
  p(L)' G^{\hat{\theta}_2}(L)
  \end{bmatrix}
  \end{bmatrix}^{-1}
  \begin{bmatrix}
  p(1)'[\pi^{\theta_1}(1) + \gamma - \ln p(1)]\\
  \vdots\\
  p(L)'[\pi^{\theta_1}(L) + \gamma - \ln p(L)]
  \end{bmatrix}.
  \end{split}
  \end{equation}
\item
  Note that you can get this expression even if the profitability shocks are not type-I extreme value, although you need numerical integration for \(\mathbb{E}\{\epsilon_a|s, a\}\) instead of the analytical solution \(\gamma - \ln p(a|s)\).
\item
  Let:
  \[
  \Sigma(p) =
  \begin{pmatrix}
  p(1)' & & \\
   & \ddots & \\
   & & p(L)'
  \end{pmatrix}
  \]
  and:
  \[
  E(p) = 
  \gamma - \ln p,
  \]
  we can have a matrix representation:
  \[
  \varphi^{(\theta_1, \hat{\theta}_2)}(p) = [I - \beta \Sigma(p) G]^{-1}\Sigma(p)[\Pi + E(p)].
  \]
\end{itemize}

\subsection{General Distribution}\label{general-distribution}

\begin{itemize}
\tightlist
\item
  If the profitability shock \(\epsilon_a\) is not an i.i.d. type-I extreme value random variable, you may need to compute \(\mathbb{E}\{\epsilon_a|s, a\}\) and \(\Lambda^{(\theta_1, \hat{\theta}_2)}(V)\) numerically.
\item
  This may or may not feasible.
\end{itemize}

\section{Unobserved Heterogeneity}\label{unobserved-heterogeneity}

\subsection{Dynamic Decision Model with a Finite Mixture}\label{dynamic-decision-model-with-a-finite-mixture}

\begin{itemize}
\tightlist
\item
  Decision makers such as a firm, a worker, and a consumer can be different in an unobserved manner.
\item
  Finite mixture models is restrictive yet flexible enough modeling framework of unobserved heterogeneity.
\item
  \citet{kasaharaNonparametricIdentificationFinite2009} consider a dynamic decision model with a finite mixture and provide a sufficient condition for identification.
\end{itemize}

\subsection{Setting}\label{setting-1}

\begin{itemize}
\tightlist
\item
  Each period, each player makes a choice \(a_t\) from a discrete and finite set \(A\) conditioning on \((x_t, x_{t - 1}, a_{t - 1}) \in X \times X \times A\) (being allowed to depend on \(x_{t - 1}\) and \(a_{t - 1}\)).
\item
  \(x_t\) is observable individual characteristics that can change over time.
\item
  Each player belongs to one of \(M\) types.
\item
  For example, parameters are different across types.
\item
  The probability of belonging to type \(m\) is denoted by \(\pi^m\) such that \(\sum_{m = 1}^M \pi^m = 1\).
\item
  Type \(m\)'s conditional choice probability: \(P_t^m(a_t|x_t, x_{t - 1}, a_{t - 1})\).
\item
  Type \(m\)'s initial probability of \((x_1, a_1)\): \(p^{*m}(x_1, a_a)\).
\item
  Type \(m\)'s transition probability of \(x_t\): \(f_t^m(x_t|\{x_{\tau}, a_{\tau}\}_{\tau = 1}^{t - 1})\) (being allowed to depend on the entire history).
\end{itemize}

\subsection{Observation}\label{observation}

\begin{itemize}
\tightlist
\item
  We have a panel data set with time-deimension equal to \(T\).
\item
  Each player's observation \(w_i = \{a_{it}, x_{it}\}_{t = 1}^T\) is drawn randomly from an \(M\)-term mixture distribution such as:
  \[
  \begin{split}
  P(\{a_t, x_t\}_{t = 1}^T) &= \sum_{m = 1}^M \pi^m p^{*m}(x_1, a_1) \prod_{t = 2}^T f_t^m(x_t|\{x_\tau, a_\tau\}_{\tau = 1}^{t - 1}) P_t^m(a_t| x_t, \{x_\tau, a_\tau\}_{\tau = 1}^{t - 1})\\
  &= \sum_{m = 1}^M \pi^m p^{*m}(x_1, a_1) \prod_{t = 2}^T f_t^m(x_t|\{x_\tau, a_\tau\}_{\tau = 1}^{t - 1}) P_t^m(a_t| x_t, x_{t - 1}, a_{t - 1}),
  \end{split}
  \]
  where the second equality uses the Markovian assumption on the conditional choice probability.
\end{itemize}

\subsection{Further Assumptions}\label{assumptions-finite-mixture}

\begin{itemize}
\tightlist
\item
  We start from a model with the following simplifying assumptions, which are often imposed in an applied work.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The choice probability of \(a_t\) does not depend on time: \(P_t^m(a_t|x_t, x_{t - 1}, a_{t - 1}) = P^m(a_t|x_t, x_{t - 1}, a_{t - 1})\). for all \(t\).
\item
  The choicd probability of \(a_t\) does not depend on \(x_{t - 1}, a_{t - 1}\): \(P^m(a_t|x_t, x_{t - 1}, a_{t - 1}) = P^m(a_t|x_t)\).
\item
  \(f_t^{m}(x_t|\{x_\tau, a_\tau\}_{\tau = 1}^{t - 1}) > 0\) for all \((x_t, \{x_\tau, a_\tau\}_{\tau = 1}^{t - 1})\) and all \(m\).
\item
  The transition function is common across types: \(f_t^m(x_t|\{x_\tau, a_\tau\}_{\tau = 1}^{t - 1}) = f_t(x_t|\{x_\tau, a_\tau\}_{\tau = 1}^{t - 1})\) for all \(m\).
\item
  The transition function does not depend on time: \(f_t(x_t|\{x_\tau, a_\tau\}_{\tau = 1}^{t - 1}) = f(x_t|x_{t - 1}, a_{t - 1})\) for all \(t\).
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Then the probability of an observation becomes:
  \[
  P(\{a_t, x_t\}_{t = 1}^T) = \sum_{m = 1}^M \pi^m p^{*m}(x_1, a_1) \prod_{t = 2}^T f(x_t|x_{t - 1}, a_{t - 1}) P^m(a_t| x_t).
  \]
\end{itemize}

\subsection{Lower-dimensional Submodels}\label{lower-dimensional-submodels}

\begin{itemize}
\tightlist
\item
  Because \(f(x_t|x_{t - 1}, a_{t - 1})\) is non-parametrically identified from data, we are only concerned with identification of type probabilities and conditional choice probabilities.
\item
  Transform the previous equation as:
  \[
  \begin{split}
  \widetilde{P}(\{a_t, x_t\}_{t = 1}^T) &:= \frac{P(\{a_t, x_t\}_{t = 1}^T)}{\prod_{t = 2}^T f(x_t|x_{t - 1}, a_{t - 1})}\\
  &= \sum_{m = 1}^M \pi^m p^{*m}(x_1, a_1) \prod_{t = 2}^T P^m(a_t| x_t).
  \end{split}
  \]
\item
  Let \(\mathcal{I} := \{i_1, \cdots, i_l\} \subset \{1, \cdots, T\}\) be a subset of time indices.
\item
  We define a \textbf{lower-dimensional submodels} given \(\mathcal{I}\) as:
  \[
  \widetilde{P}(\{a_{i_s}, x_{i_s}\}_{i_s \in \mathcal{I}}) = \sum_{m = 1}^M \pi^m p^{*m}(x_1, a_1) \prod_{s = 2}^l P^m(a_t| x_t),
  \]
  if \(1 \in \mathcal{I}\) and:
  \[
  \widetilde{P}(\{a_{i_s}, x_{i_s}\}_{i_s \in \mathcal{I}}) = \sum_{m = 1}^M\pi^m \prod_{s = 2}^l P^m(a_t| x_t),
  \]
  if \(1 \not\in \mathcal{I}\).
\item
  Under each different value of \((x_1, \cdots, x_T)\), above equations imply different restrictions on the type probabilities and conditional choice probabilities.
\item
  There are the order of \(|X|^T\) variations in \((x_1, \cdots, x_T)\), whereas the number of parameters \(\{\pi^m, p^{*m}(a, x), P^m(a|X)\}_{m = 1}^M\) is of a order of \(|X|\).
\end{itemize}

\subsection{Notations}\label{notations}

\begin{itemize}
\tightlist
\item
  For notational simplicity, consider a case with \(A = \{0, 1\}\).
\item
  Define, for \(\xi \in X\):
  \[
  \lambda_\xi^{*m} := p^{*m}[(a_1, x_1) = (1, \xi)],
  \]
  \[
  \lambda_\xi^m := P^m(a = 1|x = \xi).
  \]
\end{itemize}

\subsection{Notations for Parameters to be Identified}\label{notations-for-parameters-to-be-identified}

\begin{itemize}
\tightlist
\item
  Let \(\xi_j, j = 1, \cdots, M - 1\) be elements of \(X\) and \(k\) be an element of \(X\).
\item
  Define a matrix of type-specific distribution functions and type probabilities as:
  \[
  L := 
  \begin{pmatrix}
  1 & \lambda_{\xi_1}^1 & \cdots & \lambda_{\xi_{M - 1}^1}\\
  \vdots & \vdots & \ddots & \vdots \\
  1 & \lambda_{\xi_1}^M & \cdots & \lambda_{\xi_{M - 1}^M}\\
  \end{pmatrix},
  \]
  \[
  D_k^* :=
  \begin{pmatrix}
  \lambda_k^{*1} & & \\
  & \ddots & \\
  & & \lambda_k^{*M}
  \end{pmatrix},
  \]
  and
  \[
  V :=
  \begin{pmatrix}
  \pi^1 & & \\
  & \ddots & \\
  & & \pi^M
  \end{pmatrix}.
  \]
\end{itemize}

\subsection{Notations for Observables}\label{notations-for-observables}

\begin{itemize}
\tightlist
\item
  Define for every \((x_1, x_2, x_3)\):
  \[
  F_{x_1, x_2, x_3}^* := \widetilde{P}(\{1, x_t\}_{t = 1}^3) = \sum_{m = 1}^M \pi^m \lambda_{x_1}^{*m} \lambda_{x_2}^m \lambda_{x_3}^m.
  \]
\item
  Define for every \((x_2, x_3)\):
  \[
  F_{x_2, x_3} := \widetilde{P}(\{1, x_t\}_{t = 2}^3) = \sum_{m = 1}^M \pi^m \lambda_{x_2}^m \lambda_{x_3}^m.
  \]
\item
  In the same way, define \(F_{x_1, x_2}^*\) and \(f_{x_1, x_3}^*\).
\item
  Define for every \(x_1\):
  \[
  F_{x_1}^* := \widetilde{P}(\{1, x_1\}) = \sum_{m = 1}^M \pi^m \lambda_{x_1}^{*m}.
  \]
\item
  In the same way, define \(F_{x_2}\) and \(F_{x_3}\).
\item
  In the notations above, \(F^*\) involves \((a_1, x_1)\) and \(F\) does not.
\item
  Summing up probabilities that do not involve \(x_1\) as:
  \[
  P :=
  \begin{pmatrix}
  1 & F_{\xi_1} & \cdots & F_{\xi_{M - 1}}\\
  F_{\xi_1} & F_{\xi_1, \xi_1} & \cdots & F_{\xi_1, \xi_{M - 1}}\\
  \vdots & \vdots & \ddots & \vdots\\
  F_{\xi_{M - 1}} & F_{\xi_{M - 1}, \xi_1} & \cdots & F_{\xi_{M - 1}, \xi_{M - 1}}
  \end{pmatrix}
  \]
\item
  Summing up probabilities that involve \(x_1\) as:
  \[
  P^* :=
  \begin{pmatrix}
  k & F^*_{k, \xi_1} & \cdots & F^*_{k, \xi_{M - 1}}\\
  F^*_{k, \xi_1} & F^*_{k, \xi_1, \xi_1} & \cdots & F^*_{k, \xi_1, \xi_{M - 1}}\\
  \vdots & \vdots & \ddots & \vdots\\
  F^*_{k, \xi_{M - 1}} & F^*_{k, \xi_{M - 1}, \xi_1} & \cdots & F^*_{k, \xi_{M - 1}, \xi_{M - 1}}
  \end{pmatrix}.
  \]
\end{itemize}

\subsection{Sufficient Condition for Identification}\label{sufficient-condition-for-identification}

\begin{itemize}
\tightlist
\item
  \textbf{Identification theorem}:
\item
  Suppose that assumptions in \ref{assumptions-finite-mixture} hold.
\item
  \(T \ge 3\).
\item
  There exist some \(\{\xi_1, \cdots, \xi_{M - 1}\} \in X^{M - 1}\) such that \(L\) is non-singular.
\item
  There exists \(k \in X\) such that \(\lambda_k^{*m} > 0\) for all \(m = 1, \cdots, M\) and \(\lambda_k^{*m} \neq \lambda_k^{*n}\) for any \(m \neq n\).
\item
  Then, \(\{\pi^m, \{\lambda_\xi^{*m}, \lambda_\xi^m\}_{\xi \in X}\}_{m = 1}^M\) is uniquely identified from \(\{\widetilde{P}(\{a_t, x_t\}_{t = 1}^3)\}\).
\item
  Because the assumptions of the above theorem refer to model parameters, the authors also derive sufficient conditions based on observables.
\item
  \textbf{Corollary}:
\item
  Suppose that assumptions in \ref{assumptions-finite-mixture} hold.
\item
  \(T \ge 3\).
\item
  There exist some \(\{\xi_1, \cdots, \xi_{M - 1}\} \in X^{M - 1}\) and \(k \in X\) such that \(P\) is of full rank and that all the eigenvalues of \(P^{-1}P_k^*\) take distinct values.
\item
  Then, \(\{\pi^m, \{\lambda_\xi^{*m}, \lambda_\xi^m\}_{\xi \in X}\}_{m = 1}^M\) is uniquely identified from \(\{\widetilde{P}(\{a_t, x_t\}_{t = 1}^3)\}\).
\end{itemize}

\subsection{Remarks on the Theorem}\label{remarks-on-the-theorem}

\begin{itemize}
\tightlist
\item
  The condition says that \(L\) is non-singular.

  \begin{itemize}
  \tightlist
  \item
    This implies that all columns in \(L\) must be linearly independent.
  \item
    In other words, the changes in covariate \(x\) must induce sufficient heterogeneous variations in the conditional choice probabilities across types.
  \end{itemize}
\item
  The conditions says \(\lambda_k^{*m} > 0\) for all \(m\).

  \begin{itemize}
  \tightlist
  \item
    If there is some \(m\) that is \(\lambda_k^m = 0\) for any \(k\), such type never shows up in the data.
  \end{itemize}
\item
  The condition says \(\lambda_k^{*m} \neq \lambda_k^{*n}\) for any \(m \neq n\).

  \begin{itemize}
  \tightlist
  \item
    This condition is satisfied if initial distribution is different across types.
  \item
    If this condition fails, the identification becomes severe.
  \item
    Actually, \(T = 3\) is not enough and \(T \ge 4\) becomes necessary.
  \end{itemize}
\item
  The identification only requires one set of \(M - 1\) points \(\xi_1, \cdots, \xi_{M - 1}\) that satisfy the condition.

  \begin{itemize}
  \tightlist
  \item
    Information from other points provide overidentifying restrictions.
  \end{itemize}
\end{itemize}

\subsection{Factorization Equations}\label{factorization-equations}

\begin{itemize}
\tightlist
\item
  Parameters \(L, V, D_k^*\) and data \(P, P_k^*\) are related through the following \textbf{factorization equations} (check manually):
  \[
  P = L' V L,
  \]
  \[
  P_k^* = L'D_k^*VL.
  \]
\item
  Note that \((1, 1)\)-th element of \(P = L'VL\) is \(\sum_{m = 1}^M \pi^m = 1\) and give no information.
\end{itemize}

\subsection{Sketch of the Proof}\label{sketch-of-the-proof}

\begin{itemize}
\tightlist
\item
  Suppose that \(P\) is invertible or equivalently \(L\) is invertible.
\item
  Then, we have:
  \[
  P^{-1} = L^{-1}V^{-1} L^{'-1}.
  \]
\item
  Therefore, we have:
  \[
  \begin{split}
  P^{-1} P_k^* &= L^{-1}V^{-1} L^{'-1} L'D_k^*VL\\
  &= L^{-1} V^{-1} D_k^* V L\\
  &= L^{-1} D_k^* L,
  \end{split}
  \]
  where the third equality is because \(V\) and \(D_k^*\) are diagonal matrices.
\item
  This equation means that \(D_k^*\) is identified as the matrix of eigenvalues of \(P^{-1} P_k^*\).
\item
  Moreover, the columns of \(L^{-1}\) are identified as the eigen vectors of \(P^{-1} P_k^*\).
\item
  Finally, \(V = L^{'-1} P L^{-1}\) is identified because the right-hand side is now known.
\end{itemize}

\subsection{Constructive Estimation}\label{constructive-estimation}

\begin{itemize}
\tightlist
\item
  According to the above identification argument, we can consider a following constructive estimation procedure.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate \(P\) and \(P_k^*\) non-parametrically.
\item
  By applying an eigenvalue decomposition algorithm to \(P^{-1} P_k^*\), identify \(D_k^*\) and \(L\).
\item
  Then identify \(V\).
\item
  Once conditional choice probability is identified, we can use the standard estimation method based on the CCP approach to each type.
\end{enumerate}

\subsection{Estimation by an EM Algorithm}\label{estimation-by-an-em-algorithm}

\begin{itemize}
\tightlist
\item
  \citet{arcidiaconoConditionalChoiceProbability2011} suggest to use an EM algorithm to estimate a dynamic decision model with unobserved heterogeneity.
\item
  Return to our original notation, and suppose that state \(s_t\) is partitioned into \(s_t := (x_t, w_t)\), where \(x_t\) is observed but \(w_t\) is unobserved to an econometrician.
\item
  Suppose that the transition probability is such that:
  \[
  \begin{split}
  \mathbb{P}\{s_{t + 1}|s_t, a_t\} &= \mathbb{P}\{x_{t + 1}|x_t, w_t, a_t\} \mathbb{P}\{w_{t + 1}|w_t\} \\
  &:= g(x_{t + 1}|x_t, w_t, a_t) h(w_{t + 1}|w_t).
  \end{split}
  \]
\item
  The initial distribution of \(w_1\) is \(h(w_1|x_1)\).
\item
  We \textbf{assume} that the model is identified and only consider estimation.
\item
  For example, in the previous finite-mixture model, we considered a case with \(h(w_{t + 1} = w'|w_{t} = w) = 1\{w' = w\}\) and provided a sufficient condition for identification.
\item
  Let \(\theta_1\) be the parameters in \(\pi\) and \(\theta_2\) be the parameters in \(g\).
\item
  Let \(\theta = (\theta_1, \theta_2)\).
\end{itemize}

\subsection{Idea}\label{idea}

\begin{itemize}
\tightlist
\item
  Let \(q_{it}(w)\) be the probability that firm \(i\) is in unobserved state \(w\) in time \(t\).
\item
  The idea of the EM algorithm is:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Expectation step}: Given a parameter \(\theta^{(r)}\), a conditional choice probability \(p^{(r)}(a|x, w)\), an initial distribution of the unobserved state variable \(h^{(r)}(w_1|x_1)\), and a transition probability of the unobserved state variable \(h^{(r)}(w'|w)\), update the probability that firm \(i\) is in unobserved state \(w\) in time \(t\) to \(q_{it}^{(r + 1)}(w)\), update the initial distribution of the unobserved state variable to \(h^{(r + 1)}(w|x_1)\), update the transition probability of the unobserved state variable to \(h^{(r + 1)}(w'|w)\), and update the conditional choice probability to \(p^{(r + 1)}(a|x, w)\).
\item
  \textbf{Maximization step}: Given the probability that firm \(i\) is in unobserved state \(w\) in time \(t\) to \(q_{it}^{(r + 1)}(w)\), the initial distribution of the unobserved state variable to \(h^{(r + 1)}(w|x_1)\), the transition probability of the unobserved state variable to \(h^{(r + 1)}(w'|w)\), and the conditional choice probability to \(p^{(r + 1)}(a|x, w)\), update the parameters to \(\theta^{(r + 1)}\).
\end{enumerate}

\begin{itemize}
\tightlist
\item
  And continue this until a convergence.
\item
  By doing so, we avoid integrating out the unobserved state variables to evaluate the likelihood function.
\end{itemize}

\subsection{Optimal Conditional Choice Probability}\label{optimal-conditional-choice-probability-1}

\begin{itemize}
\tightlist
\item
  We can still define the optimal conditional choice probability given a choice probability in the future as \(\varphi^{\theta, h}(p)\) because we just assumed that some of the state is not observed to an econometrician.
\item
  We just divided parameters in \(G\) into \(\theta_2\) and \(h\).
\end{itemize}

\subsection{Likelihood Functions}\label{likelihood-functions}

\begin{itemize}
\item
  The following likelihood functions can be calculated if we know \(\theta, h\), and \(p\).
\item
  The likelihood of observing \(\{a_{it}, x_{i, t + 1}\}\) conditional on \(x_{it}\) and \(w_{it}\) is:
  \[
  L(a_{it}, x_{i, t + 1}|x_{it}, w_{it}; \theta, h, p) := \varphi^{\theta, h}(p)(a_{it}|x_{it}, w_{it}) g^{\theta_2}(x_{i, t + 1}|x_{it}, w_{it}, a_{it}).
  \]
\item
  The likelihood of observing \(\{a_{it}, x_{it}\}_{t = 1}^T\) conditional on \(x_{i1}\) is:
  \[
  \begin{split}
  L(\{a_{it}, x_{it}\}_{t = 1}^T|x_{i1}, \theta, h, p) &:= \sum_{w_{i1} = 1}^W \cdots \sum_{w_{iT} = 1}^W h(w_{i1}|x_{i1}) L(a_{i1}, x_{i, 2}|x_{i1}, w_{i1}; \theta, h, p)\\
  &\times \prod_{t = 2}^T h(w_{i, t + 1}| w_{it}) L(a_{it}, x_{i, t + 1}|x_{it}, w_{it}; \theta, h, p).
  \end{split}
  \]
\item
  The likelihood of having \(w_{it}\) in period \(t\) and having \(\{a_{it}, x_{it}\}_{t = 1}^T\) conditional on \(x_{i1}\) is:
  \[
  \begin{split}
  L(w_{it}, \{a_{it}, x_{it}\}_{t = 1}^T|x_{1t}, \theta, h, p) &:= \sum_{w_{i1} = 1}^W \cdots \sum_{w_{i, t - 1} = 1}^W \sum_{w_{i, t + 1} = 1}^W \cdots \sum_{w_{iT} = 1}^W h(w_{i1}|x_{i1}) L(a_{i1}, x_{i, 2}|x_{i1}, w_{i1}; \theta, h, p)\\
  &\times \prod_{t = 2}^T h(w_{i, t + 1}| w_{it}) L(a_{it}, x_{i, t + 1}|x_{it}, w_{it}; \theta, h, p).
  \end{split}
  \]
\item
  The likelihood of having \(w_{it}\) in period \(t\) conditional on \(\{a_{it}, x_{it}\}_{t = 1}^T\) is:
  \[
  L(w_{it}|\{a_{it}, x_{it}\}_{t = 1}^T, \theta, h, p) := \frac{L(w_{it}, \{a_{it}, x_{it}\}_{t = 1}^T|x_{1t}, \theta, h, p)}{L(\{a_{it}, x_{it}\}_{t = 1}^T|x_{1t}, \theta, h, p)}.
  \]
\end{itemize}

\subsection{Expectation Step}\label{expectation-step}

\begin{itemize}
\tightlist
\item
  We have a parameter \(\theta^{(r)}\), a conditional choice probability \(p^{(r)}(a|x, w)\), an initial distribution of the unobserved state variable \(h^{(r)}(s_1|x_1)\), and a transition probability of the unobserved state variable \(h^{(r)}(w'|w)\).
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Update the probability that firm \(i\) is in unobserved state \(w\) in time \(t\) to \(q_{it}^{(r + 1)}(w)\):
  \[
  q_{it}^{(r + 1)}(w) := L(w|\{a_{it}, x_{it}\}_{t = 1}^T, \theta^{(r)}, h^{(r)}, p^{(r)}).
  \]
\item
  Update the initial distribution of the unobserved state variable to \(h^{(r + 1)}(w|x_1)\):
  \[
  h^{(r + 1)}(w|x_1) := \frac{\sum_{i = 1}^N 1\{x_{i1} = x_1\} q_{i1}^{(r + 1)}(w)}{\sum_{i = 1}^N 1\{x_{i1} = x_1\}}.
  \]
\item
  Update the transition probability of the unobserved state variable to \(h^{(r + 1)}(w'|w)\):
  \[
  h^{(r + 1)}(w'|w) := \frac{\sum_{i = 1}^N \sum_{t = 2}^T q_{i, t - 1}^{(r + 1)}(w) q_{it}^{(r + 1)}(w')}{\sum_{i = 1}^N \sum_{t = 2}^T q_{i, t - 1}^{(r + 1)}(w)}.
  \]
\item
  Update the conditional choice probability to \(p^{(r + 1)}(a|x, w)\):
  \[
  p^{(r + 1)}(a|x, w) := \frac{\sum_{i = 1}^N \sum_{t = 1}^T q_{it}^{(r + 1)}(w) 1\{x_{it} = x\}1\{a_{it} = a\}}{\sum_{i = 1}^N \sum_{t = 1}^T q_{it}^{(r + 1)}(w) 1\{x_{it} = x\}}.
  \]
\end{enumerate}

\subsection{Maximization Step}\label{maximization-step}

\begin{itemize}
\tightlist
\item
  We have the probability that firm \(i\) is in unobserved state \(w\) in time \(t\) to \(q_{it}^{(r + 1)}(w)\), the initial distribution of the unobserved state variable to \(h^{(r + 1)}(w|x_1)\), the transition probability of the unobserved state variable to \(h^{(r + 1)}(w'|w)\), and the conditional choice probability to \(p^{(r + 1)}(a|x, w)\).
\item
  Update parameters to \(\theta^{(r + 1)}\):
  \[
  \theta^{(r + 1)} := \text{argmax}_{\theta} \sum_{i = 1}^N \sum_{t = 1}^T \sum_{w = 1}^W q_{it}^{(r + 1)}(w) \ln L(a_{it}, x_{i, t + 1}|x_{it}, w_{it}; \theta, h^{(r + 1)}, p^{(r + 1)}).
  \]
\item
  The maximization step can be either of a nested-fixed point algorithm or CCP approach.
\end{itemize}

\chapter{Dynamic Game}\label{dynamicgame}

\section{Multiple-Agent Model}\label{multiple-agent-model}

\begin{itemize}
\tightlist
\item
  There are multiple players in an industry.
\item
  There is a strategic interaction across players.
\end{itemize}

\subsection{Setting}\label{setting-2}

\begin{itemize}
\tightlist
\item
  There is \(i = 1, \cdots, N\) players.
\item
  Time is discrete \(t = 1, \cdots, \infty\).
\item
  There are \(K + 1\) actions for each player
  \(A_i = \{0, 1, \cdots, K\}\).
\item
  \(A = \prod_{i = 1}^N A_i\). \(m_a = (K + 1)^N\).
\item
  There are \(L\) states for each player \(S_i = \{1, \cdots, L\}\).
\item
  \(S = \prod_{i = 1}^N S_i\). \(m_s = L^N\).
\end{itemize}

\subsection{Timing of the Model}\label{timing-of-the-model-1}

\begin{itemize}
\tightlist
\item
  At period \(t\):
\item
  State \(s_t = (s_{t1}, \cdots, s_{tN})' \in S\) is publicly observed.
\item
  Choice-specific profitability shocks
  \(\epsilon_{ti} \in \mathbb{R}^{K + 1}\) are drawn from
  \(F(\cdot|s_{ti}, _{t,-i})\) i.i.d. and privately observed by player
  \(i\) for each \(i = 1, \cdots, N\).
\item
  \(\epsilon_{ti}\) is independent across \(i\).
\item
  Actions \(a_{ti} \in A_i, i = 1, \cdots, N\) are chosen
  simultaneously.
\item
  The state evolves according to a transition probability:
  \begin{equation}
  g(a, s, s') := \mathbb{P}\{s_{t + 1} = s'|s_t = s, a_t = a\},
  \end{equation}
\end{itemize}

\begin{equation}
G := 
\begin{pmatrix}
g(1, 1, 1) & \cdots & g(1, 1, m_s)\\
\vdots & & \vdots \\
g(m_a, 1, 1) & \cdots & g(m_a, 1, m_s)\\
&\vdots& \\
g(1, m_s, 1) & \cdots & g(1, m_s, m_s)\\
\vdots & & \vdots \\
g(m_a, m_s, 1) & \cdots & g(m_a, m_s, m_s)\\
\end{pmatrix}.
\end{equation}

\subsection{Period Profit}\label{period-profit}

\begin{itemize}
\item
  When the state is \(s_t\), action profile is \(a_t\), and the
  profitability shocks are \(\epsilon_t\), the period payoff of player
  \(i\) is: \begin{equation}
  \pi_i(a_t, s_t) + \sum_{k = 0}^K \epsilon_{tik}1\{a_{ti} = k\}, i = 1, \cdots, N,
  \end{equation} where \(\pi_i(a_t, s_t)\) is the mean period profit of
  player \(i\).
\item
  Let: \[
  \epsilon_{ti a_{ti}} = \sum_{k = 0}^K \epsilon_{tik}1\{a_{ti} = k\}
  \] be the choice-specific profitability shock.
\item
  Let \(\Pi_i\) summarize the choice-specific mean period payoffs at
  each state: \begin{equation}
  \Pi_i :=
  \begin{pmatrix}
  \pi_i(1, 1)\\
  \vdots\\
  \pi_i(m_a, 1)\\
  \vdots\\
  \pi_i(1, m_s)\\
  \vdots\\
  \pi_i(m_a, m_s)
  \end{pmatrix}.
  \end{equation}
\item
  The profit of player \(i\) is the discounted sum of future payoffs
  with discount factor \(\beta < 1\).
\end{itemize}

\subsection{Belief}\label{belief-1}

\begin{itemize}
\tightlist
\item
  Let \(\sigma_i(a|s)\) be the player \(i\)'s belief about the possibility
  of having action profile \(a\) when the realized state is \(s\), which
  may or may not coincide with the equilibrium probability.
\item
  Let \(\sigma_i\) stack them up as: \[
  \sigma_i(s) =
  \begin{pmatrix}
  \sigma_i(1|s)\\
  \vdots\\
  \sigma_i(m_a|s),
  \end{pmatrix}
  \] \[
  \sigma_i =
  \begin{pmatrix}
  \sigma_i(1)\\
  \vdots \\
  \sigma_i(m_s)\\
  \end{pmatrix},
  \] and let \(\sigma\) be: \[
  \sigma = 
  \begin{pmatrix}
  \sigma_1 \\
  \vdots\\
  \sigma_N
  \end{pmatrix}.
  \]
\end{itemize}

\subsection{Markov Perfect Equilibrium}\label{markov-perfect-equilibrium}

\begin{itemize}
\tightlist
\item
  A collection
  \((a, \sigma) = (a_1, \cdots, a_N, \sigma_1, \cdots, \sigma_N)\) is a
  pure-strategy \textbf{Markov perfect equilibrium} if:

  \begin{itemize}
  \tightlist
  \item
    All players use Markovian strategies;
  \item
    For all \(i\), \(a_i\) is a best response to \(a_{-i}\) given the
    belief \(\sigma_i\) at all state \(s \in S\);
  \item
    For all \(i\), the belief \(\sigma_i\) is consistent with the
    strategy \(a\).
  \end{itemize}
\end{itemize}

\subsection{Ex-ante Value Function}\label{ex-ante-value-function}

\begin{itemize}
\tightlist
\item
  When the belief of player \(i\) about the future behavior is
  \(\sigma_i\), then the ex-ante value function associated with this
  belief is:
\end{itemize}

\begin{equation}
\begin{split}
V_i(\sigma_i, s) &= \sum_{a \in A} \sigma_i(a|s)[\pi_i(a, s) + \beta \sum_{s' \in S} g(a, s, s') V_i(\sigma_i, s')]\\
& + \sum_{k = 0}^K \mathbb{E}\{\epsilon_i^k|a_i = k, s\}\sigma_i(a_i = k|s).
\end{split}
\end{equation}

\begin{itemize}
\tightlist
\item
  By stacking up over the state, we obtain a matrix representation:
  \begin{equation}
  V_i(\sigma_i) = \Sigma_i(\sigma_i) \Pi_i + \Sigma_i(\sigma_i) E_i(\sigma_i) + \beta \Sigma_i(\sigma_i) G V_i(\sigma_i).
  \end{equation} where \begin{equation}
  \Sigma_i(\sigma_i) = 
  \begin{pmatrix}
  \sigma_i(1)' & & \\
  & \ddots & \\
  & & \sigma_i(m_s)'
  \end{pmatrix},
  \end{equation} and \begin{equation}
  D_i(\sigma_i) =
  \begin{pmatrix}
  \sum_{k = 0}^K \mathbb{E}\{\epsilon_i^k|a_i = k, 1\}\sigma_i(a_i = k|1)\\
  \vdots\\
  \sum_{k = 0}^K \mathbb{E}\{\epsilon_i^k|a_i = k, m_s\}\sigma_i(a_i = k|m_s)
  \end{pmatrix}.
  \end{equation}
\item
  If \(I - \beta \Sigma_i(\sigma_i)G\) is invertible, we have: \[
  V_i(\sigma_i) = [I - \beta \Sigma_i(\sigma_i)G]^{-1}[\Sigma_i(\sigma_i)\Pi_i + D_i(\sigma_i)].
  \]
\end{itemize}

\subsection{Choice-specific Value Function}\label{choice-specific-value-function-1}

\begin{itemize}
\tightlist
\item
  When the state is \(s\) and the belief of player \(i\) is \(\sigma_i\),
  then the mean value of choosing action \(a_i\) is:
\end{itemize}

\begin{equation}
\begin{split}
v_i(\sigma_i, a_i, s) &= \sum_{a_{-i} \in A_{-i}} \sigma_i(a_{-i}|s)[ \pi_i(a_i, a_{-i}, s) \\
&+ \beta \sum_{s' \in S} g(a_i, a_{-i}, s, s') V_i(\sigma_i, s')].
\end{split}
\end{equation} - This is the choice-specific mean value function given
belief \(\sigma_i\).

\subsection{Optimality Condition}\label{optimality-condition-2}

\begin{itemize}
\tightlist
\item
  When the state is \(s\) and profitability shock is \(\epsilon_i\), \(a_i\)
  is optimal for player \(i\) under belief \(\sigma_i\) if and only if:
  \begin{equation}
  v_i(\sigma_i, a_i, s) + \epsilon_{i, a_i} \ge  v_i(\sigma_i, a_i', s) + \epsilon_{i, a_i'}, \forall a_i' \in A_i.
  \end{equation}
\item
  This condition is similar to the optimality condition in
  single-agent dynamic models.
\item
  Only difference is that the belief is now about the others' actions
  in addition to about own future behaviors.
\end{itemize}

\subsection{Optimal Conditional Choice Probability}\label{optimal-conditional-choice-probability-2}

\begin{itemize}
\tightlist
\item
  Therefore, the optimal conditional choice probability of player \(i\)
  with belief \(\sigma_i\) is:
\end{itemize}

\begin{equation}
\begin{split}
p(a_i|s) &= \mathbb{P}\{v_i(\sigma_i, a_i, s) + \epsilon_{i, a_i} \ge  v_i(\sigma_i, a_i', s) + \epsilon_{i, a_i'}, \forall a_i' \in A_i\}\\
&=\int \prod_{a_i' \neq a_i}1\{v_i(\sigma_i, a_i, s) + \epsilon_{i, a_i} \ge  v_i(\sigma_i, a_i', s) + \epsilon_{i, a_i'}\} d F\\
&:= \Psi(\sigma_i, a_i, s).
\end{split}
\end{equation}

\subsection{Equilibrium Condition}\label{equilibrium-condition-1}

\begin{itemize}
\tightlist
\item
  Let: \[
  p(a|s) = \prod_{i = 1}^N p(a_i|s).
  \] and \[
  \Psi(\sigma, a, s) = \prod_{i = 1}^N \Psi(\sigma_i, a_i, s).
  \]
\item
  Stacking them up as: \[
  p(s) = 
  \begin{pmatrix}
  p(1|s) \\
  \vdots \\
  p(m_a|s)
  \end{pmatrix},
  \] \[
  p = 
  \begin{pmatrix}
  p(1)\\
  \vdots\\
  p(m_s)
  \end{pmatrix},
  \]
\end{itemize}

\[
\Psi(\sigma, s) = 
\begin{pmatrix}
\Psi(\sigma, 1, s) \\
\vdots \\
\Psi(\sigma, m_a, s) \\
\end{pmatrix},
\] \[
\Psi(\sigma) = 
\begin{pmatrix}
\Psi(\sigma, 1)
\vdots\\
\Psi(\sigma, m_s)
\end{pmatrix}.
\]

\begin{itemize}
\tightlist
\item
  \citet{pesendorferAsymptoticLeastSquares2008} prove the following
  statement: \begin{equation}
  p = \Psi(p).
  \end{equation}
\item
  In any Markov perfect equilibrium, the optimal conditional choice
  probability vector \(p\) satisfies the above equality.
\item
  Conversely, any \(p\) that satisfies the equilibrium condition above
  can be derived as the optimal conditional choice probability of a
  Markov perfect equilibrium strategy profile.
\end{itemize}

\subsection{Equilibrium Condition}\label{equilibrium-condition-2}

\begin{itemize}
\tightlist
\item
  \citet{pesendorferAsymptoticLeastSquares2008} also show the following
  statements.
\item
  By Brouwer's fixed-point theorem, a Markov perfect equilibrium
  exists.
\item
  But Markov perfect equillibria need not be unique.
\item
  Therefore, we may not be able to derive the likelihood.
\item
  If the payoff function and transition probability is symmetric
  across players, then \textbf{symmetric} Markov perfect equilibrium
  exists.
\item
  This significantly reduces the dimensionality of the problem.
\end{itemize}

\subsection{Single Path of Play}\label{single-path-of-play}

\begin{itemize}
\tightlist
\item
  The estimation of dynamic games is mostly based on time series data
  of an industry.
\item
  We often assume that the data is generated from a single path of
  play.
\item
  Under Markov perfect equilibrium assumption, this means that players
  make same choices over time at the same state \((s, \epsilon_i)\).
\item
  This assumption rules out equilibrium switches over time.
\item
  If we use cross-sectional data, we have to keep this point in our
  mind, because then we observe data generated from multiple paths
  across markets.
\item
  The assumption that the same equilibrium is played across markets
  may need further justification.
\end{itemize}

\subsection{Identification}\label{identification-1}

\begin{itemize}
\tightlist
\item
  The parameters of the model is
  \((\Pi_1, \cdots, \Pi_N, F, \beta, G)\).
\item
  \(G\) is directly identified from data
\item
  \(\beta\) and \(F\) are fixed.
\item
  \((\Pi_1, \cdots, \Pi_N)\) contains \(m_a \times m_s \times N\) unknown
  parameters.
\item
  On the other hand, the equilibrium condition only has
  \(K \times m_s \times N\) restrictions.
\item
  This time, the normalization \(\pi_i(0, a_{-i}|s) = 0\) is not
  sufficient.
\item
  It is often assumed that the payoff of a player \(i\) is not directly
  influence by the state of other players: \begin{equation}
  \pi_i(a, s_i, s_{-i}) = \pi_i(a, s_i, s_{-i}'), \forall a \in A, s_i \in S_i, s_{-i}, s_{-i}' \in S_{-i}.
  \end{equation}
\item
  Under these restrictions, the number of unknown parameters is
  \(K (K + 1)^{N - 1} \times L \times N\).
\item
  So, if \(L \ge K + 1\), i.e., the number of states is larger than the
  number of actions, at least the order condition is satisfied.
\end{itemize}

\subsection{Estimation: CCP Approach}\label{estimation-ccp-approach}

\begin{itemize}
\tightlist
\item
  Because dynamic games often have multiple equillibria, nested-fixed
  point algorithm fails to pin down the likelihood of data.
\item
  Instead we use CCP approach exploiting the equilibrium condition:
  \begin{equation}
  p = \Psi^\theta(p) = \Psi^{(\theta_1, \theta_2)}(p),
  \end{equation} where \(\theta_1\) is the parameters in the mean profit
  function, and \(\theta_2\) is the parameters in the transition law.
\item
  In the first step, we estimate \(\theta_2\) and \(p\) directly from the
  data. Let \(\hat{\theta}_2\) and \(\hat{p}\) be the estimates.
\item
  Then, we can estimate \(\theta_1\) by solving: \begin{equation}
  \min_{\theta_1} [\hat{p} - \Psi^{(\theta_1, \hat{\theta}_2)}(\hat{p})]' W [\hat{p} - \Psi^{(\theta_1, \hat{\theta}_2)}(\hat{p})],
  \end{equation} where \(W\) is some weighting matrix.
\end{itemize}

\subsection{\texorpdfstring{Computing \(\Psi\)}{Computing \textbackslash Psi}}\label{computing-psi}

\begin{itemize}
\item
  Mapping from conditional choice probabilities to ex-ante value
  function: \[
  V_i(\hat{p}) = [I - \beta \Sigma_i(\hat{p})G]^{-1} [\Sigma_i(\hat{p})\Pi_i + D_i(\hat{p})].
  \]
\item
  Mapping from ex-ante value function
  \textit{and conditional choice probabilities} to conditional choice
  probability: \begin{equation}
  p_i(a_i|s) =  \mathbb{P}\{v_i(\tilde{p}, a_i, s) + \epsilon_{ia_i} \ge  v_i(\tilde{p}, a_i', s) + \epsilon_{ia_i'}, \forall a_i' \in A_i\},
  \end{equation} where \begin{equation}
  v_i(\tilde{p}, a_i, s) = \sum_{a_{-i} \in A_{-i}} \tilde{p}(a_{-i}|s) [\pi_i(a_i, a_{-i}, s) + \beta \sum_{s' \in S} g(a_i, a_{-i}, s, s') V_i(\hat{p}, s')].
  \end{equation}
\item
  If \(\epsilon_{ia}\) follows an i.i.d. type-I extreme value
  distribution, both \(D_i(\hat{p})\) and the second equation have
  closed-forms.
\end{itemize}

\section{With Continuous Dynamic Choice}\label{with-continuous-dynamic-choice}

\subsection{Continuous Control}\label{continuous-control}

\begin{itemize}
\tightlist
\item
  So far we have assumed that players' actions are discrete.
\item
  However, continuous controls such as investment prevails in the real
  world.
\item
  One way to address this issues is to discretize the data and model
  everything in a discrete way.
\item
  How to model continuous controls without discretization?
\item
  This argument applies to the single-agent models as well.
\item
  Let \(a_{ti} = (a_{tid}, a_{tic}) \in A_i = A_{id} \times A_{ic}\) be
  a generic action of player \(i\) in period \(t\), where
  \(A_{id} = \{0, 1, \cdots, K\}\) and \(A_{ic} \subset \mathbb{R}\).
\item
  Let \(s_{ti} \in S_i\) be a generic state of player \(i\) in period \(t\),
  where \(S_i \subset \mathbb{R}^L\).
\item
  Let \(\epsilon_{ti} \in \mathbb{R}^M\) be profitability shocks for
  player \(i\) in period \(t\), which are independent across players.
\end{itemize}

\subsection{Period Payoff}\label{period-payoff-1}

\begin{itemize}
\tightlist
\item
  Let \(\pi_i(a, s, \epsilon_{ti})\) be the period payoff of player \(i\)
  in period \(t\) including the profitability shocks when the action
  profile is \(a\), the state is \(s\), and the profitability shocks are
  \(\epsilon_{ti}\).
\item
  In the discrete choice framework, we assumed additive separability:
  \begin{equation}
  \pi_i(a, s, \epsilon_{ti}) = \pi_i(a, s) + \sum_{k = 0}^K \epsilon_{tik}1\{a_{ti} = k\}.
  \end{equation}
\item
  For continuous control, we may want to impose a restriction that
  ensures the monotonicity of the policy function in the profitability
  shocks, for example: \begin{equation}
  \pi_i(a, s, \epsilon_{ti}) = \pi_i(a, s) + \sum_{k = 0}^K \epsilon_{tik} 1\{a_{tid} = k\} + \epsilon_{tic} a_{tic}.
  \end{equation}
\end{itemize}

\subsection{Policy Function Estimation with Continuous Control}\label{policy-function-estimation-with-continuous-control}

\begin{itemize}
\tightlist
\item
  Let \(a_{ic}(s, \epsilon_{i}) = a_{ic}(s, \epsilon_{ic})\) be the
  policy function of firm \(i\) and suppose that it is increasing in
  \(\epsilon_{ic}\).
\item
  Moreover, assume that we know the distribution of \(\epsilon_{ic}\),
  say, \(F_{\epsilon_c}(\cdot|s)\).
\item
  We can identify the distribution of continuous control \(a_{ic}\)
  conditional on \(s\) directly from the data. Let
  \(F_{a_{ic}}(a_{ic}|s)\) be the identified distribution function of
  \(a_{ic}\) conditional on \(s\).
\item
  Then, we can identify the policy function for the continuous
  control: \begin{equation}
  \begin{split}
  F_{a_{ic}}(a|s) &= \mathbb{P}\{a_{ic} \le a|s\}\\
  &= \mathbb{P}\{a_{ic}(s, \epsilon_{ic}) \le a\}\\
  &=\mathbb{P}\{\epsilon_{ic} \le a_{ic}^{-1}(s, a)\}\\
  &=F_c[a_{ic}^{-1}(s, a)|s]\\
  &\Leftrightarrow a = F_{a_{ic}}^{-1}\{F_c[a_{ic}^{-1}(s, a)|s]|s\},
  \end{split}
  \end{equation}
\item
  Inserting \(a = a_{ic}(s, \epsilon_{ic})\) to obtain: \begin{equation}
  \begin{split}
  a_{ic}(s, \epsilon_{ic}) &= F_{a_{ic}}^{-1}\{F_c[\underbrace{a_{ic}^{-1}(s, a_{ic}(s, \epsilon_{ic}))}_{\epsilon_{ic}}|s]|s\}\\
  & = F_{a_{ic}}^{-1}[F_c^{-1}(\epsilon_{ic}|s)|s].
  \end{split}
  \end{equation}
\end{itemize}

\subsection{Converting to the Standard Discrete Choice Model}\label{converting-to-the-standard-discrete-choice-model}

\begin{itemize}
\tightlist
\item
  Inserting the identified policy for the continuous controls, we
  have:
\end{itemize}

\begin{equation}
\begin{split}
&\pi_i[a_{id}, a_{ic}(s, \epsilon_{ic}), a_{-i}, s, \epsilon_{d}] \\
&= \pi_i[a_{id}, a_{ic}(s, \epsilon_{ic}), a_{-i}, s] +\sum_{k = 0}^K \epsilon_{ik}1\{a_{id} = k\} + \epsilon_{ic} a_{ic}(s, \epsilon_{ic})
\end{split}
\end{equation}

\begin{itemize}
\tightlist
\item
  Then, we can consider a choice-specific mean value function w.r.t.
  the discrete control \(a_{id}\) by integrating out \(\epsilon_{ic}^t\)
  and others strategies and future behaviors.
\item
  Therefore, we can identify the optimal conditional choice
  probability in a reduced-form and from which we can identify the
  policy function for the discrete choice as well.
\item
  Then, we can apply the CCP approach to estimate the structural
  parameters.
\end{itemize}

\subsection{Value Function Based CCP Approach}\label{value-function-based-ccp-approach}

\begin{itemize}
\tightlist
\item
  \citet{bajariEstimatingDynamicModels2007} proposes an alternative
  estimation method.
\item
  The key is to characterize the equilibrium as follows.
\item
  Let \(V_i^{(a_i, a_{-i})}(s)\) be the ex-ante value function
  associated with strategy profile \((a_i, a_{-i})\).
\item
  The observed \((a_i^*, a_{-i}^*)\) is an equilibrium if:
  \begin{equation}
  V_i^{(a_i^*, a_{-i}^*)}(s) \ge V_i^{(a_i', a_{-i}^*)}(s), \forall a_i' \in A_i,
  \end{equation} for all \(s \in S, i = 1, \cdots, N\).
\item
  Then, we can consider an objective function such that:
  \begin{equation}
  Q(\theta) = \sum_{s = 1}^{m_s} \sum_{i = 1}^N \sum_{a_i'} \min\{V_i^{(a_i^*, a_{-i}^*)}(s) - V_i^{(a_i', a_{-i}^*)}(s), 0\}^2,
  \end{equation} which penalizes the parameter violating the
  inequality condition of the equilibrium.
\item
  There is a discretion about the choice of alternative strategies to
  construct the objective function.
\item
  Thus, the summation over continuous control does not cover the
  entire range.
\end{itemize}

\subsection{Approximating the Ex-ante Value Function}\label{approximating-the-ex-ante-value-function}

\begin{itemize}
\tightlist
\item
  Once we obtain the equilibrium policy functions, then in principle,
  we can compute the associated ex-ante value function,
  \(V_i^{(a_i, a_{-i})}\), in the equilibrium.
\item
  We often use a numerical method to compute the ex-ante value
  function when continuous controls are relevant.
\item
  Draw forward profitability shocks \(\epsilon_{ti}^{(r)}\) for
  \(t = \cdots, \tau\) for \(r = 1, \cdots, R\).
\item
  At each period, sample \(a_{tid}^{(r)}\) from the estimated
  conditional choice probability.
\item
  Also, compute
  \(a_{tic}^{(r)} = a_{tic}(s_t^{(r)}, \epsilon_{tic}^{(r)})\) using the
  estimated policy function for the continuous control and let
  \(a_{ti}^{(r)} = (a_{tid}^{(r)}, a_{tic}^{(r)})\).
\item
  Draw next period states \(s_{t + 1}^{(r)}\) from
  \(g(a_{t}^{(r)}, s_t^{(r)}, s')\).
\item
  Continue this until \(t = \tau\).
\item
  Compute: \begin{equation}
  V_i^{(a_i^*, a_{-i}^*), R\tau}(s) = \frac{1}{R}\sum_{r = 1}^R \sum_{t = 1}^\tau \beta^t \pi_i[a^{(r)}, s^{(r)}, \epsilon_i^{(r)}]
  \end{equation} to approximate \(V_i^{(a_i^*, a_{-i}^*)}(s)\).
\item
  It is a \(\tau\)-period forward simulation of the ex-ante value
  functions.
\item
  For arbitrary \(a_i^{\prime}\), we can approximate
  \(V_i^{(a_i^{\prime}, a_{-i}^*)}(s)\) by following the same steps
  using the perturbed policy \(a_i^{\prime}\).
\end{itemize}

\section{Dynamic Oligopoly Model}\label{dynamic-oligopoly-model}

\begin{itemize}
\tightlist
\item
  In the application of the dynamic game estimation to the dynamic
  oligopoly model, we often jointly consider entry and exit decisions
  and investment decisions of firms.
\item
  The entry and exit decisions are the discrete decisions and the
  investment decision is the continuous controls.
\item
  The formal models and their characterization are found in
  \citet{ericsonMarkovPerfectIndustryDynamics1995} and

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
  \end{enumerate}
\item
  \citet{Igami2018}', the paper referred to in the introduction, falls into
  this category.
\end{itemize}

\subsection{\texorpdfstring{\citet{ryanCostEnvironmentRegulation2012}}{@ryanCostEnvironmentRegulation2012}}\label{ryancostenvironmentregulation2012}

\begin{itemize}
\tightlist
\item
  \citet{ryanCostEnvironmentRegulation2012} is one of the earliest
  applications.
\item
  In 1990, the U.S. congress passed Amendments to the Clean Air act,
  adding new categories of regulated \(SO_2\) and \(NO_x\) emissions and
  requiring plants to undergo an environmental certification process.
\item
  How costly is this regulation to the economy?
\item
  The cost analysis is typically an engineering estimates of the
  expenditures on control and monitoring equipment necessary to bring
  a plant into compliance with the new regulation.
\item
  However, the regulation changes both the sunk cost of entry as well
  as the investment cost. If the sunk cost is higher, the less firm
  will be active in the market, which reinforces the market power of
  active firms.
\item
  This affects the equilibrium market structure.
\item
  The engineering based cost analysis misses this important welfare
  loss from the changes in the market structure.
\item
  This paper quantifies the welfare cost based on an empirical dynamic
  oligopoly model.
\end{itemize}

\subsection{Setting}\label{setting-3}

\begin{itemize}
\tightlist
\item
  There are several regional cement markets in the U.S.
\item
  Each market is described by \(\overline{N} \times 1\) state vector
  \(s_t\), where \(s_{it}\) is the capacity of the \(i\)th firm at time \(t\),
  and \(\overline{N}\) is an exogenously imposed maximal number of
  active firms.
\item
  \(s_{it} = 0\) means the firm is inactive.
\end{itemize}

\subsection{Timing of the Game}\label{timing-of-the-game}

\begin{itemize}
\tightlist
\item
  Incumbent firms (\(s_{it} > 0\)) receives a private draw from the
  distribution of scrap values.
\item
  Incumbent firms decide whether to exit.
\item
  Potential entrants receive a private draw of both investment and
  entry costs, while incumbent firms receive a private draw of both
  investment and disinvestment costs.
\item
  All firms simultaneously make entry and investment decisions.
\item
  Incumbent firms compete in the product market.
\item
  Firms entry, exit, and investment are realized.
\item
  The economy moves to the next period.
\end{itemize}

\subsection{Demand Function}\label{demand-function}

\begin{itemize}
\tightlist
\item
  In each market \(m\), firms face a constant elasticity of demand
  curves: \begin{equation}
  \ln Q_m(\alpha) = \alpha_{0m} + \alpha_1 \ln P_m,
  \end{equation} where \(Q_m\) is the aggregate market quantity, \(P_m\)
  is price, \(\alpha_{0m}\) is market-specific intercept, and \(\alpha_1\)
  is the elasticity of demand.
\end{itemize}

\subsection{Production Cost Function}\label{production-cost-function}

\begin{itemize}
\tightlist
\item
  The cost of output, \(q_i\), is given by: \begin{equation}
  C_i(q_i; \delta) = \delta_0 + \delta_1 q_1 + \delta_2 1\{q_i > \epsilon s_i\}(q_i - \epsilon s_i)^2,
  \end{equation} where \(q_i\) is the output of firm \(i\), \(\delta_0\) is
  the fixed cost of production, \(\delta_1\) is the linear variable
  cost, and the last term is a quadratic cost that matters only when
  the output is sufficiently close to the capacity.
\end{itemize}

\subsection{Investment Cost}\label{investment-cost}

\begin{itemize}
\tightlist
\item
  The cost of investment and disinvestment is:
\end{itemize}

\begin{equation}
\begin{split}
\Gamma(x_i; \gamma) &= 1\{x_i > 0\}(\gamma_{i1} + \gamma_2 x_i + \gamma_3 x_i^2)\\
& + 1\{x_i < 0\}(\gamma_{i4} + \gamma_{5} x_i + \gamma_6 x_i^2),
\end{split}
\end{equation} where \(x_i\) is the investment of firm \(i\), and fixed
investment and disinvestment costs \(\gamma_{i1}\) and \(\gamma_{i4}\) are
drawn from distributions \(F_{\gamma}\) and \(G_{\gamma}\).
- Let
\(\mu_\gamma^+\) and \(\sigma_\gamma^+\) be the mean and standard deviation
of \(F_\gamma\) and \(\mu_\gamma^-\) and \(\sigma_\gamma^-\) be the mean and
standard deviation of \(G_\gamma\).

\subsection{Entry and Exit Costs}\label{entry-and-exit-costs}

\begin{itemize}
\tightlist
\item
  If the firm is a new entrant, it draws entry cost \(-\kappa_i\) from
  \(F_\kappa\).
\item
  IF the firm is an incumbent, it draws scrap values \(\phi_i\) from
  \(F_\phi\).
\item
  Then entry and exit cost is:
\end{itemize}

\begin{equation}
\Phi_i(a_i, \kappa_i, \phi_i) =
\begin{cases}
- \kappa_i &\text{   if the firm enters}\\
\phi_i &\text{   if the firm exits}.
\end{cases}
\end{equation}

\subsection{Period Profit Function}\label{period-profit-function}

\begin{itemize}
\tightlist
\item
  As a consequence, the period profit function of firm \(i\) is:
  \begin{equation}
  \pi_i(s, a; \alpha, \delta, \gamma_i, \kappa_i, \phi_i) = \tilde{\pi}_i(s; \alpha, \delta) - \Gamma(x_i; \gamma_i) + \Phi_i(a_i; \kappa_i, \phi_i).
  \end{equation}
\item
  Let \(\theta\) summarize the parameter regarding the period profit.
\end{itemize}

\subsection{Transition}\label{transition}

\begin{itemize}
\tightlist
\item
  The transition is deterministic.
\item
  The investment changes the capacity \(s_i\).
\item
  As a firm exits, the capacity moves to 0.
\item
  As a firm enters, the capacity moves to the chosen investment level.
  level.
\end{itemize}

\subsection{Equilibrium}\label{equilibrium}

\begin{itemize}
\tightlist
\item
  Let \(\epsilon_i\) represent the firm's private information about the
  cost of entry, exit, investment, and disinvestment.
\item
  Each firm's Markovian strategy \(\sigma_i(s, \epsilon_i)\) is a
  mapping from states and shocks to actions.
\end{itemize}

\subsection{Value Function for Incumbents}\label{value-function-for-incumbents}

\begin{itemize}
\tightlist
\item
  The value function for a firm with \(s_i > 0\) at the time of the exit
  decision under strategy profile \(\sigma\) is:
\end{itemize}

\begin{equation}
\begin{split}
&V_i(s; \sigma(s), \theta, \epsilon_i)\\
&=\tilde{\pi}_i(s; \theta) + \max\Bigg\{\phi_i,\\
& \mathbb{E}_{\epsilon_i} \max_{x_i^* \ge 0}  \Bigg[ - \gamma_{i1} - \gamma_{2} x_i^* - \gamma_3 x_i^{*2} + \beta \int \mathbb{E}_{\epsilon_i'} V_i(s'; \sigma(s'), \theta, \epsilon_i') dP(s_i + x^*, s'_{-i}; s, \sigma(s))\Bigg],\\
&\mathbb{E}_{\epsilon_i} \max_{x_i^* < 0} \Bigg[- \gamma_{i4} - \gamma_5 x_i^* - \gamma_6 x_i^{*2} + \beta \int \mathbb{E}_{\epsilon_i'} V_i(s'; \sigma(s'), \theta, \epsilon_i') dP(s_i + x^*, s'_{-i}; s, \sigma(s))  \Bigg]\Bigg\},
\end{split}
\end{equation} where each term in the blanket represents the value of
exit, staying and making investment, and staying and making
disinvestment.
- At this timing the incumbent only observes \(\phi_i\),
although it is a bit confusing because the value function is written as
a function of \(\epsilon_i\).

\subsection{Value Function for Entrants}\label{value-function-for-entrants}

\begin{itemize}
\tightlist
\item
  The value function for a firm with \(s_i = 0\) at the time of entry
  decision under strategy profile \(\sigma\) at the time of entry and
  investment decisions are:
\end{itemize}

\begin{equation}
\begin{split}
&V_i(s; \sigma(s), \theta, \epsilon_i)\\
&=\max\Bigg\{0, \\
&\mathbb{E}_{\epsilon_i} \max_{x_i^* > 0} \Bigg[ - \gamma_{1i} - \gamma_2 x_i^* - \gamma_3 x_i^2 + \beta \int \mathbb{E}_{\epsilon_i'} V_i(s'; \sigma(s'), \theta, \epsilon_i') dP(s_i + x_i^*, s'_{-i}; s, \sigma(s))\Bigg] - \kappa_i\Bigg\}.
\end{split}
\end{equation}

\subsection{Markov Perfect Equilibrium}\label{markov-perfect-equilibrium-1}

\begin{itemize}
\tightlist
\item
  The strategy profile \(\sigma^*\) is a Markov perfect equilibrium if:
  \begin{equation}
  V_i(s; \sigma_i^*(s), \sigma_{-i}^*(s), \theta, \epsilon_i) \ge V_i(s; \sigma_i'(s), \sigma_{-i}^*(s), \theta, \epsilon_i), \forall \sigma_i',
  \end{equation} for all \(s, \epsilon_i\), and \(i\).
\item
  To apply the CCP approach, we first have to assume that the same
  equilibrium is played across markets.
\item
  This assumption is not innocuous as we saw in the previous section.
\item
  It is also important to notice that we have to fix the expectation
  about the regulation regime by firms.
\item
  We assume that firms assume that the regulatory environment is
  permanent.
\end{itemize}

\subsection{Demand and Production Cost Estimation}\label{demand-and-production-cost-estimation}

\begin{itemize}
\tightlist
\item
  To estimate the demand function, Ryan uses supply-side cost shifters
  as the instrumental variables: coal prices, gas prices, electricity
  rates, and wage rates.
\item
  Given the demand function, Ryan estimate the cost function from the
  FOC for the quantity competition.
\item
  You should already know how to do this.
\end{itemize}

\subsection{Investment Policy Function Estimation}\label{investment-policy-function-estimation}

\begin{itemize}
\tightlist
\item
  With fixed costs of investment and disinvestment, investment policy
  function follows a so-called \((s, S)\) rule, in which firms
  investment only when the current capacity is below a certain lower
  bound and makes disinvestment only when the current capacity is
  above a certain upper bound.
\item
  The lower and upper bounds, and the adjustment level are chosen
  optimal as a function of the state.
\end{itemize}

\subsection{Investment Policy Function Estimation}\label{investment-policy-function-estimation-1}

\begin{itemize}
\tightlist
\item
  Let \(s_{it}^*\) be the target level of capacity, which is
  parameterize as: \begin{equation}
  \ln s_{it}^* = \lambda_1' bs(s_{it}) + \lambda_2' bs \Bigg(\sum_{j \neq i} s_{jt}\Bigg) + u_{it}^*,
  \end{equation} where \(bs(\cdot)\) is finite-dimensional piece-wise
  cubic b-splines.
\item
  The upper and lower bounds are parameterized as:
\end{itemize}

\begin{equation}
\begin{split}
&\overline{s}_{it} = s_{it}^* + \exp\Bigg(\lambda_3' bs_1(s_{it}) + \lambda_4' bs_2\Bigg(\sum_{j \neq i} s_{jt} \Bigg) + \overline{u}_{it}^b \Bigg),\\
&\underline{s}_{it} = s_{it}^* - \exp\Bigg(\lambda_3' bs_1(s_{it}) + \lambda_4' bs_2\Bigg(\sum_{j \neq i} s_{jt} \Bigg) + \underline{u}_{it}^b \Bigg).
\end{split}
\end{equation}

\subsection{Entry and Exit Policy Functions}\label{entry-and-exit-policy-functions}

\begin{itemize}
\tightlist
\item
  The probability of entry is parameterized as: \begin{equation}
  \mathbb{P}\{\chi_i = 1; s_i = 0, s\} = \Phi\Bigg(\psi_1 + \psi_2\Bigg(\sum_{j \neq i} s_{jt}\Bigg) + \psi_3 1(t > 1990) \Bigg),
  \end{equation} and the probability of exit is parameterized as:
  \begin{equation}
  \mathbb{P}\{\chi_i = 0; s_i > 0, s\} = \Phi\Bigg(\psi_4 + \psi_5 s_{it} + \psi_6 \Bigg(\sum_{j \neq i} s_{jt}\Bigg) + \psi_7 1(t > 1990) \Bigg),
  \end{equation} where \(\Psi\) is the cumulative distribution function
  of the standard normal random variable.
\end{itemize}

\subsection{BBL Estimation}\label{bbl-estimation}

\begin{itemize}
\tightlist
\item
  Now by comparing the value function under the identified policies
  with value functions under alternative policies, one can estimate
  the structural parameters.
\item
  Alternative policies can be obtained by perturbing the upper and
  lower bounds and the target level of investment and the thresholds
  for entry and exit around the equilibrium policies.
\item
  How much to perturb is a practical issue.
\item
  Then, Ryan finds structural parameters that minimizes the BBL
  objective function.
\end{itemize}

\subsection{Structural Parameters Estimation Results}\label{structural-parameters-estimation-results}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{figuretable/dynamic} 

}

\end{figure}

\subsection{Counterfactual Simulation}\label{counterfactual-simulation}

\begin{itemize}
\tightlist
\item
  To asses the welfare cost of the amendment, Ryan solves the model
  under two sets of parameters: the actual parameters and the
  parameters before the regulation.
\item
  In the simulation, we can set whatever initial state.
\item
  Ryan consider two types of initial state:

  \begin{itemize}
  \tightlist
  \item
    No incumbent firms and 4 potential entrants.
  \item
    Two incumbent firms and two potential entrants.
  \end{itemize}
\end{itemize}

\subsection{Counterfactual Simulation Results}\label{counterfactual-simulation-results}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{figuretable/denovo} 

}

\end{figure}

\subsection{Counterfactual Simulation Estimation Results}\label{counterfactual-simulation-estimation-results}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{figuretable/mature} 

}

\end{figure}

\section{Dynamic Oligopoly with Many Firms}\label{dynamic-oligopoly-with-many-firms}

\begin{itemize}
\tightlist
\item
  Solving a dynamic game becomes quickly intractable when the number
  of firms increases and hence the dimension of the state profile
  increases.
\item
  \citet{weintraubMarkovPerfectIndustry2008} propose a new equilibrium
  concept called \textbf{oblivious equilibrium} that approximates a Markov
  perfect equilibrium when there are many firms and do not suffer from
  the aforementioned computational problem.
\end{itemize}

\subsection{Setting}\label{setting-4}

\begin{itemize}
\tightlist
\item
  The setting is effectively the same as
  \citet{ericsonMarkovPerfectIndustryDynamics1995} and

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
  \end{enumerate}
\item
  The time is discrete and infinite \(t \in \mathbb{N}\).
\item
  The information set at time \(t\) is \(\mathcal{F}_t\).
\item
  Each firm that enters the industry is assigned a positive integer
  value index \(x_{it} \in \mathbb{N}\).
\item
  It can be regarded as a quality index, but can be whatever.
\item
  Let \(S_t\) be the set of indices of incumbent firms at time \(t\).
\item
  Let \(n_t\) be the number of incumbent firms at time \(t\).
\item
  The \textbf{industry state} \(s_t\) is a vector of counts over possible
  values of \(x_{it}\) among \(i \in S_t\).
\item
  The state space is
  \(\overline{\mathcal{S}} := \{s \in N^{\infty}: \sum_{x = 0}^\infty s(x) < \infty\}\).
\item
  For expositional reason, consider an extended state space too
  \(\mathcal{S} := \{s \in \mathbb{R}_+^{\infty}: \sum_{x = 0}^\infty s(x) < \infty\}\)
\item
  For each \(i \in S_{t}\), define the state of the \textbf{competitors} by
  \(s_{-i, t}(x) := s_t(x) - 1\{x_{it} = x\}\).
\item
  The expected period profit of firm \(i\) is \(\pi(x_{it}, s_{-i, t})\).
\item
  In each period, each incumbent draws a positive real-valued sell-off
  value \(\phi_{it}\), and exits from the market if the sell-off value
  exceeds the continuation value.
\item
  If an incumbent firm stays in the market, the firm chooses an
  investment \(\iota_{it} \in \mathbb{R}_+\).
\item
  Then, the state of the firm is updated according to a rule: \[
  x_{i, t + 1} = \max\{0, x_{it} + w(\iota_{it}, \zeta_{i, t + 1})\},
  \]
\item
  where \(w\) captures the impact of investment and \(\zeta_{i, t + 1}\)
  is a shock to the investment process.
\item
  The unit cost of investment is \(d\).
\item
  In each period, new firms can enter the industry by paying a setup
  cost \(\kappa\).
\item
  Entrants do not earn profits in the period that they enter.
\item
  They appear in the following period at state \(x^e \in \mathbb{N}\).
\end{itemize}

\subsection{Timing of the Game}\label{timing-of-the-game-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Each incumbent firm observes its sell-off value, and then makes exit
  and investment decisions.
\item
  The number of entering firms is determined and each entrant pays an
  entry cost \(\kappa\).
\item
  Incumbent firms compete in the spot market and receive profits.
\item
  Exiting firms exit and receive their sell-off values.
\item
  Investment outcomes are determined, new entrants enter, and the
  industry takes on a new state \(s_{t + 1}\).
\end{enumerate}

\subsection{Assumptions}\label{assumptions}

\begin{itemize}
\tightlist
\item
  An industry state \(s \in \mathcal{S}\) is said to dominate
  \(s' \in \mathcal{S}\) if for all \(x \in \mathbb{N}\)
  \(\sum_{z \ge x} s(z) \ge \sum_{z \ge x} s'(z)\), and the relation is
  denoted by \(s \succeq s'\).
\item
  \textbf{Assumptions on} \(\pi\):
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For all \(s \in \mathcal{S}\), \(\pi(x, s)\) is increasing in \(x\).
\item
  For all \(x \in \mathbb{N}\) and \(s, s' \in \mathcal{S}\), if
  \(s \succeq s'\), then \(\pi(x, s) \le \pi(x, s')\).
\item
  For all \(x \in \mathbb{N}\) and \(s \in \mathcal{S}\), \(\pi(x, s) > 0\)
  and \(\sup_{x, z} \pi(x, s) < \infty\).
\item
  For all \(x \in \mathbb{N}\), the function
  \(\ln \pi(x, \cdot): \mathcal{S} \to \mathbb{R}_+\) is ``smooth'' enough
  (for the rigorous assumption, refer to the paper).
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions on} \(w\) and shocks:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The random variables \(\{\phi_{it}| t \ge 0, i \ge 1\}\) are i.i.d.
  and have finite expectations and well-defined density functions with
  support \(\mathbb{R}_+\).
\item
  The random variables \(\{\zeta_{it}| t \ge 0, i \ge 1\}\) are i.i.d.
  and independent of \(\{\phi_{it}| t \ge 0, i \ge 1\}\).
\item
  For all \(\zeta\), \(w(\iota, \zeta)\) is non-decreasing in \(\iota\).
\item
  For all \(\iota > 0\),
  \(\mathbb{P}\{w(\iota, \zeta_{i, t + 1} > 0\} > 0\).
\item
  There exists a positive constant \(\overline{w} \in \mathbb{N}\) such
  that \(|w(\iota, \zeta)| \le \overline{w}\) for all \((\iota, \zeta)\).
\item
  There exist a positive constant \(\overline{\iota}\) such that
  \(\iota_{it} < \overline{\iota}\), \(\forall i, t\).
\item
  For all \(k \in \{- \overline{w}, \cdots, \overline{w}\}\),
  \(\mathbb{P}\{w(\iota, \zeta_{i, t + 1} = k\}\) is continuous in
  \(\iota\).
\item
  The transitions generated by \(w(\iota, \zeta)\) are \textbf{unique
  investment choice admissible}.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  The notion of unique investment choice admissibility is introduced
  by @2 and means that
  under the investment function firms' investment decision problem has
  a unique solution.
\item
  Without this assumption, the existence of pure-strategy equilibrium
  is not guaranteed and the computation can become complicated.
\item
  \textbf{Assumptions on potential entrants}:
\item
  When there are a large number of potential entrants who play a
  symmetric mixed entry strategy, the equilibrium number of entrants
  is well-approximated by a Poisson distribution.
\item
  We assume this for simplicity.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The number of firms entering during period \(t\) is a Poisson random
  variable that is independent of \(\{\phi_{it}| t \ge 0, i \ge 1\}\)
  conditional on \(s_t\).
\item
  \(\kappa > \beta \overline{\phi}\), where \(\overline{\phi}\) is the
  expected net present value of entering the market, investing zero
  and earning zero profits each period, and then exiting at an optimal
  stopping time.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Let \(\lambda(s_t)\) be the expected number of firms entering at
  industry state, which is endogenously determined.
\end{itemize}

\subsection{Strategy Profile}\label{strategy-profile}

\begin{itemize}
\item
  Investment strategy
  \(\iota: \mathbb{N} \times \mathcal{S} \to \mathbb{R}_+\) :
  \(\iota_{it} = \iota(x_{it}, s_{-it})\).
\item
  \begin{description}
  \tightlist
  \item[Exit strategy \(\rho: \mathbb{N} \times \mathcal{S} \to \mathbb{R}_+\)]
  an incumbent exits if and only if
  \(\phi_{it} > \rho(x_{it}, s_{-it})\).
  \end{description}
\item
  Bundle them as \(\mu = (\iota, \rho) \in \mathcal{M}\).
\item
  Entry rate \(\lambda: \mathcal{S} \to \mathbb{R}_+\),
  \(\lambda \in \Lambda\).
\end{itemize}

\subsection{Value Function}\label{value-function}

\begin{itemize}
\tightlist
\item
  The expected net present value for a firm at state \(x\) when its
  competitors state is \(s\), given that its competitors each follows a
  common strategy \(\mu \in \mathcal{M}\), the entry rate function is
  \(\lambda \in \Lambda\), and the firm itself follows strategy
  \(\mu' \in \mathcal{M}\) is: \[
  V(x, s|\mu', \mu, \lambda) := \mathbb{E}_{\mu', \mu, \lambda}\left\{\sum_{k = t}^{\tau_i} \beta^{k - t}[\pi(x_{ik}, s_{-ik}) - d \iota_{ik}] + \beta^{\tau_i - t} \phi_{i, \tau_i}|x_{it} = x, s_{-it} = s\right\},
  \] where \(\tau_i\) is a random variable that represents the time at
  which firm \(i\) exits under the exit strategy.
\item
  We also write as \(V(x, s|\mu, \lambda) := V(x, s|\mu, \mu, \lambda)\)
  when all firms follow the same strategy.
\end{itemize}

\subsection{Markov-perfect Equilibrium}\label{markov-perfect-equilibrium-2}

\begin{itemize}
\tightlist
\item
  A strategy profile \(\mu \in \mathcal{M}\) and an entry rate
  \(\lambda \in \Lambda\) is a Markov-perfect equilibrium if:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The strategy profile satisfies: \[
  \sup_{\mu' \in \mathcal{M}} V(x, s|\mu', \mu, \lambda) = V(x, s|\mu, \lambda), \forall x \in \mathbb{N}, \forall s \in \overline{\mathcal{S}}.
  \]
\item
  The entry rate satisfies: \[
  \sum_{s \in \overline{S}} \lambda(s) \{\beta \mathbb{E}_{\mu, \lambda}[V(x^e, s_{-i, t + 1}|\mu, \lambda)|s_t = s] - \kappa\}
   = 0,
   \] \[
   \beta \mathbb{E}_{\mu, \lambda}[V(x^e, s_{-i, t + 1}|\mu, \lambda)|s_t = s] - \kappa \le 0, \forall s \in \mathcal{\overline{S}},
   \] \[
   \lambda(s) \ge 0,s \in \mathcal{\overline{S}}.
   \]
\end{enumerate}

\begin{itemize}
\tightlist
\item
  That is, at each industry state, either the expected entry profit is
  zero or the entry rate is zero.
\item
  The authors prove that there exists a symmetric equilibrium.
\end{itemize}

\subsection{Oblivious Strategy}\label{oblivious-strategy}

\begin{itemize}
\tightlist
\item
  The Markov-perfect equilibrium becomes quickly computationally
  intractable when the number of firms increases, because firms'
  strategies depends on other firms' states.
\item
  We consider a firm who is \textbf{oblivious} of other firms' exact states
  but only cares the \textbf{long-run average industry state} on top of its
  own state.
\item
  Let \(\widetilde{\mathcal{M}} \subset \mathcal{M}\) and
  \(\widetilde{\Lambda} \subset \Lambda\) be the set of \textbf{oblivious
  strategies} and the set of \textbf{oblivious entry rate functions} in
  the sense that both \(\mu \in \widetilde{\mathcal{M}}\) and
  \(\lambda \in \widetilde{\Lambda}\) do not depend on \(s\).
\end{itemize}

\subsection{Long-run Average Industry State}\label{long-run-average-industry-state}

\begin{itemize}
\tightlist
\item
  Then, if all firms use a common strategy
  \(\mu \in \widetilde{\mathcal{M}} \subset \mathcal{M}\), each firm's
  state evolves as an independent transient Markov chain.
\item
  Let the \(k\)-period transition probability of this Markov chain be
  denoted by \(P_{\mu}^k(x, y)\).
\item
  The expected time that a firm spends at state \(x\) is
  \(\sum_{k = 0}^\infty P_\mu^k(x^e, x)\).
\item
  The expected lifespan of a firm is
  \(\sum_{k = 0}^\infty \sum_{x \in \mathbb{N}} P_\mu^k(x^e, x)\).
\item
  Let \(\tilde{s}_t(x) := \mathbb{E}[s_t(x)]\) be the expected number of
  firms at state \(x\).
\item
  Under the stated assumptions, if firms make decisions according to
  an oblivious strategy \(\mu \in \widetilde{M}\) and enter according to
  an oblivious entry rate function \(\lambda \in \widetilde{\Lambda}\),
  and the expected time that firm spends in the industry is finite,
  then: \[
   \lim_{t \to \infty} \tilde{s}_t(x) = \lambda \sum_{k = 0}^\infty P_{\mu}^k(x^e, x),
   \] for all \(x \in \mathbb{N}\).
\item
  We write the long-run average industry state as
  \(\tilde{s}_{\mu, \lambda}(x) := \lim_{t \to \infty} \tilde{s}_t(x)\).
\end{itemize}

\subsection{Oblivious Value Function}\label{oblivious-value-function}

\begin{itemize}
\item
  For an oblivious strategy \(\mu', \mu \in \widetilde{\mathcal{M}}\)
  and an oblivious entry rate function
  \(\lambda \in \widetilde{\Lambda}\), we define an \textbf{oblivious value
  function}: \[
  \widetilde{V}(x|\mu', \mu, \lambda) := \mathbb{E}_{\mu'} \left\{\sum_{k = t}^{\tau_i} \beta^{k - t}[\pi(x_{ik}, \tilde{s}_{\mu, \lambda}) - d \iota_{ik}] + \beta^{\tau_i - t} \phi_{i, \tau_i}| x_{it} = x \right\}.
  \]
\item
  The firm approximates the value function by evaluating at the
  long-run average industry state.
\item
  Note that it still depends on other firms' strategy \(\mu\) because it
  determines the long-run average industry state.
\item
  We also write as
  \(\widetilde{V}(x|\mu, \lambda) := \widetilde{V}(x|\mu, \mu, \lambda)\).
\end{itemize}

\subsection{Oblivious Equilibrium}\label{oblivious-equilibrium}

\begin{itemize}
\tightlist
\item
  An oblivious strategy \(\mu', \mu \in \widetilde{\mathcal{M}}\) and an
  oblivious entry rate function \(\lambda \in \widetilde{\Lambda}\) is
  an \textbf{oblivious equilibrium} if:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The oblivious strategy satisfies: \[
  \sup_{\mu'  \in \widetilde{\mathcal{M}}} \widetilde{V}(x|\mu', \mu, \lambda) = \widetilde{V}(x|\mu, \lambda), \forall x \in \mathbb{N}.
  \]
\item
  The oblivious entry rate function satisfies: \[
  \lambda [\beta \widetilde{V}(x^e|\mu, \lambda) - \kappa] = 0,
  \] \[
  \beta \widetilde{V}(x^e|\mu, \lambda) - \kappa \le 0,
  \] \[
  \lambda \ge 0.
  \]
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Computing the equilibrium is surprisingly easy because the dynamic
  programming involves only one-dimensional state variable \(x_{it}\).
\item
  Given a strategy profile, first compute \(\tilde{s}_{\mu, \lambda}\).
\item
  Given \(\tilde{s}_{\mu, \lambda}\), the dynamic programming is only of
  \(x_{it}\).
\end{itemize}

\subsection{Asymptotic Results and Extensions}\label{asymptotic-results-and-extensions}

\begin{itemize}
\tightlist
\item
  The authors show that under a certain condition when the market size
  goes to infinity, an oblivious equilibrium approximates an
  Markov-perfect equilibrium in the sense that a deviation from the
  oblivious equilibrium to a (possibly non-oblivious) best response
  does not improve the value for a firm.
\item
  \citet{Benkard2015} consider an extension of the current model to the
  \textbf{partially oblivious equlibrium} in which a subset of firms follow
  a non-oblivious strategy and the other firms follow an oblivious
  strategy.
\item
  \citet{Ifrach2017} further extends the current model to the \textbf{moment-based
  Markov equilibrium} in which a firm's strategy depends on some sets
  of moments regarding the industry state.
\end{itemize}

\chapter{Auction}\label{auction}

\section{General symmetric information model}\label{general-symmetric-information-model}

\subsection{Setting}\label{setting-5}

\begin{itemize}
\tightlist
\item
  The argument of this section is based on \citet{hendricksChapter32Empirical2007}.
\item
  General symmetric information model \citep{milgromTheoryAuctionsCompetitive1982}.
\item
  The seller has a single item.
\item
  There are \(n\) potential risk neutral buyers/bidders.
\item
  Each bidder \(i\) observes a real-valued private signal \(X_i\).
\item
  There is a random variable or vector \(V\) that influences the value of the object to the bidders.
\item
  The joint distribution of \((V, X_1, \cdots, X_n)\) is \(F\).
\item
  Bidder \(i\)'s payoff is \(U_i = u_i(V, X_i, X_{-i})\) when the bidder \(i\) obtains the object being sold.
\item
  The seller announces a reserve price \(r\).
\item
  The primitives of the model, the number of bidders \(n\), the distribution \(F\), and the utility functions \(\{u_i\}_{i = 1}^n\), are common knowledge among buyers.
\item
  Assumption: \(u_i\) is non-negative, continuous, increasing in each argument and symmetric in the components of \(X_{-i}\).
\item
  Assumption: \((V, X_1, \cdots, X_n)\) are affiliated.

  \begin{itemize}
  \tightlist
  \item
    The \(n\) random variables \(X = (X_1, \cdots, X_n)\) with joint density \(f(x)\) are affiliated if for all \(x\) and \(y\), \(f(x \wedge y) f(x \vee y) \ge f(x) f(y)\).
  \item
    \(x \wedge y \equiv (\min\{x_1, y_1\}, \cdots, \min\{x_n, y_n\})\) and \(x \vee y \equiv (\max\{x_1, y_1\}, \cdots, \max\{x_n, y_n\})\).
  \item
    If affiliated, they are non-negatively correlated.
  \end{itemize}
\item
  \(\to\) \(U_1, \cdots, U_n\) are affiliated.
\item
  Let \(Y_1, \cdots, Y_{n - 1}\) is the ordering of the largest through the smallest signals from \(X_2, \cdots, X_n\).
\item
  Then, \((V, X_1, Y_1, \cdots, Y_{n - 1})\) are also affiliated.
\end{itemize}

\subsection{Discussion About the Asssumptions}\label{discussion-about-the-asssumptions}

\begin{itemize}
\tightlist
\item
  The private information is assumed to be single-dimensional.

  \begin{itemize}
  \tightlist
  \item
    If the private information is multi-dimensional, the identification of type requires at least as many messages.
  \item
    Inversion from the message to the private information is then not straightforward.
  \item
    There are few empirical studies of auctions of multi-dimensional private information such as \citet{bajariBiddingIncompleteContracts2014} and \citet{takahashiStrategicDesignUncertain2018}.
  \end{itemize}
\item
  The distribution of the signals is assumed to be symmetric across bidders.

  \begin{itemize}
  \tightlist
  \item
    We can introduce asymmetric signals.
  \item
    A bidder may have more precise signals.
  \end{itemize}
\item
  The utility is independent of the winner's identify when a bidder is not awarded the item.

  \begin{itemize}
  \tightlist
  \item
    If the item is the valuable asset in the oligopoly industry, the implication to the profit can be different when the close competitor is awarded the asset.
  \end{itemize}
\item
  The number of potential bidders is assumed to be common knowledge.

  \begin{itemize}
  \tightlist
  \item
    The participation to the auction may be endogenously determined.
  \end{itemize}
\end{itemize}

\subsection{Bidding Strategy}\label{bidding-strategy}

\begin{itemize}
\tightlist
\item
  A \textbf{bidding strategy} for bidder \(i\) is a correspondence \(\beta_i: X_i \to \mathbb{R}_+\).
\item
  A mapping from the private signal into a non-negative real value.
\item
  Under the stated assumptions, there exists a Bayesian Nash equilibrium with non-decreasing bid functions \citep{krishnaAuctionTheory2009}.
\item
  The following argument crucially depends on this property of the equilibrium bidding rule.
\end{itemize}

\subsection{Special Cases}\label{special-cases}

\begin{itemize}
\tightlist
\item
  Two special cases about the payoff functions:
\item
  \textbf{Private value (PV)}: \(u_i(v, x_i, x_{-i}) = x_i\): Bidder \(i\) knows his own valuation and is only uncertain about how much others value the item.

  \begin{itemize}
  \tightlist
  \item
    The assumption holds in more general settings than we may think.
  \item
    If \(\mathbb{E}\{u(v, x_i, x_{-i})|X_i = x_i, X_{-i} = x_{-i}\} = f(x_i)\) for some monotone increasing function \(f\), then we can redefine \(x'_i = f(x_i)\) as the private signal.
  \item
    In general, \(\mathbb{E}\{u(v, x_i, x_{-i})|X_i = x_i, X_{-i} = x_{-i}\} \neq f(x_i)\) for any monnotone increasing function \(f\). Then, it is referred to as the \textbf{common value (CV)} model.
  \end{itemize}
\item
  \textbf{Pure common values (PCV)}: \(u_i(v, x_i, x_{-i}) = v\): All buyers have the same valuation, which is unknown to them when they bid, and only learned though the private signals.
\item
  Two special cases about the signals:
\item
  \textbf{Independent signals (IPV, ICV)}: Signals \(X_1, \cdots, X_n\) are independent.
\item
  \textbf{Affiliated signals (APV, ACV)}: Signals \(X_1, \cdots, X_n\) are affiliated.
\item
  Example: Offshore oil and gas leases.

  \begin{itemize}
  \tightlist
  \item
    \(V\): the size of oil or gas deposits under the tract.
  \item
    CV: bidders are uncertain about \(V\) and have different private information about the value of \(V\) because of the seismic data they obtain.
  \item
    PV: bidders are almost certain about \(V\) or have little discrepancy in private assessment of \(V\). But there is a heterogeneity in the costs of exploration and drilling and this information is private.
  \end{itemize}
\item
  In the following, we mostly consider a type of CV model such as \(u_i(v, x_i, x_{-i}) = u(v, x_i)\).
\end{itemize}

\section{Second-Price Auctions}\label{second-price-auctions}

\subsection{The Button Auction}\label{the-button-auction}

\begin{itemize}
\tightlist
\item
  Let:
  \[
  w(x, y) := \mathbb{E}\{u(V, x)|X_1 = x_1, Y_1 = y_1\},
  \]
  be the expected payoff of the bidder when her signal is \(x\) and the highest rival's signals is \(y_1\).
\item
  Affilication implies that \(w(x, y)\) is increasing in \(x\).
\item
  Let \(\underline{x}\) is the lower bound of the support of \(X\).
\item
  \textbf{Button auction}:

  \begin{itemize}
  \tightlist
  \item
    The price rises continuously.
  \item
    Bidders stays active as long as they keep fingers on the button.
  \item
    A bidder wins once all other bidders take their fingers off.
  \item
    The price paid by the winner is the price level when the second last bidder takes the fingers off.
  \end{itemize}
\item
  The bidding strategy is the mapping from a price level to being active or not.
\end{itemize}

\subsection{Equilibrium Bidding Strategies}\label{equilibrium-bidding-strategies}

\begin{itemize}
\tightlist
\item
  Case 1:

  \begin{itemize}
  \tightlist
  \item
    A bidder cannot observe the prices at which the other bidders take fingers off.
  \item
    We guess that the equilibrium strategy is to take the fingers off at the threshold:
    \[
      \beta(x) = w(x, x)
      \]
    and verify this.
  \item
    Suppose that the other bidders follow the bidding strategy and the price level is \(b\) and the auction does not yet end.
  \item
    Suppose that I win at this moment.
  \item
    This means that there is at least one other bidder that has signal \(y = \beta^{-1}(b)\).
  \item
    Then, the payoff to me is \(w(x, y) - b = w(x, y) - w(y, y)\).
  \item
    It is positive if and only if \(x > y\), because affiliation implies that the expected payoff is increasing in the own signal.
  \item
    Thus, \(b = \beta(x) = w(x, x)\) is the best response.
  \end{itemize}
\item
  Case 2:

  \begin{itemize}
  \tightlist
  \item
    Active bidders observe the prices at which rivals drop out.
  \item
    No bidder who drops out can become active again.
  \item
    The bidding strategy is the mapping from the number of rivals who dropped out and the prices at which they dropped out.
  \item
    Let \(\beta_k(x)\) be the price at which a bidder drops out when \(k\) rivals dropped out at prices \(b_1, \cdots, b_k\).
  \item
    We guess that the equilibrium strategy is:
    \[
      \beta_k(x) = \mathbb{E}\{u(V, x)| X_1 = x, Y_1 = \cdots = Y_{n - k - 1} = x, Y_{n - k} = \beta_{k - 1}^{-1}(b_k), \cdots, Y_{n - 1} = \beta_0^{-1}(b_1)\}
      \]
    and verify this.
  \item
    Suppose that the other bidders follow the bidding strategy and the price level is \(b\) and \(k\) bidders dropped at \(b_1, \cdots, b_k\).
  \item
    Suppose that I win at this moment.
  \item
    This means there are \(n - k - 1\) bidders with signals \(y = \beta_k^{-1}(b)\).
  \item
    Then, the payoff to me is:
    \begin{equation}
      \begin{split}
      &\mathbb{E}\{u(V, x)| X_1 = x, Y_1 = \cdots = Y_{n - k - 1} = y, Y_{n - k} = \beta_{k - 1}^{-1}(b_k), \cdots, Y_{n - 1} = \beta_0^{-1}(b_1)\}\\
      &- b\\
      &=\mathbb{E}\{u(V, x)| X_1 = x, Y_1 = \cdots = Y_{n - k - 1} = y, Y_{n - k} = \beta_{k - 1}^{-1}(b_k), \cdots, Y_{n - 1} = \beta_0^{-1}(b_1)\}\\
      &- \mathbb{E}\{u(V, x)| X_1 = y, Y_1 = \cdots = Y_{n - k - 1} = y, Y_{n - k} = \beta_{k - 1}^{-1}(b_k), \cdots, Y_{n - 1} = \beta_0^{-1}(b_1)\}.
      \end{split}
      \end{equation}
  \item
    This is positive if and only if \(x > y\), because affiliation implies that the expected payoff is increasing in the own signal.
  \item
    Thus, the above bidding strategy is the best response.
  \end{itemize}
\end{itemize}

\subsection{Reserve Price}\label{reserve-price}

\begin{itemize}
\tightlist
\item
  The seller does not sell the item if the winning bid is below \(r > 0\).
\item
  The participation threshold is:
  \[
  x^*(r) = \inf\left\{x: \mathbb{E}[w(x, Y_1)| X_1 = x, Y_1 < x] \ge r\right\}.
  \]
\item
  That is, a bidder participates if and only if \(x \ge x^*(r)\).
\end{itemize}

\subsection{Variations}\label{variations}

\begin{itemize}
\tightlist
\item
  If PV, i.e., \(w(x, y) = x\), then, the equilibrium strategy is to participate and drop at \(\beta(x) = x\) if \(x \ge r\) and not to participate if \(x < r\).
\item
  This is the unique equilibrium with weakly dominant strategies.
\item
  Under the common value assumption, there can be many asymmetric equillibria \citep{milgromRationalExpectationsInformation1981, bikhchandaniEquilibriaOpenCommon1991}.
\item
  If bidders can call their bids, the game becomes more complicated because bidders can announce a ``jump'' bid at any time to signal their valuations \citep{averyStrategicJumpBidding1998}.
\item
  Be aware of the complications arising in the versions of the English auction.
\end{itemize}

\subsection{Estimation of a IPV Button Auction}\label{estimation-of-a-ipv-button-auction}

\begin{itemize}
\tightlist
\item
  Parameters of interest is \(F\), the distribution of private signals and the payoff relevant random variable \(V\).
\item
  The data consists of \(\{w_t, n_t, r_t\}_{t = 1}^T\) if \(m_t \ge 1\) for auction \(t = 1, \cdots, T\):

  \begin{itemize}
  \tightlist
  \item
    \(w_t\): the winning bid;
  \item
    \(n_t\): the number of potential bidders;
  \item
    \(r_t\): the reserve price;
  \item
    \(m_t\): the latent variable about the number of actual bidders.
  \end{itemize}
\item
  This is the case only the winning bid is observed but not the other bids.
\item
  The winning bid is \(w_t = \max\{x_{2:n_t}, r_t\}\), where \(x_{2:n_t}\) is the second highest bid among \(n_t\) bids.
\end{itemize}

\subsection{Likelihood of IPV Button Auction}\label{likelihood-of-ipv-button-auction}

\begin{itemize}
\tightlist
\item
  \citet{donaldIdentificationEstimationTesting1996} estimate the model with a maximum likelihood estimator.
\item
  Assume that \(F_X(\cdot) = F_X(\cdot; \theta)\) with a finite dimensional parameter \(\theta\).
\item
  The likelihood is:

  \begin{itemize}
  \tightlist
  \item
    If \(m_t = 0\), the \(F_X(r_t)^{n_t}\).
  \item
    If \(m_t = 1\) then \(\mathbb{P}\{m_t = 1\} = n_t F_X(r_t)^{n_t - 1} [1 - F_X(r_t)]\).
  \item
    If \(m_t > 1\), then \(h_t(w_t) := n_t (n_t - 1) F_X(w_t)^{n_t - 2} [1 - F_X(w_t)] f_X(w_t)\).
  \end{itemize}
\item
  The likelihood function is, if the data is only about the auctions with \(m_t \ge 1\):
  \[
  L = \prod_{t = 1}^T \frac{h_t(w_t)^{1\{m_t > 1\}} \mathbb{P}\{m_t = 1\}}{1 - \mathbb{P}\{m_t = 0\}}
  \]
\item
  The approach is still valid when the private signals are asymmetric and/or some bidders are not risk neutral, because \(b(x) = x\) is still a dominant strategy.
\end{itemize}

\subsection{Optimal Reserve Price}\label{optimal-reserve-price}

\begin{itemize}
\tightlist
\item
  The expected revenue to the seller who values the item as \(x_0\) when setting the reserve price at \(r\) is:
  \[
  R = x_0 F_X(r)^n + r n F_X(r)^{n - 1}[1 - F_X(r)] + \int_r^{\overline{x}} w n(n - 1)F_X(w)^{n - 2}[1 - F_X(w)] f_X(w) dw.
  \]
\item
  The first-order condition is:
  \[
  r = x_0 + \frac{1 - F_X(r)}{f_X(r)}.
  \]
\item
  Thus, the identification of \(F_X\) allows the seller to set the revenue maximizing reserve price.
\end{itemize}

\subsection{Likelihood of IPV English Auction with Bid Data}\label{likelihood-of-ipv-english-auction-with-bid-data}

\begin{itemize}
\tightlist
\item
  The likelihood function is:
  \[
  L = \prod_{t = 1}^T [1 - F_X(w_t)] \left[ \prod_{i = 2}^{m_t} f_X(b_{it}) \right] F_X^{n_t - m_t}(r_t).
  \]
\item
  \(b_{1t} \ge b_{2t} \ge \cdots \ge b_{m_t} \ge r\).
\item
  If \(n_t\) is not observed to econometrician, the econometrician can:

  \begin{itemize}
  \tightlist
  \item
    assume \(n = \max_{t = 1, \cdots, T} \{m_t\}\);
  \item
    assume \(n_t = n\) and estimate \(n\) as a parameter;
  \item
    assume \(n_t\) is drawn from a parametric distribution and estimate the parameters.
  \end{itemize}
\end{itemize}

\subsection{Observed Heterogeneity}\label{observed-heterogeneity}

\begin{itemize}
\tightlist
\item
  Let \(z_{it}\) be the observed attribute of bidder \(i\) in auction \(t\).
\item
  Assume that:
  \[
  x_{it} = \alpha + \beta z_{it} + u_{it}.
  \]
\item
  Then:
  \[
  x_{it} \ge b_{it} \Leftrightarrow u_{it} \ge b_{it} - \alpha - z_{it} \beta := \tilde{b}_{it}.
  \]
\item
  We can first regress \(b_{it}\) on \(z_{it}\) to estimate \(\alpha\) and \(\beta\) to compute \(\tilde{b}_{it}\).
\item
  Then, the rest of the argument is the same as above by replacing \(b_{it}\) with \(\tilde{b}_{it}\).
\end{itemize}

\subsection{Identification}\label{identification-2}

\begin{itemize}
\tightlist
\item
  \citet{atheyIdentificationStandardAuction2002} and \citet{atheyChapter60Nonparametric2007} synthesize and extend the identification arguments of various auction models.
\item
  Button auction with the symmetric IPV framework is non-parametrically identified only by the winning bid data.
\item
  Button auction with the asymmetric IPV framework is non-parameterically identified by the winning bid and winner's identity data.
\item
  The non-parametric identification can fail with a common value in general.
\item
  The actual English auctions can be dirty and not easy to characterize the equilibrium: they are open cry auctions that signals their values, bidders may not indicate they are inactive at every highest bid, and there may be a minimum bid increment.
\item
  \citet{haileInferenceIncompleteModel2003} considers a set identification of the signal distribution:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    signal is no less than the higher bid by the bidder: \(x_i \ge b_i\).
  \item
    signal is no greater than the winning bid plus the minimum bid increment: \(x_i \le w + \Delta\).
  \end{enumerate}

  \begin{itemize}
  \tightlist
  \item
    Let \(F_{i:n}\) be the distribution of the \(i\)-th highest order statistics from \(F_X\).
  \item
    Let \(G_{i:n}\) be the empirical distribution of the \(i\)-th highest bids.
  \item
    By 1, we have \(F_{i:n}(x) \le G_{i:n}(x)\).
  \item
    By 2, we have \(F_{2:n}(x) \ge G_{1:n}(x + \Delta)\).
  \item
    These inequalities put the bounds on \(F_X\).
  \end{itemize}
\end{itemize}

\section{First-Price Auctions}\label{first-price-auctions}

\subsection{First-Price Sealed Bid Auction}\label{first-price-sealed-bid-auction}

\begin{itemize}
\tightlist
\item
  Each bidder independently submit a bid to the auctioneer.
\item
  The high bidder wins and pays his bid.
\end{itemize}

\subsection{Equilibrium Bidding Strategies}\label{equilibrium-bidding-strategies-1}

\begin{itemize}
\item
  Assume IPV.
\item
  Then \(x^*(r) = r\).
\item
  Let \(\beta\) be the bid function that is increasing in the signal and \(\eta\) is the inverse of \(\beta\).
\item
  Assume \(\beta(r) = r\) and \(\beta(x) = 0\) for \(x < r\) (this is a restriction).
\item
  Suppose that the other bidders follow strategy \(\beta\).
\item
  The expected profit when a bidder with signal \(x\) submits a bid \(b\) is:
  \[
  \pi(b, x) = (x - b) F_X[\eta(b)]^{n - 1}.
  \]
\item
  The first-order condition is:
  \[
  (x - b) (n - 1) F_X[\eta(b)]^{n - 2} f_X[\eta(b)] \eta'(b)- F_X[\eta(b)]^{n - 1} = 0.
  \]
\item
  If \(\beta\) is the equilibrium strategy, we have:
  \[
  [x - \beta(x)] (n - 1) F_X(x)^{n - 2} f_X(x) - \beta'(x) F_X(x)^{n - 1} = 0.
  \]
\item
  Let \(G(x) = F_X(x)^{n - 1}\) and \(g(x) = G'(x)\).
\item
  Then, we have:
  \[
  [x - \beta(x)] g(x) - \beta'(x) G(x) = 0.
  \]
\item
  This is a linear differential equation such that:
  \[
  \beta'(x) + p(x) \beta(x) = q(x),
  \]
  with a boundary condition:
  \[
  \beta(r) = r,
  \]
  where
  \[
  p(x) = \frac{g(x)}{G(x)},
  \]
  and
  \[
  q(x) = x \frac{g(x)}{G(x)}.
  \]
\item
  Let \(\mu(x)\) be a function such that:
  \[
  \mu(x) p(x) = \mu'(x).
  \]
\item
  Multiply \(\mu(x)\) to the both sides of the first-order condition to get:
  \[
  \begin{split}
  &\mu(x) \beta'(x) + \mu(x) p(x) \beta(x) = \mu(x) q(x)\\
  &\Leftrightarrow \mu(x) \beta'(x) + \mu'(x) \beta(x) = \mu(x) q(x)\\
  &\Leftrightarrow [\mu(x) \beta(x)]' = \mu(x) q(x).
  \end{split}
  \]
\item
  Hence,
  \[
  \mu(x) \beta(x) = \mu(r) \beta(r) + \int_{r}^x \mu(t) q(t) dt.
  \]
\item
  On the other hand,
  \[
  [\ln \mu(x)]' = p(x).
  \]
\item
  Hence,
  \[
  \mu(x) = \mu(r) \exp\left(\int_{r}^x p(t) dt  \right) = \exp\left(\int_{r}^x p(t) dt  \right),
  \]
  by setting \(\mu(r) = 1\).
\item
  Now,
  \[
  \begin{split}
  \int_{r}^x p(t) dt &= \int_{r}^x \frac{g(t)}{G(t)} dt\\
  &= [\ln G(t)]_r^x.
  \end{split}
  \]
\item
  Hence,
  \[
  \mu(x) = G(x).
  \]
\item
  Inserting these results gives:
  \[
  \begin{split}
  \beta(x) &= \frac{\beta(r)\mu(r) + \int_r^x \mu(t) q(t) dt}{\mu(x)}\\
  &= \frac{rG(r) + \int_r^x G(t) t \frac{g(t)}{G(t)} dt}{G(x)}\\
  &= \frac{rG(r) + \int_r^x t g(t) dt}{G(x)}\\
  &= \frac{[t G(t)]_r^x + rG(r) - \int_{r}^x G(t) dt }{G(x)}\\
  &= x - \frac{\int_r^x G(t) dt}{G(x)}\\
  &= x - \frac{\int_r^x F_X(t)^{n - 1} dt}{F_X(x)^{n - 1}}.
  \end{split}
  \]
\item
  The term \(- \frac{\int_r^x F_X(t)^{n - 1} dt}{F_X(x)^{n - 1}}\) is called the \textbf{markdown factor}, which is decreasing in the number of bidders \(n\) and increasing in the dispersion of the value distribution.
\item
  The assumption of a binding reserve price (\(\beta(r) = r\) and \(\beta(x) = 0\) for \(x < r\)) ensures that there is a unique symmetric equilibrium \citep{atheyChapter60Nonparametric2007}.
\end{itemize}

\subsection{Maximum Likelihood Estimation of the IPV First-Price Auction}\label{maximum-likelihood-estimation-of-the-ipv-first-price-auction}

\begin{itemize}
\item
  \citet{donaldPiecewisePseudoMaximumLikelihood1993} proposed a maximum likelihood estimator.
\item
  The data consists of \(\{w_t, r_t, n_t\}_{t = 1}^T\) for the sample where the number of actual bidders \(m_t \ge 1\).
\item
  The probability density of having \(w_t\) is:
  \[
  \begin{split}
  h_t(w_t) &= n_t F_X[\eta_t(w_t)]^{n_t - 1} f_X[\eta_t(w_t)] \eta_t'(w_t)\\
  &= \frac{n_t F_X[\eta_t(w_t)]^{n_t}}{(n_t - 1)[\eta_t(w_t) - w_t]},
  \end{split}
  \]
  where the second equation is from the first-order condition.
\item
  Because the probability of \(m_t \ge 1\) is \(1 - F_X(r_t)^{n_t}\), the likelihood is:
  \[
  L = \prod_{t = 1}^T \frac{h_t(w_t)}{1 - F_X(r_t)^{n_t}}.
  \]
\item
  To apply this approach, we may need to have a closed-form for \(\eta\), and this may require to assume a specific functional-form for \(F_X\).
\end{itemize}

\subsection{Non-Parametric Approach}\label{non-parametric-approach}

\begin{itemize}
\tightlist
\item
  \citet{guerreOptimalNonparametricEstimation2000} proposed a non-parametric approach.
\item
  The data consists of \(\{\{b_{it}\}_{i = 1}^{m_t}, n_t, r_t\}_{t = 1}^T\) and some observed covariates \(z_{it}\) for \(t\) with \(m_t \ge 1\).
\item
  Assume \(n_t = n\), or in other words, focus on the data with the same number of potential bidders and estimate separately across different \(n\).
\item
  Let \(H(b)\) be the distribution of the highest rival's bid and \(h(b)\) be its density.
\item
  Then, the expected payoff of bidding \(b\) when the signal is \(x\) is:
  \[
  \pi(b, x) = (x - b) H(b).
  \]
\item
  The first-order condition with respect to \(b\) is:
  \[
  \begin{split}
  & (x - b) h(b) - H(b) = 0\\
  &\Leftrightarrow x = b + \frac{H(b)}{h(b)}
  \end{split}
  \]
  where the right-hand side is actually \(\eta(b)\), the inverse of the bidding strategy \(\beta(x)\).
\item
  The idea is that \(H(b)\) and \(h(b)\) are directly identified from the data, and so, the value \(\eta(b)\) can be computed for each bid.
\end{itemize}

\subsection{Non-Parmaetric Approach: Estimation}\label{non-parmaetric-approach-estimation}

\begin{itemize}
\tightlist
\item
  Note that:
  \[
  H(b) = F_b(b)^{n - 1},
  \]
  and
  \[
  h(b) = (n - 1) f_b(b) F_b(b)^{n - 2},
  \]
  where \(f_b\) and \(F_b\) are the density and distribution of the bids.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate \(f(b)\) non-parametrically, say, by a kernel regression:
  \[
  \hat{f}_b(b) = \frac{1}{TN h_b}\sum_{t = 1}^T \sum_{i = 1}^n K\left(\frac{b_{it} - b}{h_b}\right)
  \]
  \[
  \widehat{F}_b(b) = \frac{\#\{b_{it} = r\}}{NT} +  \int_{r}^b \hat{f}_b(t) dt.
  \]
  for \(b > r\).
\item
  Form the implied \(x_{it}\) by:
  \[
  \hat{x}_{it} = b_{it} + \frac{\widehat{H}(b_{it})}{\hat{h}(b_{it})}.
  \]
\item
  Estimate \(f_X\) non-parametrically, say, by a kernel regression:
  \[
  \hat{f}_X(x) = \frac{1}{NT h_x} \sum_{t = 1}^T \sum_{i = 1}^n K\left(\frac{\hat{x}_{it} - x}{h_x}\right).
  \]
  and construct:
  \[
  \widehat{F}_X(r) = \frac{\#\{\hat{x}_{it} = r\}}{NT} + \int_r^x \hat{f}_X(t) dt.
  \]
\end{enumerate}

\begin{itemize}
\tightlist
\item
  For this argument to hold, it has to be that \(\eta(b)\) is strictly increasing in \(b\). Otherwise, for the same \(x\), multiple \(b\) can be associated.
\item
  This approach can be extended to the symmetric IPV and affiliated values.
\item
  \citet{krasnokutskayaIdentificationEstimationAuction2011} considered a model with unobserved heterogeneity, in which the bidder's cost is \(c_i = x_i v\) and \(x_i\) is private and independent and \(v\) is known among bidders but not to econometrician.
\end{itemize}

\chapter{Applications}\label{applications}

\begin{itemize}
\tightlist
\item
  Recently published empirical studies using a structural estimation based on a partial equilibrium model, mostly in the field of industrial organization.
\end{itemize}

\section{2018-2019}\label{section}

\subsection{American Economic Review}\label{american-economic-review}

\begin{itemize}
\item
  \citet{wollmannTrucksBailoutsEquilibrium2018}: Estimate a structural model of the US commercial vehicle market and demonstrate the importance of allowing for endogenous product offerings in a merger analysis.
\item
  \citet{dinersteinConsumerPriceSearch2018}: Study how the redesign of the search engine at eBay affect consumer search and price competition among sellers.
\item
  \citet{crawfordAsymmetricInformationImperfect2018}: Estimate a structural model of credit demand, loan use, pricing, and firm default using matched firm-bank data from Italy, and find evidence of adverse selection and how banks can mitigate the negative effects by adjusting credit supply.
\item
  \citet{hortacsuBidShadingBidder2018}: Estimate a structural model of bidding at the uniform price auctions of US Treasury bills and notes that takes into account informational asymmetries introduced by the bidding system and show that primary dealers have bid-shading ability higher than their willingness-to-pay.
\item
  \citet{aizawaAdvertisingRiskSelection2018}: Estimate an equilibrium model of Medicare Advantage with advertising allowing rich individual heterogeneity and show that advertising is effective in attracting healthy individuals for are newly eligible for Medicare, contributing to advantageous selection into Medicare Advantage.
\item
  \citet{doraszelskiJustStartingOut2018}: Draw on models of fictitious play and adaptive learning to analyze the evolution of the new market for frequency response within the UK electricity system and explain the convergence of pricing to a rest point that is consistent with equilibrium play.
\item
  \citet{acemogluInnovationReallocationGrowth2018}: Estimate a model of firm-level innovation, productivity growth, and reallocation featuring endogenous entry and exit and the selection between high- and low-type firms which differ in terms for their innovation capacity, and show that taxing the continued operation of incumbent can lead to gains because of the exit of less productive firms.
\item
  \citet{duboisIdentifyingIndustryMargins2018}: Estimate a structural model of pharmaceutical with price constraints and infer whether these constraints are binding and study its consequences.
\item
  \citet{hoEquilibriumProviderNetworks2019}: Estimate a Nash-in-Nash bargaining model between insurers and hospitals and evaluate the consequence of narrowing hospital networks in commercial heal care markets in the US.
\item
  \citet{crawfordQualityOverprovisionCable2019}: Estimate a model of endogenous quality choice in imperfectly competitive markets and show that a quality over-provision in the US cable television markets is caused by the presence of competition from high-end satellite TV providers.
\item
  \citet{fackTruthTellingPreferenceEstimation2019}: Propose a new approach to estimate student preferences with data from matching mechanisms and estimate the model with school choice data in Paris.
\end{itemize}

\subsection{Econometrica}\label{econometrica}

\begin{itemize}
\item
  \citet{trebbiInsurgencySmallWars2019}: Propose methodologies for the detection of unobserved coalitions of militants in conflict areas and apply to the Afghan conflict during the 2004-2009 period and to Pakistan during the 2008-2011 period, identifying systematically different coalition structures.
\item
  \citet{einavProviderIncentivesHealthcare2018}: Estimate a dynamic discrete choice model of long-term care hospitals discharge decisions and study the design of provider incentive in the post-acute setting.
\item
  \citet{miraveteMarketPowerLaffer2018}: Estimate a model of taxation in a imperfectly competitive market that leads to incomplete tax pass-through using a data from alcoholic beverages in Pennsylvania and study the welfare implication of the state's current tax policy.
\item
  \citet{crawfordWelfareEffectsVertical2018}: Estimate a structural model of view-ship, subscription, distributor pricing, and affiliate fee bargaining using a data set on the US cable an satellite television industry to analyze the impact of simulated vertical mergers and divestitures of regional sports networks on competition and welfare.
\item
  \citet{agarwalDemandAnalysisUsing2018}: Propose an empirical method for studying random utility models in a school choice mechanisms and apply it to the data from Cambridge.
\end{itemize}

\section{Asymmetric Information and Market Power}\label{asymmetric-information-and-market-power}

\begin{itemize}
\tightlist
\item
  I present this paper in detail because the structure of the paper, especially the structure of the introduction, is textbook-perfect.
\item
  It also applies textbook-perfect demand and cost estimation techniques but to an empirically interesting setting.
\item
  The introduction consists of:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Background and motivation}: Following the seminal work\ldots; Although the basic\ldots; The vast majority\ldots; A recent strand\ldots;
  \item
    \textbf{Question}: We measure\ldots{}
  \item
    \textbf{Materials}: We exploit detailed data on\ldots{}
  \item
    \textbf{Methods}: After providing reduced-form evidence\ldots{}
  \item
    \textbf{Details of the materials and methods}: model (We begin by\ldots), its characterization (The degree of competition\ldots), estimation (We estimate the model\ldots), identification (We face two important challenges\ldots).
  \item
    \textbf{Results}: In our results\ldots{}
  \item
    \textbf{Counterfactuals}: We run three counterfactuals\ldots{}
  \item
    \textbf{Implications}: All in all\ldots{}
  \item
    \textbf{Contributions}: Our paper is related to\ldots{}
  \end{itemize}
\item
  These topics should be discussed \textbf{in this order} in a structural estimation paper.
\item
  The paper is organized as follows:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Data}: Source; sampling procedure; cleaning; transformation; summary statistics; motivating findings.
  \item
    \textbf{Model}: Economic model to estimate; relevance to the research question; justification of the assumptions; discussion on key channels; relevance to theoretical models in the literature.
  \item
    \textbf{Estimation}: Econometric specification; estimation procedure; identification.
  \item
    \textbf{Results}: Estimation results; key findings and their interpretations; fit of the model.
  \item
    \textbf{Conterfactuals}: Policy experiments; policy implications.
  \end{itemize}
\item
  The data section can come after model and estimation sections if it is a methodological paper that builds estimation and/or identification techniques on an abstract model.
\end{itemize}

\subsection{Motivation}\label{motivation}

\begin{itemize}
\tightlist
\item
  Asymmetric information works differently in imperfectly competitive markets.
\item
  \textbf{Competitive market}: adverse selection \(\to\) higher average cost \(\to\) higher price.
\item
  \textbf{Imperfectly competitive market}: additional channel: adverse selection \(\to\) lower benefit of setting a high price \(\to\) lower price \citep{mahoneyImperfectCompetitionSelection2017, lesterScreeningAdverseSelection2018}.
\item
  Adverse selection can moderate the welfare losses from market power, and \emph{vice versa}.
\end{itemize}

\subsection{Question, Method, and Materials}\label{question-method-and-materials}

\begin{itemize}
\tightlist
\item
  This paper measures the consequences of asymmetric information and imperfect competition in the market for small business lines of credit.
\item
  To do so, formulate and estimate a model of credit demand, loan use, default, and bank pricing;
\item
  using data on a representative sample of Italian firms, the population of medium and large Italian banks, individual lines of credits between them, and subsequent defaults.
\end{itemize}

\subsection{Findings}\label{findings}

\begin{itemize}
\tightlist
\item
  Find evidence of adverse selection:

  \begin{itemize}
  \tightlist
  \item
    The unobserved determinants of the choice to borrow and of default are positively correlated.
  \item
    The unobserved determinants of loan use and default are positively correlated.
  \item
    Both are statistically significant.
  \end{itemize}
\item
  Find positive effect of interest rates on default:

  \begin{itemize}
  \tightlist
  \item
    Evidence of moral hazard?
  \end{itemize}
\end{itemize}

\subsection{Policy Experiments}\label{policy-experiments}

\begin{itemize}
\tightlist
\item
  What if the degree of adverse selection changes?

  \begin{itemize}
  \tightlist
  \item
    The severer adverse selection still causes a higher price and a smaller credit supply.
  \item
    But market power significantly mitigates this effect.
  \end{itemize}
\item
  What if banks' cost of capital, say, due to a financial crisis?

  \begin{itemize}
  \tightlist
  \item
    In the presence of adverse selection, the pass-through is smaller for a bank with higher market power.
  \end{itemize}
\item
  What if banks merge?

  \begin{itemize}
  \tightlist
  \item
    Under high adverse selection, a merger can \emph{decrease} prices.
  \end{itemize}
\end{itemize}

\subsection{Source}\label{source}

\begin{itemize}
\tightlist
\item
  Data on individual loans from the Central Credit Register.
\item
  Firm-level balance sheet data from the Company Accounts Data Services.
\item
  Banks' balance-sheet and income-statement data from the Banking Supervision Register.
\item
  Data on bank branches at the local level.
\item
  The resulting data is over 1988-1998.
\end{itemize}

\subsection{Loan Data}\label{loan-data}

\begin{itemize}
\tightlist
\item
  Italian banks have to report data for each individual borrower to the register.
\item
  Focus on the short-term lines of credit:

  \begin{itemize}
  \tightlist
  \item
    Interest rate is independent of the maturity.
  \item
    Homogeneous product.
  \item
    Not collateralized.
  \item
    Main source of borrowing for Italian firms.
  \end{itemize}
\item
  Focus on firms' main credit line in the first year they open any credit line.

  \begin{itemize}
  \tightlist
  \item
    Avoid heterogeneous experience in ratings, loan negotiations, and learning across banks and firms.
  \end{itemize}
\item
  This reduces the sample size from 90,000 to 36,500.
\item
  Average loan amount EUR370,000, average interest rate 14.2\%.
\item
  Average bank asset EUR11 billion, average employees 3,200.
\end{itemize}

\subsection{Firm Data}\label{firm-data}

\begin{itemize}
\tightlist
\item
  The service collects yearly data on the balance sheets and income statements of a sample of 35,000 Italian non-financial and non-agricultural firms, roughly 30\% of the total value added reported in the national accounting.
\item
  The service also computes an indicator of the risk profile of each firm, Score, and reports to banks.
\item
  The Score is approximately the information that a lending bank has available at the time a loan is granted.
\item
  A firm is classified as a borrowing firm if it appears in the Credit Register, and is classified as a non-borrowing firm if it does not appear in the Credit Register and reports zero bank borrowing in the balance sheet.
\item
  Banks' loan approval decisions are not observed.
\end{itemize}

\subsection{Default Data}\label{default-data}

\begin{itemize}
\tightlist
\item
  A loan is classified as default if a firm's main line of credit defined it as a bad debt within three years of being granted.
\item
  Reporting a loan as a bad debt to the Credit Registry can happen prior to a legally certified bankruptcy filing, but it usually prevents the firm from borrowing any other loans.
\item
  6\% of new loans default during the sample period.
\end{itemize}

\subsection{Positive Correlation Tests}\label{positive-correlation-tests}

\begin{itemize}
\tightlist
\item
  Positive correlation tests \citep{chiapporiTestingAsymmetricInformation2000} are often used to test the presence of asymmetric information.
\item
  Are firms more likely to demand credit more likely to default?
  \[
  d_i = 1\{X_i^d \beta + \nu_i > 0\},
  \]
  \[
  f_i =
  \begin{cases}
  X_i^f \gamma + \eta_i &\text{   if   } d_i = 1\\
  -&\text{    if   } d_i = 0,
  \end{cases}
  \]
  where \(d_i\) is equal to one if the firm borrows and \(f_i\) is equal to one if the borrow defaults.
\item
  \(X_i^d\) and \(X_i^f\) include year, market, firms' Score, amount of granted credit, sector Fixed effects, firms' balance sheet variables.
\item
  The number of banks in a firm's market is only included in \(X_i^d\) (instrument).
\item
  \(f_i\) is observed only if \(d_i = 1\).
\item
  A positive and significant correlation of 0.09 between \(\nu_i\) and \(\eta_i\).
\item
  Are riskier firms use more credit?
  \[
  l_i = X_i \beta + \epsilon_i,
  \]
  \[
  f_i = X_i \gamma + \eta_i,
  \]
  where \(l_i\) is the amount of its loan used by the firm.
\item
  A positive and significant correlation of 0.03 between \(\epsilon_i\) and \(\eta_i\).
\item
  These positive correlations can be interpreted as evidence of adverse selection \citep{stiglitzCreditRationingMarkets1981}.
\item
  We further control several factors such as strategic interactions in the following structural model.
\end{itemize}

\subsection{Setting}\label{setting-6}

\begin{itemize}
\tightlist
\item
  Each of \(i = 1, \cdots, I_{mt}\) firms in market \(m\) in year \(t\) is willing to invest in a project and is looking for credit to finance it.
\item
  Firms select their main line of credit from \(j = 1, \cdots, J_{mt}\) banks in \(m\) in \(t\).
\item
  Each bank sets interest rates \(P_{ijmt}\).
\item
  \textbf{Informational asymmetry}: conditional on observable, a firm's riskiness is known by that firm but not by any of the banks in its market; instead, banks are assumed to known the distribution.
\item
  \textbf{Screening device}: assume that banks use interest rates as their only screening device; the amount of credit granted from a bank to a firm is exogenously given.
\end{itemize}

\subsection{Firm Preference over Banks}\label{firm-preference-over-banks}

\begin{itemize}
\tightlist
\item
  Firm \(i\) in market \(m\) in year \(t\) obtains the following utility as it chooses bank \(j\) as its main credit line:
  \begin{equation}
  U_{ijmt}^D := \overline{\alpha}_0^D + X_{jmt}^{\prime D} \beta^D + \xi_{jmt}^D + \alpha^D P_{ijmt} + Y_{ijmt}^{\prime D} \eta^D + \epsilon_i^D + \nu_{ijmt}^D. \label{eq:demand-utility}
  \end{equation}
\item
  \(X_{ijm}^D\): a vector of bank-market-year determinants of demand; observed by everyone.
\item
  \(Y_{ijmt}^D\): a vector of firm-bank-market-year determinants of demand; observed by everyone.
\item
  \(\xi_{jmt}^D\): the bank's attributes; not observed to econometrician.
\item
  \(\epsilon_i^D\): the firm's propensity to borrow; only observed to the firm.
\item
  \(\nu_{ijmt}^D\): an idiosyncratic shock; only observed to the firm.
\item
  \(\epsilon_i^D\) is the source of asymmetric information.
\item
  Let \(\alpha_{0i}^D := \overline{\alpha}_0^D + \epsilon_i^D\).
\end{itemize}

\subsection{Required Loand Amount}\label{required-loand-amount}

\begin{itemize}
\tightlist
\item
  Firm \(i\) in market \(m\) in year \(t\) borrows the following amount of loan if it chooses bank \(j\) as its main line:
  \[
  L_{ijmt} := \alpha_0^L + X_{jmt}^{\prime L} \beta^L + \alpha^L P_{ijmt} + Y_{ijmt}^{\prime L} \eta^L + \epsilon_i^L.
  \]
\item
  \(\epsilon_i^L\): the firm's propensity to use credit; only observed to the firm.
\item
  \(\epsilon_i^L\) is another source of asymmetric information.
\item
  Notice that \textbf{there is no firm-bank-specific unobserved heterogeneity}; why?; we need to know how much a firm will borrow when the firm borrowed from a different bank than in the data; because a loan between a firm and a bank is observed only when the firm borrows from the bank, we need to exclude any firm-bank-specific unobserved heterogeneity in order to predict loans with hypothetical banks.
\end{itemize}

\subsection{Default Decision}\label{default-decision}

\begin{itemize}
\tightlist
\item
  Conditional on borrowing, each firm chooses to default if its utility from doing so is greater than 0:
  \[
  U_{ijmt}^F := \alpha_0^F + X_{jmt}^{\prime F} \beta^F + \alpha^F P_{ijmt} + Y_{ijmt}^{\prime F} \eta^F + \epsilon_i^F.
  \]
\item
  \(\epsilon_i^F\): the firm's propensity to default; only observed to the firm.
\item
  \(\epsilon_i^F\) is another source of asymmetric information.
\item
  Notice that there is no firm-bank-specific unobserved heterogeneity for the same reason.
\end{itemize}

\subsection{Information Structure}\label{information-structure}

\begin{itemize}
\tightlist
\item
  \(\epsilon_i^D, \epsilon_i^L\), and \(\epsilon_i^F\) are assumed to be fixed at the firm level and do not vary across banks.
\item
  They are assumed to follow:
  \[
  \begin{pmatrix}
  \epsilon_i^D\\
  \epsilon_i^L\\
  \epsilon_i^F
  \end{pmatrix}
  \sim
  N
  \left( 
  \begin{pmatrix}
  0 \\
  0 \\
  0
  \end{pmatrix},
  \begin{pmatrix}
  \sigma_D^2 & \rho_{DL} \sigma_D \sigma_L & \rho_{DF} \sigma_D\\
  \rho_{DL} \sigma_D \sigma_L & \sigma_L^2 & \rho_{LF} \sigma_L\\
  \rho_{DF} \sigma_D & \rho_{LF} \sigma_L & 1
  \end{pmatrix}
  \right).
  \]
\end{itemize}

\subsection{Moral Hazard}\label{moral-hazard}

\begin{itemize}
\tightlist
\item
  The model allows for the presence of moral hazard.
\item
  \citet{holmstromFinancialIntermediationLoanable1997}: If moral hazard is present, higher repayment requirements on loans can reduce the incentives to exert efforts and increases the default probability.
\item
  Interpreting \(\alpha^F\) a causal effect of price on default (by using an instrument), we will be able to interpret the positive \(\alpha^F\) as evidence of moral hazard.
\end{itemize}

\subsection{Bank Problem}\label{bank-problem}

\begin{itemize}
\tightlist
\item
  The expected profit for bank \(j\) from charging a price \(P_{ijmt}\) offered to firm \(i\) in market \(m\) in year \(t\) is:
  \[
  \Pi_{ijmt} := P_{ijmt} Q_{ijmt} (1 - F_{ijmt}) - MC_{ijmt} Q_{ijmt}.
  \]
\item
  \(Q_{ijmt}\): the bank's expectation of the firm's demand.
\item
  \(F_{ijmt}\): the bank's expectation of the firm's default.
\item
  \(MC_{ijmt}\): the bank's marginal cost.
\end{itemize}

\subsection{The Effect of Price on Default Probability}\label{the-effect-of-price-on-default-probability}

\begin{itemize}
\tightlist
\item
  There are two channels.
\item
  If \(\alpha^F\) is positive, higher interest rate can increase the default probability, possibly because of moral hazard.
\item
  A higher interest rate also changes the composition of borrower types; borrowing conditional on a high interest rate means that the firm has higher demand for loan; if \(\rho_{DF} > 0\), this implies the firm is riskier.
\end{itemize}

\subsection{The First-Order Condition}\label{the-first-order-condition}

\begin{itemize}
\tightlist
\item
  The pricing equation is:
  \[
  P_{ijmt} = \frac{MC_{ijmt}}{1 - F_{ijmt} + F_{ijmt}' \mathcal{M}_{ijmt}} + \frac{(1 - F_{ijmt}) \mathcal{M}_{ijmt}}{1 - F_{ijmt} + F_{ijmt}' \mathcal{M}_{ijmt}}.
  \]
\item
  The first term is the \textbf{effective marginal cost} and the second \textbf{effective markup}.
\item
  \(\mathcal{M}_{ijmt} := - Q_{ijmt} / Q_{ijmt}'\) is the bank \(j\)'s markup on a loan to firm \(i\).
\end{itemize}

\subsection{The Effect of Higher Adverse Selection}\label{the-effect-of-higher-adverse-selection}

\begin{itemize}
\tightlist
\item
  As measured by the higher \(\rho_{DF}\).
\item
  \textbf{Average borrower effect}: tends to increase the price.

  \begin{itemize}
  \tightlist
  \item
    A higher \(\rho_{DF}\) implies a higher default probability \(F_{ijmt}\) for a given price.
  \item
    This decreases the denominator of the pricing equation.
  \end{itemize}
\item
  \textbf{Marginal borrower effect}: tends to suppress the price.

  \begin{itemize}
  \tightlist
  \item
    A higher \(\rho_{DF}\) (in most cases) implies a higher sensitivity of default probability to price \(F_{ijmt}'\) for a given price.
  \item
    This increases the denominator of the pricing equation.
  \item
    Because the marginal borrower is safer than the average borrow to larger degree, the firm will want to keep them by reducing the price.
  \end{itemize}
\item
  Which of the effects dominates depend on the markup \(\mathcal{M}_{ijmt}\).

  \begin{itemize}
  \tightlist
  \item
    Low levels of competition imply margins are high, increasing the value to the bank of marginal borrowers.
  \end{itemize}
\end{itemize}

\subsection{Estimating Equilibrium Pricing Strategy and Augmenting Missing Price Data}\label{estimating-equilibrium-pricing-strategy-and-augmenting-missing-price-data}

\begin{itemize}
\tightlist
\item
  To estimate bank choice problem for a firm, we need to have price for each pair of bank and firm.
\item
  However, the price is observed only between a bank and a firm that actually held a credit line.
\item
  We augment the missing price by predicted values.
\item
  But the prediction depends on what kind of information set we assume for banks' pricing decisions.
\item
  We assume that large banks mostly predict the demand based on hard information such as the balance-sheet and income-statement variables and Scores.
\item
  Specifically, we fit the following model to observed prices:
  \[
  P_{ijmt} = \gamma_0 + \gamma_1 \mathcal{D}_{ijmt} + \gamma_2 \mathcal{L}_{ijmt} + \lambda_{jmt} + \omega_i^P + \tau_{ijmt}.
  \]
\item
  \(\mathcal{D}_{ijmt}\) is the distance between firm \(i\) and the nearest branch of bank \(j\).
\item
  \(\mathcal{L}_{ijmt}\) are dummies for the size of the granted loan amount.
\item
  Regard this as a \textbf{reduced-form} estimates of the equilibrium pricing strategy of the banks.
\item
  Let \(\tilde{\gamma}_0\), \(\tilde{\gamma}_1\), \(\tilde{\gamma}_2\), \(\tilde{lambda}_{jmt}\), and \(\tilde{\omega}_i^P\) the estimates.
\item
  Let \(\tilde{P}_{ijmt}\) be the predicted value from these estimates:
  \begin{equation}
  \begin{split}
  \tilde{P}_{ijmt} &:= \tilde{\gamma}_0 + \tilde{\gamma}_1 \mathcal{D}_{ijmt} + \tilde{\gamma_2} \mathcal{L}_{ijmt} + \tilde{\lambda}_{jmt} + \tilde{\omega}_i^P\\
  &:= \tilde{P}_{jmt} + \tilde{\gamma}_1 \mathcal{D}_{ijmt} + \tilde{\gamma_2} \mathcal{L}_{ijmt} + \tilde{\omega}_i^P.
  \end{split} \label{eq:price-predicted}
  \end{equation}
\item
  We predict prices offered to non-borrowing firms by propensity score matching.
\end{itemize}

\subsection{Inserting Pricing Estimates into the Utility}\label{inserting-pricing-estimates-into-the-utility}

\begin{itemize}
\tightlist
\item
  We assume that firm-bank-market-year determinants of demand \(Y_{ijmt}^D\) is of the following form:
  \[
  Y_{ijmt}^D := \eta_1^D \mathcal{D}_{ijmt} + \eta_2^D \mathcal{L}_{ijmt} + \eta_3^D Y_i + \omega_i^D. 
  \]
\item
  \(Y_i\) is the observed firm covariates.
\item
  \(\omega_i^D\)\$ is the firm covariates not observed to econometrician.
\item
  We further assume that unobserved firm-level attributes \(\omega_i^D\) determining the demand is related to unobserved firm-level attributes \(\omega_i^P\) determining bank's pricing decision are related as:
  \[
  \omega_i^D = \eta_4^D \omega_i^P.
  \]
\item
  Because previous regression of price gives estimates of \(\omega_i^P\), \(\tilde{\omega}_i^P\), we treat this as if an observed covariate.
\item
  At the end, we have:
  \begin{equation}
  Y_{ijmt}^{\prime D} \eta^D = \eta_1^D \mathcal{D}_{ijmt} + \eta_2^D \mathcal{L}_{ijmt} + \eta_3^D Y_i + \eta_4 \tilde{\omega_i}^P. \label{eq:demand-determinants}
  \end{equation}
\item
  Inserting equations \eqref{eq:price-predicted} and \eqref{eq:demand-determinants} into equation \eqref{eq:demand-utility} gives us:
  \begin{equation}
  \begin{split}
  U_{ijmt}^D &= \overline{\alpha}_0^D + X_{jmt}^{\prime D} \beta^D + \xi_{jmt}^D + \alpha^D P_{ijmt} + Y_{ijmt}^{\prime D} \eta^D + \epsilon_i^D + \nu_{ijmt}^D\\
  &= \overline{\alpha}_0^D + X_{jmt}^{\prime D} \beta^D + \xi_{jmt}^D + \alpha^D[\tilde{P}_{jmt} + \tilde{\gamma}_1 \mathcal{D}_{ijmt} + \tilde{\gamma_2} \mathcal{L}_{ijmt} + \tilde{\omega}_i^P] + \eta_1^D \mathcal{D}_{ijmt} + \eta_2^D \mathcal{L}_{ijmt} + \eta_3^D Y_i + \tilde{\omega}_i^D\\
  &= \underbrace{(\overline{\alpha}_0^D + X_{jmt}^{\prime D} \beta^D + \xi_{jmt}^D + \alpha^D \tilde{P}_{jmt})}_{\tilde{\delta}_{jmt}^D} + \underbrace{(\eta_1^D + \alpha^D \tilde{\gamma}_1)}_{\tilde{\eta}_1^D}\mathcal{D}_{ijmt} + \tilde{(\eta_2^D + \alpha^D \tilde{\gamma}_2^D)}_{\tilde{\eta}_2^D} \mathcal{L}_{ijmt}\\
  &+ \eta_3^D Y_i + \underbrace{(\eta_4^D + \alpha^D)}_{\tilde{\eta}_4^D} \tilde{\omega}_i^P + \epsilon_i^D + \alpha^D \underbrace{\tilde{\tau}_{ijmt} + \nu_{ijmt}}_{\zeta_{ijmt}}\\
  &:= \tilde{\delta}_{jmt}^D + Y_{ijmt}^{\prime D} \tilde{\eta}^D + \epsilon_i^D + \zeta_{ijmt}\\
  &:= \tilde{\delta}_{jmt}^D(X_{jmt}^D, \widetilde{P}_{jmt}, \xi_{jmt}^D, \overline{\alpha}_0^D, \alpha^D, \beta^D) + V_{ijmt}^D(Y_{ijmt}^D, \sigma_D, \tilde{\eta}^D) + \zeta_{ijmt}.
  \end{split}
  \end{equation}
\item
  \(Y_{ijmt}^D : = \{\mathcal{D}_{ijmt}, \mathcal{L}_{ijmt}, Y_i, \tilde{\omega}_i^P\}\).
\item
  \(\tilde{\eta}^D := \{\tilde{\eta}_1^D, \tilde{\eta}_2^D, \eta_3^D, \tilde{\eta}_4^D\}\).
\item
  Inserting the reduced-form estimates of the equilibrium pricing strategy into the demand model; kind of CCP approach; find parameters that make this estimate consistent with equilibrium conditions.
\item
  Predictors for the equilibrium pricing strategy is all included in the utility for choosing a bank; thus, at the equilibrium, the change in covariate affect the utility through two channels; direct effect and indirect effect through price change; \(\tilde{\eta}_1^D, \tilde{\eta}_2^D\), and \(\tilde{\eta}_4^D\) represent the composite effects; because the effect on pricing is already identified, we can separate the effects through these two channels in the second stage.
\item
  The error terms is also a composite of preference shock \(\nu_{ijmt}\) and prediction error in pricing \(\tilde{\tau}_{ijmt}\).
\item
  \(\alpha_D\) is identified in the second stage after estimating \(\tilde{\eta}^D\) in the first stage.
\end{itemize}

\subsection{Choice Probability}\label{choice-probability}

\begin{itemize}
\tightlist
\item
  The probability that borrower \(i\) in market \(m\) in year \(t\) chooses bank \(j\) is given by:
  \[
  Pr_{ijmt}^D := \int \frac{\exp[\tilde{\delta}_{jmt}^D(X_{jmt}^D, \widetilde{P}_{jmt}, \xi_{jmt}^D, \overline{\alpha}_0^D, \alpha^D, \beta^D) + V_{ijmt}^D(Y_{ijmt}^D, \sigma_D, \tilde{\eta}^D)]}{1 + \sum_{l} \exp[\tilde{\delta}_{lmt}^D(X_{lmt}^D, \widetilde{P}_{lmt}, \xi_{lmt}^D, \overline{\alpha}_0^D, \alpha^D, \beta^D) + V_{ilmt}^D(Y_{ilmt}^D, \sigma_D, \tilde{\eta}^D)]} f(\epsilon_i^D) d\epsilon_i^D.
  \]
\end{itemize}

\subsection{Equilibrium Loan Strategy}\label{equilibrium-loan-strategy}

\begin{itemize}
\tightlist
\item
  In the equilibrium, the probability of having loan \(L\) conditional on borrowing (\(D = 1\)) is:
  \begin{equation}
  \begin{split}
  Pr_{ijmt, L|D = 1}^L &:= \mathbb{E}\left\{\mathbb{P}[L_{ijmt} = \alpha_0^L + \alpha^L P_{ijmt} + Y_{ijmt}^{\prime L} \eta^L + \epsilon_i^L|\epsilon_i^D] D = 1 \right\}\\
  &= \int \phi_{\epsilon_i^L|\epsilon_i^D} \left(\frac{L_{ijmt} - \alpha_0^L - \alpha^L P_{ijmt} - Y_{ijmt}^{\prime L} \eta^L - \tilde{\mu}_{\epsilon_i^L|\epsilon_i^D}^L}{\tilde{\sigma}_{\epsilon_i^L|\epsilon_i^D}} \right) f(\epsilon_i^D|D = 1) d \epsilon_i^D.
  \end{split} \label{eq:loan-strategy}
  \end{equation}
  where
  \[
  \epsilon_i^L | \epsilon_i^D \sim N\left(\frac{\sigma_L}{\sigma_D} \rho_{DL} \epsilon_i^D, \sigma_L^2 (1 - \rho_{DL}^2) \right) := N(\tilde{\mu}_{\epsilon_i^L|\epsilon_i^D}^, \tilde{\sigma}_{\epsilon_i^L|\epsilon_i^D}).
  \]
\end{itemize}

\subsection{Equilibrium Default Strategy}\label{equilibrium-default-strategy}

\begin{itemize}
\tightlist
\item
  In the equilibrium, the probability of default (\(F = 1\)) conditional on borrowing (\(D = 1\)) is:
  \begin{equation}
  \begin{split}
  Pr_{ijmt, F = 1| D = 1, L}^F &:= \int \Phi_{\epsilon_i^F|\epsilon_i^D, \epsilon_i^L}\left(\frac{\alpha_0^F + X_{jmt}^{\prime F} \beta^F + \alpha^F P_{ijmt} + Y_{ijmt}^{\prime F} \eta^F - \tilde{\mu}_{\epsilon_i^F|\epsilon_i^D, \epsilon_i^L}}{\tilde{\sigma}_{\epsilon_i^F | \epsilon_i^D, \epsilon_i^L}} \right) f(\epsilon_i^D | D = 1) d\epsilon_i^D,
  \end{split} \label{eq:default-strategy}
  \end{equation}
  where
  \[
  \epsilon_i^F | \epsilon_i^D, \epsilon_i^L \sim N(A \epsilon_i^D + B \epsilon_i^L, \sigma_F^2 - (A \rho_{DF} + B \rho_{LF})) := N(\tilde{\mu}_{\epsilon_i^F|\epsilon_i^D, \epsilon_i^L}, \tilde{\sigma}_{\epsilon_i^F | \epsilon_i^D, \epsilon_i^L}).
  \]
  \[
  A := \frac{\rho_{DF} \sigma_L^2 - \rho_{LF} \rho_{DL}}{\sigma_D^2 \sigma_L^2 - \rho_{DL}^2}.
  \]
  \[
  B := \frac{-\rho_{DF} \rho_{DL} + \rho_{LF} \sigma_D^2}{\sigma_D^2 \sigma_L^2 - \rho_{DL}^2}.
  \]
\end{itemize}

\subsection{Control Function Approach to Deal with Endogeneity in Loand and Defaulty Equations}\label{control-function-approach-to-deal-with-endogeneity-in-loand-and-defaulty-equations}

\begin{itemize}
\tightlist
\item
  The structural parameters in loan use and default strategies are identified by using instrumental variables.
\item
  Use prices in the other market as instruments (Hausman-type instruments).
\item
  Use a control function approach.
\item
  Regress prices on the convariates in loan use equation \textbf{and the instrument}.
\item
  Let \(\hat{u}_{ijmt}^L\) be the residual estimate.
\item
  Regress prices on the covariates in default equation \textbf{and the instrument}.
\item
  Let \(\hat{u}_{ijmt}^F\) be the residual estimate.
\item
  Replace \(\tilde{P}_{jmt}\) in equation \eqref{eq:loan-strategy} with the predicted value plus \(\hat{u}_{ijmt}^L\).
\item
  Replace \(\tilde{P}_{jmt}\) in equation \eqref{eq:default-strategy} with the predicted value plus \(\hat{u}_{ijmt}^F\).
\item
  Because of the instruments, the values of \(\hat{u}_{ijmt}^L\) and \(\hat{u}_{ijmt}^F\) can change conditional on the covariates in the loan strategy and default strategy.
\item
  These variations identify \(\alpha^L\) and \(\alpha^F\) in the following first-stage equation.
\end{itemize}

\subsection{First-Stage Estimation}\label{first-stage-estimation}

\begin{itemize}
\tightlist
\item
  In the first-stage, we identify the composite parameters in the bank choice; the coefficients consist of structural parameters and the \emph{biases} from endogeneity.
\item
  We separate structural parameters from biases in the second stage using instrumental variables.
\item
  We estimate parameters by maximizing the following simulated log-likelihood function:
  \[
  log L := \sum_{i} d_{ijmt} \{\log(P_{ijmt}^D) + \log (Pr_{immt}^L) + f_{ijmt} \log (Pr_{ijmt}^T) + (1 - f_{ijmt}) log (1 - Pr_{ijmt}^F) \}.
  \]
\item
  \(d_{ijmt}\): firm \(i\) borrows from bank \(j\) in market \(m\) in year \(t\).
\item
  \(f_{ijmt}\): firm \(i\) defaults from bank \(j\)
\end{itemize}

\subsection{Second-Stage Estimation}\label{second-stage-estimation}

\begin{itemize}
\tightlist
\item
  From the first-stage estimates, we obtain the estimate of \(\tilde{\delta}_{jmt}\), denoted by \(\hat{\tilde{\delta}_{jmt}}\).
\item
  Consider a regression such as:
  \[
  \hat{\tilde{\delta}_{jmt}} = \overline{\alpha}_0^D + \alpha^D \tilde{P}_{jmt} + X_{jmt}^{\prime D} \beta^D + \xi_{jmt}^D,
  \]
  where \(\tilde{P}_{jmt}\) and \(\xi_{jmt}^D\) can be correlated.
\item
  Use the euro value of collected deposits and the number of deposit accounts at the bank-market-year level as instruments.
\item
  The high degree of autonomy that local branch managers have in their lending decisions will imply better service and condition for loans.
\item
  Because deposit conditions are determined in the market with households, it will be independent of loan market conditions.
\end{itemize}

\subsection{Estimation Results}\label{estimation-results}

\includegraphics{figuretable/Crawford_2018_Table4.png}

\subsection{Findings from Estimation Results}\label{findings-from-estimation-results}

\begin{itemize}
\tightlist
\item
  Interest rates have negative impact on bank choice and loan amount.

  \begin{itemize}
  \tightlist
  \item
    On average among five largest banks, 10\% increase in the interest rate reduces the bank's market share by 10\% and increases rival banks' shares by 1\%.
  \end{itemize}
\item
  A higher interest rate leads to a higher default probability.

  \begin{itemize}
  \tightlist
  \item
    If the control function approach successfully identify the structural effect of price increase on the default probability, the positive estimate can be interpreted as evidence of moral hazard as we have discussed.
  \end{itemize}
\item
  Correlation between unobserved demand and loan amount shocks, and between demand and default shocks, are positive and statistically significant.
\end{itemize}

\subsection{Fit of the Model}\label{fit-of-the-model}

\includegraphics{figuretable/Crawford_2018_Table5.png}

\subsection{Counterfactuals}\label{counterfactuals}

\includegraphics{figuretable/Crawford_2018_Table6.png}

\includegraphics{figuretable/Crawford_2018_Table7.png}

\subsection{What if Adverse Selection Got Severer?}\label{what-if-adverse-selection-got-severer}

\begin{itemize}
\tightlist
\item
  A doubling in the correlations \(\rho_{DF}\) and \(\rho_{LF}\) causes 1.87 percent points increases in the average interest rates.
\item
  This causes 1.28 percent points decrease in the share and EUR700 decrease in the loan amount.
\item
  The default probability substantially increases from 5.5 to 11.4\%.
\item
  The effective markup of a bank is negatively correlated with the price and default probability changes, and positively correlated with demand and loan amount changes.

  \begin{itemize}
  \tightlist
  \item
    A bank with higher market power takes care of marginal borrowers more than a bank with less market power.
  \end{itemize}
\end{itemize}

\subsection{What if Cost of Capital Increased?}\label{what-if-cost-of-capital-increased}

\begin{itemize}
\tightlist
\item
  5\% (or 70 basis points) increase in the bank's marginal cost leads to 1.78 percent points increase in the interest rates.
\item
  The default probability increases only by 1.84 percent points in this case.

  \begin{itemize}
  \tightlist
  \item
    With price increase, riskier borrowers will borrow from a bank.
  \item
    But in the current case, the degree of adverse selection is fixed.
  \item
    So the increase in default probability is moderate.
  \end{itemize}
\item
  The effective markup of a bank is negatively correlated with the price and default changes, and positively correlated with demand and loan amount change.
\end{itemize}

\subsection{Merger Simulation}\label{merger-simulation-2}

\includegraphics{figuretable/Crawford_2018_Table8.png}

\begin{itemize}
\tightlist
\item
  Under severe adverse selection, unilateral effects of a merger on prices is moderate.
\end{itemize}

\chapter{Assignment 1: Basic Programming in R}\label{assignment1}

Report the following results in html format using R markdown. In other words, replicate this document. You write functions in a separate R file and put in \texttt{R} folder in the project folder. Build the project as a package and load it from the R markdown file. The execution code sholuld be written in R markdown file.

You submit:

\begin{itemize}
\tightlist
\item
  R file containing functions.
\item
  R markdown file containing your answers and executing codes.
\item
  HTML(or PDF) report generated from the R markdown.
\end{itemize}

\section{Simulate data}\label{simulate-data}

Consider to simulate data from the following model and estimate the parameters from the simulated data.

\[
y_{ij} = 1\{j = \text{argmax}_{k = 1, 2} \beta x_k + \epsilon_{ik} \},
\]
where \(\epsilon_{ik}\) follows i.i.d. type-I extreme value distribution, \(\beta = 0.2\), \(x_1 = 0\) and \(x_2 = 1\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  To simulate data, first make a data frame as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2,000 x 3
##        i     k     x
##    <int> <int> <dbl>
##  1     1     1     0
##  2     1     2     1
##  3     2     1     0
##  4     2     2     1
##  5     3     1     0
##  6     3     2     1
##  7     4     1     0
##  8     4     2     1
##  9     5     1     0
## 10     5     2     1
## # i 1,990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Second, draw type-I extreme value random variables. Set the seed at 1. You can use \texttt{evd} package to draw the variables. You should get exactly the same realization if the seed is correctly set.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2,000 x 4
##        i     k     x       e
##    <int> <int> <dbl>   <dbl>
##  1     1     1     0  0.281 
##  2     1     2     1 -0.167 
##  3     2     1     0  1.93  
##  4     2     2     1  1.97  
##  5     3     1     0  0.830 
##  6     3     2     1 -1.06  
##  7     4     1     0 -0.207 
##  8     4     2     1  0.617 
##  9     5     1     0  0.0444
## 10     5     2     1  1.92  
## # i 1,990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Third, compute the latent value of each option to obtain the following data frame:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2,000 x 5
##        i     k     x       e  latent
##    <int> <int> <dbl>   <dbl>   <dbl>
##  1     1     1     0  0.281   0.281 
##  2     1     2     1 -0.167   0.0331
##  3     2     1     0  1.93    1.93  
##  4     2     2     1  1.97    2.17  
##  5     3     1     0  0.830   0.830 
##  6     3     2     1 -1.06   -0.863 
##  7     4     1     0 -0.207  -0.207 
##  8     4     2     1  0.617   0.817 
##  9     5     1     0  0.0444  0.0444
## 10     5     2     1  1.92    2.12  
## # i 1,990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Finally, compute \(y\) by comparing the latent values of \(k = 1, 2\) for each \(i\) to obtain the following result:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2,000 x 6
##        i     k     x       e  latent     y
##    <int> <int> <dbl>   <dbl>   <dbl> <dbl>
##  1     1     1     0  0.281   0.281      1
##  2     1     2     1 -0.167   0.0331     0
##  3     2     1     0  1.93    1.93       0
##  4     2     2     1  1.97    2.17       1
##  5     3     1     0  0.830   0.830      1
##  6     3     2     1 -1.06   -0.863      0
##  7     4     1     0 -0.207  -0.207      0
##  8     4     2     1  0.617   0.817      1
##  9     5     1     0  0.0444  0.0444     0
## 10     5     2     1  1.92    2.12       1
## # i 1,990 more rows
\end{verbatim}

\section{Estimate the parameter}\label{estimate-the-parameter}

Now you generated simulated data. Suppose you observe \(x_k\) and \(y_{ik}\) for each \(i\) and \(k\) and estimate \(\beta\) by a maximum likelihood estimator. The likelihood for \(i\) to choose \(k\) (\(y_{ik} = 1\)) can be shown to be:
\[
p_{ik}(\beta) = \frac{\exp(\beta x_k)}{\exp(\beta x_1) + \exp(\beta x_2)}.
\]

Then, the likelihood of observing \(\{y_{ik}\}_{i, k}\) is:
\[
L(\beta) = \prod_{i = 1}^{1000} p_{i1}(\beta)^{y_{i1}} [1 - p_{i1}(\beta)]^{1 - y_{i1}},
\]
and the log likelihood is:
\[
l(\beta) = \sum_{i = 1}^{1000}\{y_{i1}\log p_{i1}(\beta) + (1 - y_{i1})\log [1 - p_{i1}(\beta)\}.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function to compute the likelihood for a given \(\beta\) and data and name the function \texttt{compute\_loglikelihood\_a1(b,\ df)}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{compute\_loglikelihood\_a1}\NormalTok{(}
    \AttributeTok{b =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{df =}\NormalTok{ df}
\NormalTok{  ) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.7542617
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the value of log likelihood for \(\beta = 0, 0.1, \cdots, 1\) and plot the result using \texttt{ggplot2} packages. You can use \texttt{latex2exp} package to use LaTeX math symbol in the label:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b\_seq }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\NormalTok{output }\OtherTok{\textless{}{-}} 
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{b =}\NormalTok{ b\_seq,}
    \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{      l }\OtherTok{\textless{}{-}} 
        \FunctionTok{compute\_loglikelihood\_a1}\NormalTok{(}
\NormalTok{          b, }
\NormalTok{          df}
\NormalTok{          )}
      \FunctionTok{return}\NormalTok{(l)}
\NormalTok{\}}
\NormalTok{output }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ b\_seq, }
    \AttributeTok{y =}\NormalTok{ output}
\NormalTok{    )}
\NormalTok{output }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ x, }
      \AttributeTok{y =}\NormalTok{ y}
\NormalTok{      )}
\NormalTok{    ) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(}\StringTok{"$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta$"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Loglikelihood"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-22-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find and report \(\beta\) that maximizes the log likelihood for the simulated data. You can use \texttt{optim} function to achieve this. You will use \texttt{Brent} method and set the lower bound at -1 and upper bound at 1 for the parameter search.
\end{enumerate}

\begin{verbatim}
## $par
## [1] 0.2371046
## 
## $value
## [1] -0.6861689
## 
## $counts
## function gradient 
##       NA       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
\end{verbatim}

\chapter{Assignment 2: Production Function Estimation}\label{assignment2}

\section{Simulate data}\label{simulate-data-1}

Consider the following production and investment process for \(j = 1, \cdots, 1000\) firms across \(t = 1, \cdots, 10\) periods.

The log production function is of the form:
\[
y_{jt} = \beta_0 + \beta_l l_{jt} + \beta_k k_{jt} + \omega_{jt} + \eta_{jt},
\]
where \(\omega_{jt}\) is an anticipated shock and \(\eta_{jt}\) is an ex post shock.

The anticipated shocks evolve as:
\[
\omega_{jt} = \alpha \omega_{j, t - 1} + \nu_{jt},
\]
where \(\nu_{jt}\) is an i.i.d. normal random variable with mean 0 and standard deviation \(\sigma_\nu\). The ex post shock is an i.i.d. normal random variable with mean 0 and standard deviation \(\sigma_{\eta}\).

The product price the same across firms and normalized at 1. The price is normalized at 1. The wage \(w_t\) is constant at 0.5.

Finally, the capital accumulate according to:
\[
K_{j, t + 1} = (1 - \delta) K_{jt} + I_{jt}.
\]

We set the parameters as follows:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
parameter & variable & value \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\beta_0\) & \texttt{beta\_0} & 1 \\
\(\beta_l\) & \texttt{beta\_l} & 0.2 \\
\(\beta_k\) & \texttt{beta\_k} & 0.7 \\
\(\alpha\) & \texttt{alpha} & 0.7 \\
\(\sigma_{\eta}\) & \texttt{sigma\_eta} & 0.2 \\
\(\sigma_{\nu}\) & \texttt{sigma\_nu} & 0.5 \\
\(\sigma_{w}\) & \texttt{sigma\_w} & 0.1 \\
\(\delta\) & \texttt{delta} & 0.05 \\
\end{longtable}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define the parameter variables as above.
\item
  Write a function that returns the log output given \(l_{jt}\), \(k_{jt}\), \(\omega_{jt}\), and \(\eta_{jt}\) under the given parameter values according to the above production function and name it \texttt{log\_production(l,\ k,\ omega,\ eta,\ beta\_0,\ beta\_l,\ beta\_k)}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{log\_production}\NormalTok{(}
    \AttributeTok{l =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{k =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{omega =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{eta =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{beta\_0 =}\NormalTok{ beta\_0,}
    \AttributeTok{beta\_l =}\NormalTok{ beta\_l,}
    \AttributeTok{beta\_k =}\NormalTok{ beta\_k}
\NormalTok{    ) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.9
\end{verbatim}

Suppose that the labor is determined after \(\omega_{jt}\) is observed, but before \(\eta_{jt}\) is observed, given the log capital level \(k_{jt}\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Derive the optimal log labor as a function of \(\omega_{jt}\), \(\eta_{jt}\), \(k_{jt}\), and wage. Write a function to return the optimal log labor given the variables and parameters and name it \texttt{log\_labor\_choice(k,\ wage,\ omega,\ beta\_0,\ beta\_l,\ beta\_k,\ sigma\_eta)}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{log\_labor\_choice}\NormalTok{(}
  \AttributeTok{k =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{wage =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{omega =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{beta\_0 =}\NormalTok{ beta\_0, }
  \AttributeTok{beta\_l =}\NormalTok{ beta\_l, }
  \AttributeTok{beta\_k =}\NormalTok{ beta\_k, }
  \AttributeTok{sigma\_eta =}\NormalTok{ sigma\_eta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.388203
\end{verbatim}

As discussed in the class, if there is no additional variation in labor, the coefficient on the labor \(\beta_l\) is not identified. Thus, if we generate labor choice from the previous function, \(\beta_l\) will not be identified from the simulated data. To see this, we write a modified version of the previous function in which \(\omega_{jt}\) is replaced with \(\omega_{jt} + \iota_{jt}\), where \(\iota_{jt}\) is an optimization error that follows an i.i.d. normal distribution with mean 0 and standard deviation 0.05. That is, the manager of the firm perceives as if the shock is \(\omega_{jt} + \iota_{jt}\), even though the true shock is \(\omega_{jt}\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Modify the previous function by including \(\iota_{jt}\) as an additional input and name it \texttt{log\_labor\_choice\_error(k,\ wage,\ omega,\ beta\_0,\ beta\_l,\ beta\_k,\ iota,\ sigma\_eta)}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{log\_labor\_choice\_error}\NormalTok{(}
  \AttributeTok{k =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{wage =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{omega =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{beta\_0 =}\NormalTok{ beta\_0, }
  \AttributeTok{beta\_l =}\NormalTok{ beta\_l, }
  \AttributeTok{beta\_k =}\NormalTok{ beta\_k, }
  \AttributeTok{iota =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{sigma\_eta =}\NormalTok{ sigma\_eta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.638203
\end{verbatim}

Consider an investment process such that:
\[
I_{jt} = (\delta + \gamma \omega_{jt}) K_{jt},
\]
where \(I_{jt}\) and \(K_{jt}\) are investment and capital in level. Set \(\gamma = 0.1\), i.e., the investment is strictly increasing in \(\omega_{jt}\). The investment function should be derived by solving the dynamic problem of a firm. But here, we just specify it in a reduced-form.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Define variable \(\gamma\) and assign it the value. Write a function that returns the investment given \(K_{jt}\), \(\omega_{jt}\), and parameter values, according to the previous equation, and name it \texttt{investment\_choice(k,\ omega,\ gamma,\ delta)}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gamma }\OtherTok{\textless{}{-}} \FloatTok{0.1}
\FunctionTok{investment\_choice}\NormalTok{(}
  \AttributeTok{k =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{omega =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{gamma =}\NormalTok{ gamma, }
  \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4077423
\end{verbatim}

Simulate the data first using the labor choice without optimization error and second using the labor choice with optimization error. To do so, we specify the initial values for the state variables \(k_{jt}\) and \(\omega_{jt}\) as follows.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Draw \(k_{j1}\) from an i.i.d. normal distribution with mean 1 and standard deviation 0.5. Draw \(\omega_{j1}\) from its stationary distribution (check the stationary distribution of AR(1) process). Draw a wage. Before simulating the rest of the data, set the seed at 1.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1,000 x 5
##        j     t     k   omega  wage
##    <int> <dbl> <dbl>   <dbl> <dbl>
##  1     1     1 0.687  0.795    0.5
##  2     2     1 1.09   0.779    0.5
##  3     3     1 0.582 -0.610    0.5
##  4     4     1 1.80   0.148    0.5
##  5     5     1 1.16   0.0486   0.5
##  6     6     1 0.590 -1.16     0.5
##  7     7     1 1.24   0.568    0.5
##  8     8     1 1.37  -1.34     0.5
##  9     9     1 1.29  -0.873    0.5
## 10    10     1 0.847  0.699    0.5
## # i 990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Draw optimization error \(\iota_{jt}\) and compute the labor and investment choice of period 1. For labor choice, compute both types of labor choices.
\end{enumerate}

\begin{verbatim}
## # A tibble: 1,000 x 9
##        j     t     k   omega  wage     iota      l l_error     inv
##    <int> <dbl> <dbl>   <dbl> <dbl>    <dbl>  <dbl>   <dbl>   <dbl>
##  1     1     1 0.687  0.795    0.5 -0.0443   1.72   1.67    0.257 
##  2     2     1 1.09   0.779    0.5 -0.0961   2.06   1.94    0.381 
##  3     3     1 0.582 -0.610    0.5  0.0810  -0.123 -0.0218 -0.0196
##  4     4     1 1.80   0.148    0.5  0.0260   1.89   1.92    0.391 
##  5     5     1 1.16   0.0486   0.5 -0.00279  1.21   1.21    0.176 
##  6     6     1 0.590 -1.16     0.5  0.0348  -0.809 -0.766  -0.120 
##  7     7     1 1.24   0.568    0.5  0.00268  1.93   1.93    0.370 
##  8     8     1 1.37  -1.34     0.5 -0.0655  -0.346 -0.428  -0.330 
##  9     9     1 1.29  -0.873    0.5 -0.106    0.165  0.0327 -0.135 
## 10    10     1 0.847  0.699    0.5 -0.0104   1.74   1.73    0.280 
## # i 990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Draw ex post shock and compute the output according to the production function for both labor without optimization error and with optimization error. Name the output without optimization error \texttt{y} and the one with optimization error \texttt{y\_error}.
\end{enumerate}

\begin{verbatim}
## # A tibble: 1,000 x 12
##        j     t     k   omega  wage     iota      l l_error     inv     eta     y
##    <int> <dbl> <dbl>   <dbl> <dbl>    <dbl>  <dbl>   <dbl>   <dbl>   <dbl> <dbl>
##  1     1     1 0.687  0.795    0.5 -0.0443   1.72   1.67    0.257   0.148  2.77 
##  2     2     1 1.09   0.779    0.5 -0.0961   2.06   1.94    0.381   0.0773 3.03 
##  3     3     1 0.582 -0.610    0.5  0.0810  -0.123 -0.0218 -0.0196  0.259  1.03 
##  4     4     1 1.80   0.148    0.5  0.0260   1.89   1.92    0.391  -0.161  2.62 
##  5     5     1 1.16   0.0486   0.5 -0.00279  1.21   1.21    0.176  -0.321  1.79 
##  6     6     1 0.590 -1.16     0.5  0.0348  -0.809 -0.766  -0.120   0.187  0.274
##  7     7     1 1.24   0.568    0.5  0.00268  1.93   1.93    0.370   0.361  3.19 
##  8     8     1 1.37  -1.34     0.5 -0.0655  -0.346 -0.428  -0.330  -0.0113 0.539
##  9     9     1 1.29  -0.873    0.5 -0.106    0.165  0.0327 -0.135   0.377  1.44 
## 10    10     1 0.847  0.699    0.5 -0.0104   1.74   1.73    0.280   0.316  2.96 
## # i 990 more rows
## # i 1 more variable: y_error <dbl>
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Repeat this procedure for \(t = 1, \cdots 10\) by updating the capital and anticipated shocks, and name the resulting data frame \texttt{df\_all}. Use the previously generated \texttt{df} as the data for \texttt{t\ =\ 1}. In each perio, generate \texttt{nu}, \texttt{iota}, and \texttt{eta} in this order, if you want to match the realization of the random variables.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_all}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10,000 x 13
##        j     t     k   omega  wage     iota      l l_error     inv     eta     y
##    <int> <dbl> <dbl>   <dbl> <dbl>    <dbl>  <dbl>   <dbl>   <dbl>   <dbl> <dbl>
##  1     1     1 0.687  0.795    0.5 -0.0443   1.72   1.67    0.257   0.148  2.77 
##  2     2     1 1.09   0.779    0.5 -0.0961   2.06   1.94    0.381   0.0773 3.03 
##  3     3     1 0.582 -0.610    0.5  0.0810  -0.123 -0.0218 -0.0196  0.259  1.03 
##  4     4     1 1.80   0.148    0.5  0.0260   1.89   1.92    0.391  -0.161  2.62 
##  5     5     1 1.16   0.0486   0.5 -0.00279  1.21   1.21    0.176  -0.321  1.79 
##  6     6     1 0.590 -1.16     0.5  0.0348  -0.809 -0.766  -0.120   0.187  0.274
##  7     7     1 1.24   0.568    0.5  0.00268  1.93   1.93    0.370   0.361  3.19 
##  8     8     1 1.37  -1.34     0.5 -0.0655  -0.346 -0.428  -0.330  -0.0113 0.539
##  9     9     1 1.29  -0.873    0.5 -0.106    0.165  0.0327 -0.135   0.377  1.44 
## 10    10     1 0.847  0.699    0.5 -0.0104   1.74   1.73    0.280   0.316  2.96 
## # i 9,990 more rows
## # i 2 more variables: y_error <dbl>, nu <dbl>
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  Check the simulated data by making summary table.
\end{enumerate}

\begin{tabular}{l|r|r|r|r|r}
\hline
  & N & Mean & Sd & Min & Max\\
\hline
j & 10000 & 500.5000000 & 288.6894251 & 1.0000000 & 1000.0000000\\
\hline
t & 10000 & 5.5000000 & 2.8724249 & 1.0000000 & 10.0000000\\
\hline
k & 10000 & 0.9797900 & 0.5838949 & -1.2822534 & 3.2332312\\
\hline
omega & 10000 & -0.0055826 & 0.7025102 & -2.5894171 & 2.6281307\\
\hline
wage & 10000 & 0.5000000 & 0.0000000 & 0.5000000 & 0.5000000\\
\hline
iota & 10000 & -0.0000696 & 0.0502883 & -0.1841453 & 0.1715419\\
\hline
l & 10000 & 0.9799746 & 1.0965108 & -3.3281023 & 4.9679634\\
\hline
l\_error & 10000 & 0.9798876 & 1.0971595 & -3.3765433 & 4.9520674\\
\hline
inv & 10000 & 0.1793502 & 0.3006526 & -1.2722627 & 3.2975332\\
\hline
eta & 10000 & 0.0015825 & 0.2001539 & -0.7650371 & 0.7455922\\
\hline
y & 10000 & 1.8778479 & 1.1171035 & -2.4680251 & 6.1228291\\
\hline
y\_error & 10000 & 1.8778305 & 1.1169266 & -2.4777133 & 6.1196499\\
\hline
nu & 10000 & -0.0021155 & 0.4984324 & -2.1513907 & 1.8253882\\
\hline
\end{tabular}

\section{Estimate the parameters}\label{estimate-the-parameters}

For now, use the labor choice with optimization error.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  First, simply regress \(y_{jt}\) on \(l_{jt}\) and \(k_{jt}\) using the least square method.
\end{enumerate}

\begin{verbatim}
## 
## Call:
## lm(formula = y_error ~ l_error + k, data = df_all)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.73002 -0.14117 -0.00071  0.13743  0.87983 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 0.892542   0.004058 219.966   <2e-16 ***
## l_error     0.997913   0.002396 416.454   <2e-16 ***
## k           0.007599   0.004503   1.688   0.0915 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.2068 on 9997 degrees of freedom
## Multiple R-squared:  0.9657, Adjusted R-squared:  0.9657 
## F-statistic: 1.408e+05 on 2 and 9997 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Second, take within-transformation on \(y_{jt}\), \(l_{jt}\), and \(k_{jt}\) and let \(\Delta y_{jt}\), \(\Delta l_{jt}\), and \(\Delta k_{jt}\) denote them. Then, regress \(\Delta y_{jt}\) on \(\Delta l_{jt}\), and \(\Delta k_{jt}\) by the least squares method.
\end{enumerate}

\begin{verbatim}
## 
## Call:
## lm(formula = dy_error ~ -1 + dl_error + dk, data = df_all_within)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.72450 -0.13285 -0.00244  0.12931  0.77657 
## 
## Coefficients:
##            Estimate Std. Error t value Pr(>|t|)    
## dl_error  0.9910916  0.0029548 335.413   <2e-16 ***
## dk       -0.0009029  0.0127539  -0.071    0.944    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.1961 on 9998 degrees of freedom
## Multiple R-squared:  0.9184, Adjusted R-squared:  0.9184 
## F-statistic: 5.629e+04 on 2 and 9998 DF,  p-value: < 2.2e-16
\end{verbatim}

Next, we attempt to estimate the parameters using Olley-Pakes method. Estimate the first-step model of Olley-Pakes method:
\[
y_{jt} = \beta_1 l_{jt} + \phi(k_{jt}, I_{jt}) + \eta_{jt},
\]
by approximating \(\phi_t\) by a kernel function.

Remark that \(\phi\) in general depends on observed and unobserved state variables. For this reason, in theory, \(\phi\) should be estimated for each period. In this exercise, we assume \(\phi\) is common across periods because we know that there is no unobserved state variables in the true data generating process. Moreover, we do not include \(w_t\) because we know that it is time -invariant. Do not forget to consider them in the actual data analysis.

You can use \texttt{npplreg} function of \texttt{np} package to estimate a partially linear model with a multivariate kernel. You first use \texttt{npplregbw} to obtain the optimal band width and then use \texttt{npplreg} to estimate the model under the optimal bandwidth. The computation of the optimal bandwidth is time consuming.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Return the summary of the first stage estimation and plot the fitted values against the data points.
\end{enumerate}

\begin{verbatim}
## 
## Partially Linear Model
## Regression data: 10000 training points, in 3 variable(s)
## With 1 linear parametric regressor(s), 2 nonparametric regressor(s)
## 
##                     y(z)           
## Bandwidth(s): 0.07355058 0.01435558
## 
##                     x(z)           
## Bandwidth(s): 0.03908594 0.01191551
## 
##                   l_error
## Coefficient(s): 0.2493396
## 
## Kernel Regression Estimator: Local-Constant
## Bandwidth Type: Fixed
## 
## Residual standard error: 0.1934778
## R-squared: 0.9700706
## 
## Continuous Kernel Type: Second-Order Gaussian
## No. Continuous Explanatory Vars.: 2
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-34-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Check that \(\beta_l\) is not identified with the data without optimization error. Estimate the first stage model of Olley-Pakes with the labor choice without optimization error and report the result.
\end{enumerate}

\begin{verbatim}
## 
## Partially Linear Model
## Regression data: 10000 training points, in 3 variable(s)
## With 1 linear parametric regressor(s), 2 nonparametric regressor(s)
## 
##                     y(z)           
## Bandwidth(s): 0.07347226 0.01437256
## 
##                     x(z)            
## Bandwidth(s): 0.02960262 0.009987366
## 
##                        l
## Coefficient(s): 1.187301
## 
## Kernel Regression Estimator: Local-Constant
## Bandwidth Type: Fixed
## 
## Residual standard error: 0.1932366
## R-squared: 0.9701184
## 
## Continuous Kernel Type: Second-Order Gaussian
## No. Continuous Explanatory Vars.: 2
\end{verbatim}

Then, we estimate the second stage model of Olley-Pakes method:
\[
y_{jt} - \hat{\beta_l} l_{jt} = \beta_0 + \beta_k k_{jt} + \alpha[\hat{\phi}(k_{j, t - 1}, I_{j, t - 1}) - \beta_0 - \beta_k k_{j, t-1}] + \nu_{jt} + \eta_{jt}.
\]

In this model, we do not have to non-parametetrically estimate the conditional expectation of \(\omega_{jt}\) on \(\omega_{j, t - 1}\), because we know that the anticipated shock follows an AR(1) process. Remark that we in general have to non-parametrically estimate it.

The model is non-linear in parameters, because of the term \(\alpha \beta_0\) and \(\alpha \beta_k\). We estimate \(\alpha\), \(\beta_0\), and \(\beta_k\) by a GMM estimator. The moment is:
\[
g_{JT}(\alpha, \beta_0, \beta_k) \equiv \frac{1}{JT}\sum_{j = 1}^J \sum_{t = 1}^T \{y_{jt} - \hat{\beta_l} l_{jt} - \beta_0 - \beta_k k_{jt} - \alpha[\hat{\phi}(k_{j, t - 1}, I_{j, t - 1}) - \beta_0 - \beta_k k_{j, t-1}]\} 
\begin{bmatrix}
k_{jt} \\
k_{j, t - 1} \\
I_{j, t - 1}
\end{bmatrix}.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Using the estimates in the first step, compute:
  \[
  y_{jt} - \hat{\beta_l} l_{jt},
  \]
  and:
  \[
  \hat{\phi}(k_{j, t - 1}, I_{j, t - 1}),
  \]
  for each \(j\) and \(t\) and save it as a data frame names \texttt{df\_all\_1st}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_all\_1st}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10,000 x 4
##        j     t y_error_tilde phi_t_1
##    <int> <dbl>         <dbl>   <dbl>
##  1     1     1         2.34   NA    
##  2     1     2         1.37    2.21 
##  3     1     3         0.621   1.49 
##  4     1     4         0.447   0.880
##  5     1     5         0.878   0.611
##  6     1     6         1.62    0.926
##  7     1     7         0.558   1.40 
##  8     1     8         0.684   0.439
##  9     1     9         0.939   0.525
## 10     1    10         1.49    0.838
## # i 9,990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Compute a function that returns the value of \(g_{JT}(\alpha, \beta_0, \beta_k)\) given parameter values, data, and \texttt{df\_all\_1st}, and name it \texttt{moment\_olleypakes\_2nd}. Show the values of the moments evaluated at the true parameters.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{moment\_olleypakes\_2nd}\NormalTok{(}
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{beta\_0 =}\NormalTok{ beta\_0, }
  \AttributeTok{beta\_k =}\NormalTok{ beta\_k, }
  \AttributeTok{df\_all =}\NormalTok{ df\_all, }
  \AttributeTok{df\_all\_1st =}\NormalTok{ df\_all\_1st}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.018459481 -0.019010969 -0.003815687
\end{verbatim}

Based on the moment, we can define the objective function of a generalized method of moments estimator with a weighting matrix \(W\) as:
\[
Q_{JT}(\alpha, \beta_0, \beta_k) \equiv g_{JT}(\alpha, \beta_0, \beta_k)' W g_{JT}(\alpha, \beta_0, \beta_k).
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function that returns the value of \(Q_{JT}(\alpha, \beta_0, \beta_k)\) given the vector of parameter values, data, and \texttt{df\_all\_1st}, and name it \texttt{objective\_olleypakes\_2nd}. Setting \(W\) at the identity matrix, show the value of the objective function evaluated at the true parameters.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{W }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    alpha, }
\NormalTok{    beta\_0, }
\NormalTok{    beta\_k}
\NormalTok{    )}
\FunctionTok{objective\_olleypakes\_2nd}\NormalTok{(}
  \AttributeTok{theta =}\NormalTok{ theta, }
  \AttributeTok{df\_all =}\NormalTok{ df\_all, }
  \AttributeTok{df\_all\_1st =}\NormalTok{ df\_all\_1st,}
  \AttributeTok{W =}\NormalTok{ W}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              [,1]
## [1,] 0.0007167288
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Draw the graph of the objective function when one of \(\alpha\), \(\beta_0\), and \(\beta_k\) are changed from 0 to 1 by 0.1 while the others are set at the true value. Is the objective function minimized at around the true value?
\end{enumerate}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-42-1} \end{center}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-42-2} \end{center}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-42-3} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Find the parameters that minimize the objective function using \texttt{optim}. You may use \texttt{L-BFGS-B} method to solve it.
\end{enumerate}

\begin{verbatim}
## $par
## [1] 0.7023647 0.9766275 0.6694232
## 
## $value
## [1] 2.027934e-07
## 
## $counts
## function gradient 
##       10       10 
## 
## $convergence
## [1] 0
## 
## $message
## [1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
\end{verbatim}

\chapter{Assignment 3: Demand Function Estimation I}\label{assignment3}

\section{Simulate data}\label{simulate-data-2}

We simulate data from a discrete choice model. There are \(T\) markets and each market has \(N\) consumers. There are \(J\) products and the indirect utility of consumer \(i\) in market \(t\) for product \(j\) is:
\[
u_{itj} = \beta_{it}' x_j + \alpha_{it} p_{jt} + \xi_{jt} + \epsilon_{ijt},
\]
where \(\epsilon_{ijt}\) is an i.i.d. type-I extreme random variable. \(x_j\) is \(K\)-dimensional observed characteristics of the product. \(p_{jt}\) is the retail price of the product in the market.

\(\xi_{jt}\) is product-market specific fixed effect. \(p_{jt}\) can be correlated with \(\xi_{jt}\) but \(x_{jt}\)s are independent of \(\xi_{jt}\). \(j = 0\) is an outside option whose indirect utility is:
\[
u_{it0} = \epsilon_{i0t},
\]
where \(\epsilon_{i0t}\) is an i.i.d. type-I extreme random variable.

\(\beta_{it}\) and \(\alpha_{it}\) are different across consumers, and they are distributed as:
\[
\beta_{itk} = \beta_{0k} + \sigma_k \nu_{itk},
\]
\[
\alpha_{it} = - \exp(\mu + \omega \upsilon_{it}) = - \exp(\mu + \frac{\omega^2}{2}) + [- \exp(\mu + \omega \upsilon_{it}) + \exp(\mu + \frac{\omega^2}{2})] \equiv \alpha_0 + \tilde{\alpha}_{it},
\]
where \(\nu_{itk}\) for \(k = 1, \cdots, K\) and \(\upsilon_{it}\) are i.i.d. standard normal random variables. \(\alpha_0\) is the mean of \(\alpha_i\) and \(\tilde{\alpha}_i\) is the deviation from the mean.

Given a choice set in the market, \(\mathcal{J}_t \cup \{0\}\), a consumer chooses the alternative that maximizes her utility:
\[
q_{ijt} = 1\{u_{ijt} = \max_{k \in \mathcal{J}_t \cup \{0\}} u_{ikt}\}.
\]
The choice probability of product \(j\) for consumer \(i\) in market \(t\) is:
\[
\sigma_{jt}(p_t, x_t, \xi_t) = \mathbb{P}\{u_{ijt} = \max_{k \in \mathcal{J}_t \cup \{0\}} u_{ikt}\}.
\]

Suppose that we only observe the share data:
\[
s_{jt} = \frac{1}{N} \sum_{i = 1}^N q_{ijt},
\]
along with the product-market characteristics \(x_{jt}\) and the retail prices \(p_{jt}\) for \(j \in \mathcal{J}_t \cup \{0\}\) for \(t = 1, \cdots, T\). We do not observe the choice data \(q_{ijt}\) nor shocks \(\xi_{jt}, \nu_{it}, \upsilon_{it}, \epsilon_{ijt}\).

In this assignment, we consider a model with \(\xi_{jt} = 0\), i.e., the model without the unobserved fixed effects. However, the code to simulate data should be written for general \(\xi_{jt}\), so that we can use the same code in the next assignment in which we consider a model with the unobserved fixed effects.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set the seed, constants, and parameters of interest as follows.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set the seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# number of products}
\NormalTok{J }\OtherTok{\textless{}{-}} \DecValTok{10}
\CommentTok{\# dimension of product characteristics including the intercept}
\NormalTok{K }\OtherTok{\textless{}{-}} \DecValTok{3}
\CommentTok{\# number of markets}
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{100}
\CommentTok{\# number of consumers per market}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{500}
\CommentTok{\# number of Monte Carlo}
\NormalTok{L }\OtherTok{\textless{}{-}} \DecValTok{500}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set parameters of interests}
\NormalTok{beta }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(K); }
\NormalTok{beta[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{beta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  4.0000000  0.1836433 -0.8356286
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(K)); sigma}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.5952808 0.3295078 0.8204684
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{omega }\OtherTok{\textless{}{-}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

Generate the covariates as follows.

The product-market characteristics:
\[
x_{j1} = 1, x_{jk} \sim N(0, \sigma_x), k = 2, \cdots, K,
\]
where \(\sigma_x\) is referred to as \texttt{sd\_x} in the code.

The product-market-specific unobserved fixed effect:
\[
\xi_{jt} = 0.
\]
The marginal cost of product \(j\) in market \(t\):
\[
c_{jt} \sim \text{logNormal}(0, \sigma_c),
\]
where \(\sigma_c\) is referred to as \texttt{sd\_c} in the code.

The retail price:
\[
p_{jt} - c_{jt} \sim \text{logNorm}(\gamma \xi_{jt}, \sigma_p),
\]
where \(\gamma\) is referred to as \texttt{price\_xi} and \(\sigma_p\) as \texttt{sd\_p} in the code. This price is not the equilibrium price. We will revisit this point in a subsequent assignment.

The value of the auxiliary parameters are set as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set auxiliary parameters}
\NormalTok{price\_xi }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{prop\_jt }\OtherTok{\textless{}{-}} \FloatTok{0.6}
\NormalTok{sd\_x }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{sd\_c }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\NormalTok{sd\_p }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \texttt{X} is the data frame such that a row contains the characteristics vector \(x_{j}\) of a product and columns are product index and observed product characteristics. The dimension of the characteristics \(K\) is specified above. Add the row of the outside option whose index is \(0\) and all the characteristics are zero.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make product characteristics data}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
\NormalTok{    sd\_x }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)), }
    \AttributeTok{nrow =}\NormalTok{ J}
\NormalTok{    )}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{cbind}\NormalTok{(}
    \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, J), }
\NormalTok{    X}
\NormalTok{    )}
\FunctionTok{colnames}\NormalTok{(X) }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{)}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{J,}
\NormalTok{    X}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{()}
\CommentTok{\# add outside option}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
    \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{dim}\NormalTok{(X)[}\DecValTok{2}\NormalTok{]),}
\NormalTok{    X}
\NormalTok{    ) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 11 x 4
##        j   x_1     x_2      x_3
##    <dbl> <dbl>   <dbl>    <dbl>
##  1     0     0  0       0      
##  2     1     1  0.244  -0.00810
##  3     2     1  0.369   0.472  
##  4     3     1  0.288   0.411  
##  5     4     1 -0.153   0.297  
##  6     5     1  0.756   0.459  
##  7     6     1  0.195   0.391  
##  8     7     1 -0.311   0.0373 
##  9     8     1 -1.11   -0.995  
## 10     9     1  0.562   0.310  
## 11    10     1 -0.0225 -0.0281
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \texttt{M} is the data frame such that a row contains the price \(\xi_{jt}\), marginal cost \(c_{jt}\), and price \(p_{jt}\). After generating the variables, drop \texttt{1\ -\ prop\_jt} products from each market using \texttt{dplyr::sample\_frac} function. The variation in the available products is important for the identification of the distribution of consumer-level unobserved heterogeneity. Add the row of the outside option to each market whose index is \(0\) and all the variables take value zero.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make market{-}product data}
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{J, }
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{xi =} \DecValTok{0}\NormalTok{,}
    \AttributeTok{c =} \FunctionTok{exp}\NormalTok{(sd\_c }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J}\SpecialCharTok{*}\NormalTok{T)),}
    \AttributeTok{p =} \FunctionTok{exp}\NormalTok{(price\_xi }\SpecialCharTok{*}\NormalTok{ xi }\SpecialCharTok{+}\NormalTok{ sd\_p }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J}\SpecialCharTok{*}\NormalTok{T)) }\SpecialCharTok{+}\NormalTok{ c}
\NormalTok{  ) }
\NormalTok{M }\OtherTok{\textless{}{-}} 
\NormalTok{  M }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{group\_by}\NormalTok{(t) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{sample\_frac}\NormalTok{(prop\_jt) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{ungroup}\NormalTok{()}
\CommentTok{\# add outside option}
\NormalTok{outside }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{j =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{xi =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{c =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{p =} \DecValTok{0}
\NormalTok{    )}
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
\NormalTok{    M,}
\NormalTok{    outside}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{arrange}\NormalTok{(}
\NormalTok{    t, }
\NormalTok{    j}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 700 x 5
##        j     t    xi     c     p
##    <dbl> <int> <dbl> <dbl> <dbl>
##  1     0     1     0 0      0   
##  2     2     1     0 0.929  1.97
##  3     3     1     0 0.976  1.91
##  4     4     1     0 1.02   2.05
##  5     6     1     0 0.995  1.98
##  6     7     1     0 1.02   1.98
##  7     8     1     0 0.997  1.99
##  8     0     2     0 0      0   
##  9     1     2     0 0.980  1.97
## 10     4     2     0 1.04   2.04
## # i 690 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Generate the consumer-level heterogeneity. \texttt{V} is the data frame such that a row contains the vector of shocks to consumer-level heterogeneity, \((\nu_{i}', \upsilon_i)\). They are all i.i.d. standard normal random variables.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make consumer{-}market data}
\NormalTok{V }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
    \FunctionTok{rnorm}\NormalTok{(N }\SpecialCharTok{*}\NormalTok{ T }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)), }
    \AttributeTok{nrow =}\NormalTok{ N }\SpecialCharTok{*}\NormalTok{ T}
\NormalTok{    ) }
\FunctionTok{colnames}\NormalTok{(V) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"v\_x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{), }\StringTok{"v\_p"}\NormalTok{)}
\NormalTok{V }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \FunctionTok{expand.grid}\NormalTok{(}
      \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N, }
      \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T}
\NormalTok{      ),}
\NormalTok{    V}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 50,000 x 6
##        i     t  v_x_1   v_x_2  v_x_3     v_p
##    <int> <int>  <dbl>   <dbl>  <dbl>   <dbl>
##  1     1     1  1.32  -0.0670 -0.758 -0.590 
##  2     2     1  0.930  1.34    1.16   0.0684
##  3     3     1  1.08   0.768  -0.725 -0.130 
##  4     4     1 -0.300  0.156  -0.641 -0.896 
##  5     5     1  1.04   1.17   -0.224  1.31  
##  6     6     1  0.709 -0.286   0.948  1.15  
##  7     7     1 -1.27   0.193  -0.212 -0.156 
##  8     8     1 -0.932 -0.780   1.49  -0.362 
##  9     9     1  1.37  -0.205   0.594 -0.998 
## 10    10     1 -0.461 -0.834   0.221 -1.62  
## # i 49,990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Join \texttt{X}, \texttt{M}, \texttt{V} using \texttt{dplyr::left\_join} and name it \texttt{df}. \texttt{df} is the data frame such that a row contains variables for a consumer about a product that is available in a market.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make choice data}
\NormalTok{df }\OtherTok{\textless{}{-}} 
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N, }
    \AttributeTok{j =} \DecValTok{0}\SpecialCharTok{:}\NormalTok{J}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{    V, }
    \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"t"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{    X, }
    \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"j"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{    M, }
    \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"j"}\NormalTok{, }\StringTok{"t"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(p)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{arrange}\NormalTok{(}
\NormalTok{    t, }
\NormalTok{    i, }
\NormalTok{    j}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 350,000 x 13
##        t     i     j v_x_1   v_x_2  v_x_3     v_p   x_1    x_2     x_3    xi
##    <int> <int> <dbl> <dbl>   <dbl>  <dbl>   <dbl> <dbl>  <dbl>   <dbl> <dbl>
##  1     1     1     0 1.32  -0.0670 -0.758 -0.590      0  0      0          0
##  2     1     1     2 1.32  -0.0670 -0.758 -0.590      1  0.369  0.472      0
##  3     1     1     3 1.32  -0.0670 -0.758 -0.590      1  0.288  0.411      0
##  4     1     1     4 1.32  -0.0670 -0.758 -0.590      1 -0.153  0.297      0
##  5     1     1     6 1.32  -0.0670 -0.758 -0.590      1  0.195  0.391      0
##  6     1     1     7 1.32  -0.0670 -0.758 -0.590      1 -0.311  0.0373     0
##  7     1     1     8 1.32  -0.0670 -0.758 -0.590      1 -1.11  -0.995      0
##  8     1     2     0 0.930  1.34    1.16   0.0684     0  0      0          0
##  9     1     2     2 0.930  1.34    1.16   0.0684     1  0.369  0.472      0
## 10     1     2     3 0.930  1.34    1.16   0.0684     1  0.288  0.411      0
## # i 349,990 more rows
## # i 2 more variables: c <dbl>, p <dbl>
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Draw a vector of preference shocks \texttt{e} whose length is the same as the number of rows of \texttt{df}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# draw idiosyncratic shocks}
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ evd}\SpecialCharTok{::}\FunctionTok{rgev}\NormalTok{(}\FunctionTok{dim}\NormalTok{(df)[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  0.32969177 -1.03771238  1.41496338  5.02048718 -0.01302806  0.57956001
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function \texttt{compute\_indirect\_utility(df,\ beta,\ sigma,\ mu,\ omega)} that returns a vector whose element is the mean indirect utility of a product for a consumer in a market. The output should have the same length with \(e\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute indirect utility}
\NormalTok{u }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_indirect\_utility}\NormalTok{(}
\NormalTok{    df, }
\NormalTok{    beta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(u)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             u
## [1,] 0.000000
## [2,] 3.681882
## [3,] 3.807728
## [4,] 3.779036
## [5,] 3.764454
## [6,] 4.193113
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Write a function \texttt{compute\_choice(X,\ M,\ V,\ e,\ beta,\ sigma,\ mu,\ omega)} that first construct \texttt{df} from \texttt{X}, \texttt{M}, \texttt{V}, second call \texttt{compute\_indirect\_utility} to obtain the vector of mean indirect utilities \texttt{u}, third compute the choice vector \texttt{q} based on the vector of mean indirect utilities and \texttt{e}, and finally return the data frame to which \texttt{u} and \texttt{q} are added as columns.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute choice}
\NormalTok{df\_choice }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_choice}\NormalTok{(}
\NormalTok{    X, }
\NormalTok{    M, }
\NormalTok{    V, }
\NormalTok{    e, }
\NormalTok{    beta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    )}
\NormalTok{df\_choice}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 350,000 x 16
##        t     i     j v_x_1   v_x_2  v_x_3     v_p   x_1    x_2     x_3    xi
##    <int> <int> <dbl> <dbl>   <dbl>  <dbl>   <dbl> <dbl>  <dbl>   <dbl> <dbl>
##  1     1     1     0 1.32  -0.0670 -0.758 -0.590      0  0      0          0
##  2     1     1     2 1.32  -0.0670 -0.758 -0.590      1  0.369  0.472      0
##  3     1     1     3 1.32  -0.0670 -0.758 -0.590      1  0.288  0.411      0
##  4     1     1     4 1.32  -0.0670 -0.758 -0.590      1 -0.153  0.297      0
##  5     1     1     6 1.32  -0.0670 -0.758 -0.590      1  0.195  0.391      0
##  6     1     1     7 1.32  -0.0670 -0.758 -0.590      1 -0.311  0.0373     0
##  7     1     1     8 1.32  -0.0670 -0.758 -0.590      1 -1.11  -0.995      0
##  8     1     2     0 0.930  1.34    1.16   0.0684     0  0      0          0
##  9     1     2     2 0.930  1.34    1.16   0.0684     1  0.369  0.472      0
## 10     1     2     3 0.930  1.34    1.16   0.0684     1  0.288  0.411      0
## # i 349,990 more rows
## # i 5 more variables: c <dbl>, p <dbl>, u <dbl>, e <dbl>, q <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df\_choice)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        t                i               j              v_x_1          
##  Min.   :  1.00   Min.   :  1.0   Min.   : 0.000   Min.   :-4.302781  
##  1st Qu.: 25.75   1st Qu.:125.8   1st Qu.: 2.000   1st Qu.:-0.683141  
##  Median : 50.50   Median :250.5   Median : 5.000   Median : 0.001562  
##  Mean   : 50.50   Mean   :250.5   Mean   : 4.791   Mean   :-0.002669  
##  3rd Qu.: 75.25   3rd Qu.:375.2   3rd Qu.: 8.000   3rd Qu.: 0.669657  
##  Max.   :100.00   Max.   :500.0   Max.   :10.000   Max.   : 3.809895  
##      v_x_2               v_x_3                v_p                 x_1        
##  Min.   :-4.542122   Min.   :-3.957618   Min.   :-4.218131   Min.   :0.0000  
##  1st Qu.:-0.680086   1st Qu.:-0.673321   1st Qu.:-0.671449   1st Qu.:1.0000  
##  Median : 0.002374   Median : 0.004941   Median : 0.001083   Median :1.0000  
##  Mean   :-0.000890   Mean   : 0.003589   Mean   :-0.002011   Mean   :0.8571  
##  3rd Qu.: 0.673194   3rd Qu.: 0.676967   3rd Qu.: 0.671318   3rd Qu.:1.0000  
##  Max.   : 4.313621   Max.   : 4.244194   Max.   : 4.017246   Max.   :1.0000  
##       x_2                x_3                xi          c         
##  Min.   :-1.10735   Min.   :-0.9947   Min.   :0   Min.   :0.0000  
##  1st Qu.:-0.15269   1st Qu.: 0.0000   1st Qu.:0   1st Qu.:0.9404  
##  Median : 0.19492   Median : 0.2970   Median :0   Median :0.9841  
##  Mean   : 0.05989   Mean   : 0.1128   Mean   :0   Mean   :0.8560  
##  3rd Qu.: 0.36916   3rd Qu.: 0.3911   3rd Qu.:0   3rd Qu.:1.0260  
##  Max.   : 0.75589   Max.   : 0.4719   Max.   :0   Max.   :1.2099  
##        p               u                  e                 q         
##  Min.   :0.000   Min.   :-190.479   Min.   :-2.6364   Min.   :0.0000  
##  1st Qu.:1.913   1st Qu.:  -2.177   1st Qu.:-0.3301   1st Qu.:0.0000  
##  Median :1.981   Median :   0.000   Median : 0.3635   Median :0.0000  
##  Mean   :1.712   Mean   :  -1.291   Mean   : 0.5763   Mean   :0.1429  
##  3rd Qu.:2.039   3rd Qu.:   1.978   3rd Qu.: 1.2418   3rd Qu.:0.0000  
##  Max.   :2.293   Max.   :  10.909   Max.   :14.0966   Max.   :1.0000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Write a function \texttt{compute\_share(X,\ M,\ V,\ e,\ beta,\ sigma,\ mu,\ omega)} that first construct \texttt{df} from \texttt{X}, \texttt{M}, \texttt{V}, second call \texttt{compute\_choice} to obtain a data frame with \texttt{u} and \texttt{q}, third compute the share of each product at each market \texttt{s} and the log difference in the share from the outside option, \(\ln(s_{jt}/s_{0t})\), denoted by \texttt{y}, and finally return the data frame that is summarized at the product-market level, dropped consumer-level variables, and added \texttt{s} and \texttt{y}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute share}
\NormalTok{df\_share }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_share}\NormalTok{(}
\NormalTok{    X, }
\NormalTok{    M, }
\NormalTok{    V, }
\NormalTok{    e, }
\NormalTok{    beta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    )}
\NormalTok{df\_share}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 700 x 11
##        t     j   x_1    x_2      x_3    xi     c     p     q     s       y
##    <int> <dbl> <dbl>  <dbl>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>
##  1     1     0     0  0      0           0 0      0      144 0.288  0     
##  2     1     2     1  0.369  0.472       0 0.929  1.97    47 0.094 -1.12  
##  3     1     3     1  0.288  0.411       0 0.976  1.91    37 0.074 -1.36  
##  4     1     4     1 -0.153  0.297       0 1.02   2.05    35 0.07  -1.41  
##  5     1     6     1  0.195  0.391       0 0.995  1.98    60 0.12  -0.875 
##  6     1     7     1 -0.311  0.0373      0 1.02   1.98    44 0.088 -1.19  
##  7     1     8     1 -1.11  -0.995       0 0.997  1.99   133 0.266 -0.0795
##  8     2     0     0  0      0           0 0      0      170 0.34   0     
##  9     2     1     1  0.244 -0.00810     0 0.980  1.97    84 0.168 -0.705 
## 10     2     4     1 -0.153  0.297       0 1.04   2.04    35 0.07  -1.58  
## # i 690 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df\_share)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        t                j               x_1              x_2          
##  Min.   :  1.00   Min.   : 0.000   Min.   :0.0000   Min.   :-1.10735  
##  1st Qu.: 25.75   1st Qu.: 2.000   1st Qu.:1.0000   1st Qu.:-0.15269  
##  Median : 50.50   Median : 5.000   Median :1.0000   Median : 0.19492  
##  Mean   : 50.50   Mean   : 4.791   Mean   :0.8571   Mean   : 0.05989  
##  3rd Qu.: 75.25   3rd Qu.: 8.000   3rd Qu.:1.0000   3rd Qu.: 0.36916  
##  Max.   :100.00   Max.   :10.000   Max.   :1.0000   Max.   : 0.75589  
##       x_3                xi          c                p        
##  Min.   :-0.9947   Min.   :0   Min.   :0.0000   Min.   :0.000  
##  1st Qu.: 0.0000   1st Qu.:0   1st Qu.:0.9404   1st Qu.:1.913  
##  Median : 0.2970   Median :0   Median :0.9841   Median :1.981  
##  Mean   : 0.1128   Mean   :0   Mean   :0.8560   Mean   :1.712  
##  3rd Qu.: 0.3911   3rd Qu.:0   3rd Qu.:1.0260   3rd Qu.:2.039  
##  Max.   : 0.4719   Max.   :0   Max.   :1.2099   Max.   :2.293  
##        q                s                y           
##  Min.   : 26.00   Min.   :0.0520   Min.   :-1.89354  
##  1st Qu.: 43.00   1st Qu.:0.0860   1st Qu.:-1.35812  
##  Median : 52.00   Median :0.1040   Median :-1.16644  
##  Mean   : 71.43   Mean   :0.1429   Mean   :-0.99214  
##  3rd Qu.: 73.00   3rd Qu.:0.1460   3rd Qu.:-0.81801  
##  Max.   :195.00   Max.   :0.3900   Max.   : 0.05196
\end{verbatim}

\section{Estimate the parameters}\label{estimate-the-parameters-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate the parameters assuming there is no consumer-level heterogeneity, i.e., by assuming:
  \[
  \ln \frac{s_{jt}}{s_{0t}} = \beta' x_{jt} + \alpha p_{jt}.
  \]
  This can be implemented using \texttt{lm} function. Print out the estimate results.
\end{enumerate}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ -1 + x_1 + x_2 + x_3 + p, data = df_share)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.57415 -0.09781  0.00000  0.10491  0.51149 
## 
## Coefficients:
##     Estimate Std. Error t value Pr(>|t|)    
## x_1  1.20614    0.18150   6.646 6.10e-11 ***
## x_2  0.21995    0.02841   7.741 3.49e-14 ***
## x_3 -0.92818    0.03364 -27.589  < 2e-16 ***
## p   -1.12982    0.09086 -12.435  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.1677 on 696 degrees of freedom
## Multiple R-squared:  0.9778, Adjusted R-squared:  0.9777 
## F-statistic:  7678 on 4 and 696 DF,  p-value: < 2.2e-16
\end{verbatim}

We estimate the model using simulated share.

When optimizing an objective function that uses the Monte Carlo simulation, it is important to keep the realizations of the shocks the same across the evaluations of the objective function. If the realization of the shocks differ across the objective function evaluations, the optimization algorithm will not converge because it cannot distinguish the change in the value of the objective function due to the difference in the parameters and the difference in the realized shocks.

The best practice to avoid this problem is to generate the shocks outside the optimization algorithm as in the current case. If the size of the shocks can be too large to store in the memory, the second best practice is to make sure to set the seed inside the optimization algorithm so that the realized shocks are the same across function evaluations.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  For this reason, we first draw Monte Carlo consumer-level heterogeneity \texttt{V\_mcmc} and Monte Carlo preference shocks \texttt{e\_mcmc}. The number of simulations is \texttt{L}. This does not have to be the same with the actual number of consumers \texttt{N}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# mixed logit estimation}
\DocumentationTok{\#\# draw mcmc V}
\NormalTok{V\_mcmc }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
    \FunctionTok{rnorm}\NormalTok{(L }\SpecialCharTok{*}\NormalTok{ T }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)), }
    \AttributeTok{nrow =}\NormalTok{ L }\SpecialCharTok{*}\NormalTok{ T}
\NormalTok{    ) }
\FunctionTok{colnames}\NormalTok{(V\_mcmc) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"v\_x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{), }\StringTok{"v\_p"}\NormalTok{)}
\NormalTok{V\_mcmc }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \FunctionTok{expand.grid}\NormalTok{(}
      \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{L, }
      \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T}
\NormalTok{      ),}
\NormalTok{    V\_mcmc}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V\_mcmc}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 50,000 x 6
##        i     t   v_x_1  v_x_2   v_x_3    v_p
##    <int> <int>   <dbl>  <dbl>   <dbl>  <dbl>
##  1     1     1 -0.715  -0.798 -0.548   1.09 
##  2     2     1  0.0243 -0.943 -1.88    0.471
##  3     3     1 -0.183   0.660  0.669   1.45 
##  4     4     1  0.0207  3.36  -0.363   1.58 
##  5     5     1 -1.94    0.221  1.02    0.943
##  6     6     1  0.876  -0.636  0.0432  0.324
##  7     7     1  1.96   -0.195 -0.0950  1.39 
##  8     8     1  1.11    0.571  1.77    0.497
##  9     9     1  1.45    0.154  1.96    0.740
## 10    10     1 -1.00   -0.413  0.0542 -0.469
## # i 49,990 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# draw mcmc e}
\NormalTok{df\_mcmc }\OtherTok{\textless{}{-}} 
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{L, }
    \AttributeTok{j =} \DecValTok{0}\SpecialCharTok{:}\NormalTok{J}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{    V\_mcmc, }
    \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"t"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{    X, }
    \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"j"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{    M, }
    \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"j"}\NormalTok{, }\StringTok{"t"}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(p)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{arrange}\NormalTok{(}
\NormalTok{    t, }
\NormalTok{    i, }
\NormalTok{    j}
\NormalTok{    )}
\CommentTok{\# draw idiosyncratic shocks}
\NormalTok{e\_mcmc }\OtherTok{\textless{}{-}}\NormalTok{ evd}\SpecialCharTok{::}\FunctionTok{rgev}\NormalTok{(}\FunctionTok{dim}\NormalTok{(df\_mcmc)[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(e\_mcmc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  0.265602821  0.652183731 -0.006127627 -0.317288366  3.145022297
## [6] -1.277026910
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use \texttt{compute\_share} to check the simulated share at the true parameter using the Monte Carlo shocks. Remember that the number of consumers should be set at \texttt{L} instead of \texttt{N}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_share\_mcmc}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 700 x 11
##        t     j   x_1    x_2      x_3    xi     c     p     q     s      y
##    <int> <dbl> <dbl>  <dbl>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>
##  1     1     0     0  0      0           0 0      0      171 0.342  0    
##  2     1     2     1  0.369  0.472       0 0.929  1.97    46 0.092 -1.31 
##  3     1     3     1  0.288  0.411       0 0.976  1.91    37 0.074 -1.53 
##  4     1     4     1 -0.153  0.297       0 1.02   2.05    38 0.076 -1.50 
##  5     1     6     1  0.195  0.391       0 0.995  1.98    38 0.076 -1.50 
##  6     1     7     1 -0.311  0.0373      0 1.02   1.98    52 0.104 -1.19 
##  7     1     8     1 -1.11  -0.995       0 0.997  1.99   118 0.236 -0.371
##  8     2     0     0  0      0           0 0      0      194 0.388  0    
##  9     2     1     1  0.244 -0.00810     0 0.980  1.97    62 0.124 -1.14 
## 10     2     4     1 -0.153  0.297       0 1.04   2.04    37 0.074 -1.66 
## # i 690 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Vectorize the parameters to a vector \texttt{theta} because \texttt{optim} requires the maximiand to be a vector.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set parameters}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    beta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    )}
\NormalTok{theta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  4.0000000  0.1836433 -0.8356286  1.5952808  0.3295078  0.8204684  0.5000000
## [8]  1.0000000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write a function \texttt{compute\_nlls\_objective\_a3(theta,\ df\_share,\ X,\ M,\ V\_mcmc,\ e\_mcmc)} that first computes the simulated share and then compute the mean-squared error between the share data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nlls\_objective}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0004815657
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Draw a graph of the objective function that varies each parameter from 0.5, 0.6, \(\cdots\), 1.5 of the true value. First try with the actual shocks \texttt{V} and \texttt{e} and then try with the Monte Carlo shocks \texttt{V\_mcmc} and \texttt{e\_mcmc}. You will some of the graph does not look good with the Monte Carlo shocks. It will cause the approximation error.
\end{enumerate}

Because this takes time, you may want to parallelize the computation using \texttt{\%dopar} functionality of \texttt{foreach} loop. To do so, first install \texttt{doParallel} package and then load it and register the workers as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{registerDoParallel}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This automatically detect the number of cores available at your computer and registers them as the workers. Then, you only have to change \texttt{\%do\%} to \texttt{\%dopar} in the \texttt{foreach} loop as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{foreach}\NormalTok{ (}
  \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}
\NormalTok{  ) }\SpecialCharTok{\%dopar\%}\NormalTok{ \{}
    \CommentTok{\# this part is parallelized}
\NormalTok{    y }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ i}
    \FunctionTok{return}\NormalTok{(y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] 2
## 
## [[2]]
## [1] 4
## 
## [[3]]
## [1] 6
## 
## [[4]]
## [1] 8
\end{verbatim}

In windows, you may have to explicitly pass packages, functions, and data to the worker by using \texttt{.export} and \texttt{.packages} options as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp\_func }\OtherTok{\textless{}{-}} 
  \ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    y }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ x}
    \FunctionTok{return}\NormalTok{(y)}
\NormalTok{\}}
\FunctionTok{foreach}\NormalTok{ (}
  \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, }
  \AttributeTok{.export =} \StringTok{"temp\_func"}\NormalTok{,}
  \AttributeTok{.packages =} \StringTok{"magrittr"}
\NormalTok{  ) }\SpecialCharTok{\%dopar\%}\NormalTok{ \{}
    \CommentTok{\# this part is parallelized}
\NormalTok{    y }\OtherTok{\textless{}{-}} \FunctionTok{temp\_func}\NormalTok{(i)}
    \FunctionTok{return}\NormalTok{(y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in e$fun(obj, substitute(ex), parent.frame(), e$data): already
## exporting variable(s): temp_func
\end{verbatim}

\begin{verbatim}
## [[1]]
## [1] 2
## 
## [[2]]
## [1] 4
## 
## [[3]]
## [1] 6
## 
## [[4]]
## [1] 8
\end{verbatim}

If you have called a function in a package in this way \texttt{dplyr::mutate}, then you will not have to pass \texttt{dplyr} by \texttt{.packages} option. This is one of the reasons why I prefer to explicitly call the package every time I call a function. If you have compiled your functions in a package, you will just have to pass the package as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# this function is compiled in the package EmpiricalIO}
\CommentTok{\# temp\_func \textless{}{-} function(x) \{}
\CommentTok{\#   y \textless{}{-} 2 * x}
\CommentTok{\#   return(y)}
\CommentTok{\# \}}
\FunctionTok{foreach}\NormalTok{ (}
  \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, }
  \AttributeTok{.packages =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"EmpiricalIO"}\NormalTok{,}
    \StringTok{"magrittr"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%dopar\%}\NormalTok{ \{}
    \CommentTok{\# this part is parallelized}
\NormalTok{    y }\OtherTok{\textless{}{-}} \FunctionTok{temp\_func}\NormalTok{(i)}
    \FunctionTok{return}\NormalTok{(y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] 2
## 
## [[2]]
## [1] 4
## 
## [[3]]
## [1] 6
## 
## [[4]]
## [1] 8
\end{verbatim}

The graphs with the true shocks:

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-76-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-76-2} \end{center}

\begin{verbatim}
## 
## [[3]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-76-3} \end{center}

\begin{verbatim}
## 
## [[4]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-76-4} \end{center}

\begin{verbatim}
## 
## [[5]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-76-5} \end{center}

\begin{verbatim}
## 
## [[6]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-76-6} \end{center}

\begin{verbatim}
## 
## [[7]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-76-7} \end{center}

\begin{verbatim}
## 
## [[8]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-76-8} \end{center}

The graphs with the Monte Carlo shocks:

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-78-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-78-2} \end{center}

\begin{verbatim}
## 
## [[3]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-78-3} \end{center}

\begin{verbatim}
## 
## [[4]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-78-4} \end{center}

\begin{verbatim}
## 
## [[5]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-78-5} \end{center}

\begin{verbatim}
## 
## [[6]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-78-6} \end{center}

\begin{verbatim}
## 
## [[7]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-78-7} \end{center}

\begin{verbatim}
## 
## [[8]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-78-8} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Use \texttt{optim} to find the minimizer of the objective function using \texttt{Nelder-Mead} method. You can start from the true parameter values. Compare the estimates with the true parameters.
\end{enumerate}

\begin{verbatim}
## $par
## [1]  3.9907237  0.1778582 -0.8244977  1.5326774  0.3602383  0.9336009  0.4883030
## [8]  1.0462494
## 
## $value
## [1] 0.0004678286
## 
## $counts
## function gradient 
##      237       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
\end{verbatim}

\begin{verbatim}
##         true  estimates
## 1  4.0000000  3.9907237
## 2  0.1836433  0.1778582
## 3 -0.8356286 -0.8244977
## 4  1.5952808  1.5326774
## 5  0.3295078  0.3602383
## 6  0.8204684  0.9336009
## 7  0.5000000  0.4883030
## 8  1.0000000  1.0462494
\end{verbatim}

\chapter{Assignment 4: Demand Function Estimation II}\label{assignment4}

\section{Simulate data}\label{simulate-data-3}

\textbf{Be carefull that some parameters are changed from assignment 3}. We simulate data from a discrete choice model that is the same with in assignment 3 except for the existence of unobserved product-specific fixed effects. There are \(T\) markets and each market has \(N\) consumers. There are \(J\) products and the indirect utility of consumer \(i\) in market \(t\) for product \(j\) is:
\[
u_{itj} = \beta_{it}' x_j + \alpha_{it} p_{jt} + \xi_{jt} + \epsilon_{ijt},
\]
where \(\epsilon_{ijt}\) is an i.i.d. type-I extreme random variable. \(x_j\) is \(K\)-dimensional observed characteristics of the product. \(p_{jt}\) is the retail price of the product in the market.

\(\xi_{jt}\) is product-market specific fixed effect. \(p_{jt}\) can be correlated with \(\xi_{jt}\) but \(x_{jt}\)s are independent of \(\xi_{jt}\). \(j = 0\) is an outside option whose indirect utility is:
\[
u_{it0} = \epsilon_{i0t},
\]
where \(\epsilon_{i0t}\) is an i.i.d. type-I extreme random variable.

\(\beta_{it}\) and \(\alpha_{it}\) are different across consumers, and they are distributed as:
\[
\beta_{itk} = \beta_{0k} + \sigma_k \nu_{itk},
\]
\[
\alpha_{it} = - \exp(\mu + \omega \upsilon_{it}) = - \exp(\mu + \frac{\omega^2}{2}) + [- \exp(\mu + \omega \upsilon_{it}) + \exp(\mu + \frac{\omega^2}{2})] \equiv \alpha_0 + \tilde{\alpha}_{it},
\]
where \(\nu_{itk}\) for \(k = 1, \cdots, K\) and \(\upsilon_{it}\) are i.i.d. standard normal random variables. \(\alpha_0\) is the mean of \(\alpha_i\) and \(\tilde{\alpha}_i\) is the deviation from the mean.

Given a choice set in the market, \(\mathcal{J}_t \cup \{0\}\), a consumer chooses the alternative that maximizes her utility:
\[
q_{ijt} = 1\{u_{ijt} = \max_{k \in \mathcal{J}_t \cup \{0\}} u_{ikt}\}.
\]
The choice probability of product \(j\) for consumer \(i\) in market \(t\) is:
\[
\sigma_{jt}(p_t, x_t, \xi_t) = \mathbb{P}\{u_{ijt} = \max_{k \in \mathcal{J}_t \cup \{0\}} u_{ikt}\}.
\]

Suppose that we only observe the share data:
\[
s_{jt} = \frac{1}{N} \sum_{i = 1}^N q_{ijt},
\]
along with the product-market characteristics \(x_{jt}\) and the retail prices \(p_{jt}\) for \(j \in \mathcal{J}_t \cup \{0\}\) for \(t = 1, \cdots, T\). We do not observe the choice data \(q_{ijt}\) nor shocks \(\xi_{jt}, \nu_{it}, \upsilon_{it}, \epsilon_{ijt}\).

We draw \(\xi_{jt}\) from i.i.d. normal distribution with mean 0 and standard deviation \(\sigma_{\xi}\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set the seed, constants, and parameters of interest as follows.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set the seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# number of products}
\NormalTok{J }\OtherTok{\textless{}{-}} \DecValTok{10}
\CommentTok{\# dimension of product characteristics including the intercept}
\NormalTok{K }\OtherTok{\textless{}{-}} \DecValTok{3}
\CommentTok{\# number of markets}
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{100}
\CommentTok{\# number of consumers per market}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{500}
\CommentTok{\# number of Monte Carlo}
\NormalTok{L }\OtherTok{\textless{}{-}} \DecValTok{500}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set parameters of interests}
\NormalTok{beta }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(K); }
\NormalTok{beta[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{beta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  4.0000000  0.1836433 -0.8356286
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(K)); sigma}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.5952808 0.3295078 0.8204684
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{omega }\OtherTok{\textless{}{-}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

Generate the covariates as follows.

The product-market characteristics:
\[
x_{j1} = 1, x_{jk} \sim N(0, \sigma_x), k = 2, \cdots, K,
\]
where \(\sigma_x\) is referred to as \texttt{sd\_x} in the code.

The product-market-specific unobserved fixed effect:
\[
\xi_{jt} \sim N(0, \sigma_\xi),
\]
where \(\sigma_xi\) is referred to as \texttt{sd\_xi} in the code.

The marginal cost of product \(j\) in market \(t\):
\[
c_{jt} \sim \text{logNormal}(0, \sigma_c),
\]
where \(\sigma_c\) is referred to as \texttt{sd\_c} in the code.

The retail price:
\[
p_{jt} - c_{jt} \sim \text{logNorm}(\gamma \xi_{jt}, \sigma_p^2),
\]
where \(\gamma\) is referred to as \texttt{price\_xi} and \(\sigma_p\) as \texttt{sd\_p} in the code. This price is not the equilibrium price. We will revisit this point in a subsequent assignment.

The value of the auxiliary parameters are set as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set auxiliary parameters}
\NormalTok{price\_xi }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sd\_x }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{sd\_xi }\OtherTok{\textless{}{-}} \FloatTok{0.1}
\NormalTok{sd\_c }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{sd\_p }\OtherTok{\textless{}{-}} \FloatTok{0.01}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \texttt{X} is the data frame such that a row contains the characteristics vector \(x_{j}\) of a product and columns are product index and observed product characteristics. The dimension of the characteristics \(K\) is specified above. Add the row of the outside option whose index is \(0\) and all the characteristics are zero.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make product characteristics data}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
\NormalTok{    sd\_x }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)), }
    \AttributeTok{nrow =}\NormalTok{ J}
\NormalTok{    )}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{cbind}\NormalTok{(}
    \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, J), }
\NormalTok{    X}
\NormalTok{    )}
\FunctionTok{colnames}\NormalTok{(X) }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{)}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{J, X) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{()}
\CommentTok{\# add outside option}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
    \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{dim}\NormalTok{(X)[}\DecValTok{2}\NormalTok{]),}
\NormalTok{    X}
\NormalTok{    ) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 11 x 4
##        j   x_1     x_2     x_3
##    <dbl> <dbl>   <dbl>   <dbl>
##  1     0     0  0       0     
##  2     1     1  0.975  -0.0324
##  3     2     1  1.48    1.89  
##  4     3     1  1.15    1.64  
##  5     4     1 -0.611   1.19  
##  6     5     1  3.02    1.84  
##  7     6     1  0.780   1.56  
##  8     7     1 -1.24    0.149 
##  9     8     1 -4.43   -3.98  
## 10     9     1  2.25    1.24  
## 11    10     1 -0.0899 -0.112
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \texttt{M} is the data frame such that a row contains the price \(\xi_{jt}\), marginal cost \(c_{jt}\), and price \(p_{jt}\). After generating the variables, drop some products in each market. \textbf{In this assignment, we drop products in a different way from the last assignment}. In order to change the number of available products in each market, for each market, first draw \(J_t\) from a discrete uniform distribution between \(1\) and \(J\). Then, drop products from each market using \texttt{dplyr::sample\_frac} function with the realized number of available products. The variation in the available products is important for the identification of the distribution of consumer-level unobserved heterogeneity. Add the row of the outside option to each market whose index is \(0\) and all the variables take value zero.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make market{-}product data}
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{J, }
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}
      \AttributeTok{xi =}\NormalTok{ sd\_xi }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J }\SpecialCharTok{*}\NormalTok{ T),}
      \AttributeTok{c =} \FunctionTok{exp}\NormalTok{(sd\_c }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J }\SpecialCharTok{*}\NormalTok{ T)),}
      \AttributeTok{p =} \FunctionTok{exp}\NormalTok{(price\_xi }\SpecialCharTok{*}\NormalTok{ xi }\SpecialCharTok{+}\NormalTok{ sd\_p }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J }\SpecialCharTok{*}\NormalTok{ T)) }\SpecialCharTok{+}\NormalTok{ c}
\NormalTok{    ) }
\NormalTok{M }\OtherTok{\textless{}{-}} 
\NormalTok{  M }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{group\_by}\NormalTok{(t) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{sample\_frac}\NormalTok{(}\AttributeTok{size =}\NormalTok{ purrr}\SpecialCharTok{::}\FunctionTok{rdunif}\NormalTok{(}\DecValTok{1}\NormalTok{, J) }\SpecialCharTok{/}\NormalTok{ J) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{ungroup}\NormalTok{()}
\CommentTok{\# add outside option}
\NormalTok{outside }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{j =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{xi =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{c =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{p =} \DecValTok{0}
\NormalTok{    )}
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
\NormalTok{    M,}
\NormalTok{    outside}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{arrange}\NormalTok{(}
\NormalTok{    t, }
\NormalTok{    j}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 633 x 5
##        j     t      xi     c     p
##    <dbl> <int>   <dbl> <dbl> <dbl>
##  1     0     1  0      0      0   
##  2     1     1 -0.0156 0.604  1.58
##  3     4     1  0.0418 1.30   2.35
##  4     0     2  0      0      0   
##  5     1     2 -0.0394 0.890  1.87
##  6     3     2  0.110  2.29   3.40
##  7     4     2  0.0763 0.997  2.09
##  8     6     2 -0.0253 1.15   2.13
##  9     7     2  0.0697 0.613  1.68
## 10     8     2  0.0557 0.629  1.67
## # i 623 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Generate the consumer-level heterogeneity. \texttt{V} is the data frame such that a row contains the vector of shocks to consumer-level heterogeneity, \((\nu_{i}', \upsilon_i)\). They are all i.i.d. standard normal random variables.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make consumer{-}market data}
\NormalTok{V }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
    \FunctionTok{rnorm}\NormalTok{(N }\SpecialCharTok{*}\NormalTok{ T }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)), }
    \AttributeTok{nrow =}\NormalTok{ N }\SpecialCharTok{*}\NormalTok{ T}
\NormalTok{    ) }
\FunctionTok{colnames}\NormalTok{(V) }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \FunctionTok{paste}\NormalTok{(}\StringTok{"v\_x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{), }
    \StringTok{"v\_p"}
\NormalTok{    )}
\NormalTok{V }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \FunctionTok{expand.grid}\NormalTok{(}
      \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N, }
      \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T}
\NormalTok{      ),}
\NormalTok{    V}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 50,000 x 6
##        i     t  v_x_1   v_x_2  v_x_3     v_p
##    <int> <int>  <dbl>   <dbl>  <dbl>   <dbl>
##  1     1     1 -1.37   0.211   1.65   0.0141
##  2     2     1  1.37   0.378   1.35   0.387 
##  3     3     1 -2.06  -0.0662 -2.45  -1.17  
##  4     4     1 -0.992 -0.727  -1.33  -1.42  
##  5     5     1  0.252  1.87    0.751  0.317 
##  6     6     1 -1.06  -0.531   1.34  -0.224 
##  7     7     1 -0.217  1.03    0.909 -0.593 
##  8     8     1 -0.838 -0.861  -0.612  1.54  
##  9     9     1  0.659 -1.43   -1.77   0.340 
## 10    10     1  0.452 -0.239   0.138  0.695 
## # i 49,990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Join \texttt{X}, \texttt{M}, \texttt{V} using \texttt{dplyr::left\_join} and name it \texttt{df}. \texttt{df} is the data frame such that a row contains variables for a consumer about a product that is available in a market.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make choice data}
\NormalTok{df }\OtherTok{\textless{}{-}} 
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N, }
    \AttributeTok{j =} \DecValTok{0}\SpecialCharTok{:}\NormalTok{J}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{      V, }
      \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"t"}\NormalTok{)}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{      X, }
      \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"j"}\NormalTok{)}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{      M, }
      \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"j"}\NormalTok{, }\StringTok{"t"}\NormalTok{)}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(p)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{arrange}\NormalTok{(}
\NormalTok{      t, }
\NormalTok{      i, }
\NormalTok{      j}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 316,500 x 13
##        t     i     j  v_x_1   v_x_2 v_x_3     v_p   x_1    x_2     x_3      xi
##    <int> <int> <dbl>  <dbl>   <dbl> <dbl>   <dbl> <dbl>  <dbl>   <dbl>   <dbl>
##  1     1     1     0 -1.37   0.211   1.65  0.0141     0  0      0       0     
##  2     1     1     1 -1.37   0.211   1.65  0.0141     1  0.975 -0.0324 -0.0156
##  3     1     1     4 -1.37   0.211   1.65  0.0141     1 -0.611  1.19    0.0418
##  4     1     2     0  1.37   0.378   1.35  0.387      0  0      0       0     
##  5     1     2     1  1.37   0.378   1.35  0.387      1  0.975 -0.0324 -0.0156
##  6     1     2     4  1.37   0.378   1.35  0.387      1 -0.611  1.19    0.0418
##  7     1     3     0 -2.06  -0.0662 -2.45 -1.17       0  0      0       0     
##  8     1     3     1 -2.06  -0.0662 -2.45 -1.17       1  0.975 -0.0324 -0.0156
##  9     1     3     4 -2.06  -0.0662 -2.45 -1.17       1 -0.611  1.19    0.0418
## 10     1     4     0 -0.992 -0.727  -1.33 -1.42       0  0      0       0     
## # i 316,490 more rows
## # i 2 more variables: c <dbl>, p <dbl>
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Draw a vector of preference shocks \texttt{e} whose length is the same as the number of rows of \texttt{df}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# draw idiosyncratic shocks}
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ evd}\SpecialCharTok{::}\FunctionTok{rgev}\NormalTok{(}\FunctionTok{dim}\NormalTok{(df)[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  0.1917775 -0.3312816  0.2428217  1.0164097  1.4761643  2.8297340
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function \texttt{compute\_indirect\_utility(df,\ beta,\ sigma,\ mu,\ omega)} that returns a vector whose element is the mean indirect utility of a product for a consumer in a market. The output should have the same length with \(e\). (This function is the same with assignment 3. You can use the function.)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute indirect utility}
\NormalTok{u }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_indirect\_utility}\NormalTok{(}
    \AttributeTok{df =}\NormalTok{ df, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(u)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               u
## [1,]  0.0000000
## [2,] -0.6238974
## [3,] -1.6225075
## [4,]  0.0000000
## [5,]  2.6171184
## [6,]  0.6490776
\end{verbatim}

In the previous assingment, we computed predicted share by simulating choice and taking their average. Instead, we compute the actual share by:
\[
s_{jt} = \frac{1}{N} \sum_{i = 1}^N \frac{\exp[\beta_{it}' x_j + \alpha_{it} p_{jt} + \xi_{jt}]}{1 + \sum_{k \in \mathcal{J}_t} \exp[\beta_{it}' x_k + \alpha_{it} p_{kt} + \xi_{jt}]}
\]
and the predicted share by:
\[
\widehat{\sigma}_{j}(x, p_t, \xi_t) = \frac{1}{L} \sum_{l = 1}^L \frac{\exp[\beta_{t}^{(l)\prime} x_j + \alpha_{t}^{(l)} p_{jt} + \xi_{jt}]}{1 + \sum_{k \in \mathcal{J}_t} \exp[\beta_{t}^{(l)\prime} x_k + \alpha_{t}^{(l)} p_{kt} + \xi_{jt}]}.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  To do so, write a function \texttt{compute\_choice\_smooth(X,\ M,\ V,\ beta,\ sigma,\ mu,\ omega)} in which the choice of each consumer is not:
  \[
  q_{ijt} = 1\{u_{ijt} = \max_{k \in \mathcal{J}_t \cup \{0\}} u_{ikt}\},
  \]
  but
  \[
  \tilde{q}_{ijt} = \frac{\exp(\bar{u}_{ijt})}{1 + \sum_{k \in \mathcal{J}_t} \exp(\bar{u}_{ikt})},
  \]
  where \(\bar{u}_{ijt} = \beta_{it}' x_j + \alpha_{it} p_{jt} + \xi_{jt}\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_choice\_smooth }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_choice\_smooth}\NormalTok{(}
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(df\_choice\_smooth)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        t                i               j             v_x_1          
##  Min.   :  1.00   Min.   :  1.0   Min.   : 0.00   Min.   :-4.302781  
##  1st Qu.: 23.00   1st Qu.:125.8   1st Qu.: 2.00   1st Qu.:-0.685539  
##  Median : 48.00   Median :250.5   Median : 4.00   Median : 0.001041  
##  Mean   : 49.67   Mean   :250.5   Mean   : 4.49   Mean   :-0.002541  
##  3rd Qu.: 77.00   3rd Qu.:375.2   3rd Qu.: 7.00   3rd Qu.: 0.673061  
##  Max.   :100.00   Max.   :500.0   Max.   :10.00   Max.   : 3.809895  
##      v_x_2               v_x_3                v_p                 x_1       
##  Min.   :-4.542122   Min.   :-3.957618   Min.   :-4.218131   Min.   :0.000  
##  1st Qu.:-0.679702   1st Qu.:-0.672701   1st Qu.:-0.669446   1st Qu.:1.000  
##  Median : 0.000935   Median : 0.003104   Median : 0.001976   Median :1.000  
##  Mean   : 0.000478   Mean   : 0.003428   Mean   : 0.000017   Mean   :0.842  
##  3rd Qu.: 0.673109   3rd Qu.: 0.678344   3rd Qu.: 0.670699   3rd Qu.:1.000  
##  Max.   : 4.313621   Max.   : 4.244194   Max.   : 4.074300   Max.   :1.000  
##       x_2               x_3                xi                   c         
##  Min.   :-4.4294   Min.   :-3.9787   Min.   :-0.2996949   Min.   :0.0000  
##  1st Qu.:-0.6108   1st Qu.: 0.0000   1st Qu.:-0.0527368   1st Qu.:0.5250  
##  Median : 0.7797   Median : 1.1878   Median : 0.0000000   Median :0.8775  
##  Mean   : 0.3015   Mean   : 0.5034   Mean   :-0.0005149   Mean   :0.9507  
##  3rd Qu.: 1.4766   3rd Qu.: 1.6424   3rd Qu.: 0.0556663   3rd Qu.:1.3203  
##  Max.   : 3.0236   Max.   : 1.8877   Max.   : 0.3810277   Max.   :4.3043  
##        p               u                  q           
##  Min.   :0.000   Min.   :-345.287   Min.   :0.000000  
##  1st Qu.:1.516   1st Qu.:  -3.030   1st Qu.:0.001435  
##  Median :1.916   Median :   0.000   Median :0.030121  
##  Mean   :1.797   Mean   :  -1.869   Mean   :0.157978  
##  3rd Qu.:2.336   3rd Qu.:   1.559   3rd Qu.:0.161379  
##  Max.   :5.513   Max.   :  22.434   Max.   :1.000000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Next, write a function \texttt{compute\_share\_smooth(X,\ M,\ V,\ beta,\ sigma,\ mu,\ omega)} that calls \texttt{compute\_choice\_smooth} and then returns the share based on above \(\tilde{q}_{ijt}\). If we use these functions with the Monte Carlo shocks, it gives us the predicted share of the products.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_share\_smooth }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_share\_smooth}\NormalTok{(}
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(df\_share\_smooth)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        t                j              x_1             x_2         
##  Min.   :  1.00   Min.   : 0.00   Min.   :0.000   Min.   :-4.4294  
##  1st Qu.: 23.00   1st Qu.: 2.00   1st Qu.:1.000   1st Qu.:-0.6108  
##  Median : 48.00   Median : 4.00   Median :1.000   Median : 0.7797  
##  Mean   : 49.67   Mean   : 4.49   Mean   :0.842   Mean   : 0.3015  
##  3rd Qu.: 77.00   3rd Qu.: 7.00   3rd Qu.:1.000   3rd Qu.: 1.4766  
##  Max.   :100.00   Max.   :10.00   Max.   :1.000   Max.   : 3.0236  
##       x_3                xi                   c                p        
##  Min.   :-3.9787   Min.   :-0.2996949   Min.   :0.0000   Min.   :0.000  
##  1st Qu.: 0.0000   1st Qu.:-0.0527368   1st Qu.:0.5250   1st Qu.:1.516  
##  Median : 1.1878   Median : 0.0000000   Median :0.8775   Median :1.916  
##  Mean   : 0.5034   Mean   :-0.0005149   Mean   :0.9507   Mean   :1.797  
##  3rd Qu.: 1.6424   3rd Qu.: 0.0556663   3rd Qu.:1.3203   3rd Qu.:2.336  
##  Max.   : 1.8877   Max.   : 0.3810277   Max.   :4.3043   Max.   :5.513  
##        q                 s                  y           
##  Min.   :  1.748   Min.   :0.003497   Min.   :-4.23971  
##  1st Qu.: 17.982   1st Qu.:0.035964   1st Qu.:-1.95098  
##  Median : 40.241   Median :0.080483   Median :-1.22808  
##  Mean   : 78.989   Mean   :0.157978   Mean   :-1.15979  
##  3rd Qu.:123.006   3rd Qu.:0.246011   3rd Qu.:-0.03626  
##  Max.   :325.631   Max.   :0.651262   Max.   : 1.26578
\end{verbatim}

Use this \texttt{df\_share\_smooth} as the data to estimate the parameters in the following section.

\section{Estimate the parameters}\label{estimate-the-parameters-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  First draw Monte Carlo consumer-level heterogeneity \texttt{V\_mcmc} and Monte Carlo preference shocks \texttt{e\_mcmc}. The number of simulations is \texttt{L}. This does not have to be the same with the actual number of consumers \texttt{N}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# mixed logit estimation}
\DocumentationTok{\#\# draw mcmc V}
\NormalTok{V\_mcmc }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
    \FunctionTok{rnorm}\NormalTok{(L }\SpecialCharTok{*}\NormalTok{ T }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)), }
    \AttributeTok{nrow =}\NormalTok{ L }\SpecialCharTok{*}\NormalTok{ T}
\NormalTok{    ) }
\FunctionTok{colnames}\NormalTok{(V\_mcmc) }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \FunctionTok{paste}\NormalTok{(}\StringTok{"v\_x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{), }
    \StringTok{"v\_p"}
\NormalTok{    )}
\NormalTok{V\_mcmc }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{L, }
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T}
\NormalTok{    ),}
\NormalTok{  V\_mcmc}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V\_mcmc}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 50,000 x 6
##        i     t   v_x_1  v_x_2   v_x_3    v_p
##    <int> <int>   <dbl>  <dbl>   <dbl>  <dbl>
##  1     1     1  0.488  -1.51   0.528  -0.468
##  2     2     1  1.16    0.507 -0.527  -0.516
##  3     3     1 -2.49   -0.318 -0.0996 -0.893
##  4     4     1  0.0952 -0.133 -2.05    1.92 
##  5     5     1 -1.11    0.103  2.24    0.753
##  6     6     1  0.903   0.496  0.287   1.53 
##  7     7     1  0.913  -0.144  0.129  -1.17 
##  8     8     1 -1.52    0.357 -0.475  -0.736
##  9     9     1  0.643   0.219  0.815  -1.27 
## 10    10     1 -0.358   0.272 -0.650  -2.09 
## # i 49,990 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# draw mcmc e}
\NormalTok{df\_mcmc }\OtherTok{\textless{}{-}} 
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{L, }
    \AttributeTok{j =} \DecValTok{0}\SpecialCharTok{:}\NormalTok{J}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{      V\_mcmc, }
      \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"t"}\NormalTok{)}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{      X, }
      \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"j"}\NormalTok{)}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{      M, }
      \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"j"}\NormalTok{, }\StringTok{"t"}\NormalTok{)}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(p)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{arrange}\NormalTok{(}
\NormalTok{      t, }
\NormalTok{      i, }
\NormalTok{      j}
\NormalTok{      )}
\CommentTok{\# draw idiosyncratic shocks}
\NormalTok{e\_mcmc }\OtherTok{\textless{}{-}}\NormalTok{ evd}\SpecialCharTok{::}\FunctionTok{rgev}\NormalTok{(}\FunctionTok{dim}\NormalTok{(df\_mcmc)[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(e\_mcmc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  0.1006013  2.7039824  1.0540278  2.4697389  1.6721181 -1.0283872
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Vectorize the parameters to a vector \texttt{theta} because \texttt{optim} requires the maximiand to be a vector.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set parameters}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    beta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    )}
\NormalTok{theta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  4.0000000  0.1836433 -0.8356286  1.5952808  0.3295078  0.8204684  0.5000000
## [8]  1.0000000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Estimate the parameters assuming there is no product-specific unobserved fixed effects \(\xi_{jt}\), i.e., using the functions in assignment 3. To do so, first modify \texttt{M} to \texttt{M\_no} in which \texttt{xi} is replaced with 0 and estimate the model with \texttt{M\_no}. Otherwise, your function will compute the share with the true \texttt{xi}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M\_no }\OtherTok{\textless{}{-}} 
\NormalTok{  M }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}\AttributeTok{xi =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $par
## [1]  4.0467164  0.1707430 -0.8092369  1.8086380  0.3718435  0.7275257  0.4892642
## [8]  1.0453963
## 
## $value
## [1] 0.0003270119
## 
## $counts
## function gradient 
##      221       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
\end{verbatim}

\begin{verbatim}
##         true  estimates
## 1  4.0000000  4.0467164
## 2  0.1836433  0.1707430
## 3 -0.8356286 -0.8092369
## 4  1.5952808  1.8086380
## 5  0.3295078  0.3718435
## 6  0.8204684  0.7275257
## 7  0.5000000  0.4892642
## 8  1.0000000  1.0453963
\end{verbatim}

Next, we estimate the model allowing for the product-market-specific unobserved fixed effect \(\xi_{jt}\) using the BLP algorithm. To do so, we slightly modify the \texttt{compute\_indirect\_utility}, \texttt{compute\_choice\_smooth}, and \texttt{compute\_share\_smooth} functions so that they receive \(\delta_{jt}\) to compute the indirect utilities, choices, and shares. Be careful that the treatment of \(\alpha_i\) is slightly different from the lecture note, because we assumed that \(\alpha_i\)s are log-normal random variables.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Compute and print out \(\delta_{jt}\) at the true parameters, i.e.:
  \[
  \delta_{jt} = \beta_0' x_j + \alpha_0' p_{jt} + \xi_{jt}.
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 633 x 3
##        t     j  delta
##    <int> <dbl>  <dbl>
##  1     1     0  0    
##  2     1     1 -0.115
##  3     1     4 -3.46 
##  4     2     0  0    
##  5     2     1 -0.920
##  6     2     3 -6.29 
##  7     2     4 -2.70 
##  8     2     6 -2.97 
##  9     2     7 -0.846
## 10     2     8  2.04 
## # i 623 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Write a function \texttt{compute\_indirect\_utility\_delta(df,\ delta,\ sigma,\ mu,\ omega)} that returns a vector whose element is the mean indirect utility of a product for a consumer in a market. The output should have the same length with \(e\). Print out the output with \(\delta_{jt}\) evaluated at the true parameters. Check if the output is close to the true indirect utilities.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute indirect utility from delta}
\NormalTok{u\_delta }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_indirect\_utility\_delta}\NormalTok{(}
\NormalTok{    df, }
\NormalTok{    delta, }
\NormalTok{    sigma,}
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(u\_delta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               u
## [1,]  0.0000000
## [2,] -0.6238974
## [3,] -1.6225075
## [4,]  0.0000000
## [5,]  2.6171184
## [6,]  0.6490776
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(u }\SpecialCharTok{{-}}\NormalTok{ u\_delta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        u             
##  Min.   :-5.684e-14  
##  1st Qu.:-4.441e-16  
##  Median : 0.000e+00  
##  Mean   : 1.388e-17  
##  3rd Qu.: 3.331e-16  
##  Max.   : 5.684e-14
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write a function \texttt{compute\_choice\_smooth\_delta(X,\ M,\ V,\ delta,\ sigma,\ mu,\ omega)} that first construct \texttt{df} from \texttt{X}, \texttt{M}, \texttt{V}, second call \texttt{compute\_indirect\_utility\_delta} to obtain the vector of mean indirect utilities \texttt{u}, third compute the (smooth) choice vector \texttt{q} based on the vector of mean indirect utilities, and finally return the data frame to which \texttt{u} and \texttt{q} are added as columns. Print out the output with \(\delta_{jt}\) evaluated at the true parameters. Check if the output is close to the true (smooth) choice vector.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute choice}
\NormalTok{df\_choice\_smooth\_delta }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_choice\_smooth\_delta}\NormalTok{(}
\NormalTok{    X, }
\NormalTok{    M, }
\NormalTok{    V, }
\NormalTok{    delta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    )}
\NormalTok{df\_choice\_smooth\_delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 316,500 x 15
##        t     i     j  v_x_1   v_x_2 v_x_3     v_p   x_1    x_2     x_3      xi
##    <int> <int> <dbl>  <dbl>   <dbl> <dbl>   <dbl> <dbl>  <dbl>   <dbl>   <dbl>
##  1     1     1     0 -1.37   0.211   1.65  0.0141     0  0      0       0     
##  2     1     1     1 -1.37   0.211   1.65  0.0141     1  0.975 -0.0324 -0.0156
##  3     1     1     4 -1.37   0.211   1.65  0.0141     1 -0.611  1.19    0.0418
##  4     1     2     0  1.37   0.378   1.35  0.387      0  0      0       0     
##  5     1     2     1  1.37   0.378   1.35  0.387      1  0.975 -0.0324 -0.0156
##  6     1     2     4  1.37   0.378   1.35  0.387      1 -0.611  1.19    0.0418
##  7     1     3     0 -2.06  -0.0662 -2.45 -1.17       0  0      0       0     
##  8     1     3     1 -2.06  -0.0662 -2.45 -1.17       1  0.975 -0.0324 -0.0156
##  9     1     3     4 -2.06  -0.0662 -2.45 -1.17       1 -0.611  1.19    0.0418
## 10     1     4     0 -0.992 -0.727  -1.33 -1.42       0  0      0       0     
## # i 316,490 more rows
## # i 4 more variables: c <dbl>, p <dbl>, u <dbl>, q <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df\_choice\_smooth\_delta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        t                i               j             v_x_1          
##  Min.   :  1.00   Min.   :  1.0   Min.   : 0.00   Min.   :-4.302781  
##  1st Qu.: 23.00   1st Qu.:125.8   1st Qu.: 2.00   1st Qu.:-0.685539  
##  Median : 48.00   Median :250.5   Median : 4.00   Median : 0.001041  
##  Mean   : 49.67   Mean   :250.5   Mean   : 4.49   Mean   :-0.002541  
##  3rd Qu.: 77.00   3rd Qu.:375.2   3rd Qu.: 7.00   3rd Qu.: 0.673061  
##  Max.   :100.00   Max.   :500.0   Max.   :10.00   Max.   : 3.809895  
##      v_x_2               v_x_3                v_p                 x_1       
##  Min.   :-4.542122   Min.   :-3.957618   Min.   :-4.218131   Min.   :0.000  
##  1st Qu.:-0.679702   1st Qu.:-0.672701   1st Qu.:-0.669446   1st Qu.:1.000  
##  Median : 0.000935   Median : 0.003104   Median : 0.001976   Median :1.000  
##  Mean   : 0.000478   Mean   : 0.003428   Mean   : 0.000017   Mean   :0.842  
##  3rd Qu.: 0.673109   3rd Qu.: 0.678344   3rd Qu.: 0.670699   3rd Qu.:1.000  
##  Max.   : 4.313621   Max.   : 4.244194   Max.   : 4.074300   Max.   :1.000  
##       x_2               x_3                xi                   c         
##  Min.   :-4.4294   Min.   :-3.9787   Min.   :-0.2996949   Min.   :0.0000  
##  1st Qu.:-0.6108   1st Qu.: 0.0000   1st Qu.:-0.0527368   1st Qu.:0.5250  
##  Median : 0.7797   Median : 1.1878   Median : 0.0000000   Median :0.8775  
##  Mean   : 0.3015   Mean   : 0.5034   Mean   :-0.0005149   Mean   :0.9507  
##  3rd Qu.: 1.4766   3rd Qu.: 1.6424   3rd Qu.: 0.0556663   3rd Qu.:1.3203  
##  Max.   : 3.0236   Max.   : 1.8877   Max.   : 0.3810277   Max.   :4.3043  
##        p               u                  q           
##  Min.   :0.000   Min.   :-345.287   Min.   :0.000000  
##  1st Qu.:1.516   1st Qu.:  -3.030   1st Qu.:0.001435  
##  Median :1.916   Median :   0.000   Median :0.030121  
##  Mean   :1.797   Mean   :  -1.869   Mean   :0.157978  
##  3rd Qu.:2.336   3rd Qu.:   1.559   3rd Qu.:0.161379  
##  Max.   :5.513   Max.   :  22.434   Max.   :1.000000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df\_choice\_smooth}\SpecialCharTok{$}\NormalTok{q }\SpecialCharTok{{-}}\NormalTok{ df\_choice\_smooth\_delta}\SpecialCharTok{$}\NormalTok{q)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -9.437e-16 -6.939e-18  0.000e+00 -1.050e-19  1.843e-18  9.992e-16
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function \texttt{compute\_share\_delta(X,\ M,\ V,\ delta,\ sigma,\ mu,\ omega)} that first construct \texttt{df} from \texttt{X}, \texttt{M}, \texttt{V}, second call \texttt{compute\_choice\_delta} to obtain a data frame with \texttt{u} and \texttt{q}, third compute the share of each product at each market \texttt{s} and the log difference in the share from the outside option, \(\ln(s_{jt}/s_{0t})\), denoted by \texttt{y}, and finally return the data frame that is summarized at the product-market level, dropped consumer-level variables, and added \texttt{s} and \texttt{y}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute share}
\NormalTok{df\_share\_smooth\_delta }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_share\_smooth\_delta}\NormalTok{(}
\NormalTok{    X, }
\NormalTok{    M, }
\NormalTok{    V, }
\NormalTok{    delta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    ) }
\NormalTok{df\_share\_smooth\_delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 633 x 11
##        t     j   x_1    x_2     x_3      xi     c     p      q      s      y
##    <int> <dbl> <dbl>  <dbl>   <dbl>   <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>
##  1     1     0     0  0      0       0      0      0    199.   0.398   0    
##  2     1     1     1  0.975 -0.0324 -0.0156 0.604  1.58 260.   0.521   0.270
##  3     1     4     1 -0.611  1.19    0.0418 1.30   2.35  40.8  0.0816 -1.58 
##  4     2     0     0  0      0       0      0      0    106.   0.211   0    
##  5     2     1     1  0.975 -0.0324 -0.0394 0.890  1.87  32.9  0.0658 -1.17 
##  6     2     3     1  1.15   1.64    0.110  2.29   3.40   6.78 0.0136 -2.75 
##  7     2     4     1 -0.611  1.19    0.0763 0.997  2.09  14.1  0.0282 -2.01 
##  8     2     6     1  0.780  1.56   -0.0253 1.15   2.13  17.4  0.0347 -1.81 
##  9     2     7     1 -1.24   0.149   0.0697 0.613  1.68  25.2  0.0504 -1.43 
## 10     2     8     1 -4.43  -3.98    0.0557 0.629  1.67 290.   0.580   1.01 
## # i 623 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df\_share\_smooth\_delta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        t                j              x_1             x_2         
##  Min.   :  1.00   Min.   : 0.00   Min.   :0.000   Min.   :-4.4294  
##  1st Qu.: 23.00   1st Qu.: 2.00   1st Qu.:1.000   1st Qu.:-0.6108  
##  Median : 48.00   Median : 4.00   Median :1.000   Median : 0.7797  
##  Mean   : 49.67   Mean   : 4.49   Mean   :0.842   Mean   : 0.3015  
##  3rd Qu.: 77.00   3rd Qu.: 7.00   3rd Qu.:1.000   3rd Qu.: 1.4766  
##  Max.   :100.00   Max.   :10.00   Max.   :1.000   Max.   : 3.0236  
##       x_3                xi                   c                p        
##  Min.   :-3.9787   Min.   :-0.2996949   Min.   :0.0000   Min.   :0.000  
##  1st Qu.: 0.0000   1st Qu.:-0.0527368   1st Qu.:0.5250   1st Qu.:1.516  
##  Median : 1.1878   Median : 0.0000000   Median :0.8775   Median :1.916  
##  Mean   : 0.5034   Mean   :-0.0005149   Mean   :0.9507   Mean   :1.797  
##  3rd Qu.: 1.6424   3rd Qu.: 0.0556663   3rd Qu.:1.3203   3rd Qu.:2.336  
##  Max.   : 1.8877   Max.   : 0.3810277   Max.   :4.3043   Max.   :5.513  
##        q                 s                  y           
##  Min.   :  1.748   Min.   :0.003497   Min.   :-4.23971  
##  1st Qu.: 17.982   1st Qu.:0.035964   1st Qu.:-1.95098  
##  Median : 40.241   Median :0.080483   Median :-1.22808  
##  Mean   : 78.989   Mean   :0.157978   Mean   :-1.15979  
##  3rd Qu.:123.006   3rd Qu.:0.246011   3rd Qu.:-0.03626  
##  Max.   :325.631   Max.   :0.651262   Max.   : 1.26578
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df\_share\_smooth}\SpecialCharTok{$}\NormalTok{s }\SpecialCharTok{{-}}\NormalTok{ df\_share\_smooth\_delta}\SpecialCharTok{$}\NormalTok{s)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -1.665e-16 -1.388e-17  0.000e+00  5.549e-20  6.939e-18  2.220e-16
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Write a function \texttt{solve\_delta(df\_share\_smooth,\ X,\ M,\ V,\ delta,\ sigma,\ mu,\ omega)} that finds \(\delta_{jt}\) that equates the actua share and the predicted share based on \texttt{compute\_share\_smooth\_delta} by the fixed-point algorithm with an operator:
  \[
  T(\delta_{jt}^{(r)}) = \delta_{jt}^{(r)} + \kappa \cdot \log\left(\frac{s_{jt}}{\sigma_{jt}[\delta^{(r)}]}\right),
  \]
  where \(s_{jt}\) is the actual share of product \(j\) in market \(t\) and \(\sigma_{jt}[\delta^{(r)}]\) is the predicted share of product \(j\) in market \(t\) given \(\delta^{(r)}\). Multiplying \(\kappa\) is for the numerical stability. I set the value at \(\kappa = 1\). Adjust it if the algorithm did not work. Set the stopping criterion at \(\max_{jt}|\delta_{jt}^{(r + 1)} - \delta_{jt}^{(r)}| < \lambda\). Set \(\lambda\) at \(10^{-6}\). Make sure that \(\delta_{i0t}\) is always set at zero while the iteration.
\end{enumerate}

Start the algorithm with the true \(\delta_{jt}\) and check if the algorithm returns (almost) the same \(\delta_{jt}\) when the actual and predicted smooth share are equated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kappa }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{lambda }\OtherTok{\textless{}{-}} \FloatTok{1e{-}4}
\NormalTok{delta\_new }\OtherTok{\textless{}{-}}
  \FunctionTok{solve\_delta}\NormalTok{(}
\NormalTok{    df\_share\_smooth, }
\NormalTok{    X, }
\NormalTok{    M, }
\NormalTok{    V, }
\NormalTok{    delta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega, }
\NormalTok{    kappa, }
\NormalTok{    lambda}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(delta\_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##       t     j  delta
##   <int> <dbl>  <dbl>
## 1     1     0  0    
## 2     1     1 -0.115
## 3     1     4 -3.46 
## 4     2     0  0    
## 5     2     1 -0.920
## 6     2     3 -6.29
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(delta\_new}\SpecialCharTok{$}\NormalTok{delta }\SpecialCharTok{{-}}\NormalTok{ delta}\SpecialCharTok{$}\NormalTok{delta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
## -1.776e-15 -2.220e-16  0.000e+00 -1.193e-17  0.000e+00  1.776e-15
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Check how long it takes to compute the limit \(\delta\) under the Monte Carlo shocks starting from the true \(\delta\) to match with \texttt{df\_share\_smooth}. This is approximately the time to evaluate the objective function.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{delta\_new }\OtherTok{\textless{}{-}}
  \FunctionTok{solve\_delta}\NormalTok{(}
\NormalTok{    df\_share\_smooth, }
\NormalTok{    X, }
\NormalTok{    M, }
\NormalTok{    V\_mcmc, }
\NormalTok{    delta, }
\NormalTok{    sigma, }
\NormalTok{    mu, }
\NormalTok{    omega, }
\NormalTok{    kappa, }
\NormalTok{    lambda}
\NormalTok{  )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  delta\_new, }
  \AttributeTok{file =} \StringTok{"lecture/data/a4/delta\_new.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{delta\_new }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a4/delta\_new.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\FunctionTok{summary}\NormalTok{(delta\_new}\SpecialCharTok{$}\NormalTok{delta }\SpecialCharTok{{-}}\NormalTok{ delta}\SpecialCharTok{$}\NormalTok{delta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -1.43733 -0.28081  0.00000 -0.01762  0.22132  1.12425
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  We use the marginal cost \(c_{jt}\) as the excluded instrumental variable for \(p_{jt}\). Let \(\Psi\) be the weighing matrix for the GMM estimator. For now, let it be the identity matrix. Write a function \texttt{compute\_theta\_linear(df\_share\_smooth,\ delta,\ mu,\ omega,\ Psi)} that returns the optimal linear parameters associated with the data and \(\delta\). Notice that we only obtain \(\beta_0\) in this way because \(\alpha_0\) is directly computed from the non-linear parameters by \(-\exp(\mu + \omega^2/2)\). The first order condition for \(\beta_0\) is:
  \begin{equation}
  \beta_0 = (X'W \Phi^{-1} W'X)^{-1} X' W \Phi^{-1} W' [\delta - \alpha_0 p],
  \end{equation}
  where
\end{enumerate}

\begin{equation}
X = 
\begin{pmatrix}
x_{11}'\\
\vdots \\
x_{J_1 1}'\\
\vdots \\
x_{1T}' \\
\vdots \\
x_{J_T T} 
\end{pmatrix}
\end{equation}

\begin{equation}
W = 
\begin{pmatrix}
x_{11}' & c_{11}\\
\vdots & \vdots \\
x_{J_1 1}' & c_{J_1 1}\\
\vdots & \vdots \\
x_{1T}' & c_{1T}\\
\vdots & \vdots \\
x_{J_T T} & c_{J_T T}
\end{pmatrix},
\end{equation}

\begin{equation}
\delta =
\begin{pmatrix}
\delta_11\\
\vdots\\
\delta_{J_1 1}\\
\vdots\\
\delta_1T\\
\vdots\\
\delta_{J_T T}\\
\end{pmatrix}
\end{equation},

where \(\alpha_0 = - \exp(\mu + \omega^2/2)\). Notice that \(X\) and \(W\) does not include rows for the outwide option.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Psi }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{length}\NormalTok{(beta) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{theta\_linear }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_theta\_linear}\NormalTok{(}
\NormalTok{    df\_share\_smooth, }
\NormalTok{    delta, }
\NormalTok{    mu, }
\NormalTok{    omega, }
\NormalTok{    Psi}
\NormalTok{    ) }
\FunctionTok{cbind}\NormalTok{(}
\NormalTok{  theta\_linear, }
\NormalTok{  beta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          delta       beta
## x_1  3.9946731  4.0000000
## x_2  0.1747411  0.1836433
## x_3 -0.8244048 -0.8356286
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Write a function \texttt{solve\_xi(df\_share\_smooth,\ delta,\ beta,\ mu,\ omega)} that computes the values of \(\xi\) that are implied from the data, \(\delta\), and the linear parameters. Check that the (almost) true values are returned when true \(\delta\) and the true linear parmaeters are passed to the function. Notice that the returend \(\xi\) should not include rows for the outside option.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xi\_new }\OtherTok{\textless{}{-}} 
  \FunctionTok{solve\_xi}\NormalTok{(}
\NormalTok{    df\_share\_smooth, }
\NormalTok{    delta, }
\NormalTok{    beta, }
\NormalTok{    mu, }
\NormalTok{    omega}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(xi\_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               xi
## [1,] -0.01557955
## [2,]  0.04179416
## [3,] -0.03942900
## [4,]  0.11000254
## [5,]  0.07631757
## [6,] -0.02533617
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xi\_true }\OtherTok{\textless{}{-}}
\NormalTok{  df\_share\_smooth }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(j }\SpecialCharTok{!=} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(xi)}
\FunctionTok{summary}\NormalTok{(xi\_true }\SpecialCharTok{{-}}\NormalTok{ xi\_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        xi            
##  Min.   :-4.233e-16  
##  1st Qu.:-5.551e-17  
##  Median : 0.000e+00  
##  Mean   : 1.347e-17  
##  3rd Qu.: 8.327e-17  
##  Max.   : 8.604e-16
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Write a function \texttt{compute\_gmm\_objective\_a4(theta\_nonlinear,\ delta,\ df\_share\_smooth,\ Psi,\ X,\ M,\ V\_mcmc,\ kappa,\ lambda)} that returns the value of the GMM objective function as a function of non-linear parameters \texttt{mu}, \texttt{omega}, and \texttt{sigma}:
  \[
  \min_{\theta} \xi(\theta)' W \Phi^{-1} W' \xi(\theta),
  \]
  where \(\xi(\theta)\) is the values of \(\xi\) that solves:
  \[
  s = \sigma(p, x, \xi),
  \]
  given parameters \(\theta\). Note that the row of \(\xi(\theta)\) and \(W\) do not include the rows for the outside options.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# non{-}linear parmaeters}
\NormalTok{theta\_nonlinear }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    mu, }
\NormalTok{    omega, }
\NormalTok{    sigma}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute GMM objective function}
\NormalTok{objective }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_gmm\_objective\_a4}\NormalTok{(}
\NormalTok{    theta\_nonlinear, }
\NormalTok{    delta, }
\NormalTok{    df\_share\_smooth, }
\NormalTok{    Psi, }
\NormalTok{    X, }
\NormalTok{    M, }
\NormalTok{    V\_mcmc, }
\NormalTok{    kappa, }
\NormalTok{    lambda}
\NormalTok{    ) }
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  objective, }
  \AttributeTok{file =} \StringTok{"lecture/data/a4/objective.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{objective }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(}
  \AttributeTok{file =} \StringTok{"lecture/data/a4/objective.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\NormalTok{objective}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          xi
## xi 16.37845
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{11}
\tightlist
\item
  Draw a graph of the objective function that varies each non-linear parameter from 0, 0.2, \(\cdots\), 2.0 of the true value. Try with the actual shocks \texttt{V}.
\end{enumerate}

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-120-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-120-2} \end{center}

\begin{verbatim}
## 
## [[3]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-120-3} \end{center}

\begin{verbatim}
## 
## [[4]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-120-4} \end{center}

\begin{verbatim}
## 
## [[5]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-120-5} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{12}
\tightlist
\item
  Find non-linear parameters that minimize the GMM objective function. Because standard deviations of the same absolute value with positive and negative values have almost the same implication for the data, you can take the absolute value if the estimates of the standard deviations happened to be negative (Another way is to set the non-negativity constraints on the standard deviations).
\end{enumerate}

\begin{verbatim}
## $par
## [1] 0.4928139 1.0228455 1.5913062 0.3913233 0.8707353
## 
## $value
## [1] 7.353949e-08
## 
## $counts
## function gradient 
##      140       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
\end{verbatim}

\begin{verbatim}
##           true  estimate
## [1,] 0.5000000 0.4928139
## [2,] 1.0000000 1.0228455
## [3,] 1.5952808 1.5913062
## [4,] 0.3295078 0.3913233
## [5,] 0.8204684 0.8707353
\end{verbatim}

\chapter{Assignment 5: Merger Simulation}\label{assignment5}

\section{Simulate data}\label{simulate-data-4}

We simulate data from a discrete choice model that is the same with in assignment 4 \textbf{except for that the price is derived from the Nash equlibrium}. There are \(T\) markets and each market has \(N\) consumers. There are \(J\) products and the indirect utility of consumer \(i\) in market \(t\) for product \(j\) is:
\[
u_{itj} = \beta_{it}' x_j + \alpha_{it} p_{jt} + \xi_{jt} + \epsilon_{ijt},
\]
where \(\epsilon_{ijt}\) is an i.i.d. type-I extreme random variable. \(x_j\) is \(K\)-dimensional observed characteristics of the product. \(p_{jt}\) is the retail price of the product in the market.

\(\xi_{jt}\) is product-market specific fixed effect. \(p_{jt}\) can be correlated with \(\xi_{jt}\) but \(x_{jt}\)s are independent of \(\xi_{jt}\). \(j = 0\) is an outside option whose indirect utility is:
\[
u_{it0} = \epsilon_{i0t},
\]
where \(\epsilon_{i0t}\) is an i.i.d. type-I extreme random variable.

\(\beta_{it}\) and \(\alpha_{it}\) are different across consumers, and they are distributed as:
\[
\beta_{itk} = \beta_{0k} + \sigma_k \nu_{itk},
\]
\[
\alpha_{it} = - \exp(\mu + \omega \upsilon_{it}) = - \exp(\mu + \frac{\omega^2}{2}) + [- \exp(\mu + \omega \upsilon_{it}) + \exp(\mu + \frac{\omega^2}{2})] \equiv \alpha_0 + \tilde{\alpha}_{it},
\]
where \(\nu_{itk}\) for \(k = 1, \cdots, K\) and \(\upsilon_{it}\) are i.i.d. standard normal random variables. \(\alpha_0\) is the mean of \(\alpha_i\) and \(\tilde{\alpha}_i\) is the deviation from the mean.

Given a choice set in the market, \(\mathcal{J}_t \cup \{0\}\), a consumer chooses the alternative that maximizes her utility:
\[
q_{ijt} = 1\{u_{ijt} = \max_{k \in \mathcal{J}_t \cup \{0\}} u_{ikt}\}.
\]
The choice probability of product \(j\) for consumer \(i\) in market \(t\) is:
\[
\sigma_{ijt}(p_t, x_t, \xi_t) = \mathbb{P}\{u_{ijt} = \max_{k \in \mathcal{J}_t \cup \{0\}} u_{ikt}\}.
\]

Suppose that we only observe the (smooth) share data:
\[
s_{jt}(p_t, x_t, \xi_t) = \frac{1}{N} \sum_{i = 1}^N \sigma_{ijt}(p_t, x_t, \xi_t) = \frac{1}{N} \sum_{i = 1}^N \frac{\exp(u_{ijt})}{1 + \sum_{k \in \mathcal{J}_t \cup \{0\}} \exp(u_{ikt})}. 
\]
along with the product-market characteristics \(x_{jt}\) and the retail prices \(p_{jt}\) for \(j \in \mathcal{J}_t \cup \{0\}\) for \(t = 1, \cdots, T\). We do not observe the choice data \(q_{ijt}\) nor shocks \(\xi_{jt}, \nu_{it}, \upsilon_{it}, \epsilon_{ijt}\).

We draw \(\xi_{jt}\) from i.i.d. normal distribution with mean 0 and standard deviation \(\sigma_{\xi}\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set the seed, constants, and parameters of interest as follows.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set the seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# number of products}
\NormalTok{J }\OtherTok{\textless{}{-}} \DecValTok{10}
\CommentTok{\# dimension of product characteristics including the intercept}
\NormalTok{K }\OtherTok{\textless{}{-}} \DecValTok{3}
\CommentTok{\# number of markets}
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{100}
\CommentTok{\# number of consumers per market}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{500}
\CommentTok{\# number of Monte Carlo}
\NormalTok{L }\OtherTok{\textless{}{-}} \DecValTok{500}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set parameters of interests}
\NormalTok{beta }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(K); }
\NormalTok{beta[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{beta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  4.0000000  0.1836433 -0.8356286
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(K)); sigma}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.5952808 0.3295078 0.8204684
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{omega }\OtherTok{\textless{}{-}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

Generate the covariates as follows.

The product-market characteristics:
\[
x_{j1} = 1, x_{jk} \sim N(0, \sigma_x), k = 2, \cdots, K,
\]
where \(\sigma_x\) is referred to as \texttt{sd\_x} in the code.

The product-market-specific unobserved fixed effect:
\[
\xi_{jt} \sim N(0, \sigma_\xi),
\]
where \(\sigma_xi\) is referred to as \texttt{sd\_xi} in the code.

The marginal cost of product \(j\) in market \(t\):
\[
c_{jt} \sim \text{logNormal}(0, \sigma_c),
\]
where \(\sigma_c\) is referred to as \texttt{sd\_c} in the code.

The price is determined by a Nash equilibrium. Let \(\Delta_t\) be the \(J_t \times J_t\) ownership matrix in which the \((j, k)\)-th element \(\delta_{tjk}\) is equal to 1 if product \(j\) and \(k\) are owned by the same firm and 0 otherwise. Assume that \(\delta_{tjk} = 1\) if and only if \(j = k\) for all \(t = 1, \cdots, T\), i.e., each firm owns only one product. Next, define \(\Omega_t\) be \(J_t \times J_t\) matrix such that whose \((j, k)\)-the element \(\omega_{tjk}(p_t, x_t, \xi_t, \Delta_t)\) is:
\[
\omega_{tjk}(p_t, x_t, \xi_t, \Delta_t) = - \frac{\partial s_{jt}(p_t, x_t, \xi_t)}{\partial p_{kt}} \delta_{tjk}.
\]
Then, the equilibrium price vector \(p_t\) is determined by solving the following equilibrium condition:
\[
p_t = c_t + \Omega_t(p_t, x_t, \xi_t, \Delta_t)^{-1} s_t(p_t, x_t, \xi_t).
\]

The value of the auxiliary parameters are set as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set auxiliary parameters}
\NormalTok{price\_xi }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{sd\_x }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{sd\_xi }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{sd\_c }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\NormalTok{sd\_p }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \texttt{X} is the data frame such that a row contains the characteristics vector \(x_{j}\) of a product and columns are product index and observed product characteristics. The dimension of the characteristics \(K\) is specified above. Add the row of the outside option whose index is \(0\) and all the characteristics are zero.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make product characteristics data}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
\NormalTok{       sd\_x }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)), }
       \AttributeTok{nrow =}\NormalTok{ J}
\NormalTok{       )}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{cbind}\NormalTok{(}
       \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, J),}
\NormalTok{       X}
\NormalTok{       )}
\FunctionTok{colnames}\NormalTok{(X) }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{)}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{J, X) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{()}
\CommentTok{\# add outside option}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
  \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{dim}\NormalTok{(X)[}\DecValTok{2}\NormalTok{]),}
\NormalTok{  X}
\NormalTok{  ) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 11 x 4
##        j   x_1     x_2     x_3
##    <dbl> <dbl>   <dbl>   <dbl>
##  1     0     0  0       0     
##  2     1     1  0.975  -0.0324
##  3     2     1  1.48    1.89  
##  4     3     1  1.15    1.64  
##  5     4     1 -0.611   1.19  
##  6     5     1  3.02    1.84  
##  7     6     1  0.780   1.56  
##  8     7     1 -1.24    0.149 
##  9     8     1 -4.43   -3.98  
## 10     9     1  2.25    1.24  
## 11    10     1 -0.0899 -0.112
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \texttt{M} is the data frame such that a row contains the price \(\xi_{jt}\), marginal cost \(c_{jt}\), and price \(p_{jt}\). For now, set \(p_{jt} = 0\) and fill the equilibrium price later. After generating the variables, drop some products in each market. In order to change the number of available products in each market, for each market, first draw \(J_t\) from a discrete uniform distribution between \(1\) and \(J\). Then, drop products from each market using \texttt{dplyr::sample\_frac} function with the realized number of available products. The variation in the available products is important for the identification of the distribution of consumer-level unobserved heterogeneity. Add the row of the outside option to each market whose index is \(0\) and all the variables take value zero.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make market{-}product data}
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{J, }
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{xi =}\NormalTok{ sd\_xi }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J}\SpecialCharTok{*}\NormalTok{T),}
    \AttributeTok{c =} \FunctionTok{exp}\NormalTok{(sd\_c }\SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(J}\SpecialCharTok{*}\NormalTok{T)),}
    \AttributeTok{p =} \DecValTok{0}
\NormalTok{  ) }
\NormalTok{M }\OtherTok{\textless{}{-}} 
\NormalTok{  M }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{group\_by}\NormalTok{(t) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{sample\_frac}\NormalTok{(}\AttributeTok{size =}\NormalTok{ purrr}\SpecialCharTok{::}\FunctionTok{rdunif}\NormalTok{(}\DecValTok{1}\NormalTok{, J)}\SpecialCharTok{/}\NormalTok{J) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{ungroup}\NormalTok{()}
\CommentTok{\# add outside option}
\NormalTok{outside }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{j =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{xi =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{c =} \DecValTok{0}\NormalTok{, }
    \AttributeTok{p =} \DecValTok{0}
\NormalTok{    )}
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
\NormalTok{    M,}
\NormalTok{    outside}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{arrange}\NormalTok{(}
\NormalTok{    t, }
\NormalTok{    j}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 696 x 5
##        j     t      xi     c     p
##    <dbl> <int>   <dbl> <dbl> <dbl>
##  1     0     1  0      0         0
##  2     2     1 -0.735  1.04      0
##  3     6     1 -0.0514 0.980     0
##  4     7     1  0.194  0.961     0
##  5     8     1 -0.0269 0.989     0
##  6     0     2  0      0         0
##  7     1     2 -0.197  0.988     0
##  8     2     2 -0.0297 1.04      0
##  9     4     2  0.382  1.00      0
## 10     5     2 -0.0823 1.02      0
## # i 686 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Generate the consumer-level heterogeneity. \texttt{V} is the data frame such that a row contains the vector of shocks to consumer-level heterogeneity, \((\nu_{i}', \upsilon_i)\). They are all i.i.d. standard normal random variables.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make consumer{-}market data}
\NormalTok{V }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
    \FunctionTok{rnorm}\NormalTok{(N }\SpecialCharTok{*}\NormalTok{ T }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)), }
    \AttributeTok{nrow =}\NormalTok{ N }\SpecialCharTok{*}\NormalTok{ T}
\NormalTok{    ) }
\FunctionTok{colnames}\NormalTok{(V) }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \FunctionTok{paste}\NormalTok{(}\StringTok{"v\_x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{), }
    \StringTok{"v\_p"}
\NormalTok{    )}
\NormalTok{V }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
  \FunctionTok{expand.grid}\NormalTok{(}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N, }
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T}
\NormalTok{    ),}
\NormalTok{  V}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 50,000 x 6
##        i     t   v_x_1   v_x_2   v_x_3     v_p
##    <int> <int>   <dbl>   <dbl>   <dbl>   <dbl>
##  1     1     1  0.448   0.985   0.611   0.408 
##  2     2     1 -0.386  -0.389  -1.11   -0.667 
##  3     3     1  0.0567  0.0510  0.0329 -0.119 
##  4     4     1  0.585   0.303   0.860  -1.20  
##  5     5     1 -0.449  -1.17    0.599   0.212 
##  6     6     1 -0.782   0.0596  1.30    0.485 
##  7     7     1  1.60   -1.62   -1.91    0.669 
##  8     8     1 -1.65    2.10    0.726  -0.108 
##  9     9     1 -0.848  -0.933   2.29   -0.0195
## 10    10     1 -0.130  -0.897  -1.90   -0.185 
## # i 49,990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  We use \texttt{compute\_indirect\_utility(df,\ beta,\ sigma,\ mu,\ omega)}, \texttt{compute\_choice\_smooth(X,\ M,\ V,\ beta,\ sigma,\ mu,\ omega)}, and \texttt{compute\_share\_smooth(X,\ M,\ V,\ beta,\ sigma,\ mu,\ omega)} to compute \(s_t(p_t, x_t, \xi_t)\). On top of this, we need a function \texttt{compute\_derivative\_share\_smooth(X,\ M,\ V,\ beta,\ sigma,\ mu,\ omega)} that approximate:
\end{enumerate}

\[
\frac{\partial s_{jt}(p_t, x_t, \xi_t)}{\partial p_{kt}} = 
\begin{cases}
\frac{1}{N} \sum_{i = 1}^N \alpha_i \sigma_{ijt}(p_t, x_t, \xi_t)[1 - \sigma_{ijt}(p_t, x_t, \xi_t)] &\text{   if   } j = k\\
- \frac{1}{N}\sum_{i = 1}^N \alpha_i \sigma_{ijt}(p_t, x_t, \xi_t)\sigma_{ikt}(p_t, x_t, \xi_t)] &\text{   if   } j \neq k.
\end{cases}
\]

The returned object should be a list across markets and each element of the list should be \(J_t \times J_t\) matrix whose \((j, k)\)-th element is \(\partial s_{jt}/\partial p_{it}\) (do not include the outside option). The computation will be looped across markets. I recommend to use a parallel computing for this loop.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{derivative\_share\_smooth }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_derivative\_share\_smooth}\NormalTok{(}
    \AttributeTok{X =}\NormalTok{ X,}
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{derivative\_share\_smooth[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]        [,2]        [,3]        [,4]
## [1,] -0.15195456  0.07243405  0.04067066  0.03615775
## [2,]  0.07243405 -0.21334454  0.06758143  0.06900886
## [3,]  0.04067066  0.06758143 -0.22465048  0.11247770
## [4,]  0.03615775  0.06900886  0.11247770 -0.22508246
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{derivative\_share\_smooth[[T]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               [,1]         [,2]         [,3]         [,4]         [,5]
##  [1,] -0.096590746  0.003580709  0.003713348  0.011204782  0.012198589
##  [2,]  0.003580709 -0.054948229  0.003309376  0.009438704  0.009893682
##  [3,]  0.003713348  0.003309376 -0.055735044  0.009505457  0.009233146
##  [4,]  0.011204782  0.009438704  0.009505457 -0.160285167  0.021922796
##  [5,]  0.012198589  0.009893682  0.009233146  0.021922796 -0.136324417
##  [6,]  0.008403911  0.007465135  0.007249620  0.022645270  0.019978806
##  [7,]  0.006573094  0.003856270  0.004084570  0.016649978  0.009219389
##  [8,]  0.033096170  0.006496123  0.007885498  0.038995016  0.016868502
##  [9,]  0.013495765  0.008866219  0.008606532  0.022541027  0.030984223
## [10,]  0.003846416  0.001815922  0.001912074  0.006631000  0.005317866
##               [,6]         [,7]         [,8]         [,9]        [,10]
##  [1,]  0.008403911  0.006573094  0.033096170  0.013495765  0.003846416
##  [2,]  0.007465135  0.003856270  0.006496123  0.008866219  0.001815922
##  [3,]  0.007249620  0.004084570  0.007885498  0.008606532  0.001912074
##  [4,]  0.022645270  0.016649978  0.038995016  0.022541027  0.006631000
##  [5,]  0.019978806  0.009219389  0.016868502  0.030984223  0.005317866
##  [6,] -0.119320239  0.009873958  0.019723897  0.018980139  0.004460069
##  [7,]  0.009873958 -0.101062317  0.035849014  0.010662149  0.003862923
##  [8,]  0.019723897  0.035849014 -0.207076797  0.027381997  0.018831945
##  [9,]  0.018980139  0.010662149  0.027381997 -0.148409509  0.006094688
## [10,]  0.004460069  0.003862923  0.018831945  0.006094688 -0.053007318
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Make a list \texttt{delta} such that each element of the list is \(J_t \times J_t\) matrix \(\delta_t\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{delta[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    1    0    0    0
## [2,]    0    1    0    0
## [3,]    0    0    1    0
## [4,]    0    0    0    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{delta[[T]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
##  [1,]    1    0    0    0    0    0    0    0    0     0
##  [2,]    0    1    0    0    0    0    0    0    0     0
##  [3,]    0    0    1    0    0    0    0    0    0     0
##  [4,]    0    0    0    1    0    0    0    0    0     0
##  [5,]    0    0    0    0    1    0    0    0    0     0
##  [6,]    0    0    0    0    0    1    0    0    0     0
##  [7,]    0    0    0    0    0    0    1    0    0     0
##  [8,]    0    0    0    0    0    0    0    1    0     0
##  [9,]    0    0    0    0    0    0    0    0    1     0
## [10,]    0    0    0    0    0    0    0    0    0     1
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function \texttt{update\_price(logp,\ X,\ M,\ V,\ beta,\ sigma,\ mu,\ omega,\ delta)} that receives a price vector \(p_t^{(r)}\) and returns \(p_t^{(r + 1)}\) by:
  \[
  p_t^{(r + 1)} = c_t + \Omega_t(p_t^{(r)}, x_t, \xi_t, \Delta_t)^{-1} s_t(p_t^{(r)}, x_t, \xi_t).
  \]
  The returned object should be a vector whose row represents the condition for an inside product of each market. To impose non-negativity constraint on the price vector, we pass log price and exponentiate inside the function. Iterate this until \(\max_{jt}|p_{jt}^{(r + 1)} - p_{jt}^{(r)}| < \lambda\), for example with \(\lambda = 10^{-6}\). This iteration may or may not converge. The convergence depends on the parameters and the realization of the shocks. If the algorithm does not converge, first check the code.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set the threshold}
\NormalTok{lambda }\OtherTok{\textless{}{-}} \FloatTok{1e{-}6}
\CommentTok{\# set the initial price}
\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ M[M}\SpecialCharTok{$}\NormalTok{j }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{, }\StringTok{"p"}\NormalTok{]}
\NormalTok{logp }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{dim}\NormalTok{(p)[}\DecValTok{1}\NormalTok{]))}
\NormalTok{p\_new }\OtherTok{\textless{}{-}} 
  \FunctionTok{update\_price}\NormalTok{(}
    \AttributeTok{logp =}\NormalTok{ logp, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega, }
    \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{    )}
\CommentTok{\# iterate}
\NormalTok{distance }\OtherTok{\textless{}{-}} \DecValTok{10000}
\ControlFlowTok{while}\NormalTok{ (distance }\SpecialCharTok{\textgreater{}}\NormalTok{ lambda) \{}
\NormalTok{  p\_old }\OtherTok{\textless{}{-}}\NormalTok{ p\_new}
\NormalTok{  p\_new }\OtherTok{\textless{}{-}} 
    \FunctionTok{update\_price}\NormalTok{(}
      \FunctionTok{log}\NormalTok{(p\_old), }
\NormalTok{      X, }
\NormalTok{      M, }
\NormalTok{      V, }
\NormalTok{      beta, }
\NormalTok{      sigma, }
\NormalTok{      mu, }
\NormalTok{      omega, }
\NormalTok{      delta}
\NormalTok{      )}
\NormalTok{  distance }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(p\_new }\SpecialCharTok{{-}}\NormalTok{ p\_old))}
  \FunctionTok{print}\NormalTok{(distance)}
\NormalTok{\}}
\CommentTok{\# save}
\NormalTok{p\_actual }\OtherTok{\textless{}{-}}\NormalTok{ p\_new}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  p\_actual, }
  \AttributeTok{file =} \StringTok{"lecture/data/a5/price\_actual.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load}
\NormalTok{p\_actual }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a5/price\_actual.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{p\_actual }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          [,1]
## [1,] 2.009611
## [2,] 2.024696
## [3,] 2.099574
## [4,] 6.374277
## [5,] 1.664490
## [6,] 1.808518
\end{verbatim}

\section{Estimate the parameters}\label{estimate-the-parameters-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function \texttt{estimate\_marginal\_cost()} that estimate \(c_t\) by the equilibrium condition as:
  \[
  c_t = p_t - \Omega_t(p_t, x_t, \xi_t, \Delta_t)^{-1} s_t(p_t, x_t, \xi_t)
  \]
\end{enumerate}

Of course, in reality, we first draw Monte Carlo shocks to approximate the share, estimate the demand parameters, and use these shocks and estimates to estimate the marginal costs. In this assignment, we check the if the estimated marginal costs coincide with the true marginal costs to confirm that the codes are correctly written.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# take the logarithm}
\NormalTok{logp }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(p\_actual)}
\CommentTok{\# estimate the marginal cost}
\NormalTok{marginal\_cost\_estimate }\OtherTok{\textless{}{-}} 
  \FunctionTok{estimate\_marginal\_cost}\NormalTok{(}
    \AttributeTok{logp =}\NormalTok{ logp, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega, }
    \AttributeTok{delta =}\NormalTok{ delta)}
\NormalTok{marginal\_cost\_actual }\OtherTok{\textless{}{-}}\NormalTok{ M[M}\SpecialCharTok{$}\NormalTok{j }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{, ]}\SpecialCharTok{$}\NormalTok{c}
\CommentTok{\# plot the estimate vs actual marginal costs}
\NormalTok{marginal\_cost\_df }\OtherTok{\textless{}{-}}
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{actual =}\NormalTok{ marginal\_cost\_actual,}
    \AttributeTok{estimate =}\NormalTok{ marginal\_cost\_estimate}
\NormalTok{    )}
\FunctionTok{ggplot}\NormalTok{(}
\NormalTok{  marginal\_cost\_df, }
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ estimate, }
    \AttributeTok{y =}\NormalTok{ actual}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-141-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  (Optional) Translate \texttt{compute\_indirect\_utility}, \texttt{compute\_choice\_smooth}, \texttt{compute\_derivative\_share\_smooth}, \texttt{update\_price} into C++ using Rcpp and Eigen. Check that the outputs coincide at the machine precision level. I give you extra 2 points for this task on top of the usual 10 points for this assignment.
\end{enumerate}

\section{Conduct counterfactual simulation}\label{conduct-counterfactual-simulation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Suppose that the firm of product 1 owner purchase the firms that own product 2 and 3. Let \texttt{delta\_counterfactual} be the relevant ownership matrix. Make \texttt{delta\_counterfactual}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{delta\_counterfactual[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    1    0    0    0
## [2,]    0    1    0    0
## [3,]    0    0    1    0
## [4,]    0    0    0    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{delta\_counterfactual[[T]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
##  [1,]    1    1    1    0    0    0    0    0    0     0
##  [2,]    1    1    1    0    0    0    0    0    0     0
##  [3,]    1    1    1    0    0    0    0    0    0     0
##  [4,]    0    0    0    1    0    0    0    0    0     0
##  [5,]    0    0    0    0    1    0    0    0    0     0
##  [6,]    0    0    0    0    0    1    0    0    0     0
##  [7,]    0    0    0    0    0    0    1    0    0     0
##  [8,]    0    0    0    0    0    0    0    1    0     0
##  [9,]    0    0    0    0    0    0    0    0    1     0
## [10,]    0    0    0    0    0    0    0    0    0     1
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Compute the counterfactual price using the iteration with \texttt{update\_price}. You can start the iteration from the equilibrium price. Show the average percentage change in the price for each product. In theory, the price of any product should not drop. But some prices can slightly drop because of the numerical errors.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logp }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(p\_actual)}
\NormalTok{p\_new }\OtherTok{\textless{}{-}} 
  \FunctionTok{update\_price}\NormalTok{(}
    \AttributeTok{logp =}\NormalTok{ logp, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega, }
    \AttributeTok{delta =}\NormalTok{ delta\_counterfactual}
\NormalTok{    )}
\NormalTok{distance }\OtherTok{\textless{}{-}} \DecValTok{10000}
\ControlFlowTok{while}\NormalTok{ (distance }\SpecialCharTok{\textgreater{}}\NormalTok{ lambda) \{}
\NormalTok{  p\_old }\OtherTok{\textless{}{-}}\NormalTok{ p\_new}
\NormalTok{  p\_new }\OtherTok{\textless{}{-}} 
    \FunctionTok{update\_price}\NormalTok{(}
      \FunctionTok{log}\NormalTok{(p\_old), }
\NormalTok{      X, }
\NormalTok{      M, }
\NormalTok{      V, }
\NormalTok{      beta, }
\NormalTok{      sigma, }
\NormalTok{      mu, }
\NormalTok{      omega, }
\NormalTok{      delta\_counterfactual}
\NormalTok{      )}
\NormalTok{  distance }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(p\_new }\SpecialCharTok{{-}}\NormalTok{ p\_old))}
  \FunctionTok{print}\NormalTok{(distance)}
\NormalTok{\}}
\NormalTok{p\_counterfactual }\OtherTok{\textless{}{-}}\NormalTok{ p\_new}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  p\_counterfactual, }
  \AttributeTok{file =} \StringTok{"lecture/data/a5/price\_counterfactual.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r}
\hline
j & p\_change\\
\hline
1 & 0.0501744\\
\hline
2 & 0.1179955\\
\hline
3 & 0.1479700\\
\hline
4 & 0.0013059\\
\hline
5 & 0.0004309\\
\hline
6 & -0.0002448\\
\hline
7 & 0.0008458\\
\hline
8 & -0.0033448\\
\hline
9 & 0.0004042\\
\hline
10 & 0.0015040\\
\hline
\end{tabular}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write a function \texttt{compute\_producer\_surplus(p,\ marginal\_cost,\ X,\ M,\ V,\ beta,\ sigma,\ mu,\ omega)} that returns the producer surplus for each product in each market. Compute the actual and counterfactual producer surplus under the estimated marginal costs. Show the average percentage change in the producer surplus for each product.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute actual producer surplus}
\NormalTok{producer\_surplus\_actual }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_producer\_surplus}\NormalTok{(}
    \AttributeTok{p =}\NormalTok{ p\_actual, }
    \AttributeTok{marginal\_cost =}\NormalTok{ marginal\_cost\_estimate, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(producer\_surplus\_actual)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        s           
##  Min.   :0.008247  
##  1st Qu.:0.041636  
##  Median :0.071153  
##  Mean   :0.168761  
##  3rd Qu.:0.150643  
##  Max.   :1.607658
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute counterfactual producer surplus}
\NormalTok{producer\_surplus\_counterfactual }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_producer\_surplus}\NormalTok{(}
    \AttributeTok{p =}\NormalTok{ p\_counterfactual, }
    \AttributeTok{marginal\_cost =}\NormalTok{ marginal\_cost\_estimate, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(producer\_surplus\_counterfactual)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        s           
##  Min.   :0.008212  
##  1st Qu.:0.042687  
##  Median :0.073644  
##  Mean   :0.171809  
##  3rd Qu.:0.153746  
##  Max.   :1.607658
\end{verbatim}

\begin{tabular}{r|r}
\hline
j & producer\_surplus\_change\\
\hline
1 & 0.0231358\\
\hline
2 & 0.0131566\\
\hline
3 & 0.0073846\\
\hline
4 & 0.0534174\\
\hline
5 & 0.0449804\\
\hline
6 & 0.0563809\\
\hline
7 & 0.0372859\\
\hline
8 & 0.0072057\\
\hline
9 & 0.0421801\\
\hline
10 & 0.0385013\\
\hline
\end{tabular}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Write a function \texttt{compute\_consumer\_surplus(p,\ X,\ M,\ V,\ beta,\ sigma,\ mu,\ omega)} that returns the consumer surplus for each consumer in each market. Compute the actual and counterfactual consumer surplus under the estimated marginal costs. Show the percentage change in the total consumer surplus.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute actual consumer surplus}
\NormalTok{consumer\_surplus\_actual }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_consumer\_surplus}\NormalTok{(}
    \AttributeTok{p =}\NormalTok{ p\_actual, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(consumer\_surplus\_actual)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
##   0.00000   0.03447   1.10805   4.33269   4.65720 230.98190
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute counterfactual consumer surplus}
\NormalTok{consumer\_surplus\_counterfactual }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_consumer\_surplus}\NormalTok{(}
    \AttributeTok{p =}\NormalTok{ p\_counterfactual, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{M =}\NormalTok{ M, }
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{sigma =}\NormalTok{ sigma, }
    \AttributeTok{mu =}\NormalTok{ mu, }
    \AttributeTok{omega =}\NormalTok{ omega}
\NormalTok{    )}
\FunctionTok{summary}\NormalTok{(consumer\_surplus\_counterfactual)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
##   0.00000   0.03054   1.07265   4.31048   4.61989 231.02355
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{consumer\_surplus\_change }\OtherTok{\textless{}{-}} 
\NormalTok{  (}\FunctionTok{sum}\NormalTok{(consumer\_surplus\_counterfactual) }\SpecialCharTok{{-}} 
     \FunctionTok{sum}\NormalTok{(consumer\_surplus\_actual)) }\SpecialCharTok{/}
  \FunctionTok{sum}\NormalTok{(consumer\_surplus\_actual)}
\NormalTok{consumer\_surplus\_change}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.005127025
\end{verbatim}

\chapter{Assignment 6: Entry and Exit Analysis}\label{assignment6}

\section{Simulate data}\label{simulate-data-5}

In this assignment, we consider a Berry-type entry model. Suppose that there are \(M\) markets indexed by \(m = 1, \cdots, M\). In each market, there are \(N_m\) potential entrants such that \(N_m \le \overline{N}\). Let \(x_m\) be the \(K\) dimensional market attributes and \(z_{im}\) be the \(L\) dimensional potential entrant attributes. The size of Monte Carlo simulations in the estimation is \(R\).

A random number generation inside \texttt{\%dopar\%} is not reproducible. Therefore, we use package \texttt{doRNG} to perform reproducible \texttt{foreach} parallel.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set the constants as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{registerDoParallel}\NormalTok{()}
\CommentTok{\# register doRNG backend}
\FunctionTok{registerDoRNG}\NormalTok{()}
\CommentTok{\# set the seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# number of markets}
\NormalTok{M }\OtherTok{\textless{}{-}} \DecValTok{100}
\CommentTok{\# the upper bound of the number of potential entrants}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{10}
\CommentTok{\# the dimension of market attributes}
\NormalTok{K }\OtherTok{\textless{}{-}} \DecValTok{2}
\CommentTok{\# the dimension of potential entrant attributes}
\NormalTok{L }\OtherTok{\textless{}{-}} \DecValTok{2}
\CommentTok{\# the number of Monte Carlo simulations}
\NormalTok{R }\OtherTok{\textless{}{-}} \DecValTok{100}
\end{Highlighting}
\end{Shaded}

The payoff of entrant \(i\) in market \(m\) is:
\[
\pi_{im}(y_m) = x_m'\beta - \delta \ln \left(\sum_{i = 1}^{N_m} y_{im}\right) + z_{im}'\alpha + \sqrt{1 - \rho^2} \nu_{im} + \rho \epsilon_{m},
\]
where \(y_{im} \in \{0, 1\}\) is the indicator for entrant \(i\) in market \(m\) to enter the market, and \(\nu_{im}\) and \(\epsilon_m\) are entrant- and market-specific idiosyncratic shocks that are drawn from an i.i.d. standard normal distribution. In each market, all the attributes and idiosyncratic shocks are observed by the potential entrants. \(N_m\), \(x_m\), \(z_{im}\), and \(y_m\) are observed to econometrician but \(\nu_{im}\) and \(\epsilon_m\) are not.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Set the parameters as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# parameters of interest}
\NormalTok{beta }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(K)); }
\NormalTok{beta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6264538 0.1836433
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alpha }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(L)); }
\NormalTok{alpha}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8356286 1.5952808
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{delta }\OtherTok{\textless{}{-}} \DecValTok{1}\NormalTok{; }
\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rho }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{)); }
\NormalTok{rho}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3295078
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# auxiliary parameters}
\NormalTok{x\_mu }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{x\_sd }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{z\_mu }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{z\_sd }\OtherTok{\textless{}{-}} \DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Draw exogenous variables as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# number of potential entrants}
\NormalTok{E }\OtherTok{\textless{}{-}} 
\NormalTok{  purrr}\SpecialCharTok{::}\FunctionTok{rdunif}\NormalTok{(}
\NormalTok{    M, }
    \DecValTok{1}\NormalTok{, }
\NormalTok{    N}
\NormalTok{    ); }
\NormalTok{E}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1]  3  1  5  5 10  6 10  7  9  5  5  9  9  5  5  2 10  9  1  4  3  6 10 10  6
##  [26]  4  4 10  9  7  6  9  8  9  7  8  6 10  7  3 10  6  8  2  2  6  6  1  3  3
##  [51]  8  6  7  6  8  7  1  4  8  9  9  7  4  7  6  1  5  6  1  9  7  7  3  6  2
##  [76] 10 10  7  3  2 10  1 10 10  8 10  5  7  8  5  6  8  1  3 10  3  1  6  6  4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# market attributes}
\NormalTok{X }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
  \FunctionTok{rnorm}\NormalTok{(}
\NormalTok{    M }\SpecialCharTok{*}\NormalTok{ K, }
\NormalTok{    x\_mu, }
\NormalTok{    x\_sd}
\NormalTok{    ),}
  \AttributeTok{nrow =}\NormalTok{ M}
\NormalTok{  )}
\FunctionTok{colnames}\NormalTok{(X) }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{)}
\NormalTok{X[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               x_1        x_2
##  [1,] -0.70600620 -2.6939703
##  [2,]  0.59446415  3.9516867
##  [3,]  4.53426099  1.6597744
##  [4,] -3.57070040 -3.4017501
##  [5,]  2.78183856  2.5630682
##  [6,]  1.99885111  0.5237362
##  [7,]  4.18929951  5.3937619
##  [8,]  0.08744823 -1.2982460
##  [9,]  2.11005643 -0.2906353
## [10,]  1.80129637 -1.7783285
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# entrant attributes}
\NormalTok{Z }\OtherTok{\textless{}{-}}
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{m =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{M}
\NormalTok{    ) }\SpecialCharTok{\%dorng\%}\NormalTok{ \{}
\NormalTok{    Z\_m }\OtherTok{\textless{}{-}} 
      \FunctionTok{matrix}\NormalTok{(}
      \FunctionTok{rnorm}\NormalTok{(}
\NormalTok{        E[m] }\SpecialCharTok{*}\NormalTok{ L, }
\NormalTok{        z\_mu, }
\NormalTok{        z\_sd}
\NormalTok{        ),}
      \AttributeTok{nrow =}\NormalTok{ E[m]}
\NormalTok{    )}
    \FunctionTok{colnames}\NormalTok{(Z\_m) }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"z"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{L, }\AttributeTok{sep =} \StringTok{"\_"}\NormalTok{)}
    \FunctionTok{return}\NormalTok{(Z\_m)}
\NormalTok{  \}}
\NormalTok{Z[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             z_1       z_2
## [1,] -2.3581574 -7.334507
## [2,] -0.4604547  3.771050
## [3,]  2.7599294  4.610126
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# unobserved market attributes}
\NormalTok{EP }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
  \FunctionTok{rnorm}\NormalTok{(M),}
  \AttributeTok{nrow =}\NormalTok{ M}
\NormalTok{  )}
\NormalTok{EP[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] -1.1131230  0.6169665  0.5134937  0.3694591  1.7238941 -0.2061446
##  [7] -1.3141951  0.0634741 -0.2319775  0.6350603
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# unobserved entrant attributes}
\NormalTok{NU }\OtherTok{\textless{}{-}}
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{m =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{M}
\NormalTok{    ) }\SpecialCharTok{\%dorng\%}\NormalTok{ \{}
\NormalTok{    NU\_m }\OtherTok{\textless{}{-}} 
      \FunctionTok{matrix}\NormalTok{(}
      \FunctionTok{rnorm}\NormalTok{(E[m]),}
      \AttributeTok{nrow =}\NormalTok{ E[m]}
\NormalTok{    )}
    \FunctionTok{return}\NormalTok{(NU\_m)}
\NormalTok{  \}}
\NormalTok{NU[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]
## [1,]  0.3934210
## [2,]  0.2303175
## [3,] -0.6046126
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Write a function \texttt{compute\_payoff(y\_m,\ X\_m,\ Z\_m,\ EP\_m,\ NU\_m,\ beta,\ alpha,\ delta,\ rho)} that returns the vector of payoffs of the potential entrants when the vector of entry decisions is \texttt{y\_m}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{N\_m }\OtherTok{\textless{}{-}} \FunctionTok{dim}\NormalTok{(Z[[m]])[}\DecValTok{1}\NormalTok{]}
\NormalTok{y\_m }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, N\_m))}
\NormalTok{y\_m[}\FunctionTok{length}\NormalTok{(y\_m)] }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{X\_m }\OtherTok{\textless{}{-}}\NormalTok{ X[m, , drop }\OtherTok{=} \ConstantTok{FALSE}\NormalTok{]}
\NormalTok{Z\_m }\OtherTok{\textless{}{-}}\NormalTok{ Z[[m]]}
\NormalTok{EP\_m }\OtherTok{\textless{}{-}}\NormalTok{ EP[m, , drop }\OtherTok{=} \ConstantTok{FALSE}\NormalTok{]}
\NormalTok{NU\_m }\OtherTok{\textless{}{-}}\NormalTok{ NU[[m]]}


\FunctionTok{compute\_payoff}\NormalTok{(}
  \AttributeTok{y\_m =}\NormalTok{ y\_m, }
  \AttributeTok{X\_m =}\NormalTok{ X\_m, }
  \AttributeTok{Z\_m =}\NormalTok{ Z\_m, }
  \AttributeTok{EP\_m =}\NormalTok{ EP\_m, }
  \AttributeTok{NU\_m =}\NormalTok{ NU\_m, }
  \AttributeTok{beta =}\NormalTok{ beta, }
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{delta =}\NormalTok{ delta, }
  \AttributeTok{rho =}\NormalTok{ rho}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]
## [1,] -15.296633
## [2,]   3.851629
## [3,]   0.000000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Assume that the order of entry is predetermined. Assume that the potential entrants sequentially decide entry according to the order of the payoff excluding the competitive effects, i.e.:
  \[
  x_m'\beta + z_{im}'\alpha + \sqrt{1 - \rho^2} \nu_{im} + \rho \epsilon_{m}.
  \]
  Write a function \texttt{compute\_order\_sequential\_entry(X\_m,\ Z\_m,\ EP\_m,\ NU\_m,\ beta,\ alpha,\ rho)} that returns the order of entry of the potential entrants by the baseline payoff. Note that if the less profitable entrant finds it profitable to enter then the more profitable entrant still finds it profitable to enter. Then write a function \texttt{compute\_sequential\_entry(X\_m,\ Z\_m,\ EP\_m,\ NU\_m,\ beta,\ alpha,\ delta,\ rho)} that returns the equilibrium vector of entry at a market. To do so, you must find at which entrant the payoff becomes negative for the first time.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{compute\_order\_sequential\_entry}\NormalTok{(}
    \AttributeTok{X\_m =}\NormalTok{ X\_m,}
    \AttributeTok{Z\_m =}\NormalTok{ Z\_m, }
    \AttributeTok{EP\_m =}\NormalTok{ EP\_m, }
    \AttributeTok{NU\_m =}\NormalTok{ NU\_m, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{rho =}\NormalTok{ rho}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3 2 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{compute\_sequential\_entry}\NormalTok{(}
  \AttributeTok{X\_m =}\NormalTok{ X\_m, }
  \AttributeTok{Z\_m =}\NormalTok{ Z\_m, }
  \AttributeTok{EP\_m =}\NormalTok{ EP\_m, }
  \AttributeTok{NU\_m =}\NormalTok{ NU\_m, }
  \AttributeTok{beta =}\NormalTok{ beta, }
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{delta =}\NormalTok{ delta, }
  \AttributeTok{rho =}\NormalTok{ rho}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
## [2,]    1
## [3,]    1
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Next, assume \(\rho = 0\). Assume that potential entrants simultaneously decide entry. Write a function \texttt{compute\_best\_response\_simultaneous\_entry} that returns the best response function of the potential participant given an entry decision. Then, write a function \texttt{compute\_simultaneous\_entry(X\_m,\ Z\_m,\ EP\_m,\ NU\_m,\ beta,\ alpha,\ delta)} that returns the equilibrium vector of entry at a market, given an initial entry decision where all firms decide to enter. To do so, you need to compute the best response given other firm's entry decisions, and iterate the best response mapping until convergence.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{compute\_best\_response\_simultaneous\_entry}\NormalTok{(}
    \AttributeTok{y\_m =}\NormalTok{ y\_m,}
    \AttributeTok{X\_m =}\NormalTok{ X\_m, }
    \AttributeTok{Z\_m =}\NormalTok{ Z\_m, }
    \AttributeTok{EP\_m =}\NormalTok{ EP\_m, }
    \AttributeTok{NU\_m =}\NormalTok{ NU\_m, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{    ) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
## [2,]    1
## [3,]    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{compute\_simultaneous\_entry}\NormalTok{(}
  \AttributeTok{X\_m =}\NormalTok{ X\_m, }
  \AttributeTok{Z\_m =}\NormalTok{ Z\_m, }
  \AttributeTok{EP\_m =}\NormalTok{ EP\_m, }
  \AttributeTok{NU\_m =}\NormalTok{ NU\_m, }
  \AttributeTok{beta =}\NormalTok{ beta, }
  \AttributeTok{alpha =}\NormalTok{ alpha,}
  \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
## [2,]    1
## [3,]    1
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function \texttt{compute\_sequential\_entry\_across\_markets(X,\ Z,\ EP,\ NU,\ beta,\ alpha,\ delta,\ rho)} compute the equilibrium entry vectors under the assumption of sequential entry. The output should be a list of entry vectors across markets. Write a function to compute the equilibrium payoffs across markets, \texttt{compute\_payoff\_across\_markets(Y,\ X,\ Z,\ EP,\ NU,\ beta,\ alpha,\ delta,\ rho)} and check that the payoffs under the equilibrium entry vectors are non-negative. Otherwise, there are some bugs in the code.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y\_sequential }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_sequential\_entry\_across\_markets}\NormalTok{(}
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{Z =}\NormalTok{ Z, }
    \AttributeTok{EP =}\NormalTok{ EP, }
    \AttributeTok{NU =}\NormalTok{ NU, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{rho =}\NormalTok{ rho}
\NormalTok{    )}
\NormalTok{Y\_sequential[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
## [2,]    1
## [3,]    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y\_sequential[[M]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    1
## [2,]    1
## [3,]    1
## [4,]    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{payoff\_sequential }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_payoff\_across\_markets}\NormalTok{(}
    \AttributeTok{Y =}\NormalTok{ Y\_sequential, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{Z =}\NormalTok{ Z, }
    \AttributeTok{EP =}\NormalTok{ EP, }
    \AttributeTok{NU =}\NormalTok{ NU, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{rho =}\NormalTok{ rho}
\NormalTok{    )}
\FunctionTok{min}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(payoff\_sequential))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Write a function \texttt{compute\_simultaneous\_entry\_across\_markets(X,\ Z,\ EP,\ NU,\ beta,\ alpha,\ delta,\ rho\ =\ 0)} compute the equilibrium entry vectors under the assumption of simultaneous entry. The output should be a list of entry vectors across markets. Check that the payoffs under the equilibrium entry vectors are non-negative. Otherwise, there are some bugs in the code. I also recommend to write this function with
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute simultaneous entry across markets}
\NormalTok{Y\_simultaneous }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_simultaneous\_entry\_across\_markets}\NormalTok{(}
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{Z =}\NormalTok{ Z, }
    \AttributeTok{EP =}\NormalTok{ EP, }
    \AttributeTok{NU =}\NormalTok{ NU, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{delta =}\NormalTok{ delta)}
\NormalTok{Y\_simultaneous[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
## [2,]    1
## [3,]    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y\_simultaneous[[M]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    1
## [2,]    1
## [3,]    1
## [4,]    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{payoff\_simultaneous }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_payoff\_across\_markets}\NormalTok{(}
    \AttributeTok{Y =}\NormalTok{ Y\_simultaneous, }
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{Z =}\NormalTok{ Z, }
    \AttributeTok{EP =}\NormalTok{ EP, }
    \AttributeTok{NU =}\NormalTok{ NU, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{rho =} \DecValTok{0}
\NormalTok{    )}
\FunctionTok{min}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(payoff\_simultaneous))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\section{Estimate the parameters}\label{estimate-the-parameters-4}

We estimate the parameters by matching the actual and predicted number of entrants in each market. To do so, we simulate the model for \(R\) times.
Under the assumption of the sequential entry, we can uniquely predict the equilibrium identify of the entrants. So, we consider the following objective function:
\[
\frac{1}{RM}\sum_{r = 1}^R \sum_{m = 1}^M \left[\sum_{i = 1}^{N_m}|y_{im} - y_{im}^{(r)}| \right]^2,
\]
where \(y_{im}^{(r)}\) is the entry decision in \(r\)-th simulation. On the other hand, under the assumption of the simultaneous entry, we can only uniquely predict the equilibrium number of the entrants. So, we consider the following objective function:
\[
\frac{1}{RM}\sum_{r = 1}^R \sum_{m = 1}^M \left[\sum_{i = 1}^{N_m}(y_{im} - y_{im}^{(r)}) \right]^2,
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw \(R\) unobserved shocks:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
 \FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# unobserved market attributes}
\NormalTok{EP\_mc }\OtherTok{\textless{}{-}}
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{r =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{R}
\NormalTok{    ) }\SpecialCharTok{\%dorng\%}\NormalTok{ \{}
\NormalTok{    EP }\OtherTok{\textless{}{-}} 
      \FunctionTok{matrix}\NormalTok{(}
      \FunctionTok{rnorm}\NormalTok{(M),}
      \AttributeTok{nrow =}\NormalTok{ M}
\NormalTok{      )}
    \FunctionTok{return}\NormalTok{(EP)}
\NormalTok{  \}}


\FunctionTok{head}\NormalTok{(EP\_mc[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]
## [1,]  0.74570967
## [2,] -0.07155828
## [3,] -0.03724045
## [4,]  0.69069075
## [5,] -0.71328829
## [6,]  0.01630815
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# unobserved entrant attributes}
\NormalTok{NU\_mc }\OtherTok{\textless{}{-}}
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{r =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{R}
\NormalTok{    ) }\SpecialCharTok{\%dorng\%}\NormalTok{ \{}
\NormalTok{  NU }\OtherTok{\textless{}{-}}
    \FunctionTok{foreach}\NormalTok{ (}
      \AttributeTok{m =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{M}
\NormalTok{      ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{      NU\_m }\OtherTok{\textless{}{-}} 
        \FunctionTok{matrix}\NormalTok{(}
        \FunctionTok{rnorm}\NormalTok{(E[m]),}
        \AttributeTok{nrow =}\NormalTok{ E[m]}
\NormalTok{        )}
      \FunctionTok{return}\NormalTok{(NU\_m)}
\NormalTok{    \}}
  \FunctionTok{return}\NormalTok{(NU)}
\NormalTok{  \}}

\NormalTok{NU\_mc[[}\DecValTok{1}\NormalTok{]][[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]
## [1,]  0.2226442
## [2,] -1.1481303
## [3,] -0.1690491
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write a function \texttt{compute\_monte\_carlo\_sequential\_entry(X,\ Z,\ EP\_mc,\ NU\_mc,\ beta,\ alpha,\ delta,\ rho)} that returns the Monte Carlo simulation. Then, write function \texttt{compute\_objective\_sequential\_entry(Y,\ X,\ Z,\ EP\_mc,\ NU\_mc,\ theta)} that calls\texttt{compute\_monte\_carlo\_sequential\_entry} and returns the value of the objective function given data and parameters under the assumption of sequential entry.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sequential entry}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
\NormalTok{  theta\_sequential }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    beta, }
\NormalTok{    alpha, }
\NormalTok{    delta, }
\NormalTok{    rho}
\NormalTok{    )}
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ Y\_sequential}
\CommentTok{\# compute monte carlo simulations }
\NormalTok{Y\_mc }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_monte\_carlo\_sequential\_entry}\NormalTok{(}
    \AttributeTok{X =}\NormalTok{ X, }
    \AttributeTok{Z =}\NormalTok{ Z, }
    \AttributeTok{EP\_mc =}\NormalTok{ EP\_mc, }
    \AttributeTok{NU\_mc =}\NormalTok{ NU\_mc, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{rho =}\NormalTok{ rho}
\NormalTok{    )}
\NormalTok{Y\_mc[[}\DecValTok{1}\NormalTok{]][[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
## [2,]    1
## [3,]    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute objective function}
\FunctionTok{compute\_objective\_sequential\_entry}\NormalTok{(}
  \AttributeTok{Y =}\NormalTok{ Y, }
  \AttributeTok{X =}\NormalTok{ X, }
  \AttributeTok{Z =}\NormalTok{ Z, }
  \AttributeTok{EP\_mc =}\NormalTok{ EP\_mc, }
  \AttributeTok{NU\_mc =}\NormalTok{ NU\_mc, }
  \AttributeTok{theta =}\NormalTok{ theta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.34
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write a function \texttt{compute\_objective\_simultaneous\_entry(Y,\ X,\ Z,\ EP\_mc,\ NU\_mc,\ theta)} that returns the value of the objective function given data and parameters under the assumption of simultaneous entry.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# simultaneous entry}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
\NormalTok{  theta\_simultaneous }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    beta, }
\NormalTok{    alpha, }
\NormalTok{    delta}
\NormalTok{    )}
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ Y\_simultaneous}
\CommentTok{\# compute monte carlo simulations}
\NormalTok{Y\_mc }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_monte\_carlo\_simultaneous\_entry}\NormalTok{(}
  \AttributeTok{X =}\NormalTok{ X, }
  \AttributeTok{Z =}\NormalTok{ Z, }
  \AttributeTok{EP\_mc =}\NormalTok{ EP\_mc, }
  \AttributeTok{NU\_mc =}\NormalTok{ NU\_mc, }
  \AttributeTok{beta =}\NormalTok{ beta, }
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{  )}
\NormalTok{Y\_mc[[}\DecValTok{1}\NormalTok{]][[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
## [2,]    1
## [3,]    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute objective function}
\FunctionTok{compute\_objective\_simultaneous\_entry}\NormalTok{(}
  \AttributeTok{Y =}\NormalTok{ Y, }
  \AttributeTok{X =}\NormalTok{ X, }
  \AttributeTok{Z =}\NormalTok{ Z, }
  \AttributeTok{EP\_mc =}\NormalTok{ EP\_mc, }
  \AttributeTok{NU\_mc =}\NormalTok{ NU\_mc, }
  \AttributeTok{theta =}\NormalTok{ theta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2456
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Check the value of the objective function around the true parameter under the assumption of the sequential entry.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sequential entry}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
\NormalTok{  theta\_sequential }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    beta, }
\NormalTok{    alpha, }
\NormalTok{    delta, }
\NormalTok{    rho}
\NormalTok{    )}
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ Y\_sequential}
\NormalTok{model }\OtherTok{\textless{}{-}}\NormalTok{ compute\_sequential\_entry\_across\_markets}
\NormalTok{label }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
           \FunctionTok{paste}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta\_"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{""}\NormalTok{), }
           \FunctionTok{paste}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{alpha\_"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{L, }\AttributeTok{sep =} \StringTok{""}\NormalTok{),}
           \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{delta"}\NormalTok{,}
           \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{rho"}
\NormalTok{           )}
\NormalTok{label }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"$"}\NormalTok{, label, }\StringTok{"$"}\NormalTok{, }\AttributeTok{sep =} \StringTok{""}\NormalTok{)}
\CommentTok{\# compute the graph}
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta)}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{  theta\_i }\OtherTok{\textless{}{-}}\NormalTok{ theta[i]}
\NormalTok{  theta\_i\_list }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i }\SpecialCharTok{*} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{1.5}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{  objective\_i }\OtherTok{\textless{}{-}} 
    \FunctionTok{foreach}\NormalTok{ (}
              \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_i\_list),}
             \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{             ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{               theta\_ij }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i\_list[j]}
\NormalTok{               theta\_j }\OtherTok{\textless{}{-}}\NormalTok{ theta}
\NormalTok{               theta\_j[i] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_ij}
\NormalTok{               objective\_ij }\OtherTok{\textless{}{-}} 
                 \FunctionTok{compute\_objective\_sequential\_entry}\NormalTok{(}
\NormalTok{                   Y, }
\NormalTok{                   X, }
\NormalTok{                   Z, }
\NormalTok{                   EP\_mc, }
\NormalTok{                   NU\_mc, }
\NormalTok{                   theta\_j}
\NormalTok{                   )}
               \FunctionTok{return}\NormalTok{(objective\_ij)}
\NormalTok{             \}}
\NormalTok{  df\_graph }\OtherTok{\textless{}{-}} 
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ theta\_i\_list, }
      \AttributeTok{y =}\NormalTok{ objective\_i}
\NormalTok{      ) }
\NormalTok{  g }\OtherTok{\textless{}{-}} 
    \FunctionTok{ggplot}\NormalTok{(}
      \AttributeTok{data =}\NormalTok{ df\_graph, }
      \FunctionTok{aes}\NormalTok{(}
        \AttributeTok{x =}\NormalTok{ x, }
        \AttributeTok{y =}\NormalTok{ y}
\NormalTok{        )}
\NormalTok{      ) }\SpecialCharTok{+} 
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}
      \AttributeTok{xintercept =}\NormalTok{ theta\_i, }
      \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"objective function"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(label[i])) }\SpecialCharTok{+} 
    \FunctionTok{theme\_classic}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(g)}
\NormalTok{\}}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  graph, }
  \AttributeTok{file =} \StringTok{"lecture/data/a6/graph\_sequential.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(}
  \AttributeTok{file =} \StringTok{"lecture/data/a6/graph\_sequential.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\NormalTok{graph}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-165-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-165-2} \end{center}

\begin{verbatim}
## 
## [[3]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-165-3} \end{center}

\begin{verbatim}
## 
## [[4]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-165-4} \end{center}

\begin{verbatim}
## 
## [[5]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-165-5} \end{center}

\begin{verbatim}
## 
## [[6]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-165-6} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Check the value of the objective function around the true parameter under the assumption of the simultaneous entry.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# simultaneous entry}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
\NormalTok{  theta\_simultaneous }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    beta, }
\NormalTok{    alpha, }
\NormalTok{    delta}
\NormalTok{    )}
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ Y\_simultaneous}
\NormalTok{model }\OtherTok{\textless{}{-}}\NormalTok{ compute\_simultaneous\_entry\_across\_markets}
\NormalTok{label }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
           \FunctionTok{paste}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta\_"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\AttributeTok{sep =} \StringTok{""}\NormalTok{), }
           \FunctionTok{paste}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{alpha\_"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{L, }\AttributeTok{sep =} \StringTok{""}\NormalTok{),}
           \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{delta"}
\NormalTok{           )}
\NormalTok{label }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"$"}\NormalTok{, label, }\StringTok{"$"}\NormalTok{, }\AttributeTok{sep =} \StringTok{""}\NormalTok{)}
\CommentTok{\# compute the graph}
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta)}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{  theta\_i }\OtherTok{\textless{}{-}}\NormalTok{ theta[i]}
\NormalTok{  theta\_i\_list }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i }\SpecialCharTok{*} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\FloatTok{1.5}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{  objective\_i }\OtherTok{\textless{}{-}} 
    \FunctionTok{foreach}\NormalTok{ (}
              \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_i\_list),}
              \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{             ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{               theta\_ij }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i\_list[j]}
\NormalTok{               theta\_j }\OtherTok{\textless{}{-}}\NormalTok{ theta}
\NormalTok{               theta\_j[i] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_ij}
\NormalTok{               objective\_ij }\OtherTok{\textless{}{-}} 
                 \FunctionTok{compute\_objective\_simultaneous\_entry}\NormalTok{(}
\NormalTok{                   Y, }
\NormalTok{                   X, }
\NormalTok{                   Z, }
\NormalTok{                   EP\_mc, }
\NormalTok{                   NU\_mc, }
\NormalTok{                   theta\_j}
\NormalTok{                   )}
               \FunctionTok{return}\NormalTok{(objective\_ij)}
\NormalTok{             \}}
\NormalTok{  df\_graph }\OtherTok{\textless{}{-}} 
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ theta\_i\_list, }
      \AttributeTok{y =}\NormalTok{ objective\_i}
\NormalTok{      ) }
\NormalTok{  g }\OtherTok{\textless{}{-}} 
    \FunctionTok{ggplot}\NormalTok{(}
    \AttributeTok{data =}\NormalTok{ df\_graph, }
    \FunctionTok{aes}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ x, }
      \AttributeTok{y =}\NormalTok{ y}
\NormalTok{      )}
\NormalTok{    ) }\SpecialCharTok{+} 
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}
      \AttributeTok{xintercept =}\NormalTok{ theta\_i, }
      \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"objective function"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(label[i])) }\SpecialCharTok{+} 
    \FunctionTok{theme\_classic}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(g)}
\NormalTok{\}}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  graph, }
  \AttributeTok{file =} \StringTok{"lecture/data/a6/graph\_simultaneous.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a6/graph\_simultaneous.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{graph}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-167-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-167-2} \end{center}

\begin{verbatim}
## 
## [[3]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-167-3} \end{center}

\begin{verbatim}
## 
## [[4]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-167-4} \end{center}

\begin{verbatim}
## 
## [[5]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-167-5} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Estimate the parameters under the assumption of the sequential entry.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sequential entry}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
\NormalTok{  theta\_sequential }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    beta, }
\NormalTok{    alpha, }
\NormalTok{    delta, }
\NormalTok{    rho}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ Y\_sequential}
\NormalTok{result\_sequential }\OtherTok{\textless{}{-}}
  \FunctionTok{optim}\NormalTok{(}
        \AttributeTok{par =}\NormalTok{ theta,}
        \AttributeTok{fn =}\NormalTok{ compute\_objective\_sequential\_entry,}
        \AttributeTok{method =} \StringTok{"Nelder{-}Mead"}\NormalTok{,}
        \AttributeTok{Y =}\NormalTok{ Y,}
        \AttributeTok{X =}\NormalTok{ X,}
        \AttributeTok{Z =}\NormalTok{ Z,}
        \AttributeTok{EP\_mc =}\NormalTok{ EP\_mc,}
        \AttributeTok{NU\_mc =}\NormalTok{ NU\_mc}
\NormalTok{        )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  result\_sequential, }
  \AttributeTok{file =} \StringTok{"lecture/data/a6/estimate\_sequential.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result\_sequential }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a6/estimate\_sequential.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{result\_sequential}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $par
## [1] 0.7761887 0.2204343 1.0747480 2.0150864 0.9116741 0.2875538
## 
## $value
## [1] 0.2638
## 
## $counts
## function gradient 
##      233       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comparison }\OtherTok{\textless{}{-}}

  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{actual =}\NormalTok{ theta,}
    \AttributeTok{estimate =}\NormalTok{ result\_sequential}\SpecialCharTok{$}\NormalTok{par}
\NormalTok{  )}
\NormalTok{comparison}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      actual  estimate
## 1 0.6264538 0.7761887
## 2 0.1836433 0.2204343
## 3 0.8356286 1.0747480
## 4 1.5952808 2.0150864
## 5 1.0000000 0.9116741
## 6 0.3295078 0.2875538
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Estimate the parameters under the assumption of the simultaneous entry. Set the lower bound for \(\delta\) at 0.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# simultaneous entry}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
\NormalTok{  theta\_simultaneous }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    beta, }
\NormalTok{    alpha, }
\NormalTok{    delta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ Y\_simultaneous}
\NormalTok{result\_simultaneous }\OtherTok{\textless{}{-}}
  \FunctionTok{optim}\NormalTok{(}
        \AttributeTok{par =}\NormalTok{ theta,}
        \AttributeTok{fn =}\NormalTok{ compute\_objective\_simultaneous\_entry,}
        \AttributeTok{method =} \StringTok{"Nelder{-}Mead"}\NormalTok{,}
        \AttributeTok{Y =}\NormalTok{ Y,}
        \AttributeTok{X =}\NormalTok{ X,}
        \AttributeTok{Z =}\NormalTok{ Z,}
        \AttributeTok{EP\_mc =}\NormalTok{ EP\_mc,}
        \AttributeTok{NU\_mc =}\NormalTok{ NU\_mc)}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  result\_simultaneous, }
  \AttributeTok{file =} \StringTok{"lecture/data/a6/estimate\_simultaneous.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result\_simultaneous }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a6/estimate\_simultaneous.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{result\_simultaneous}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $par
## [1] 0.7347919 0.2151107 0.9427083 1.7495325 0.9448480
## 
## $value
## [1] 0.2158
## 
## $counts
## function gradient 
##      151       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comparison }\OtherTok{\textless{}{-}}

  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{actual =}\NormalTok{ theta,}
    \AttributeTok{estimate =}\NormalTok{ result\_simultaneous}\SpecialCharTok{$}\NormalTok{par}
\NormalTok{  )}
\NormalTok{comparison}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      actual  estimate
## 1 0.6264538 0.7347919
## 2 0.1836433 0.2151107
## 3 0.8356286 0.9427083
## 4 1.5952808 1.7495325
## 5 1.0000000 0.9448480
\end{verbatim}

\section{Conduct counterfactual simulations}\label{conduct-counterfactual-simulations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fix the first draw of the Monte Carlo shocks. Suppose that the competitive effect becomes mild, i.e.~\(\delta\) is changed to 0.5. Under these shocks, compute the equilibrium number of entrants across markets and plot the histogram with the estimated and counterfactual parameters. Conduct this analysis under the assumptions of sequential and simultaneous entry.
\end{enumerate}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-174-1} \end{center}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-175-1} \end{center}

\chapter{Assignment 7: Dynamic Decision}\label{assignment7}

\section{Simulate data}\label{simulate-data-6}

Suppose that there is a firm and it makes decisions for \(t = 1, \cdots, \infty\). We solve the model under the infinite-horizon assumption, but generate data only for \(t = 1, \cdots, T\). There are \(L = 5\) state \(s \in  \{1, 2, 3, 4, 5\}\) states for the player. The firm can choose \(K + 1 = 2\) actions \(a \in \{0, 1\}\).

The mean period payoff to the firm is:
\[
\pi(a, s) :=  \alpha \ln s - \beta a,
\]
where \(\alpha, \beta > 0\). The period payoff is:
\[
\pi(a, s) + \epsilon(a),
\]
and \(\epsilon(a)\) is an i.i.d. type-I extreme random variable that is independent of all the other variables.

At the beginning of each period, the state \(s\) and choice-specific shocks \(\epsilon(a), a = 0, 1\) are realized, and the the firm chooses her action. Then, the game moves to the next period.

Suppose that \(s > 1\) and \(s < L\). If \(a = 0\), the state stays at the same state with probability \(1 - \kappa\) and moves down by 1 with probability \(\kappa\). If \(a = 1\), the state moves up by 1 with probability \(\gamma\), moves down by 1 with probability \(\kappa\), and stays at the same with probability \(1 - \kappa - \gamma\).

Suppose that \(s = 1\). If \(a = 0\), the state stays at the same state with probability 1. If \(a = 1\), the state moves up by 1 with probability \(\gamma\) and stays at the same with probability \(1 - \gamma\).

Suppose that \(s = L\). If \(a = 0\), the state stays at the same state with probability \(1 - \kappa\) and moves down by 1 with probability \(\kappa\). If \(a = 1\), the state moves down by 1 with probability \(\kappa\), and stays at the same with probability \(1 - \kappa\).

The mean period profit is summarized in \(\Pi\) as:
\[
\Pi :=
\begin{pmatrix}
\pi(0, 1)\\
\vdots\\
\pi(K, 1)\\
\vdots \\
\pi(0, L)\\
\vdots\\
\pi(K, L)\\
\end{pmatrix}
\]

The transition law is summarized in \(G\) as:

\[
g(a, s, s') := \mathbb{P}\{s_{t + 1} = s'|s_t = s, a_t = a\},
\]

\[
G := 
\begin{pmatrix}
g(0, 1, 1) & \cdots & g(0, 1, L)\\
\vdots & & \vdots \\
g(K, 1, 1) & \cdots & g(K, 1, L)\\
& \vdots & \\
g(0, L, 1) & \cdots & g(0, L, L)\\
\vdots & & \vdots \\
g(K, L, 1) & \cdots & g(K, L, L)\\
\end{pmatrix}.
\]
The discount factor is denoted by \(\delta\). We simulate data for \(N\) firms for \(T\) periods each.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set constants and parameters as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# set constants }
\NormalTok{L }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{K }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{lambda }\OtherTok{\textless{}{-}} \FloatTok{1e{-}10}
\CommentTok{\# set parameters}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{beta }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{kappa }\OtherTok{\textless{}{-}} \FloatTok{0.1}
\NormalTok{gamma }\OtherTok{\textless{}{-}} \FloatTok{0.6}
\NormalTok{delta }\OtherTok{\textless{}{-}} \FloatTok{0.95}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write function \texttt{compute\_pi(alpha,\ beta,\ L,\ K)} that computes \(\Pi\) given parameters and compute the true \(\Pi\) under the true parameters. Don't use methods in \texttt{dplyr} and deal with matrix operations.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{PI }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_PI}\NormalTok{(}
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{L =}\NormalTok{ L, }
    \AttributeTok{K =}\NormalTok{ K}
\NormalTok{    ); }
\NormalTok{PI}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]
## k0_l1  0.0000000
## k1_l1 -3.0000000
## k0_l2  0.3465736
## k1_l2 -2.6534264
## k0_l3  0.5493061
## k1_l3 -2.4506939
## k0_l4  0.6931472
## k1_l4 -2.3068528
## k0_l5  0.8047190
## k1_l5 -2.1952810
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write function \texttt{compute\_G(kappa,\ gamma,\ L,\ K)} that computes \(G\) given parameters and compute the true \(G\) under the true parameters. Don't use methods in \texttt{dplyr} and deal with matrix operations.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{G }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_G}\NormalTok{(}
    \AttributeTok{kappa =}\NormalTok{ kappa, }
    \AttributeTok{gamma =}\NormalTok{ gamma, }
    \AttributeTok{L =}\NormalTok{ L, }
    \AttributeTok{K =}\NormalTok{ K}
\NormalTok{    ); }
\NormalTok{G}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        l1  l2  l3  l4  l5
## k0_l1 1.0 0.0 0.0 0.0 0.0
## k1_l1 0.4 0.6 0.0 0.0 0.0
## k0_l2 0.1 0.9 0.0 0.0 0.0
## k1_l2 0.1 0.3 0.6 0.0 0.0
## k0_l3 0.0 0.1 0.9 0.0 0.0
## k1_l3 0.0 0.1 0.3 0.6 0.0
## k0_l4 0.0 0.0 0.1 0.9 0.0
## k1_l4 0.0 0.0 0.1 0.3 0.6
## k0_l5 0.0 0.0 0.0 0.1 0.9
## k1_l5 0.0 0.0 0.0 0.1 0.9
\end{verbatim}

The exante-value function is written as a function of a conditional choice probability as follows:
\[
\varphi^{(\theta_1, \theta_2)}(p) := [I - \delta \Sigma(p) G]^{-1}\Sigma(p)[\Pi + E(p)],
\]
where \(\theta_1 = (\alpha, \beta)\) and \(\theta_2 = (\kappa, \gamma)\) and:
\[
\Sigma(p) =
\begin{pmatrix}
p(1)' & & \\
 & \ddots & \\
 & & p(L)'
\end{pmatrix}
\]
and:
\[
E(p) = 
\gamma - \ln p.
\]
Note that \(\gamma\) in the formula of \(E(p)\) refers to the Euler constant, not the parameter defined before.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Write a function \texttt{compute\_exante\_value(p,\ PI,\ G,\ L,\ K,\ delta)} that returns the exante value function given a conditional choice probability. Don't use methods in \texttt{dplyr} and deal with matrix operations. When a choice probability is zero at some element, the corresponding element of \(E(p)\) can be set at zero, because anyway we multiply the zero probability to the element and the corresponding element in \(E(p)\) does not affect the result.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} 
  \FunctionTok{matrix}\NormalTok{(}
    \FunctionTok{rep}\NormalTok{(}\FloatTok{0.5}\NormalTok{, L }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)), }
    \AttributeTok{ncol =} \DecValTok{1}
\NormalTok{    ); }
\NormalTok{p}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       [,1]
##  [1,]  0.5
##  [2,]  0.5
##  [3,]  0.5
##  [4,]  0.5
##  [5,]  0.5
##  [6,]  0.5
##  [7,]  0.5
##  [8,]  0.5
##  [9,]  0.5
## [10,]  0.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_exante\_value}\NormalTok{(}
    \AttributeTok{p =}\NormalTok{ p, }
    \AttributeTok{PI =}\NormalTok{ PI, }
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{L =}\NormalTok{ L, }
    \AttributeTok{K =}\NormalTok{ K, }
    \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{    ); }
\NormalTok{V}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         [,1]
## l1  5.777876
## l2  7.597282
## l3  9.126304
## l4 10.115439
## l5 10.593438
\end{verbatim}

The optimal conditional choice probability is written as a function of an exante value function as follows:
\[
\Lambda^{(\theta_1, \theta_2)}(V)(a, s) := \frac{\exp[\pi(a, s) + \delta \sum_{s'}V(s')g(a, s, s')]}{\sum_{a'}\exp[\pi(a', s) + \delta \sum_{s'}V(s')g(a', s, s')]},
\]
where \(V\) is an exante value function.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Write a function \texttt{compute\_ccp(V,\ PI,\ G,\ L,\ K,\ delta)} that returns the optimal conditional choice probability given an exante value function. Don't use methods in \texttt{dplyr} and deal with matrix operations. To do so, write a function \texttt{compute\_choice\_value(V,\ PI,\ G,\ delta)} that returns the choice-specific value function. Use this for debugging by checking if the results are intuitive.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{value }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_choice\_value}\NormalTok{(}
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{PI =}\NormalTok{ PI, }
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{    ); }
\NormalTok{value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]
## k0_l1  5.488982
## k1_l1  3.526044
## k0_l2  7.391148
## k1_l2  5.262691
## k0_l3  9.074038
## k1_l3  6.637845
## k0_l4 10.208846
## k1_l4  7.481306
## k0_l5 10.823075
## k1_l5  7.823075
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_ccp}\NormalTok{(}
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{PI =}\NormalTok{ PI, }
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{L =}\NormalTok{ L, }
    \AttributeTok{K =}\NormalTok{ K, }
    \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{    ); }
\NormalTok{p}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]
## k0_l1 0.87685057
## k1_l1 0.12314943
## k0_l2 0.89363847
## k1_l2 0.10636153
## k0_l3 0.91954591
## k1_l3 0.08045409
## k0_l4 0.93863232
## k1_l4 0.06136768
## k0_l5 0.95257413
## k1_l5 0.04742587
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write a function that find the equilibrium conditional choice probability and ex-ante value function by iterating the update of an exante value function and an optimal conditional choice probability. The iteration should stop when \(\max_s|V^{(r + 1)}(s) - V^{(r)}(s)| < \lambda\) with \(\lambda = 10^{-10}\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output }\OtherTok{\textless{}{-}} 
  \FunctionTok{solve\_dynamic\_decision}\NormalTok{(}
    \AttributeTok{PI =}\NormalTok{ PI, }
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{L =}\NormalTok{ L, }
    \AttributeTok{K =}\NormalTok{ K, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{lambda =}\NormalTok{ lambda}
\NormalTok{    ); }
\NormalTok{output}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $p
##             [,1]
## k0_l1 0.82218962
## k1_l1 0.17781038
## k0_l2 0.80024354
## k1_l2 0.19975646
## k0_l3 0.83074516
## k1_l3 0.16925484
## k0_l4 0.87691534
## k1_l4 0.12308466
## k0_l5 0.95257413
## k1_l5 0.04742587
## 
## $V
##        [,1]
## l1 15.46000
## l2 18.03675
## l3 20.86514
## l4 23.33721
## l5 25.15557
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ output}\SpecialCharTok{$}\NormalTok{p}
\NormalTok{V }\OtherTok{\textless{}{-}}\NormalTok{ output}\SpecialCharTok{$}\NormalTok{V}
\NormalTok{value }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_choice\_value}\NormalTok{(}
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{PI =}\NormalTok{ PI, }
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{    ); }
\NormalTok{value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           [,1]
## k0_l1 14.68700
## k1_l1 13.15574
## k0_l2 17.23669
## k1_l2 15.84887
## k0_l3 20.10249
## k1_l3 18.51157
## k0_l4 22.62865
## k1_l4 20.66511
## k0_l5 24.52976
## k1_l5 21.52976
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function \texttt{simulate\_dynamic\_decision(p,\ s,\ PI,\ G,\ L,\ K,\ T,\ delta,\ seed)} that simulate the data for a single firm starting from an initial state for \(T\) periods. The function should accept a value of seed and set the seed at the beginning of the procedure inside the function, because the process is stochastic. To match the generated random numbers, for each period, generate action using \texttt{rmultinom} and then state using \texttt{rmultinom}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set initial value}
\NormalTok{s }\OtherTok{\textless{}{-}} \DecValTok{1}
\CommentTok{\# draw simulation for a firm}
\NormalTok{seed }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{df }\OtherTok{\textless{}{-}} 
  \FunctionTok{simulate\_dynamic\_decision}\NormalTok{(}
    \AttributeTok{p =}\NormalTok{ p, }
    \AttributeTok{s =}\NormalTok{ s, }
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{L =}\NormalTok{ L, }
    \AttributeTok{K =}\NormalTok{ K, }
    \AttributeTok{T =}\NormalTok{ T, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{seed =}\NormalTok{ seed}
\NormalTok{    ); }
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 100 x 3
##        t     s     a
##    <int> <dbl> <dbl>
##  1     1     1     0
##  2     2     1     0
##  3     3     1     0
##  4     4     1     1
##  5     5     2     1
##  6     6     1     0
##  7     7     1     0
##  8     8     1     0
##  9     9     1     0
## 10    10     1     0
## # i 90 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Write a function \texttt{simulate\_dynamic\_decision\_across\_firms(p,\ s,\ PI,\ G,\ L,\ K,\ T,\ N,\ delta)} that returns simulation data for \(N\) firm. For firm \(i\), set the seed at \(i\)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} 
  \FunctionTok{simulate\_dynamic\_decision\_across\_firms}\NormalTok{(}
    \AttributeTok{p =}\NormalTok{ p, }
    \AttributeTok{s =}\NormalTok{ s,  }
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{L =}\NormalTok{ L, }
    \AttributeTok{K =}\NormalTok{ K, }
    \AttributeTok{T =}\NormalTok{ T, }
    \AttributeTok{N =}\NormalTok{ N, }
    \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{    )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  df, }
  \AttributeTok{file =} \StringTok{"lecture/data/a7/df.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a7/df.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 100,000 x 4
##        i     t     s     a
##    <int> <int> <dbl> <dbl>
##  1     1     1     1     0
##  2     1     2     1     0
##  3     1     3     1     0
##  4     1     4     1     1
##  5     1     5     2     1
##  6     1     6     1     0
##  7     1     7     1     0
##  8     1     8     1     0
##  9     1     9     1     0
## 10     1    10     1     0
## # i 99,990 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Write a function \texttt{estimate\_ccp(df)} that returns a non-parametric estimate of the conditional choice probability in the data. Compare the estimated conditional choice probability and the true conditional choice probability by a bar plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_est }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_ccp}\NormalTok{(}\AttributeTok{df =}\NormalTok{ df)}
\NormalTok{check\_ccp }\OtherTok{\textless{}{-}} 
  \FunctionTok{cbind}\NormalTok{(}
\NormalTok{    p, }
\NormalTok{    p\_est}
\NormalTok{    )}
\FunctionTok{colnames}\NormalTok{(check\_ccp) }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \StringTok{"true"}\NormalTok{, }
    \StringTok{"estimate"}
\NormalTok{    )}
\NormalTok{check\_ccp }\OtherTok{\textless{}{-}} 
\NormalTok{  check\_ccp }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  reshape2}\SpecialCharTok{::}\FunctionTok{melt}\NormalTok{()}
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ check\_ccp, }
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ Var1, }
    \AttributeTok{y =}\NormalTok{ value, }
    \AttributeTok{fill =}\NormalTok{ Var2}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}
    \AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }
    \AttributeTok{position =} \StringTok{"dodge"}
\NormalTok{    ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{fill =} \StringTok{"Value"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"action/state"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"probability"}\NormalTok{)  }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-186-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  Write a function \texttt{estimate\_G(df)} that returns a non-parametric estiamte of the transition matrix in the data. Compare the estimated transition matrix and the true transition matrix by a bar plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{G\_est }\OtherTok{\textless{}{-}} 
  \FunctionTok{estimate\_G}\NormalTok{(}
    \AttributeTok{df =}\NormalTok{ df}
\NormalTok{  ); }
\NormalTok{G\_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              l1         l2        l3         l4        l5
## k0_l1 1.0000000 0.00000000 0.0000000 0.00000000 0.0000000
## k1_l1 0.3930818 0.60691824 0.0000000 0.00000000 0.0000000
## k0_l2 0.1012162 0.89878384 0.0000000 0.00000000 0.0000000
## k1_l2 0.1031410 0.31276454 0.5840945 0.00000000 0.0000000
## k0_l3 0.0000000 0.09660837 0.9033916 0.00000000 0.0000000
## k1_l3 0.0000000 0.09974569 0.3071489 0.59310540 0.0000000
## k0_l4 0.0000000 0.00000000 0.1012564 0.89874358 0.0000000
## k1_l4 0.0000000 0.00000000 0.1039339 0.29966003 0.5964060
## k0_l5 0.0000000 0.00000000 0.0000000 0.09891400 0.9010860
## k1_l5 0.0000000 0.00000000 0.0000000 0.09751037 0.9024896
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{check\_G }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{type =} \StringTok{"true"}\NormalTok{, }
\NormalTok{    reshape2}\SpecialCharTok{::}\FunctionTok{melt}\NormalTok{(G)}
\NormalTok{    )}
\NormalTok{check\_G\_est }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{type =} \StringTok{"estimate"}\NormalTok{, }
\NormalTok{    reshape2}\SpecialCharTok{::}\FunctionTok{melt}\NormalTok{(G\_est)}
\NormalTok{    )}
\NormalTok{check\_G }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
\NormalTok{    check\_G, }
\NormalTok{    check\_G\_est}
\NormalTok{    )}
\NormalTok{check\_G}\SpecialCharTok{$}\NormalTok{variable }\OtherTok{\textless{}{-}}
  \FunctionTok{paste}\NormalTok{(}
\NormalTok{    check\_G}\SpecialCharTok{$}\NormalTok{Var1, }
\NormalTok{    check\_G}\SpecialCharTok{$}\NormalTok{Var2, }
    \AttributeTok{sep =} \StringTok{"\_"}
\NormalTok{    )}
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ check\_G, }
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ variable, }
    \AttributeTok{y =}\NormalTok{ value,}
    \AttributeTok{fill =}\NormalTok{ type}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{+}
    \FunctionTok{geom\_bar}\NormalTok{(}
      \AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }
      \AttributeTok{position =} \StringTok{"dodge"}
\NormalTok{      ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{fill =} \StringTok{"Value"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"action/state/state"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"probability"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_blank}\NormalTok{())  }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-187-1} \end{center}

\section{Estimate parameters}\label{estimate-parameters}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Vectorize the parameters as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta\_1 }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    alpha, }
\NormalTok{    beta}
\NormalTok{    )}
\NormalTok{theta\_2 }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    kappa, }
\NormalTok{    gamma}
\NormalTok{    )}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    theta\_1, }
\NormalTok{    theta\_2}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

First, we estimate the parameters by a nested fixed-point algorithm. The loglikelihood for \(\{a_{it}, s_{it}\}_{i = 1, \cdots, N, t = 1, \cdots, T}\) is:
\[
\frac{1}{NT} \sum_{i = 1}^N \sum_{t = 1}^T[\log\mathbb{P}\{a_{it}|s_{it}\} + \log \mathbb{P}\{s_{i, t + 1}|a_{it}, s_{it}\}],
\]
with \(\mathbb{P}\{s_{i, T + 1}|a_{iT}, s_{iT}\} = 1\) for all \(i\) as \(s_{i, T + 1}\) is not observed.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write a function \texttt{compute\_loglikelihood\_NFP(theta,\ df,\ delta,\ L,\ K)} that compute the loglikelihood.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loglikelihood }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_loglikelihood\_NFP}\NormalTok{(}
    \AttributeTok{theta =}\NormalTok{ theta, }
    \AttributeTok{df =}\NormalTok{ df, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{L =}\NormalTok{ L,}
    \AttributeTok{K =}\NormalTok{ K}
\NormalTok{    ); }
\NormalTok{loglikelihood}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.7474961
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Check the value of the objective function around the true parameter.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# label}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{alpha"}\NormalTok{, }
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta"}\NormalTok{, }
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{kappa"}\NormalTok{, }
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{gamma"}
\NormalTok{    )}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{paste}\NormalTok{(}
    \StringTok{"$"}\NormalTok{, }
\NormalTok{    label, }
    \StringTok{"$"}\NormalTok{, }
    \AttributeTok{sep =} \StringTok{""}
\NormalTok{    )}
\CommentTok{\# compute the graph}
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta)}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{  theta\_i }\OtherTok{\textless{}{-}}\NormalTok{ theta[i]}
\NormalTok{  theta\_i\_list }\OtherTok{\textless{}{-}} 
\NormalTok{    theta\_i }\SpecialCharTok{*} \FunctionTok{seq}\NormalTok{(}
    \FloatTok{0.8}\NormalTok{, }
    \FloatTok{1.2}\NormalTok{, }
    \AttributeTok{by =} \FloatTok{0.05}
\NormalTok{    )}
\NormalTok{  objective\_i }\OtherTok{\textless{}{-}} 
    \FunctionTok{foreach}\NormalTok{ (}
      \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_i\_list),}
      \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{      ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{               theta\_ij }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i\_list[j]}
\NormalTok{               theta\_j }\OtherTok{\textless{}{-}}\NormalTok{ theta}
\NormalTok{               theta\_j[i] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_ij}
\NormalTok{               objective\_ij }\OtherTok{\textless{}{-}} 
                 \FunctionTok{compute\_loglikelihood\_NFP}\NormalTok{(}
\NormalTok{                   theta\_j, }
\NormalTok{                   df, }
\NormalTok{                   delta, }
\NormalTok{                   L, }
\NormalTok{                   K}
\NormalTok{                   ); }
\NormalTok{               loglikelihood}

               \FunctionTok{return}\NormalTok{(objective\_ij)}
\NormalTok{             \}}
\NormalTok{  df\_graph }\OtherTok{\textless{}{-}} 
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ theta\_i\_list, }
      \AttributeTok{y =}\NormalTok{ objective\_i}
\NormalTok{      ) }
\NormalTok{  g }\OtherTok{\textless{}{-}} 
    \FunctionTok{ggplot}\NormalTok{(}
      \AttributeTok{data =}\NormalTok{ df\_graph, }
      \FunctionTok{aes}\NormalTok{(}
        \AttributeTok{x =}\NormalTok{ x, }
        \AttributeTok{y =}\NormalTok{ y}
\NormalTok{        )}
\NormalTok{      ) }\SpecialCharTok{+} 
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}
      \AttributeTok{xintercept =}\NormalTok{ theta\_i, }
      \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"objective function"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(label[i]))  }\SpecialCharTok{+} 
    \FunctionTok{theme\_classic}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(g)}
\NormalTok{\}}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  graph, }
  \AttributeTok{file =} \StringTok{"lecture/data/a7/NFP\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a7/NFP\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{graph}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-191-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-191-2} \end{center}

\begin{verbatim}
## 
## [[3]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-191-3} \end{center}

\begin{verbatim}
## 
## [[4]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-191-4} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Estiamte the parameters by maximizing the loglikelihood. To keep the model to be well-defined, impose an ad hoc lower and upper bounds such that \(\alpha \in [0, 1], \beta \in [0, 5], \kappa \in [0, 0.2], \gamma \in [0, 0.7]\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{length}\NormalTok{(theta))}
\NormalTok{upper }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\FloatTok{0.7}\NormalTok{)}
\NormalTok{NFP\_result }\OtherTok{\textless{}{-}}
  \FunctionTok{optim}\NormalTok{(}
    \AttributeTok{par =}\NormalTok{ theta,}
    \AttributeTok{fn =}\NormalTok{ compute\_loglikelihood\_NFP,}
    \AttributeTok{method =} \StringTok{"L{-}BFGS{-}B"}\NormalTok{,}
    \AttributeTok{lower =}\NormalTok{ lower,}
    \AttributeTok{upper =}\NormalTok{ upper,}
    \AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{fnscale =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{df =}\NormalTok{ df, }
    \AttributeTok{delta =}\NormalTok{ delta,}
    \AttributeTok{L =}\NormalTok{ L,}
    \AttributeTok{K =}\NormalTok{ K}
\NormalTok{  )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  NFP\_result, }
  \AttributeTok{file =} \StringTok{"lecture/data/a7/NFP\_result.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{NFP\_result }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a7/NFP\_result.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{NFP\_result}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $par
## [1] 0.5273235 3.0652558 0.1000122 0.5955431
## 
## $value
## [1] -0.7474743
## 
## $counts
## function gradient 
##       21       21 
## 
## $convergence
## [1] 0
## 
## $message
## [1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{compare }\OtherTok{\textless{}{-}}
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{true =}\NormalTok{ theta,}
    \AttributeTok{estimate =}\NormalTok{ NFP\_result}\SpecialCharTok{$}\NormalTok{par}
\NormalTok{  ); }
\NormalTok{compare}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   true  estimate
## 1  0.5 0.5273235
## 2  3.0 3.0652558
## 3  0.1 0.1000122
## 4  0.6 0.5955431
\end{verbatim}

Next, we estimate the parameters by CCP approach.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Write a function \texttt{estimate\_theta\_2(df)} that returns the estimates of \(\kappa\) and \(\gamma\) directly from data by counting relevant events.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta\_2\_est }\OtherTok{\textless{}{-}} 
  \FunctionTok{estimate\_theta\_2}\NormalTok{(}
    \AttributeTok{df =}\NormalTok{ df}
\NormalTok{  ); }
\NormalTok{theta\_2\_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09988488 0.59551895
\end{verbatim}

The objective function of the minimum distance estimator based on the conditional choice probability approach is:
\[
\frac{1}{KL}\sum_{s = 1}^L \sum_{a = 1}^K\{\hat{p}(a, s) - p^{(\theta_1, \theta_2)}(a, s)\}^2,
\]
where \(\hat{p}\) is the non-parametric estimate of the conditional choice probability and \(p^{(\theta_1, \theta_2)}\) is the optimal conditional choice probability under parameters \(\theta_1\) and \(\theta_2\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write a function \texttt{compute\_CCP\_objective(theta\_1,\ theta\_2,\ p\_est,\ L,\ K,\ delta)} that returns the objective function of the above minimum distance estimator given a non-parametric estimate of the conditional choice probability and \(\theta_1\) and \(\theta_2\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{compute\_CCP\_objective}\NormalTok{(}
  \AttributeTok{theta\_1 =}\NormalTok{ theta\_1, }
  \AttributeTok{theta\_2 =}\NormalTok{ theta\_2, }
  \AttributeTok{p\_est =}\NormalTok{ p\_est,}
  \AttributeTok{L =}\NormalTok{ L, }
  \AttributeTok{K =}\NormalTok{ K, }
  \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5.000511e-06
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Check the value of the objective function around the true parameter.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# label}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{alpha"}\NormalTok{, }
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta"}
\NormalTok{    )}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{paste}\NormalTok{(}
    \StringTok{"$"}\NormalTok{, }
\NormalTok{    label, }
    \StringTok{"$"}\NormalTok{, }
    \AttributeTok{sep =} \StringTok{""}
\NormalTok{    )}
\CommentTok{\# compute the graph}
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_1)}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{  theta\_i }\OtherTok{\textless{}{-}}\NormalTok{ theta\_1[i]}
\NormalTok{  theta\_i\_list }\OtherTok{\textless{}{-}} 
\NormalTok{    theta\_i }\SpecialCharTok{*} \FunctionTok{seq}\NormalTok{(}
      \FloatTok{0.8}\NormalTok{, }
      \FloatTok{1.2}\NormalTok{, }
      \AttributeTok{by =} \FloatTok{0.05}
\NormalTok{      )}
\NormalTok{  objective\_i }\OtherTok{\textless{}{-}} 
    \FunctionTok{foreach}\NormalTok{ (}
      \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_i\_list),}
      \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{      ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{               theta\_ij }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i\_list[j]}
\NormalTok{               theta\_j }\OtherTok{\textless{}{-}}\NormalTok{ theta\_1}
\NormalTok{               theta\_j[i] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_ij}
\NormalTok{               objective\_ij }\OtherTok{\textless{}{-}} 
                 \FunctionTok{compute\_CCP\_objective}\NormalTok{(}
\NormalTok{                   theta\_j, }
\NormalTok{                   theta\_2, }
\NormalTok{                   p\_est, }
\NormalTok{                   L, }
\NormalTok{                   K, }
\NormalTok{                   delta}
\NormalTok{                   )}
               \FunctionTok{return}\NormalTok{(objective\_ij)}
\NormalTok{             \}}
\NormalTok{  df\_graph }\OtherTok{\textless{}{-}} 
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ theta\_i\_list, }
      \AttributeTok{y =}\NormalTok{ objective\_i}
\NormalTok{      ) }
\NormalTok{  g }\OtherTok{\textless{}{-}} 
    \FunctionTok{ggplot}\NormalTok{(}
      \AttributeTok{data =}\NormalTok{ df\_graph, }
      \FunctionTok{aes}\NormalTok{(}
        \AttributeTok{x =}\NormalTok{ x, }
        \AttributeTok{y =}\NormalTok{ y)}
\NormalTok{      ) }\SpecialCharTok{+} 
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}
      \AttributeTok{xintercept =}\NormalTok{ theta\_i, }
      \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"objective function"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(label[i]))  }\SpecialCharTok{+} 
    \FunctionTok{theme\_classic}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(g)}
\NormalTok{\}}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  graph, }
  \AttributeTok{file =} \StringTok{"lecture/data/a7/CCP\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a7/CCP\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{graph}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-197-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-197-2} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Estiamte the parameters by minimizing the objective function. To keep the model to be well-defined, impose an ad hoc lower and upper bounds such that \(\alpha \in [0, 1], \beta \in [0, 5]\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{length}\NormalTok{(theta\_1))}
\NormalTok{upper }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{CCP\_result }\OtherTok{\textless{}{-}}
  \FunctionTok{optim}\NormalTok{(}
        \AttributeTok{par =}\NormalTok{ theta\_1,}
        \AttributeTok{fn =}\NormalTok{ compute\_CCP\_objective,}
        \AttributeTok{method =} \StringTok{"L{-}BFGS{-}B"}\NormalTok{,}
        \AttributeTok{lower =}\NormalTok{ lower,}
        \AttributeTok{upper =}\NormalTok{ upper,}
        \AttributeTok{theta\_2 =}\NormalTok{ theta\_2\_est, }
        \AttributeTok{p\_est =}\NormalTok{ p\_est, }
        \AttributeTok{L =}\NormalTok{ L, }
        \AttributeTok{K =}\NormalTok{ K, }
        \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{        )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  CCP\_result, }
  \AttributeTok{file =} \StringTok{"lecture/data/a7/CCP\_result.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{CCP\_result }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a7/CCP\_result.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{CCP\_result}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $par
## [1] 0.5271684 3.0644600
## 
## $value
## [1] 1.790528e-06
## 
## $counts
## function gradient 
##       11       11 
## 
## $convergence
## [1] 0
## 
## $message
## [1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{compare }\OtherTok{\textless{}{-}}

  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{true =}\NormalTok{ theta\_1,}
    \AttributeTok{estimate =}\NormalTok{ CCP\_result}\SpecialCharTok{$}\NormalTok{par}
\NormalTok{  ); }
\NormalTok{compare}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   true  estimate
## 1  0.5 0.5271684
## 2  3.0 3.0644600
\end{verbatim}

\chapter{Assignment 8: Dynamic Game}\label{assignment8}

\section{Simulate data}\label{simulate-data-7}

Suppose that there are \(m = 1, \cdots, M\) markets and in each market there are \(i = 1, \cdots, N\) firms and each firm makes decisions for \(t = 1, \cdots, \infty\). In the following, I suppress the index of market, \(m\). We solve the model under the infinite-horizon assumption, but generate data only for \(t = 1, \cdots, T\). There are \(L = 5\) state \(\{1, 2, 3, 4, 5\}\) states for each firm. Each firm can choose \(K + 1 = 2\) actions \(\{0, 1\}\). Thus, \(m_a := (K + 1)^N\) and \(m_s = L^N\). Let \(a_i\) and \(s_i\) be firm \(i\)'s action and state and \(a\) and \(s\) are vectors of individual actions and states.

The mean period payoff to firm \(i\) is:
\[
\pi_i(a, s) := \tilde{\pi}(a_i, s_i, \overline{s}) :=  \alpha \ln s_i - \eta \ln s_i \sum_{j \neq i} \ln s_j - \beta a_i,
\]
where \(\alpha, \beta, \eta> 0\), and \(\alpha > \eta\). The term \(\eta\) means that the returns to investment decreases as rival's average state profile improves. The period payoff is:
\[
\tilde{\pi}(a_i, s_i, \overline{s})+ \epsilon_i(a_i),
\]
and \(\epsilon_i(a_i)\) is an i.i.d. type-I extreme random variable that is independent of all the other variables.

At the beginning of each period, the state \(s\) is realized and publicly observed. Then choice-specific shocks \(\epsilon_i(a_i), a_i = 0, 1\) are realized and privately observed by firm \(i = 1, \cdots, N\). Then each firm simultaneously chooses her action. Then, the game moves to next period.

State transition is independent across firms conditional on individual state and action.

Suppose that \(s_i > 1\) and \(s_i < L\). If \(a_i = 0\), the state stays at the same state with probability \(1 - \kappa\) and moves down by 1 with probability \(\kappa\). If \(a = 1\), the state moves up by 1 with probability \(\gamma\), moves down by 1 with probability \(\kappa\), and stays at the same with probability \(1 - \kappa - \gamma\).

Suppose that \(s_i = 1\). If \(a_i = 0\), the state stays at the same state with probability 1. If \(a_i = 1\), the state moves up by 1 with probability \(\gamma\) and stays at the same with probability \(1 - \gamma\).

Suppose that \(s_i = L\). If \(a_i = 0\), the state stays at the same state with probability \(1 - \kappa\) and moves down by 1 with probability \(\kappa\). If \(a = 1\), the state moves down by 1 with probability \(\kappa\), and stays at the same with probability \(1 - \kappa\).

The mean period profit is summarized in \(\Pi\) as:

\[
\Pi :=
\begin{pmatrix}
\pi(1, 1)\\
\vdots\\
\pi(m_a, 1)\\
\vdots \\
\pi(1, m_s)\\
\vdots\\
\pi(m_a, m_s)\\
\end{pmatrix}
\]

The transition law is summarized in \(G\) as:

\[
g(a, s, s') := \mathbb{P}\{s_{t + 1} = s'|s_t = s, a_t = a\},
\]

\[
G := 
\begin{pmatrix}
g(1, 1, 1) & \cdots & g(1, 1, m_s)\\
\vdots & & \vdots \\
g(m_a, 1, 1) & \cdots & g(m_a, 1, m_s)\\
& \vdots & \\
g(1, m_s, 1) & \cdots & g(1, m_s, m_s)\\
\vdots & & \vdots \\
g(m_a, m_s, 1) & \cdots & g(m_a, m_s, m_s)\\
\end{pmatrix}.
\]
The discount factor is denoted by \(\delta\). We simulate data for \(M\) markets with \(N\) firms for \(T\) periods.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set constants and parameters as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# set constants }
\NormalTok{L }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{K }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{M }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{lambda }\OtherTok{\textless{}{-}} \FloatTok{1e{-}10}
\CommentTok{\# set parameters}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{eta }\OtherTok{\textless{}{-}} \FloatTok{0.3}
\NormalTok{beta }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{kappa }\OtherTok{\textless{}{-}} \FloatTok{0.1}
\NormalTok{gamma }\OtherTok{\textless{}{-}} \FloatTok{0.6}
\NormalTok{delta }\OtherTok{\textless{}{-}} \FloatTok{0.95}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write a function \texttt{compute\_action\_state\_space(K,\ L,\ N)} that returns a data frame for action and state space. Returned objects are list of data frame \texttt{A} and \texttt{S}. In \texttt{A}, column \texttt{k} is the index of an action profile, \texttt{i} is the index of a firm, and \texttt{a} is the action of the firm. In \texttt{S}, column \texttt{l} is the index of an state profile, \texttt{i} is the index of a firm, and \texttt{s} is the state of the firm.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_action\_state\_space}\NormalTok{(}
    \AttributeTok{L =}\NormalTok{ L,}
    \AttributeTok{K =}\NormalTok{ K, }
    \AttributeTok{N =}\NormalTok{ N}
\NormalTok{    )}
\NormalTok{A }\OtherTok{\textless{}{-}}\NormalTok{ output}\SpecialCharTok{$}\NormalTok{A}
\FunctionTok{head}\NormalTok{(A)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##       k     i     a
##   <int> <int> <int>
## 1     1     1     0
## 2     1     2     0
## 3     1     3     0
## 4     2     1     1
## 5     2     2     0
## 6     2     3     0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(A)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##       k     i     a
##   <int> <int> <int>
## 1     7     1     0
## 2     7     2     1
## 3     7     3     1
## 4     8     1     1
## 5     8     2     1
## 6     8     3     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S }\OtherTok{\textless{}{-}}\NormalTok{ output}\SpecialCharTok{$}\NormalTok{S}
\FunctionTok{head}\NormalTok{(S)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##       l     i     s
##   <int> <int> <int>
## 1     1     1     1
## 2     1     2     1
## 3     1     3     1
## 4     2     1     2
## 5     2     2     1
## 6     2     3     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(S)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##       l     i     s
##   <int> <int> <int>
## 1   124     1     4
## 2   124     2     5
## 3   124     3     5
## 4   125     1     5
## 5   125     2     5
## 6   125     3     5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# dimension}
\NormalTok{m\_a }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(A}\SpecialCharTok{$}\NormalTok{k); }
\NormalTok{m\_a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m\_s }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(S}\SpecialCharTok{$}\NormalTok{l); }
\NormalTok{m\_s}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 125
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write function \texttt{compute\_PI\_game(alpha,\ beta,\ eta,\ A,\ S)} that returns a list of \(\Pi_i\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{PI }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_PI\_game}\NormalTok{(}
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{eta =}\NormalTok{ eta, }
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(PI[[N]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
## [2,]    0
## [3,]    0
## [4,]    0
## [5,]   -2
## [6,]   -2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(PI[[N]])[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ m\_s }\SpecialCharTok{*}\NormalTok{ m\_a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Write function \texttt{compute\_G\_game(g,\ A,\ S)} that converts an individual transition probability matrix into a joint transition probability matrix \(G\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{G\_marginal }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_G}\NormalTok{(}
    \AttributeTok{kappa =}\NormalTok{ kappa,}
    \AttributeTok{gamma =}\NormalTok{ gamma, }
    \AttributeTok{L =}\NormalTok{ L, }
    \AttributeTok{K =}\NormalTok{ K}
\NormalTok{    )}
\NormalTok{G }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_G\_game}\NormalTok{(}
    \AttributeTok{G\_marginal =}\NormalTok{ G\_marginal, }
    \AttributeTok{A =}\NormalTok{ A, }
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(G)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         1    2 3 4 5    6    7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
## [1,] 1.00 0.00 0 0 0 0.00 0.00 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [2,] 0.40 0.60 0 0 0 0.00 0.00 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [3,] 0.40 0.00 0 0 0 0.60 0.00 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [4,] 0.16 0.24 0 0 0 0.24 0.36 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [5,] 0.40 0.00 0 0 0 0.00 0.00 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [6,] 0.16 0.24 0 0 0 0.00 0.00 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##      25   26   27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
## [1,]  0 0.00 0.00  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [2,]  0 0.00 0.00  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [3,]  0 0.00 0.00  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [4,]  0 0.00 0.00  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [5,]  0 0.60 0.00  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [6,]  0 0.24 0.36  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##      48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
## [1,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [2,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [3,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [4,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [5,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [6,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##      73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97
## [1,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [2,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [3,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [4,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [5,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## [6,]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##      98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
## [1,]  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## [2,]  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## [3,]  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## [4,]  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## [5,]  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## [6,]  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
##      117 118 119 120 121 122 123 124 125
## [1,]   0   0   0   0   0   0   0   0   0
## [2,]   0   0   0   0   0   0   0   0   0
## [3,]   0   0   0   0   0   0   0   0   0
## [4,]   0   0   0   0   0   0   0   0   0
## [5,]   0   0   0   0   0   0   0   0   0
## [6,]   0   0   0   0   0   0   0   0   0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(G)[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ m\_s }\SpecialCharTok{*}\NormalTok{ m\_a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(G)[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ m\_s}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

The ex-ante-value function for a firm is written as a function of a conditional choice probability as follows:
\[
\varphi_i^{(\theta_1, \theta_2)}(p) := [I - \delta \Sigma(p) G]^{-1}[\Sigma(p)\Pi_i + D_i(p)],
\]
where \(\theta_1 = (\alpha, \beta, \eta)\) and \(\theta_2 = (\kappa, \gamma)\), \(p_i(a_i|s)\) is the probability that firm \(i\) choose action \(a_i\) when the state profile is \(s\), and:
\[
p(a|s) = \prod_{i = 1}^N p_i(a_i|s), 
\]

\[
p(s) = 
\begin{pmatrix}
p(1|s) \\
\vdots \\
p(m_a|s)
\end{pmatrix},
\]

\[
p = 
\begin{pmatrix}
p(1)\\
\vdots\\
p(m_s)
\end{pmatrix},
\]

\[
\Sigma(p) =
\begin{pmatrix}
p(1)' & & \\
 & \ddots & \\
 & & p(L)'
\end{pmatrix}
\]

and:

\[
D_i(p) =
\begin{pmatrix}
\sum_{k = 0}^K \mathbb{E}\{\epsilon_i^k|a_i = k, 1\}p_i(a_i = k|1)\\
\vdots\\
\sum_{k = 0}^K \mathbb{E}\{\epsilon_i^k|a_i = k, m_s\}p_i(a_i = k|m_s)
\end{pmatrix}.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Write a function \texttt{initialize\_p\_marginal(A,\ S)} that defines an initial marginal condition choice probability. In the output \texttt{p\_marginal}, \texttt{p} is the probability for firm \texttt{i} to take action \texttt{a} conditional on the state profile being \texttt{l}. Next, write a function \texttt{compute\_p\_joint(p\_marginal,\ A,\ S)} that computes a corresponding joint conditional choice probability from a marginal conditional choice probability. In the output \texttt{p\_joint}, \texttt{p} is the joint probability that firms take action profile \texttt{k} condition on the state profile being \texttt{l}. Finally, write a function \texttt{compute\_p\_marginal(p\_joint,\ A,\ S)} that compute a corresponding marginal conditional choice probability from a joint conditional choice probability.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define a conditional choice probability for each firm}
\NormalTok{p\_marginal }\OtherTok{\textless{}{-}} 
  \FunctionTok{initialize\_p\_marginal}\NormalTok{(}
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\NormalTok{p\_marginal}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 750 x 4
##        i     l     a     p
##    <int> <int> <int> <dbl>
##  1     1     1     0   0.5
##  2     1     1     1   0.5
##  3     1     2     0   0.5
##  4     1     2     1   0.5
##  5     1     3     0   0.5
##  6     1     3     1   0.5
##  7     1     4     0   0.5
##  8     1     4     1   0.5
##  9     1     5     0   0.5
## 10     1     5     1   0.5
## # i 740 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(p\_marginal)[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ N }\SpecialCharTok{*}\NormalTok{ m\_s }\SpecialCharTok{*}\NormalTok{ (K }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute joint conditional choice probability from marginal probability}
\NormalTok{p\_joint }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_p\_joint}\NormalTok{(}
    \AttributeTok{p\_marginal =}\NormalTok{ p\_marginal, }
    \AttributeTok{A =}\NormalTok{ A, }
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\NormalTok{p\_joint}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1,000 x 3
##        l     k     p
##    <int> <int> <dbl>
##  1     1     1 0.125
##  2     1     2 0.125
##  3     1     3 0.125
##  4     1     4 0.125
##  5     1     5 0.125
##  6     1     6 0.125
##  7     1     7 0.125
##  8     1     8 0.125
##  9     2     1 0.125
## 10     2     2 0.125
## # i 990 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(p\_joint)[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ m\_s }\SpecialCharTok{*}\NormalTok{ m\_a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute marginal conditional choice probability from joint probability}
\NormalTok{p\_marginal\_2 }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_p\_marginal}\NormalTok{(}
    \AttributeTok{p\_joint =}\NormalTok{ p\_joint, }
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(p\_marginal }\SpecialCharTok{{-}}\NormalTok{ p\_marginal\_2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write a function \texttt{compute\_sigma(p\_marginal,\ A,\ S)} that computes \(\Sigma(p)\) given a joint conditional choice probability. Then, write a function \texttt{compute\_D(p\_marginal)} that returns a list of \(D_i(p)\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute Sigma for ex{-}ante value function calculation}
\NormalTok{sigma }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_sigma}\NormalTok{(}
    \AttributeTok{p\_marginal =}\NormalTok{ p\_marginal,}
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(sigma)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 6 x 1000 sparse Matrix of class "dgCMatrix"
##                                                                             
## [1,] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125 .     .     .     .    
## [2,] .     .     .     .     .     .     .     .     0.125 0.125 0.125 0.125
## [3,] .     .     .     .     .     .     .     .     .     .     .     .    
## [4,] .     .     .     .     .     .     .     .     .     .     .     .    
## [5,] .     .     .     .     .     .     .     .     .     .     .     .    
## [6,] .     .     .     .     .     .     .     .     .     .     .     .    
##                                                                             
## [1,] .     .     .     .     .     .     .     .     .     .     .     .    
## [2,] 0.125 0.125 0.125 0.125 .     .     .     .     .     .     .     .    
## [3,] .     .     .     .     0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125
## [4,] .     .     .     .     .     .     .     .     .     .     .     .    
## [5,] .     .     .     .     .     .     .     .     .     .     .     .    
## [6,] .     .     .     .     .     .     .     .     .     .     .     .    
##                                                                             
## [1,] .     .     .     .     .     .     .     .     .     .     .     .    
## [2,] .     .     .     .     .     .     .     .     .     .     .     .    
## [3,] .     .     .     .     .     .     .     .     .     .     .     .    
## [4,] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125 .     .     .     .    
## [5,] .     .     .     .     .     .     .     .     0.125 0.125 0.125 0.125
## [6,] .     .     .     .     .     .     .     .     .     .     .     .    
##                                                                               
## [1,] .     .     .     .     .     .     .     .     .     .     .     .     .
## [2,] .     .     .     .     .     .     .     .     .     .     .     .     .
## [3,] .     .     .     .     .     .     .     .     .     .     .     .     .
## [4,] .     .     .     .     .     .     .     .     .     .     .     .     .
## [5,] 0.125 0.125 0.125 0.125 .     .     .     .     .     .     .     .     .
## [6,] .     .     .     .     0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125 .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                                               
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
##                                                         
## [1,] . . . . . . . . . . . . . . . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . .
## [4,] . . . . . . . . . . . . . . . . . . . . . . . . . .
## [5,] . . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . . . . . . . . . . . . . . . . . . .
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(sigma)[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ m\_s}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(sigma)[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ m\_s }\SpecialCharTok{*}\NormalTok{ m\_a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute D for ex{-}ante value function calculation}
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{compute\_D}\NormalTok{(p\_marginal)}
\FunctionTok{head}\NormalTok{(D[[N]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          [,1]
## [1,] 1.270363
## [2,] 1.270363
## [3,] 1.270363
## [4,] 1.270363
## [5,] 1.270363
## [6,] 1.270363
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(D[[N]])[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ m\_s}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function \texttt{compute\_exante\_value\_game(p\_marginal,\ A,\ S,\ PI,\ G,\ delta)} that returns a list of matrices whose \(i\)-th element represents the ex-ante value function given a conditional choice probability for firm \(i\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute ex{-}ante value funciton for each firm}
\NormalTok{V }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_exante\_value\_game}\NormalTok{(}
    \AttributeTok{p\_marginal =}\NormalTok{ p\_marginal,}
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{S =}\NormalTok{ S,}
    \AttributeTok{PI =}\NormalTok{ PI,}
    \AttributeTok{G =}\NormalTok{ G,}
    \AttributeTok{delta =}\NormalTok{ delta}
\NormalTok{    )}
\FunctionTok{head}\NormalTok{(V[[N]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 6 x 1 Matrix of class "dgeMatrix"
##         [,1]
## l1 10.786330
## l2 10.175982
## l3  9.606812
## l4  9.255459
## l5  9.115332
## l6 10.175982
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(V[[N]])[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ m\_s}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

The optimal conditional choice probability is written as a function of an ex-ante value function and a conditional choice probability of others as follows:
\[
\Lambda_i^{(\theta_1, \theta_2)}(V_i, p_{-i})(a_i, s) := \frac{\exp\{\sum_{a_{-i}}p_{-i}(a_{-i}|s)[\pi_i(a_i, a_{-i}, s) + \delta \sum_{s'}V_i(s')g(a_i, a_{-i}, s, s')]\}}{\sum_{a_i'}\exp\{\sum_{a_{-i}}p_{-i}(a_{-i}|s)[\pi_i(a_i', a_{-i}, s) + \delta \sum_{s'}V_i(s')g(a_i', a_{-i}, s, s')]\}},
\]
where \(V\) is an ex-ante value function.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Write a function \texttt{compute\_profile\_value\_game(V,\ PI,\ G,\ delta,\ S,\ A)} that returns a data frame that contains information on value function at a state and action profile for each firm. In the output \texttt{value}, \texttt{i} is the index of a firm, \texttt{l} is the index of a state profile, \texttt{k} is the index of an action profile, and \texttt{value} is the value for the firm at the state and action profile.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute state{-}action{-}profile value function}
\NormalTok{value }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_profile\_value\_game}\NormalTok{(}
    \AttributeTok{V =}\NormalTok{ V, }
    \AttributeTok{PI =}\NormalTok{ PI,}
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{S =}\NormalTok{ S, }
    \AttributeTok{A =}\NormalTok{ A}
\NormalTok{    )}
\NormalTok{value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3,000 x 4
##        i     l     k value
##    <int> <int> <int> <dbl>
##  1     1     1     1 10.2 
##  2     1     1     2  9.63
##  3     1     1     3  9.90
##  4     1     1     4  9.13
##  5     1     1     5  9.90
##  6     1     1     6  9.13
##  7     1     1     7  9.55
##  8     1     1     8  8.64
##  9     1     2     1 13.0 
## 10     1     2     2 12.1 
## # i 2,990 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(value)[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{==}\NormalTok{ N }\SpecialCharTok{*}\NormalTok{ m\_s }\SpecialCharTok{*}\NormalTok{ m\_a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Write a function \texttt{compute\_choice\_value\_game(p\_marginal,\ V,\ PI,\ G,\ delta,\ A,\ S)} that computes a data frame that contains information on a choice-specific value function given an ex-ante value function and a conditional choice probability of others.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute choice{-}specific value function}
\NormalTok{value }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_choice\_value\_game}\NormalTok{(}
    \AttributeTok{p\_marginal =}\NormalTok{ p\_marginal,}
    \AttributeTok{V =}\NormalTok{ V,}
    \AttributeTok{PI =}\NormalTok{ PI,}
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{A =}\NormalTok{ A, }
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\NormalTok{value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 750 x 4
##        i     l     a value
##    <int> <int> <int> <dbl>
##  1     1     1     0  9.90
##  2     1     1     1  9.13
##  3     1     2     0 12.4 
##  4     1     2     1 11.4 
##  5     1     3     0 14.5 
##  6     1     3     1 13.2 
##  7     1     4     0 16.0 
##  8     1     4     1 14.3 
##  9     1     5     0 16.8 
## 10     1     5     1 14.8 
## # i 740 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  Write a function \texttt{compute\_ccp\_game(p\_marginal,\ V,\ PI,\ G,\ delta,\ A,\ S)} that computes a data frame that contains information on a conditional choice probability given an ex-ante value function and a conditional choice probability of others.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute conditional choice probability }
\NormalTok{p\_marginal }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_ccp\_game}\NormalTok{(}
    \AttributeTok{p\_marginal =}\NormalTok{ p\_marginal,}
    \AttributeTok{V =}\NormalTok{ V,}
    \AttributeTok{PI =}\NormalTok{ PI,}
    \AttributeTok{G =}\NormalTok{ G,}
    \AttributeTok{delta =}\NormalTok{ delta,}
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\NormalTok{p\_marginal}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 750 x 4
##        i     l     a     p
##    <int> <int> <int> <dbl>
##  1     1     1     0 0.683
##  2     1     1     1 0.317
##  3     1     2     0 0.734
##  4     1     2     1 0.266
##  5     1     3     0 0.794
##  6     1     3     1 0.206
##  7     1     4     0 0.840
##  8     1     4     1 0.160
##  9     1     5     0 0.881
## 10     1     5     1 0.119
## # i 740 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Write a function \texttt{solve\_dynamic\_game(PI,\ G,\ L,\ K,\ delta,\ lambda,\ A,\ S)} that find the equilibrium conditional choice probability and ex-ante value function by iterating the update of an ex-ante value function and a best-response conditional choice probability. The iteration should stop when \(\max_s|V^{(r + 1)}(s) - V^{(r)}(s)| < \lambda\) with \(\lambda = 10^{-10}\). There is no theoretical guarantee for the convergence.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# solve the dynamic game model}
\NormalTok{output }\OtherTok{\textless{}{-}}
  \FunctionTok{solve\_dynamic\_game}\NormalTok{(}
    \AttributeTok{PI =}\NormalTok{ PI,}
    \AttributeTok{G =}\NormalTok{ G, }
    \AttributeTok{L =}\NormalTok{ L,}
    \AttributeTok{K =}\NormalTok{ K,}
    \AttributeTok{delta =}\NormalTok{ delta,}
    \AttributeTok{lambda =}\NormalTok{ lambda,}
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  output, }
  \AttributeTok{file =} \StringTok{"lecture/data/a8/equilibrium.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a8/equilibrium.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{p\_marginal }\OtherTok{\textless{}{-}}\NormalTok{ output}\SpecialCharTok{$}\NormalTok{p\_marginal;}
\FunctionTok{head}\NormalTok{(p\_marginal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
##       i     l     a     p
##   <int> <int> <int> <dbl>
## 1     1     1     0 0.534
## 2     1     1     1 0.466
## 3     1     2     0 0.545
## 4     1     2     1 0.455
## 5     1     3     0 0.629
## 6     1     3     1 0.371
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V }\OtherTok{\textless{}{-}}\NormalTok{ output}\SpecialCharTok{$}\NormalTok{V[[N]];}
\FunctionTok{head}\NormalTok{(V)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 6 x 1 Matrix of class "dgeMatrix"
##        [,1]
## l1 18.98883
## l2 18.51236
## l3 18.08141
## l4 17.77417
## l5 17.59426
## l6 18.51236
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute joint conitional choice probability}

\NormalTok{p\_joint }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_p\_joint}\NormalTok{(}
    \AttributeTok{p\_marginal =}\NormalTok{ p\_marginal, }
    \AttributeTok{A =}\NormalTok{ A, }
    \AttributeTok{S =}\NormalTok{ S}
\NormalTok{    );}
\FunctionTok{head}\NormalTok{(p\_joint)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##       l     k     p
##   <int> <int> <dbl>
## 1     1     1 0.152
## 2     1     2 0.133
## 3     1     3 0.133
## 4     1     4 0.116
## 5     1     5 0.133
## 6     1     6 0.116
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{11}
\tightlist
\item
  Write a function \texttt{simulate\_dynamic\_game(p\_joint,\ l,\ G,\ N,\ T,\ S,\ A,\ seed)} that simulate the data for a market starting from an initial state for \(T\) periods. The function should accept a value of seed and set the seed at the beginning of the procedure inside the function, because the process is stochastic. To match the generated random numbers, for each period, generate action using \texttt{rmultinom} and then state using \texttt{rmultinom}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# simulate a dynamic game}
\CommentTok{\# set initial state profile}
\NormalTok{l }\OtherTok{\textless{}{-}} \DecValTok{1}
\CommentTok{\# draw simulation for a firm}
\NormalTok{seed }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{df }\OtherTok{\textless{}{-}} 
  \FunctionTok{simulate\_dynamic\_game}\NormalTok{(}
    \AttributeTok{p\_joint =}\NormalTok{ p\_joint,}
    \AttributeTok{l =}\NormalTok{ l,}
    \AttributeTok{G =}\NormalTok{ G,}
    \AttributeTok{N =}\NormalTok{ N,}
    \AttributeTok{T =}\NormalTok{ T,}
    \AttributeTok{S =}\NormalTok{ S, }
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{seed =}\NormalTok{ seed}
\NormalTok{    )}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 300 x 6
##        t     i     l     k     s     a
##    <int> <int> <dbl> <dbl> <int> <int>
##  1     1     1     1     4     1     1
##  2     1     2     1     4     1     1
##  3     1     3     1     4     1     0
##  4     2     1     2     1     2     0
##  5     2     2     2     1     1     0
##  6     2     3     2     1     1     0
##  7     3     1     2     5     2     0
##  8     3     2     2     5     1     0
##  9     3     3     2     5     1     1
## 10     4     1     2     3     2     0
## # i 290 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{12}
\tightlist
\item
  Write a function \texttt{simulate\_dynamic\_decision\_across\_markets(p\_joint,\ l,\ G,\ N,\ T,\ M,\ S,\ A,\ seed)} that returns simulation data for \(M\) markets. For firm \(m\), set the seed at \(m\)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# simulate data across markets}
\NormalTok{df }\OtherTok{\textless{}{-}} 
  \FunctionTok{simulate\_dynamic\_decision\_across\_markets}\NormalTok{(}
    \AttributeTok{p\_joint =}\NormalTok{ p\_joint,}
    \AttributeTok{l =}\NormalTok{ l,}
    \AttributeTok{G =}\NormalTok{ G,}
    \AttributeTok{N =}\NormalTok{ N,}
    \AttributeTok{T =}\NormalTok{ T,}
    \AttributeTok{M =}\NormalTok{ M,}
    \AttributeTok{S =}\NormalTok{ S,}
    \AttributeTok{A =}\NormalTok{ A}
\NormalTok{    )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  df,}
  \AttributeTok{file =} \StringTok{"lecture/data/a8/df.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a8/df.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 300,000 x 7
##        m     t     i     l     k     s     a
##    <int> <int> <int> <dbl> <dbl> <int> <int>
##  1     1     1     1     1     4     1     1
##  2     1     1     2     1     4     1     1
##  3     1     1     3     1     4     1     0
##  4     1     2     1     2     1     2     0
##  5     1     2     2     2     1     1     0
##  6     1     2     3     2     1     1     0
##  7     1     3     1     2     5     2     0
##  8     1     3     2     2     5     1     0
##  9     1     3     3     2     5     1     1
## 10     1     4     1     2     3     2     0
## # i 299,990 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        m                t                i           l                k        
##  Min.   :   1.0   Min.   :  1.00   Min.   :1   Min.   :  1.00   Min.   :1.000  
##  1st Qu.: 250.8   1st Qu.: 25.75   1st Qu.:1   1st Qu.: 44.00   1st Qu.:1.000  
##  Median : 500.5   Median : 50.50   Median :2   Median : 75.00   Median :2.000  
##  Mean   : 500.5   Mean   : 50.50   Mean   :2   Mean   : 71.89   Mean   :2.497  
##  3rd Qu.: 750.2   3rd Qu.: 75.25   3rd Qu.:3   3rd Qu.:102.00   3rd Qu.:4.000  
##  Max.   :1000.0   Max.   :100.00   Max.   :3   Max.   :125.00   Max.   :8.000  
##        s               a         
##  Min.   :1.000   Min.   :0.0000  
##  1st Qu.:2.000   1st Qu.:0.0000  
##  Median :3.000   Median :0.0000  
##  Mean   :3.288   Mean   :0.2131  
##  3rd Qu.:5.000   3rd Qu.:0.0000  
##  Max.   :5.000   Max.   :1.0000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{13}
\tightlist
\item
  Write a function \texttt{estimate\_ccp\_marginal\_game(df)} that returns a non-parametric estimate of the marginal conditional choice probability for each firm in the data. Compare the estimated conditional choice probability and the true conditional choice probability by a bar plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# non{-}parametrically estimate the conditional choice probability}
\NormalTok{p\_marginal\_est }\OtherTok{\textless{}{-}} 
  \FunctionTok{estimate\_ccp\_marginal\_game}\NormalTok{(}\AttributeTok{df =}\NormalTok{ df)}
\NormalTok{check\_ccp }\OtherTok{\textless{}{-}} 
\NormalTok{  p\_marginal\_est }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{rename}\NormalTok{(}\AttributeTok{estimate =}\NormalTok{ p) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(}
\NormalTok{    p\_marginal, }
    \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}
           \StringTok{"i"}\NormalTok{,}
           \StringTok{"l"}\NormalTok{, }
           \StringTok{"a"}
\NormalTok{           )}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{rename}\NormalTok{(}\AttributeTok{true =}\NormalTok{ p) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(a }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ check\_ccp, }
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ true, }
    \AttributeTok{y =}\NormalTok{ estimate}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{fill =} \StringTok{"Value"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"true"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"estimate"}\NormalTok{)  }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-216-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{14}
\tightlist
\item
  Write a function \texttt{estimate\_G\_marginal(df)} that returns a non-parametric estimate of the marginal transition probability matrix. Compare the estimated transition matrix and the true transition matrix by a bar plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# non{-}parametrically estimate individual transition probability}
\NormalTok{G\_marginal\_est }\OtherTok{\textless{}{-}} 
  \FunctionTok{estimate\_G\_marginal}\NormalTok{(}\AttributeTok{df =}\NormalTok{ df)}
\NormalTok{check\_G }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{type =} \StringTok{"true"}\NormalTok{,}
\NormalTok{    reshape2}\SpecialCharTok{::}\FunctionTok{melt}\NormalTok{(G\_marginal)}
\NormalTok{    )}
\NormalTok{check\_G\_est }\OtherTok{\textless{}{-}} 
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{type =} \StringTok{"estimate"}\NormalTok{,}
\NormalTok{    reshape2}\SpecialCharTok{::}\FunctionTok{melt}\NormalTok{(G\_marginal\_est)}
\NormalTok{    )}
\NormalTok{check\_G }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
\NormalTok{    check\_G, }
\NormalTok{    check\_G\_est}
\NormalTok{    )}
\NormalTok{check\_G}\SpecialCharTok{$}\NormalTok{variable }\OtherTok{\textless{}{-}} 
  \FunctionTok{paste}\NormalTok{(}
\NormalTok{    check\_G}\SpecialCharTok{$}\NormalTok{Var1,}
\NormalTok{    check\_G}\SpecialCharTok{$}\NormalTok{Var2, }
    \AttributeTok{sep =} \StringTok{"\_"}
\NormalTok{    )}
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ check\_G, }
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ variable, }
    \AttributeTok{y =}\NormalTok{ value,}
    \AttributeTok{fill =}\NormalTok{ type}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{+}
    \FunctionTok{geom\_bar}\NormalTok{(}
      \AttributeTok{stat =} \StringTok{"identity"}\NormalTok{,}
      \AttributeTok{position =} \StringTok{"dodge"}
\NormalTok{      ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{fill =} \StringTok{"Value"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"action/state/state"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"probability"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_blank}\NormalTok{())  }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-217-1} \end{center}

\section{Estimate parameters}\label{estimate-parameters-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Vectorize the parameters as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta\_1 }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    alpha, }
\NormalTok{    beta, }
\NormalTok{    eta}
\NormalTok{    )}
\NormalTok{theta\_2 }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    kappa, }
\NormalTok{    gamma}
\NormalTok{    )}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    theta\_1, }
\NormalTok{    theta\_2}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

We estimate the parameters by a CCP approach.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function \texttt{estimate\_theta\_2\_game(df)} that returns the estimates of \(\kappa\) and \(\gamma\) directly from data by counting relevant events.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# estimate theta\_2}
\NormalTok{theta\_2\_est }\OtherTok{\textless{}{-}} 
  \FunctionTok{estimate\_theta\_2\_game}\NormalTok{(}
    \AttributeTok{df =}\NormalTok{ df}
\NormalTok{  ); }
\NormalTok{theta\_2\_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09946371 0.60228274
\end{verbatim}

The objective function of the minimum distance estimator based on the conditional choice probability approach is:
\[
\frac{1}{N K m_s} \sum_{i = 1}^N \sum_{l = 1}^{m_s} \sum_{k = 1}^{K}\{\hat{p}_i(a_k|s_l) - p_i^{(\theta_1, \theta_2)}(a_k|s_l)\}^2,
\]
where \(\hat{p}_i\) is the non-parametric estimate of the marginal conditional choice probability and \(p_i^{(\theta_1, \theta_2)}\) is the marginal conditional choice probability under parameters \(\theta_1\) and \(\theta_2\) given \(\hat{p}_i\). \(a_k\) is \(k\)-th action for a firm and \(s_l\) is \(l\)-th state profile.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write a function \texttt{compute\_CCP\_objective\_game(theta\_1,\ theta\_2,\ p\_est,\ L,\ K,\ delta)} that returns the objective function of the above minimum distance estimator given a non-parametric estimate of the conditional choice probability and \(\theta_1\) and \(\theta_2\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute the objective function of the minimum distance estimator based on the CCP approach}
\NormalTok{objective }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_CCP\_objective\_game}\NormalTok{(}
    \AttributeTok{theta\_1 =}\NormalTok{ theta\_1,}
    \AttributeTok{theta\_2 =}\NormalTok{ theta\_2, }
    \AttributeTok{p\_marginal\_est =}\NormalTok{ p\_marginal\_est,}
    \AttributeTok{A =}\NormalTok{ A,}
    \AttributeTok{S =}\NormalTok{ S, }
    \AttributeTok{delta =}\NormalTok{ delta, }
    \AttributeTok{lambda =}\NormalTok{ lambda}
\NormalTok{    )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  objective,}
  \AttributeTok{file =} \StringTok{"lecture/data/a8/objective.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{objective }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a8/objective.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{objective}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0003285307
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Check the value of the objective function around the true parameter.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# label}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{alpha"}\NormalTok{,}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta"}\NormalTok{,}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{eta"}
\NormalTok{    )}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{paste}\NormalTok{(}
    \StringTok{"$"}\NormalTok{,}
\NormalTok{    label,}
    \StringTok{"$"}\NormalTok{, }
    \AttributeTok{sep =} \StringTok{""}
\NormalTok{    )}
\CommentTok{\# compute the graph}
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_1)}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{  theta\_i }\OtherTok{\textless{}{-}}\NormalTok{ theta\_1[i]}
\NormalTok{  theta\_i\_list }\OtherTok{\textless{}{-}} 
\NormalTok{    theta\_i }\SpecialCharTok{*} \FunctionTok{seq}\NormalTok{(}
      \FloatTok{0.5}\NormalTok{, }
      \DecValTok{2}\NormalTok{,}
      \AttributeTok{by =} \FloatTok{0.2}
\NormalTok{      )}
\NormalTok{  objective\_i }\OtherTok{\textless{}{-}}
    \FunctionTok{foreach}\NormalTok{ (}
      \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_i\_list),}
      \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{      ) }\SpecialCharTok{\%dopar\%}\NormalTok{ \{}
\NormalTok{               theta\_ij }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i\_list[j]}
\NormalTok{               theta\_j }\OtherTok{\textless{}{-}}\NormalTok{ theta\_1}
\NormalTok{               theta\_j[i] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_ij}
\NormalTok{               objective\_ij }\OtherTok{\textless{}{-}} 
                 \FunctionTok{compute\_CCP\_objective\_game}\NormalTok{(}
\NormalTok{                   theta\_j,}
\NormalTok{                   theta\_2,}
\NormalTok{                   p\_marginal\_est, }
\NormalTok{                   A,}
\NormalTok{                   S,}
\NormalTok{                   delta,}
\NormalTok{                   lambda}
\NormalTok{                   )}
               \FunctionTok{return}\NormalTok{(objective\_ij)}
\NormalTok{             \}}
\NormalTok{  df\_graph }\OtherTok{\textless{}{-}} 
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ theta\_i\_list, }
      \AttributeTok{y =}\NormalTok{ objective\_i}
\NormalTok{      )}
\NormalTok{  g }\OtherTok{\textless{}{-}} 
    \FunctionTok{ggplot}\NormalTok{(}
      \AttributeTok{data =}\NormalTok{ df\_graph, }
      \FunctionTok{aes}\NormalTok{(}
        \AttributeTok{x =}\NormalTok{ x,}
        \AttributeTok{y =}\NormalTok{ y}
\NormalTok{        )}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}
      \AttributeTok{xintercept =}\NormalTok{ theta\_i,}
      \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"objective function"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(label[i])) }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(g)}
\NormalTok{\}}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  graph,}
  \AttributeTok{file =} \StringTok{"lecture/data/a8/CCP\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a8/CCP\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{graph}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-223-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-223-2} \end{center}

\begin{verbatim}
## 
## [[3]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-223-3} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Estimate the parameters by minimizing the objective function. To keep the model to be well-defined, impose an ad hoc lower and upper bounds such that \(\alpha \in [0, 1], \beta \in [0, 5], \delta \in [0, 1]\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower }\OtherTok{\textless{}{-}} 
  \FunctionTok{rep}\NormalTok{(}
    \DecValTok{0}\NormalTok{, }
    \FunctionTok{length}\NormalTok{(theta\_1)}
\NormalTok{    )}
\NormalTok{upper }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{0.3}\NormalTok{)}
\NormalTok{CCP\_result }\OtherTok{\textless{}{-}}
  \FunctionTok{optim}\NormalTok{(}
        \AttributeTok{par =}\NormalTok{ theta\_1,}
        \AttributeTok{fn =}\NormalTok{ compute\_CCP\_objective\_game,}
        \AttributeTok{method =} \StringTok{"L{-}BFGS{-}B"}\NormalTok{,}
        \AttributeTok{lower =}\NormalTok{ lower,}
        \AttributeTok{upper =}\NormalTok{ upper,}
        \AttributeTok{theta\_2 =}\NormalTok{ theta\_2\_est,}
        \AttributeTok{p\_marginal\_est =}\NormalTok{ p\_marginal\_est,}
        \AttributeTok{A =}\NormalTok{ A,}
        \AttributeTok{S =}\NormalTok{ S,}
        \AttributeTok{delta =}\NormalTok{ delta,}
        \AttributeTok{lambda =}\NormalTok{ lambda}
\NormalTok{        )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  CCP\_result, }
  \AttributeTok{file =} \StringTok{"lecture/data/a8/CCP\_result.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{CCP\_result }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a8/CCP\_result.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}

\NormalTok{CCP\_result}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $par
## [1] 1.0000000 2.0205947 0.2964074
## 
## $value
## [1] 0.0003271323
## 
## $counts
## function gradient 
##       17       17 
## 
## $convergence
## [1] 0
## 
## $message
## [1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{compare }\OtherTok{\textless{}{-}}
  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{true =}\NormalTok{ theta\_1,}
    \AttributeTok{estimate =}\NormalTok{ CCP\_result}\SpecialCharTok{$}\NormalTok{par}
\NormalTok{  ); }
\NormalTok{compare}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   true  estimate
## 1  1.0 1.0000000
## 2  2.0 2.0205947
## 3  0.3 0.2964074
\end{verbatim}

\chapter{Assignment 9: Auction}\label{assignment9}

\section{Simulate data}\label{simulate-data-8}

We simulate bid data from a second- and first-price sealed bid auctions.

First, we draw bid data from a second-price sealed bid auctions. Suppose that for each auction \(t = 1, \cdots, T\), there are \(i = 2, \cdots, n_t\) potential bidders. At each auction, an auctioneer allocates one item and sets the reserve price at \(r_t\). When the signal for bidder \(i\) in auction \(t\) is \(x_{it}\), her expected value of the item is \(x_{it}\). A signal \(x_{it}\) is drawn from an i.i.d. beta distribution \(B(\alpha, \beta)\). Let \(F_X(\cdot; \alpha, \beta)\) be its distribution and \(f_X(\cdot; \alpha, \beta)\) be the density. A reserve is set at 0.2. \(n_t\) is drawn from a Poisson distribution with mean \(\lambda\). If \(n_t = 1\), replace with \(n_t = 2\) to ensure at least two potential bidders. An equilibrium strategy is such that a bidder participates and bids \(\beta(x) = x\) if \(x \ge r_t\) and does not participate otherwise.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set the constants and parameters as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# number of auctions}
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{100}
\CommentTok{\# parameter of value distribution}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{beta }\OtherTok{\textless{}{-}} \DecValTok{2}
\CommentTok{\# prameters of number of potential bidders}
\NormalTok{lambda }\OtherTok{\textless{}{-}} \DecValTok{10}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Draw a vector of valuations and reservation prices.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# number of bidders}
\NormalTok{N }\OtherTok{\textless{}{-}} 
  \FunctionTok{rpois}\NormalTok{(}
\NormalTok{    T, }
\NormalTok{    lambda}
\NormalTok{    )}
\NormalTok{N }\OtherTok{\textless{}{-}} 
  \FunctionTok{ifelse}\NormalTok{(}
\NormalTok{    N }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }
    \DecValTok{2}\NormalTok{, }
\NormalTok{    N}
\NormalTok{    )}
\CommentTok{\# draw valuations}
\NormalTok{valuation }\OtherTok{\textless{}{-}}
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{tt =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{    n\_t }\OtherTok{\textless{}{-}}\NormalTok{ N[tt]}
\NormalTok{    header }\OtherTok{\textless{}{-}} 
      \FunctionTok{expand.grid}\NormalTok{(}
        \AttributeTok{t =}\NormalTok{ tt,}
        \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n\_t}
\NormalTok{        ) }
    \FunctionTok{return}\NormalTok{(header)}
\NormalTok{  \}}
\NormalTok{valuation }\OtherTok{\textless{}{-}} 
\NormalTok{  valuation }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}\AttributeTok{x =} 
                  \FunctionTok{rbeta}\NormalTok{(}
                    \FunctionTok{length}\NormalTok{(i),}
\NormalTok{                    alpha,beta}
\NormalTok{                    )}
\NormalTok{                )}
\FunctionTok{ggplot}\NormalTok{(}
\NormalTok{  valuation, }
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{,}
    \AttributeTok{alpha =} \FloatTok{0.8}
\NormalTok{    ) }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-228-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# draw reserve prices}
\NormalTok{reserve }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{reserve }\OtherTok{\textless{}{-}} 
\NormalTok{  tibble}\SpecialCharTok{::}\FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{t =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }
    \AttributeTok{r =}\NormalTok{ reserve}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write a function \texttt{compute\_winning\_bids\_second(valuation,\ reserve)} that returns a winning bid from each second-price auction. It returns nothing for an auction in which no bid was above the reserve price. In the output, \texttt{t} refers to the auction index, \texttt{m} to the number of actual bidders, \texttt{r} to the reserve price, and \texttt{w} to the winning bid.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute winning bids from second{-}price auction}
\NormalTok{df\_second\_w }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_winning\_bids\_second}\NormalTok{(}
    \AttributeTok{valuation =}\NormalTok{ valuation, }
    \AttributeTok{reserve =}\NormalTok{ reserve}
\NormalTok{    )}
\NormalTok{df\_second\_w}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 100 x 5
##        t     n     m     r     w
##    <int> <int> <int> <dbl> <dbl>
##  1     1     8     8   0.2 0.637
##  2     2    10    10   0.2 0.647
##  3     3     7     5   0.2 0.484
##  4     4    11     8   0.2 0.804
##  5     5    14    12   0.2 0.920
##  6     6    12    11   0.2 0.942
##  7     7    11     9   0.2 0.810
##  8     8     9     9   0.2 0.724
##  9     9    14    14   0.2 0.880
## 10    10    11     9   0.2 0.677
## # i 90 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
\NormalTok{  df\_second\_w, }
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ w)}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{,}
    \AttributeTok{alpha =} \FloatTok{0.8}
\NormalTok{    ) }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-229-1} \end{center}

Next, we simulate bid data from first-price sealed bid auctions. The setting is the same as the second-price auctions expect for the auction rule. An equilibrium bidding strategy is to participate and bid:
\[
\beta(x) = x - \frac{\int_{r_t}^x F_X(t)^{N - 1}}{F_X(x)^{N - 1}},
\]
if \(x \ge r\) and not to participate otherwise.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Write a function \texttt{bid\_first(x,\ r,\ alpha,\ beta,\ n)} that returns the equilibrium bid. To integrate a function, use \texttt{integrate} function in R. It returns 0 if \(x < r\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute bid from first{-}price auction}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ N[}\DecValTok{1}\NormalTok{]}
\NormalTok{m }\OtherTok{\textless{}{-}}\NormalTok{ N[}\DecValTok{1}\NormalTok{]}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ valuation[}\DecValTok{1}\NormalTok{, }\StringTok{"x"}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as.numeric}\NormalTok{();}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3902289
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r }\OtherTok{\textless{}{-}} 
\NormalTok{  reserve[}\DecValTok{1}\NormalTok{, }\StringTok{"r"}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as.numeric}\NormalTok{(); }
\NormalTok{r}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OtherTok{\textless{}{-}} 
  \FunctionTok{bid\_first}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ x,}
    \AttributeTok{r =}\NormalTok{ r,}
    \AttributeTok{alpha =}\NormalTok{ alpha,}
    \AttributeTok{beta =}\NormalTok{ beta,}
    \AttributeTok{n =}\NormalTok{ n}
\NormalTok{    );}
\NormalTok{b}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3596662
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ r}\SpecialCharTok{/}\DecValTok{2}\NormalTok{;}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OtherTok{\textless{}{-}} 
  \FunctionTok{bid\_first}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ x,}
    \AttributeTok{r =}\NormalTok{ r, }
    \AttributeTok{alpha =}\NormalTok{ alpha,}
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{n =}\NormalTok{ n}
\NormalTok{    ); }
\NormalTok{b}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OtherTok{\textless{}{-}} 
  \FunctionTok{bid\_first}\NormalTok{(}
    \AttributeTok{x =} \DecValTok{1}\NormalTok{, }
    \AttributeTok{r =}\NormalTok{ r, }
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{beta =}\NormalTok{ beta, }
    \AttributeTok{n =}\NormalTok{ n}
\NormalTok{    ); }
\NormalTok{b}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7978258
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Write a function \texttt{compute\_bids\_first(valuation,\ reserve,\ alpha,\ beta)} that returns bids from each first-price auctions. It returns bids below the reserve price.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute bid data from first{-}price auctions}
\NormalTok{df\_first }\OtherTok{\textless{}{-}} 
  \FunctionTok{compute\_bids\_first}\NormalTok{(}
    \AttributeTok{valuation =}\NormalTok{ valuation, }
    \AttributeTok{reserve =}\NormalTok{ reserve,}
    \AttributeTok{alpha =}\NormalTok{ alpha, }
    \AttributeTok{beta =}\NormalTok{ beta}
\NormalTok{    )}
\NormalTok{df\_first}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 994 x 7
##        t     i     x     r     n     m     b
##    <int> <int> <dbl> <dbl> <int> <int> <dbl>
##  1     1     1 0.390   0.2     8     8 0.360
##  2     1     2 0.410   0.2     8     8 0.378
##  3     1     3 0.422   0.2     8     8 0.388
##  4     1     4 0.637   0.2     8     8 0.577
##  5     1     5 0.450   0.2     8     8 0.413
##  6     1     6 0.359   0.2     8     8 0.332
##  7     1     7 0.837   0.2     8     8 0.731
##  8     1     8 0.440   0.2     8     8 0.404
##  9     2     1 0.449   0.2    10    10 0.420
## 10     2     2 0.472   0.2    10    10 0.441
## # i 984 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
\NormalTok{  df\_first,}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ b)}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{,}
    \AttributeTok{alpha =} \FloatTok{0.8}
\NormalTok{    ) }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-231-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write a function \texttt{compute\_winning\_bids\_first(valuation,\ reserve,\ alpha,\ beta)} that returns only the winning bids from each first-price auction. It will call \texttt{compute\_bids\_first} inside the function. It does not return anything when no bidder bids above the reserve price.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute winning bids from first{-}price auctions}
\NormalTok{df\_first\_w }\OtherTok{\textless{}{-}}
  \FunctionTok{compute\_winning\_bids\_first}\NormalTok{(}
    \AttributeTok{valuation =}\NormalTok{ valuation,}
    \AttributeTok{reserve =}\NormalTok{ reserve,}
    \AttributeTok{alpha =}\NormalTok{ alpha,}
    \AttributeTok{beta =}\NormalTok{ beta}
\NormalTok{    )}
\NormalTok{df\_first\_w}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 100 x 5
##        t     n     m     r     w
##    <int> <int> <int> <dbl> <dbl>
##  1     1     8     8   0.2 0.731
##  2     2    10    10   0.2 0.638
##  3     3     7     5   0.2 0.525
##  4     4    11     8   0.2 0.818
##  5     5    14    12   0.2 0.842
##  6     6    12    11   0.2 0.833
##  7     7    11     9   0.2 0.772
##  8     8     9     9   0.2 0.753
##  9     9    14    14   0.2 0.849
## 10    10    11     9   0.2 0.803
## # i 90 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
\NormalTok{  df\_first\_w, }
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ w)}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{, }
    \AttributeTok{alpha =} \FloatTok{0.8}
\NormalTok{    ) }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-232-1} \end{center}

\section{Estimate the parameters}\label{estimate-the-parameters-5}

We first estimate the parameters from the winning bids data of second-price auctions. We estimate the parameters by maximizing a log-likelihood.

\[
l(\alpha, \beta) := \frac{1}{T} \sum_{t = 1}^T \ln\frac{h_t(w_t)^{1\{m_t > 1\}} \mathbb{P}\{m_t = 1\}^{1\{m_t = 1\}}}{1 - \mathbb{P}\{m_t = 0\}},
\]
where:
\[
\mathbb{P}\{m_t = 0\} := F_X(r_t)^{n_t},
\]
\[
\mathbb{P}\{m_t = 1\} := n_t F_X(r_t; \alpha, \beta)^{n_t - 1} [1 - F_X(r_t; \alpha, \beta)].
\]

\[
h_t(w_t) := n_t (n_t - 1) F_X(w_t; \alpha, \beta)^{n_t - 2} [1 - F_X(w_t; \alpha, \beta)] f_X(w_t; \alpha, \beta).
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function \texttt{compute\_p\_second\_w(w,\ r,\ m,\ n,\ alpha,\ beta)} that computes \(\mathbb{P}\{m_t = 1\}\) if \(m_t = 1\) and \(h_t(w_t)\) if \(m_t > 1\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute probability density for winning bids from a second{-}price auction}
\NormalTok{w }\OtherTok{\textless{}{-}}\NormalTok{ df\_second\_w[}\DecValTok{1}\NormalTok{, ]}\SpecialCharTok{$}\NormalTok{w}
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ df\_second\_w[}\DecValTok{1}\NormalTok{, ]}\SpecialCharTok{$}\NormalTok{r}
\NormalTok{m }\OtherTok{\textless{}{-}}\NormalTok{ df\_second\_w[}\DecValTok{1}\NormalTok{, ]}\SpecialCharTok{$}\NormalTok{m}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ df\_second\_w[}\DecValTok{1}\NormalTok{, ]}\SpecialCharTok{$}\NormalTok{n}
\FunctionTok{compute\_p\_second\_w}\NormalTok{(}
  \AttributeTok{w =}\NormalTok{ w, }
  \AttributeTok{r =}\NormalTok{ r, }
  \AttributeTok{m =}\NormalTok{ m,}
  \AttributeTok{n =}\NormalTok{ n,}
  \AttributeTok{alpha =}\NormalTok{ alpha,}
  \AttributeTok{beta =}\NormalTok{ beta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.752949
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write a function \texttt{compute\_m0(r,\ n,\ alpha,\ beta)} that computes \(\mathbb{P}\{m_t = 0\}\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute non{-}participation probability}
\FunctionTok{compute\_m0}\NormalTok{(}
  \AttributeTok{r =}\NormalTok{ r, }
  \AttributeTok{n =}\NormalTok{ n, }
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{beta =}\NormalTok{ beta}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.368569e-08
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write a function \texttt{compute\_loglikelihood\_second\_price\_w(theta,\ df\_second\_w)} that computes the log-likelihood for a second-price auction winning bid data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute log{-}likelihood for winning bids from second{-}price auctions}
\NormalTok{theta }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    alpha, }
\NormalTok{    beta}
\NormalTok{    )}
\FunctionTok{compute\_loglikelihood\_second\_price\_w}\NormalTok{(}
  \AttributeTok{theta =}\NormalTok{ theta, }
  \AttributeTok{df\_second\_w =}\NormalTok{ df\_second\_w}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9849261
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Compare the value of objective function around the true parameters.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# label}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{alpha"}\NormalTok{,}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta"}
\NormalTok{    )}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{paste}\NormalTok{(}
    \StringTok{"$"}\NormalTok{, }
\NormalTok{    label, }
    \StringTok{"$"}\NormalTok{,}
    \AttributeTok{sep =} \StringTok{""}
\NormalTok{    )}
\CommentTok{\# compute the graph}
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta)}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{  theta\_i }\OtherTok{\textless{}{-}}\NormalTok{ theta[i]}
\NormalTok{  theta\_i\_list }\OtherTok{\textless{}{-}} 
\NormalTok{    theta\_i }\SpecialCharTok{*} \FunctionTok{seq}\NormalTok{(}
      \FloatTok{0.8}\NormalTok{,}
      \FloatTok{1.2}\NormalTok{, }
      \AttributeTok{by =} \FloatTok{0.05}
\NormalTok{      )}
\NormalTok{  objective\_i }\OtherTok{\textless{}{-}}
    \FunctionTok{foreach}\NormalTok{ (}
      \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_i\_list),}
      \AttributeTok{.packages =} \FunctionTok{c}\NormalTok{(}
                    \StringTok{"EmpiricalIO"}\NormalTok{,}
                    \StringTok{"foreach"}\NormalTok{,}
                    \StringTok{"magrittr"}
\NormalTok{                   ),}
      \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{      ) }\SpecialCharTok{\%dopar\%}\NormalTok{ \{}
\NormalTok{               theta\_ij }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i\_list[j]}
\NormalTok{               theta\_j }\OtherTok{\textless{}{-}}\NormalTok{ theta}
\NormalTok{               theta\_j[i] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_ij}
\NormalTok{               objective\_ij }\OtherTok{\textless{}{-}} 
                 \FunctionTok{compute\_loglikelihood\_second\_price\_w}\NormalTok{(}
\NormalTok{                   theta\_j, }
\NormalTok{                   df\_second\_w}
\NormalTok{                   )}
               \FunctionTok{return}\NormalTok{(objective\_ij)}
\NormalTok{             \}}
\NormalTok{  df\_graph }\OtherTok{\textless{}{-}} 
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{x =} \FunctionTok{as.numeric}\NormalTok{(theta\_i\_list), }
      \AttributeTok{y =} \FunctionTok{as.numeric}\NormalTok{(objective\_i)}
\NormalTok{      )}
\NormalTok{  g }\OtherTok{\textless{}{-}} 
    \FunctionTok{ggplot}\NormalTok{(}
      \AttributeTok{data =}\NormalTok{ df\_graph, }
      \FunctionTok{aes}\NormalTok{(}
        \AttributeTok{x =}\NormalTok{ x,}
        \AttributeTok{y =}\NormalTok{ y}
\NormalTok{        )}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}
      \AttributeTok{xintercept =}\NormalTok{ theta\_i,}
      \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"objective function"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(label[i])) }\SpecialCharTok{+} 
    \FunctionTok{theme\_classic}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(g)}
\NormalTok{\}}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  graph, }
  \AttributeTok{file =} \StringTok{"lecture/data/a9/second\_parametric\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a9/second\_parametric\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{graph}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-237-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-237-2} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Estimate the parameters by maximizing the log-likelihood.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result\_second\_parametric }\OtherTok{\textless{}{-}}
  \FunctionTok{optim}\NormalTok{(}
    \AttributeTok{par =}\NormalTok{ theta,}
    \AttributeTok{fn =}\NormalTok{ compute\_loglikelihood\_second\_price\_w,}
    \AttributeTok{df\_second\_w =}\NormalTok{ df\_second\_w,}
    \AttributeTok{method =} \StringTok{"L{-}BFGS{-}B"}\NormalTok{,}
    \AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{fnscale =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{  )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  result\_second\_parametric, }
  \AttributeTok{file =} \StringTok{"lecture/data/a9/result\_second\_parametric.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result\_second\_parametric }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a9/result\_second\_parametric.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{result\_second\_parametric}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $par
## [1] 2.199238 2.078327
## 
## $value
## [1] 0.9883372
## 
## $counts
## function gradient 
##       11       11 
## 
## $convergence
## [1] 0
## 
## $message
## [1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comparison }\OtherTok{\textless{}{-}}

  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{true =}\NormalTok{ theta,}
    \AttributeTok{estimate =}\NormalTok{ result\_second\_parametric}\SpecialCharTok{$}\NormalTok{par}
\NormalTok{  )}
\NormalTok{comparison}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   true estimate
## 1    2 2.199238
## 2    2 2.078327
\end{verbatim}

Next, we estimate the parameters from the winning bids data from first-price auctions. We estimate the parameters by maximizing a log-likelihood.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Write a function \texttt{inverse\_bid\_equation(x,\ b,\ r,\ alpha,\ beta,\ n)} that returns \(\beta(x) - b\) for a bid \(b\). Write a function \texttt{inverse\_bid\_first(b,\ r,\ alpha,\ beta,\ n)} that is an inverse function \texttt{bid\_first} with respect to the signal, that is,
  \[
  \eta(b) := \beta^{-1}(b).
  \]
\end{enumerate}

To do so, we can use a built-in function called \texttt{uniroot}, which solves \(x\) such that \(f(x) = 0\) for scalar \(x\). In \texttt{uniroot}, \texttt{lower} and \texttt{upper} are set at \(r_t\) and \(1\), respectively.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ df\_first\_w[}\DecValTok{1}\NormalTok{, }\StringTok{"r"}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.numeric}\NormalTok{()}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ df\_first\_w[}\DecValTok{1}\NormalTok{, }\StringTok{"n"}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.integer}\NormalTok{()}
\NormalTok{b }\OtherTok{\textless{}{-}} \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ r }\SpecialCharTok{+} \FloatTok{0.5} 
\NormalTok{x }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\CommentTok{\# compute inverse bid equation}
\FunctionTok{inverse\_bid\_equation}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ x,}
  \AttributeTok{b =}\NormalTok{ b,}
  \AttributeTok{r =}\NormalTok{ r,}
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{beta =}\NormalTok{ beta,}
  \AttributeTok{n =}\NormalTok{ n}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.1421105
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute inverse bid}
\FunctionTok{inverse\_bid\_first}\NormalTok{(}
  \AttributeTok{b =}\NormalTok{ b, }
  \AttributeTok{r =}\NormalTok{ r,}
  \AttributeTok{alpha =}\NormalTok{ alpha,}
  \AttributeTok{beta =}\NormalTok{ beta,}
  \AttributeTok{n =}\NormalTok{ n}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6653238
\end{verbatim}

The log-likelihood conditional on \(m_t \ge 1\) is:
\[
l(\alpha, \beta) := \frac{1}{T}\sum_{t = 1}^T \log \frac{h_t(w_t)}{1 - F_X(r_t)^{n_t}},
\]
where the probability density of having \(w_t\) is:
\[
\begin{split}
h_t(w_t) &= n_t F_X[\eta_t(w_t)]^{n_t - 1} f_X[\eta_t(w_t)] \eta_t'(w_t)\\
&= \frac{n_t F_X[\eta_t(w_t)]^{n_t}}{(n_t - 1)[\eta_t(w_t) - w_t]},
\end{split}
\]
where the second equation is from the first-order condition.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write a function \texttt{compute\_p\_first\_w(w,\ r,\ alpha,\ beta,\ n)} that returns \(h_t(w)\). Remark that the equilibrium bid at specific parameters is \texttt{bid\_first(1,\ r,\ alpha,\ beta,\ n)}. If the observed wining bid \texttt{w} is above the upper limit, the function will issue an error. Therefore, inside the function \texttt{compute\_p\_first\_w(w,\ r,\ alpha,\ beta,\ n)}, check if \texttt{w} is above \texttt{bid\_first(1,\ r,\ alpha,\ beta,\ n)} and if so return \(10^{-6}\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute probability density for a winning bid from a first{-}price auction}
\NormalTok{w }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\FunctionTok{compute\_p\_first\_w}\NormalTok{(}
  \AttributeTok{w =}\NormalTok{ w, }
  \AttributeTok{r =}\NormalTok{ r, }
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{beta =}\NormalTok{ beta, }
  \AttributeTok{n =}\NormalTok{ n}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2720049
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{upper }\OtherTok{\textless{}{-}} 
  \FunctionTok{bid\_first}\NormalTok{(}
  \AttributeTok{x =} \DecValTok{1}\NormalTok{, }
  \AttributeTok{r =}\NormalTok{ r, }
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{beta =}\NormalTok{ beta, }
  \AttributeTok{n =}\NormalTok{ n}
\NormalTok{  )}
\FunctionTok{compute\_p\_first\_w}\NormalTok{(}
  \AttributeTok{w =}\NormalTok{ upper }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }
  \AttributeTok{r =}\NormalTok{ r, }
  \AttributeTok{alpha =}\NormalTok{ alpha, }
  \AttributeTok{beta =}\NormalTok{ beta, }
  \AttributeTok{n =}\NormalTok{ n}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1e-06
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Write a function \texttt{compute\_loglikelihood\_first\_price\_w(theta,\ df\_first\_w)} that computes the log-likelihood for a first-price auction winning bid data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute log{-}likelihood for winning bids for first{-}price auctions}
\FunctionTok{compute\_loglikelihood\_first\_price\_w}\NormalTok{(}
  \AttributeTok{theta =}\NormalTok{ theta, }
  \AttributeTok{df\_first\_w =}\NormalTok{ df\_first\_w}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.597414
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Compare the value of the objective function around the true parameters.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
\NormalTok{    alpha,}
\NormalTok{    beta}
\NormalTok{    )}
\CommentTok{\# label}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{c}\NormalTok{(}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{alpha"}\NormalTok{,}
    \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{beta"}
\NormalTok{    )}
\NormalTok{label }\OtherTok{\textless{}{-}} 
  \FunctionTok{paste}\NormalTok{(}
    \StringTok{"$"}\NormalTok{,}
\NormalTok{    label,}
    \StringTok{"$"}\NormalTok{, }
    \AttributeTok{sep =} \StringTok{""}
\NormalTok{    )}
\CommentTok{\# compute the graph}
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{foreach}\NormalTok{ (}
    \AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta)}
\NormalTok{    ) }\SpecialCharTok{\%do\%}\NormalTok{ \{}
\NormalTok{  theta\_i }\OtherTok{\textless{}{-}}\NormalTok{ theta[i]}
\NormalTok{  theta\_i\_list }\OtherTok{\textless{}{-}} 
\NormalTok{    theta\_i }\SpecialCharTok{*} \FunctionTok{seq}\NormalTok{(}
      \FloatTok{0.8}\NormalTok{,}
      \FloatTok{1.2}\NormalTok{,}
      \AttributeTok{by =} \FloatTok{0.05}
\NormalTok{      )}
\NormalTok{  objective\_i }\OtherTok{\textless{}{-}}
    \FunctionTok{foreach}\NormalTok{ (}
      \AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(theta\_i\_list),}
      \AttributeTok{.packages =} \FunctionTok{c}\NormalTok{(}
        \StringTok{"EmpiricalIO"}\NormalTok{,}
        \StringTok{"foreach"}\NormalTok{,}
        \StringTok{"magrittr"}
\NormalTok{        ),}
      \AttributeTok{.combine =} \StringTok{"rbind"}
\NormalTok{      ) }\SpecialCharTok{\%dopar\%}\NormalTok{ \{}
\NormalTok{               theta\_ij }\OtherTok{\textless{}{-}}\NormalTok{ theta\_i\_list[j]}
\NormalTok{               theta\_j }\OtherTok{\textless{}{-}}\NormalTok{ theta}
\NormalTok{               theta\_j[i] }\OtherTok{\textless{}{-}}\NormalTok{ theta\_ij}
\NormalTok{               objective\_ij }\OtherTok{\textless{}{-}} 
                 \FunctionTok{compute\_loglikelihood\_first\_price\_w}\NormalTok{(}
\NormalTok{                   theta\_j,}
\NormalTok{                   df\_first\_w}
\NormalTok{                   )}
               \FunctionTok{return}\NormalTok{(objective\_ij)}
\NormalTok{             \}}
\NormalTok{  df\_graph }\OtherTok{\textless{}{-}} 
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{x =} \FunctionTok{as.numeric}\NormalTok{(theta\_i\_list), }
      \AttributeTok{y =} \FunctionTok{as.numeric}\NormalTok{(objective\_i)}
\NormalTok{      )}
\NormalTok{  g }\OtherTok{\textless{}{-}}
    \FunctionTok{ggplot}\NormalTok{(}
      \AttributeTok{data =}\NormalTok{ df\_graph,}
      \FunctionTok{aes}\NormalTok{(}
        \AttributeTok{x =}\NormalTok{ x,}
        \AttributeTok{y =}\NormalTok{ y}
\NormalTok{        )}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}
      \AttributeTok{xintercept =}\NormalTok{ theta\_i, }
      \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{      ) }\SpecialCharTok{+}
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"objective function"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(label[i])) }\SpecialCharTok{+} 
    \FunctionTok{theme\_classic}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(g)}
\NormalTok{\}}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  graph,}
  \AttributeTok{file =} \StringTok{"lecture/data/a9/first\_parametric\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a9/first\_parametric\_graph.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{graph}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-244-1} \end{center}

\begin{verbatim}
## 
## [[2]]
\end{verbatim}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-244-2} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Estimate the parameters by maximizing the log-likelihood. Set the lower bounds at zero. Use the Nelder-Mead method. Otherwise the parameter search can go to extreme values because of the discontinuity at the point where the upper limit is below the observed bid.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result\_first\_parametric }\OtherTok{\textless{}{-}}
  \FunctionTok{optim}\NormalTok{(}
    \AttributeTok{par =}\NormalTok{ theta,}
    \AttributeTok{fn =}\NormalTok{ compute\_loglikelihood\_first\_price\_w,}
    \AttributeTok{df\_first\_w =}\NormalTok{ df\_first\_w,}
    \AttributeTok{method =} \StringTok{"Nelder{-}Mead"}\NormalTok{,}
    \AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{fnscale =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{  )}
\FunctionTok{saveRDS}\NormalTok{(}
\NormalTok{  result\_first\_parametric,}
  \AttributeTok{file =} \StringTok{"lecture/data/a9/result\_first\_parametric.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result\_first\_parametric }\OtherTok{\textless{}{-}} 
  \FunctionTok{readRDS}\NormalTok{(}
    \AttributeTok{file =} \StringTok{"lecture/data/a9/result\_first\_parametric.rds"} \SpecialCharTok{\%\textgreater{}\%}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{()}
\NormalTok{  )}
\NormalTok{result\_first\_parametric}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $par
## [1] 1.977676 2.004715
## 
## $value
## [1] 1.607161
## 
## $counts
## function gradient 
##       91       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comparison }\OtherTok{\textless{}{-}}

  \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{true =}\NormalTok{ theta,}
    \AttributeTok{estimate =}\NormalTok{ result\_first\_parametric}\SpecialCharTok{$}\NormalTok{par}
\NormalTok{  )}
\NormalTok{comparison}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   true estimate
## 1    2 1.977676
## 2    2 2.004715
\end{verbatim}

Finally, we non-parametrically estimate the distribution of the valuation using bid data from first-price auctions \texttt{df\_first}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  Write a function \texttt{F\_b(b)} that returns an empirical cumulative distribution at \texttt{b}. This can be obtained by using a function \texttt{ecdf}.
  Also, write a function \texttt{f\_b(b)} that returns an empirical probability density at \texttt{b}. This can be obtained by combining functions \texttt{approxfun} and \texttt{density}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# cumulative distribution}
\FunctionTok{ggplot}\NormalTok{(}
\NormalTok{  df\_first, }
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ b)}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{stat\_ecdf}\NormalTok{(}\AttributeTok{color =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"bid"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"cumulative distribution"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-247-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{F\_b }\OtherTok{\textless{}{-}} \FunctionTok{ecdf}\NormalTok{(df\_first}\SpecialCharTok{$}\NormalTok{b)}
\FunctionTok{F\_b}\NormalTok{(}\FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4104628
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{F\_b}\NormalTok{(}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7173038
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# probability density}
\FunctionTok{ggplot}\NormalTok{(}
\NormalTok{  df\_first, }
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ b)}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-247-2} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_b }\OtherTok{\textless{}{-}} \FunctionTok{approxfun}\NormalTok{(}\FunctionTok{density}\NormalTok{(df\_first}\SpecialCharTok{$}\NormalTok{b))}
\FunctionTok{f\_b}\NormalTok{(}\FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.680124
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{f\_b}\NormalTok{(}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.469983
\end{verbatim}

The equilibrium distribution and density of the highest rival's bid are:
\[
H_b(b) := F_b(b)^{n - 1},
\]
\[
h_b(b) := (n - 1) f_b(b) F_b(b)^{n - 2}.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Write a function \texttt{H\_b(b,\ n,\ F\_b)} and \texttt{h\_b(b,\ n,\ F\_b,\ f\_b)} that return the equilibrium distribution and density of the highest rival's bid at point \texttt{b}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{H\_b}\NormalTok{(}
  \AttributeTok{b =} \FloatTok{0.4}\NormalTok{,}
  \AttributeTok{n =}\NormalTok{ n,}
  \AttributeTok{F\_b =}\NormalTok{ F\_b}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001962983
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{h\_b}\NormalTok{(}
  \AttributeTok{b =} \FloatTok{0.4}\NormalTok{,}
  \AttributeTok{n =}\NormalTok{ n,}
  \AttributeTok{F\_b =}\NormalTok{ F\_b, }
\NormalTok{  f\_b}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.05624476
\end{verbatim}

When a bidder bids \(b\), the implied valuation of her is:
\[
x = b + \frac{H_b(b)}{h_b(b)}.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{11}
\tightlist
\item
  Write a function \texttt{compute\_implied\_valuation(b,\ n,\ r)} that returns the implied valuation given a bid. Let it return \(x = 0\) if \(b < r\), because we cannot know the value when the bid is below the reserve price.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ df\_first[}\DecValTok{1}\NormalTok{, }\StringTok{"r"}\NormalTok{]}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ df\_first[}\DecValTok{1}\NormalTok{, }\StringTok{"n"}\NormalTok{]}
\FunctionTok{compute\_implied\_valuation}\NormalTok{(}
  \AttributeTok{b =} \FloatTok{0.4}\NormalTok{,}
  \AttributeTok{n =}\NormalTok{ n, }
  \AttributeTok{r =}\NormalTok{ r, }
  \AttributeTok{F\_b =}\NormalTok{ F\_b, }
  \AttributeTok{f\_b =}\NormalTok{ f\_b}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           n
## 1 0.4349007
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{12}
\tightlist
\item
  Obtain the vector of implied valuations from the vector of bids and draw the empirical cumulative distribution. Overlay it with the true empirical cumulative distribution of the valuations.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{valuation\_implied }\OtherTok{\textless{}{-}} 
\NormalTok{  df\_first }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{rowwise}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{compute\_implied\_valuation}\NormalTok{(}
\NormalTok{      b, }
\NormalTok{      n,}
\NormalTok{      r,}
\NormalTok{      F\_b, }
\NormalTok{      f\_b}
\NormalTok{      )}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(x) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"estimate"}\NormalTok{)}
\NormalTok{valuation\_true }\OtherTok{\textless{}{-}} 
\NormalTok{  valuation }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(x) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}\AttributeTok{type =} \StringTok{"true"}\NormalTok{)}
\NormalTok{valuation\_plot }\OtherTok{\textless{}{-}} 
  \FunctionTok{rbind}\NormalTok{(}
\NormalTok{    valuation\_true,}
\NormalTok{    valuation\_implied}
\NormalTok{    )}
\FunctionTok{ggplot}\NormalTok{(}
\NormalTok{  valuation\_plot,}
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ x, }
    \AttributeTok{color =}\NormalTok{ type}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{stat\_ecdf}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{lecture_files/figure-latex/unnamed-chunk-250-1} \end{center}

\chapter{Integrating with C++ using Rcpp and RcppEigen}\label{rcpp}

\section{Prerequisite}\label{prerequisite}

\begin{itemize}
\tightlist
\item
  In this chapter, we learn how to integrate C++ using Rcpp and RcppEigen.
\item
  \texttt{RcppEigen} is a package to use a linear algebra library \texttt{Eigen} with R. The original \texttt{Eigen} library and its documentation is found in \href{http://eigen.tuxfamily.org/index.php?title=Main_Page}{their website}.
\item
  Instead of \texttt{RcppEigen}, you may want to use \texttt{RcppArmadillo}. \texttt{Armadillo} is another libear algebra library in C++.
\item
  We presume that:

  \begin{itemize}
  \tightlist
  \item
    C/C++ environment is installed to the computer.

    \begin{itemize}
    \tightlist
    \item
      For OSX, you can install \href{https://developer.apple.com/xcode/}{Apple Developer Tools}.
    \item
      For Windows, you can try \href{https://cran.r-project.org/bin/windows/Rtools/}{Rtools}.
    \end{itemize}
  \item
    \texttt{Rcpp} and \texttt{RcppEigen} are installed.
  \item
    The project is created in RStudio from \texttt{File\ \textgreater{}\ New\ Project\ \textgreater{}\ New\ Directory\ \textgreater{}\ R\ Package\ using\ RcppEigen}. In the following, I use the project name \texttt{EmpiricalIO} but the name can be as you like.
  \end{itemize}
\item
  We presume the you have the following folder and file structure from the root directory:

  \begin{itemize}
  \tightlist
  \item
    \texttt{main}.

    \begin{itemize}
    \tightlist
    \item
      \texttt{main.R}: all executable statements are written in this file.
    \end{itemize}
  \item
    \texttt{R}.

    \begin{itemize}
    \tightlist
    \item
      \texttt{functions.R}: all function definitions in R are written in this file.
    \end{itemize}
  \item
    \texttt{src}.

    \begin{itemize}
    \tightlist
    \item
      \texttt{functions.cpp}: all function definitions in C++ are written in this file.

      \begin{itemize}
      \tightlist
      \item
        It includes:
      \end{itemize}

\begin{verbatim}
"src/functions.cpp"
-------------------
#include <Rcpp.h>
#include <RcppEigen.h>
\end{verbatim}

      \begin{itemize}
      \tightlist
      \item
        Inside \texttt{functions.cpp}, avoid using name spaces.
      \end{itemize}
    \item
      \texttt{Makevars}: compilation flags for osx/Linux should be written here.
    \item
      \texttt{Makevars.win}: compilation flags for Windows should be written here.
    \end{itemize}
  \item
    \texttt{inst}.

    \begin{itemize}
    \tightlist
    \item
      \texttt{include}: header files for external libraries in C/C++ are stored here.
    \end{itemize}
  \end{itemize}
\item
  \texttt{Makevars/Makevars.win} should be:
\end{itemize}

\begin{verbatim}
Makevars
--------
PKG_CPPFLAGS = -w -std=c++11 -I../inst/include/ -O3
\end{verbatim}

\begin{verbatim}
Makevars.win
------------
PKG_CPPFLAGS = -w -std=c++11 -I../inst/include/ -O3
\end{verbatim}

\begin{verbatim}
- `-w` is for supprssing some warnings in `Eigen`. If you want to keep warnings shown, this can be removed.
- `-std=c++11` is for using the latest functionalities of C++ (optional).
- `-I../inst/include/` is for setting the header path to `../inst/include/` (optional).
\end{verbatim}

\section{Workflow}\label{workflow}

\begin{itemize}
\tightlist
\item
  To minimize the likelihood of bugs and the time to edit and debug the code, I recommend you to follw the following workflow.
\item
  This workflow is based on my experience. If you find better workflow, you can overwrite by your own way.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a procedure in \texttt{main/main.R}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}
\NormalTok{y1 }\OtherTok{\textless{}{-}}\NormalTok{ x}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Rewrite the procedure to a function in \texttt{main/main.R}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\CommentTok{\# compute coefficient{-}wise square}
\NormalTok{compute\_square }\OtherTok{\textless{}{-}}
  \ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    y }\OtherTok{\textless{}{-}}\NormalTok{ x}\SpecialCharTok{\^{}}\DecValTok{2}
    \FunctionTok{return}\NormalTok{(y)}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Execute the function in \texttt{main/main.R} and check that the output is the same with the output of the original
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{y2 }\OtherTok{\textless{}{-}} \FunctionTok{compute\_square}\NormalTok{(x)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(y1 }\SpecialCharTok{{-}}\NormalTok{ y2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Cut and paste the function to \texttt{R/functions.R}.
\item
  Build the package and load the function from the library.
\item
  Check if the function can be executed as in step 3.
\item
  Copy the function to \texttt{src/functions.cpp} and comment them out.
\end{enumerate}

\begin{verbatim}
// src/functions.cpp
// # compute coefficient-wise square
// compute_square <-
//   function(x) {
//     y <- x^2
//     return(y)
//   }
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Write function in C++ by translating the copied and pasted R code.

  \begin{itemize}
  \tightlist
  \item
    The function name should be consistent with the function name in R. I often put \texttt{\_rcpp} to the end of the name.
  \item
    Put \texttt{//\ {[}{[}Rcpp::export{]}{]}} above the name of the function if you want to call this function directly from R. Otherwise, the wrapper function to call from R is not created.
  \item
    The class of the inputs and output should be consistent with \texttt{Rcpp} objects. This will be explained later.
  \end{itemize}
\end{enumerate}

\begin{verbatim}
// src/functions.cpp
// # compute coefficient-wise square
// compute_square <-
// [[Rcpp::export]]
Eigen::VectorXd compute_square_rcpp(Eigen::VectorXd x) {
  //   function(x) {
  Eigen::VectorXd y = x.array().square();
  //     y <- x^2
  //     return(y)
  //   }
  return(y);
}
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Check if clean and rebuild work.

  \begin{itemize}
  \tightlist
  \item
    If there is a compilation error happens, debug until the compilation succeeds.
  \item
    Sometimes, deleting \texttt{R/RcppExports.R} and \texttt{R/RcppExports.cpp} may be need when re-compile the functions.
  \end{itemize}
\item
  Clean up the code by eliminating the copied and pasted R code.
\end{enumerate}

\begin{verbatim}
// src/functions.cpp
// compute coefficient-wise square
// [[Rcpp::export]]
Eigen::VectorXd compute_square_rcpp(Eigen::VectorXd x) {
  Eigen::VectorXd y = x.array().square();
  return(y);
}
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Now by calling the library, you should be able to use the function written in C++ in R. Check if it returns a valid value and if the output is the same as the output of the R function.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{y3 }\OtherTok{\textless{}{-}} \FunctionTok{compute\_square\_rcpp}\NormalTok{(x)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(y2 }\SpecialCharTok{{-}}\NormalTok{ y3))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{11}
\tightlist
\item
  If there is a run-time bug in the C++ function, you may have to use some debugger for C++ to debug the function.

  \begin{itemize}
  \tightlist
  \item
    In osx, you can debug the C++ function called from R function in the following way.
  \item
    Open the terminal and run R with the debugger \texttt{lldb} by typing the following command in the terminal:
  \end{itemize}

\begin{verbatim}
# terminal
R -d lldb
\end{verbatim}

  \begin{itemize}
  \tightlist
  \item
    Run \texttt{main/main.R} by typing the following command in the terminal:
  \end{itemize}

\begin{verbatim}
# terminal
run -f main/main.R
\end{verbatim}

  \begin{itemize}
  \tightlist
  \item
    This should execute the R source code.
  \item
    After \texttt{library(EmpiricalIO)} is read, stop the process by \texttt{Ctrl\ +\ C} before the function in question is called. If there is no time gap between them, set \texttt{Sys.sleep()} in R to buy some time.
  \item
    As you stop the process, set the break point at the function in question by typing in the terminal as:
  \end{itemize}

\begin{verbatim}
# terminal
br s -n compute_square_rcpp
\end{verbatim}

  and then continue the process by typing \texttt{c} in the terminal.

  \begin{itemize}
  \tightlist
  \item
    For the rest, refer to the \href{https://lldb.llvm.org/}{documentation of lldb}.
  \item
    There is no such an easy way in Windows. You will have to establish an environment in which you can run a cpp file with executable statemtns and call the debugging functions from the file. Then, you can use some debuggers such as \texttt{gdb} to debug the functions inside the cpp file.
  \end{itemize}
\item
  If you need to modify the function, first rewrite the R function and then follow the same step to rewrite the C++ function. Never start the debugging from C++ functions.
\end{enumerate}

\section{Passing R Objects as Rcpp Objects}\label{passing-r-objects-as-rcpp-objects}

\begin{itemize}
\tightlist
\item
  R class corresponds to the following Rcpp class:
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
R & Rcpp \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{logical} & \texttt{Logical} \\
\texttt{integer} & \texttt{Integer} \\
\texttt{numeric} & \texttt{Numeric} \\
\texttt{complex} & \texttt{Complex} \\
\texttt{character} & \texttt{String} \\
\texttt{Date} & \texttt{Date} \\
\texttt{POSIXct} & \texttt{Datetime} \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  R data structure corresponds to the following Rcpp data structure:
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
R & Rcpp \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{vector} & \texttt{Vector} \\
\texttt{matrix} & \texttt{Matrix} \\
\texttt{data.frame} & \texttt{DataFrame} \\
\texttt{list} & \texttt{List} \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  For example, a numeric vector in R is passed to \texttt{Rcpp::NumericVector} in Rcpp, an integer matrix is to \texttt{Rcpp::IntegerMatrix}, and so on.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\CommentTok{\# numeric vector }
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  2.18543791 -0.01282801 -0.30530893 -0.58421346  0.77126850
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# numeric matrix}
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{2}\SpecialCharTok{*}\DecValTok{5}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          [,1]       [,2]       [,3]       [,4]      [,5]
## [1,] 2.106189 -0.2612649 -0.7788302 -0.4213451  1.218305
## [2,] 0.412157  2.0737836  1.1315325 -1.0217474 -1.799761
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Let's write a C++ function that just receives a numeric vector and returns the numeric vector, and receives a numeric matrix and returns the numeric matrix.
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// [[Rcpp::export]]
Rcpp::NumericVector pass_numeric_vector_to_rcpp(Rcpp::NumericVector x) {
  return(x);
}
// [[Rcpp::export]]
Rcpp::NumericMatrix pass_numeric_matrix_to_rcpp(Rcpp::NumericMatrix Y) {
  return(Y);
}
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Check if you can pass R objects and get the right result:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.r}
\NormalTok{x\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{pass\_numeric\_vector\_to\_rcpp}\NormalTok{(x)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(x }\SpecialCharTok{{-}}\NormalTok{ x\_rcpp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{pass\_numeric\_matrix\_to\_rcpp}\NormalTok{(Y)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(Y }\SpecialCharTok{{-}}\NormalTok{ Y\_rcpp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \textbf{Exercise}: Write functions \texttt{pass\_integer\_vector\_to\_rcpp}, \texttt{pass\_integer\_matrix\_to\_rcpp}, \texttt{pass\_list\_to\_rcpp}, \texttt{pass\_data\_frame\_to\_rcpp} that receive an integer vector, list, and data frame and just return themselves.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.r}
\CommentTok{\# integer vector}
\NormalTok{z }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5}
\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# integer matrix}
\NormalTok{W }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\NormalTok{W}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2]
## [1,]    1    1
## [2,]    1    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# list}
\NormalTok{L }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{z =}\NormalTok{ z)}
\NormalTok{L}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $x
## [1]  2.18543791 -0.01282801 -0.30530893 -0.58421346  0.77126850
## 
## $Y
##          [,1]       [,2]       [,3]       [,4]      [,5]
## [1,] 2.106189 -0.2612649 -0.7788302 -0.4213451  1.218305
## [2,] 0.412157  2.0737836  1.1315325 -1.0217474 -1.799761
## 
## $z
## [1] 1 2 3 4 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data frame}
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x1 =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{5}\NormalTok{), }\AttributeTok{x2 =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{5}\NormalTok{))}
\NormalTok{D}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            x1         x2
## 1 -0.30824994 -1.5570357
## 2  0.01551524  1.9231637
## 3 -0.44231772 -1.8568296
## 4 -1.63800773 -2.1061184
## 5 -0.64140116  0.6976485
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{pass\_integer\_vector\_to\_rcpp}\NormalTok{(z)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(z }\SpecialCharTok{{-}}\NormalTok{ z\_rcpp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{W\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{pass\_integer\_matrix\_to\_rcpp}\NormalTok{(W)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(W }\SpecialCharTok{{-}}\NormalTok{ W\_rcpp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{pass\_list\_to\_rcpp}\NormalTok{(L)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(L) }\SpecialCharTok{{-}} \FunctionTok{unlist}\NormalTok{(L\_rcpp)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{pass\_data\_frame\_to\_rcpp}\NormalTok{(D)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(D }\SpecialCharTok{{-}}\NormalTok{ D\_rcpp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\section{Passing R Objects as Eigen Objects}\label{passing-r-objects-as-eigen-objects}

\begin{itemize}
\tightlist
\item
  R data structure corresponds to the following Eigen data structure:
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
R & Eigen \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{vector} & \texttt{Eigen::VectorX} \\
\texttt{matrix} & \texttt{Eigen::MatrixX} \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  If you pass an \texttt{integer} vector and matrix, the corresponding Eigen objects are \texttt{Eigen::VectorXi} and \texttt{Eigen::MatrixXi}.
\item
  If you pass an \texttt{numeric} vector and matrix, the corresponding Eigen objects are \texttt{Eigen::VectorXd} and \texttt{Eigen::MatrixXd}.
\item
  The class of the output can be Eigen class. If you return \texttt{Eigen::VectorXd}, \texttt{Eigen::MatrixXd}, then they are automatically converted to the corresponding R objects.
\item
  Check if you can pass \texttt{x}, \texttt{Y}, and \texttt{z} as follows:
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// [[Rcpp::export]]
Eigen::VectorXd pass_numeric_vector_to_eigen(Eigen::VectorXd x) {
  return(x);
}
// [[Rcpp::export]]
Eigen::MatrixXd pass_numeric_matrix_to_eigen(Eigen::MatrixXd Y) {
  return(Y);
}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.r}
\NormalTok{x\_eigen }\OtherTok{\textless{}{-}} \FunctionTok{pass\_numeric\_vector\_to\_eigen}\NormalTok{(x)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(x }\SpecialCharTok{{-}}\NormalTok{ x\_eigen))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y\_eigen }\OtherTok{\textless{}{-}} \FunctionTok{pass\_numeric\_matrix\_to\_eigen}\NormalTok{(Y)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(Y }\SpecialCharTok{{-}}\NormalTok{ Y\_eigen))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \textbf{Exercise}: Write functions \texttt{pass\_integer\_vector\_to\_rcpp} and \texttt{pass\_integer\_matrix\_to\_rcpp} that receive an integer vector and integer matrix and just return themselves.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.r}
\NormalTok{z\_eigen }\OtherTok{\textless{}{-}} \FunctionTok{pass\_integer\_vector\_to\_eigen}\NormalTok{(z)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(z }\SpecialCharTok{{-}}\NormalTok{ z\_eigen))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{W\_eigen }\OtherTok{\textless{}{-}} \FunctionTok{pass\_integer\_matrix\_to\_eigen}\NormalTok{(W)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(W }\SpecialCharTok{{-}}\NormalTok{ W\_eigen))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  If you pass a vector and matrix by \texttt{Eigen::VectorX} and \texttt{Eigen::MatrixX}, the objects are \textbf{copied} to the new objects. This means that the new memory is allocated. If you are going to modify the passed object inside the C++ function, the objects have to be copied. Otherwise, you can just map the objects in the following way so that the new memory is not allocated, whereas you cannot modify the objects in the C++ function.
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// [[Rcpp::export]]
Eigen::VectorXd map_numeric_vector_to_eigen(Eigen::Map<Eigen::VectorXd> x) {
  return(x);
}
// [[Rcpp::export]]
Eigen::MatrixXd map_numeric_matrix_to_eigen(Eigen::Map<Eigen::MatrixXd> Y) {
  return(Y);
}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.r}
\NormalTok{x\_eigen\_map }\OtherTok{\textless{}{-}} \FunctionTok{map\_numeric\_vector\_to\_eigen}\NormalTok{(x)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(x }\SpecialCharTok{{-}}\NormalTok{ x\_eigen\_map))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y\_eigen\_map }\OtherTok{\textless{}{-}} \FunctionTok{map\_numeric\_matrix\_to\_eigen}\NormalTok{(Y)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(Y }\SpecialCharTok{{-}}\NormalTok{ Y\_eigen\_map))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\item
  I recommend to directly pass R vectors and matrices to \texttt{Eigen::VectorX} and \texttt{Eigen::MatrixX} rather than to \texttt{Vector} and \texttt{Matrix} in Rcpp, because \texttt{Eigen::VectorX} and \texttt{Eigen::MatrixX} have richer methods for linear algebra.
\item
  R list cannot be directly translated to Eigen objects, but the list of vectors and matrices, and the list of list of R objects can be passed to Eigen in the following way.
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// [[Rcpp::export]]
Rcpp::List pass_list_to_eigen(Rcpp::List L) {
  // double vector
  Eigen::VectorXd x(Rcpp::as<Eigen::VectorXd>(L.at(0)));
  // double matrix
  Eigen::MatrixXd Y(Rcpp::as<Eigen::MatrixXd>(L.at(1)));
  // integer vector
  Eigen::VectorXi z(Rcpp::as<Eigen::VectorXi>(L.at(2)));
  // integer matrix
  Eigen::MatrixXi W(Rcpp::as<Eigen::MatrixXi>(L.at(3)));
  // return
  Rcpp::List output = Rcpp::List::create(x, Y, z, W);
  return(output);
}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.r}
\NormalTok{list\_1 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{list\_1[[}\DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ x}
\NormalTok{list\_1[[}\DecValTok{2}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ Y}
\NormalTok{list\_1[[}\DecValTok{3}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ z}
\NormalTok{list\_1[[}\DecValTok{4}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ W}
\NormalTok{list\_1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1]  2.18543791 -0.01282801 -0.30530893 -0.58421346  0.77126850
## 
## [[2]]
##          [,1]       [,2]       [,3]       [,4]      [,5]
## [1,] 2.106189 -0.2612649 -0.7788302 -0.4213451  1.218305
## [2,] 0.412157  2.0737836  1.1315325 -1.0217474 -1.799761
## 
## [[3]]
## [1] 1 2 3 4 5
## 
## [[4]]
##      [,1] [,2]
## [1,]    1    1
## [2,]    1    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{list\_1\_eigen }\OtherTok{\textless{}{-}} \FunctionTok{pass\_list\_to\_eigen}\NormalTok{(list\_1)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(list\_1) }\SpecialCharTok{{-}} \FunctionTok{unlist}\NormalTok{(list\_1\_eigen)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  You can also pass a list with named arguments and return a named list as follows:
\end{itemize}

\begin{verbatim}
// src/funtions.cpp
// [[Rcpp::export]]
Rcpp::List pass_named_list_to_eigen(Rcpp::List L) {
  // double vector
  Eigen::VectorXd x(Rcpp::as<Eigen::VectorXd>(L["x"]));
  // double matrix
  Eigen::MatrixXd Y(Rcpp::as<Eigen::MatrixXd>(L["Y"]));
  // integer vector
  Eigen::VectorXi z(Rcpp::as<Eigen::VectorXi>(L["z"]));
  // integer matrix
  Eigen::MatrixXi W(Rcpp::as<Eigen::MatrixXi>(L["W"]));
  // return
  Rcpp::List output = Rcpp::List::create(
    Rcpp::Named("x") = x, 
    Rcpp::Named("Y") = Y, 
    Rcpp::Named("z") = z, 
    Rcpp::Named("W") = W);
  return(output);
}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.r}
\NormalTok{list\_2 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{list\_2}\SpecialCharTok{$}\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x}
\NormalTok{list\_2}\SpecialCharTok{$}\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ Y}
\NormalTok{list\_2}\SpecialCharTok{$}\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ z}
\NormalTok{list\_2}\SpecialCharTok{$}\NormalTok{W }\OtherTok{\textless{}{-}}\NormalTok{ W}
\NormalTok{list\_2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $x
## [1]  2.18543791 -0.01282801 -0.30530893 -0.58421346  0.77126850
## 
## $Y
##          [,1]       [,2]       [,3]       [,4]      [,5]
## [1,] 2.106189 -0.2612649 -0.7788302 -0.4213451  1.218305
## [2,] 0.412157  2.0737836  1.1315325 -1.0217474 -1.799761
## 
## $z
## [1] 1 2 3 4 5
## 
## $W
##      [,1] [,2]
## [1,]    1    1
## [2,]    1    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{list\_2\_eigen }\OtherTok{\textless{}{-}} \FunctionTok{pass\_named\_list\_to\_eigen}\NormalTok{(list\_2)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(list\_2) }\SpecialCharTok{{-}} \FunctionTok{unlist}\NormalTok{(list\_2\_eigen)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  You can also access to the column of \texttt{Rcpp::DataFrame} in the similar way.
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// [[Rcpp::export]]
Eigen::VectorXd extract_column_from_data_frame(Rcpp::DataFrame D) {
  // pass column x1 of D to Eigen::VectorXd named x1
  Eigen::VectorXd x1(Rcpp::as<Eigen::VectorXd>(D["x1"]));
  return(x1);
}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{x1 }\OtherTok{\textless{}{-}} \FunctionTok{extract\_column\_from\_data\_frame}\NormalTok{(D)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(D}\SpecialCharTok{$}\NormalTok{x1 }\SpecialCharTok{{-}}\NormalTok{ x1))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  This allows us to pass whatever objects in R to a C++ function.
\item
  If you are planning to translate R functions to C/C++, from the beginning, you should write the R functions in the way inputs and outpus can be passed to C/C++ as above.
\end{itemize}

\section{Passing R Objects in Other Objects in C/C++}\label{passing-r-objects-in-other-objects-in-cc}

\begin{itemize}
\tightlist
\item
  \texttt{integer} and \texttt{numeric} scalars in R can be simply passed to \texttt{int} and \texttt{double} in C/C++.
\item
  Vectors in R can be passed to \texttt{std::vector\textless{}int\textgreater{}} or \texttt{std::vector\textless{}double\textgreater{}} objects. This may be helpful if you want to use the methods for \texttt{std::vector}.
\end{itemize}

\section{Manipulating Objects in a C++ Function}\label{manipulating-objects-in-a-c-function}

\begin{itemize}
\tightlist
\item
  As mentioned above, the best practice is to pass vectors and matrices to \texttt{Eigen::VectorXd}/\texttt{Eigen::VectorXi} and \texttt{Eigen::MatrixXd}/\texttt{Eigen::MatrixXi} rather than \texttt{Rcpp::NumericVector}/\texttt{Rcpp::IntegerVector} and \texttt{Rcpp::NumericMatrix}/\texttt{Rcpp::IntegerMatrix}.
\item
  The other objects will be passed as \texttt{Rcpp::DataFrame} or \texttt{Rcpp::List} and at the end converted to \texttt{Eigen::VectorXd}/\texttt{Eigen::VectorXi} and \texttt{Eigen::MatrixXd}/\texttt{Eigen::MatrixXi} usin \texttt{Rcpp::as} as explained above.
\item
  The rest of manipulation will be done using the methods in Eigen. Here I introduce basic operations. For the detail, refer to the \href{https://eigen.tuxfamily.org/dox/GettingStarted.html}{online document of Eigen}.
\end{itemize}

\subsection{Matrix and Vector Arithmetic}\label{matrix-and-vector-arithmetic}

\begin{itemize}
\tightlist
\item
  Addition and subtraction:

  \begin{itemize}
  \tightlist
  \item
    Binary operator \(+\) as in \texttt{a\ +\ b}.
  \item
    Binary operator \(-\) as in \texttt{a\ -\ b}.
  \item
    Unary operator \(-\) as in \texttt{-\ a}.
  \end{itemize}
\item
  Scalar multiplication and division:

  \begin{itemize}
  \tightlist
  \item
    Binary operator \(\times\) as in \texttt{matrix\ *\ scalar}.
  \item
    Binary operator \(\times\) as in \texttt{scalar\ *\ matrix}.
  \item
    Binary operator \(/\) as in \texttt{matrix\ /\ scalar}.
  \end{itemize}
\item
  Transposition:

  \begin{itemize}
  \tightlist
  \item
    Transposition as in \texttt{matrix.transpose()}.
  \end{itemize}
\item
  Matrix-matrix and matrix-vector multiplication:

  \begin{itemize}
  \tightlist
  \item
    This part is different from R.
  \item
    Matrix multiplication is as in \texttt{A\ *\ B}.
  \item
    Coefficientwise multiplication is explained later but is as in \texttt{A.array()\ *\ B.array()}.
  \end{itemize}
\item
  Following the best practice, first write R function for these operations in \texttt{R/functions.R} and run in \texttt{main/main.R}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# R/functions.R}
\CommentTok{\# matrix and vector arithmetic}
\NormalTok{matrix\_vector\_arithmetic }\OtherTok{\textless{}{-}}
  \ControlFlowTok{function}\NormalTok{(A, B, v, c) \{}
    \CommentTok{\# addition and subtraction}
\NormalTok{    X1 }\OtherTok{\textless{}{-}}\NormalTok{ A }\SpecialCharTok{+}\NormalTok{ B}
\NormalTok{    X2 }\OtherTok{\textless{}{-}}\NormalTok{ A }\SpecialCharTok{{-}}\NormalTok{ B}
\NormalTok{    X3 }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{A}
    \CommentTok{\# scalar multiplication and division}
\NormalTok{    X4 }\OtherTok{\textless{}{-}}\NormalTok{ A }\SpecialCharTok{*}\NormalTok{ c}
\NormalTok{    X5 }\OtherTok{\textless{}{-}}\NormalTok{ c }\SpecialCharTok{*}\NormalTok{ A}
\NormalTok{    X6 }\OtherTok{\textless{}{-}}\NormalTok{ A }\SpecialCharTok{/}\NormalTok{ c}
    \CommentTok{\# transpose}
\NormalTok{    X7 }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(A)}
    \CommentTok{\# matrix{-}matrix and matrix{-}vector multiplication}
\NormalTok{    X8 }\OtherTok{\textless{}{-}}\NormalTok{ A }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(B)}
\NormalTok{    X9 }\OtherTok{\textless{}{-}}\NormalTok{ A }\SpecialCharTok{\%*\%}\NormalTok{ v}
    \CommentTok{\# return}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{X1 =}\NormalTok{ X1,}
                \AttributeTok{X2 =}\NormalTok{ X2,}
                \AttributeTok{X3 =}\NormalTok{ X3,}
                \AttributeTok{X4 =}\NormalTok{ X4,}
                \AttributeTok{X5 =}\NormalTok{ X5,}
                \AttributeTok{X6 =}\NormalTok{ X6,}
                \AttributeTok{X7 =}\NormalTok{ X7,}
                \AttributeTok{X8 =}\NormalTok{ X8,}
                \AttributeTok{X9 =}\NormalTok{ X9))}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# addition subtraction}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{2}\SpecialCharTok{*}\DecValTok{4}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{2}\SpecialCharTok{*}\DecValTok{4}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\NormalTok{c }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{v }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{4}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{)}
\NormalTok{output }\OtherTok{\textless{}{-}} \FunctionTok{matrix\_vector\_arithmetic}\NormalTok{(A, B, v, c)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Next, write these operations in C++ function:
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// [[Rcpp::export]]
Rcpp::List matrix_vector_arithmetic_rcpp(
    Eigen::MatrixXd A, Eigen::MatrixXd B, 
    Eigen::VectorXd v, double c) {
  // addition and subtraction
  Eigen::MatrixXd X1 = A + B;
  Eigen::MatrixXd X2 = A - B;
  Eigen::MatrixXd X3 = - A;
  // scalar multiplication and division
  Eigen::MatrixXd X4 = A * c;
  Eigen::MatrixXd X5 = c * A;
  Eigen::MatrixXd X6 = A / c;
  // transpose
  Eigen::MatrixXd X7 = A.transpose();
  // matrix-matrix and matrix-vector multiplication
  Eigen::MatrixXd X8 = A * B.transpose();
  Eigen::VectorXd X9 = A * v;
  // return 
  Rcpp::List output = 
    Rcpp::List::create(
      Rcpp::Named("X1") = X1,
      Rcpp::Named("X2") = X2,
      Rcpp::Named("X3") = X3,
      Rcpp::Named("X4") = X4,
      Rcpp::Named("X5") = X5,
      Rcpp::Named("X6") = X6,
      Rcpp::Named("X7") = X7,
      Rcpp::Named("X8") = X8,
      Rcpp::Named("X9") = X9);
  return(output);
}
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Then, we can check if this yields (almost) the same result with the R function:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{output\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{matrix\_vector\_arithmetic\_rcpp}\NormalTok{(A, B, v, c)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(output) }\SpecialCharTok{{-}} \FunctionTok{unlist}\NormalTok{(output\_rcpp)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The output looks like:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{output\_rcpp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $X1
##             [,1]      [,2]       [,3]      [,4]
## [1,] -0.05067246 0.6761526 -0.2917328 1.6123600
## [2,] -0.12174506 1.9851240 -3.0351683 0.6933911
## 
## $X2
##            [,1]      [,2]      [,3]       [,4]
## [1,] -1.2022352 -2.347410 0.9507484 -0.6375019
## [2,]  0.4890317  1.205438 1.3942315  0.7832583
## 
## $X3
##            [,1]       [,2]       [,3]       [,4]
## [1,]  0.6264538  0.8356286 -0.3295078 -0.4874291
## [2,] -0.1836433 -1.5952808  0.8204684 -0.7383247
## 
## $X4
##           [,1]      [,2]       [,3]     [,4]
## [1,] -1.879361 -2.506886  0.9885233 1.462287
## [2,]  0.550930  4.785842 -2.4614052 2.214974
## 
## $X5
##           [,1]      [,2]       [,3]     [,4]
## [1,] -1.879361 -2.506886  0.9885233 1.462287
## [2,]  0.550930  4.785842 -2.4614052 2.214974
## 
## $X6
##             [,1]       [,2]       [,3]      [,4]
## [1,] -0.20881794 -0.2785429  0.1098359 0.1624764
## [2,]  0.06121444  0.5317603 -0.2734895 0.2461082
## 
## $X7
##            [,1]       [,2]
## [1,] -0.6264538  0.1836433
## [2,] -0.8356286  1.5952808
## [3,]  0.3295078 -0.8204684
## [4,]  0.4874291  0.7383247
## 
## $X8
##           [,1]       [,2]
## [1,] -1.280368 -0.8861152
## [2,]  3.857726  2.3497425
## 
## $X9
## [1] -0.2184706  1.2674165
\end{verbatim}

\subsection{The Array Class and Coefficient-wise Operations}\label{the-array-class-and-coefficient-wise-operations}

\begin{itemize}
\item
  When you want to have coefficient-wise operations, you first use \texttt{.array()} method to convert the object to an array and then apply methods for arrays.
\item
  The resulting array can be assigned to a matrix object implicitly or explicitly by using \texttt{.matrix()} method.
\item
  Coefficient-wise multiplication:

  \begin{itemize}
  \tightlist
  \item
    \texttt{A\ *\ B} in R is \texttt{A.array()\ *\ B.\ array()} in Eigen.
  \end{itemize}
\item
  Other coefficient-wise math functions:

  \begin{itemize}
  \tightlist
  \item
    Absolute value: \texttt{A.array().abs()}.
  \item
    Exponential: \texttt{A.array().exp()}.
  \item
    Logarithm: \texttt{A.array().log()}.
  \item
    Power: \texttt{A.array().power(r)}.
  \item
    For the other methods, refer to the \href{https://eigen.tuxfamily.org/dox/group__CoeffwiseMathFunctions.html}{online document}.
  \end{itemize}
\item
  Write functions in R in \texttt{R/functions.R} and run in \texttt{main/main.R}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# R/functions.R}
\NormalTok{coefficientwise\_operation }\OtherTok{\textless{}{-}}
  \ControlFlowTok{function}\NormalTok{(A, B, r) \{}
    \CommentTok{\# coefficient{-}wise multiplication}
\NormalTok{    X1 }\OtherTok{\textless{}{-}}\NormalTok{ A }\SpecialCharTok{*}\NormalTok{ B}
    \CommentTok{\# other coefficient{-}wise math functions}
\NormalTok{    X2 }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(A)}
\NormalTok{    X3 }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(A)}
\NormalTok{    X4 }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(}\FunctionTok{abs}\NormalTok{(A))}
\NormalTok{    X5 }\OtherTok{\textless{}{-}}\NormalTok{ A}\SpecialCharTok{\^{}}\NormalTok{r}
    \CommentTok{\# return}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}
      \AttributeTok{X1 =}\NormalTok{ X1,}
      \AttributeTok{X2 =}\NormalTok{ X2,}
      \AttributeTok{X3 =}\NormalTok{ X3,}
      \AttributeTok{X4 =}\NormalTok{ X4,}
      \AttributeTok{X5 =}\NormalTok{ X5}
\NormalTok{    ))}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\CommentTok{\# coefficient{-}wise operations}
\NormalTok{r }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{output }\OtherTok{\textless{}{-}} \FunctionTok{coefficientwise\_operation}\NormalTok{(A, B, r)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Write C++ function in \texttt{src/functions.cpp} and call from \texttt{main/main.R}:
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// [[Rcpp::export]]
Rcpp::List coefficientwise_operation_rcpp(
  Eigen::MatrixXd A,
  Eigen::MatrixXd B,
  int r
) {
  // coefficient-wise multiplication
  Eigen::MatrixXd X1 = A.array() * B.array();
  // other coefficient-wise math functions
  Eigen::MatrixXd X2 = A.array().abs();
  Eigen::MatrixXd X3 = A.array().exp();
  Eigen::MatrixXd X4 = A.array().abs().log();
  Eigen::MatrixXd X5 = A.array().pow(r);
  // return
  Rcpp::List output =
    Rcpp::List::create(
      Rcpp::Named("X1") = X1,
      Rcpp::Named("X2") = X2,
      Rcpp::Named("X3") = X3,
      Rcpp::Named("X4") = X4,
      Rcpp::Named("X5") = X5
    );
  return(output);
}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{coefficientwise\_operation\_rcpp}\NormalTok{(A, B, r)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(output) }\SpecialCharTok{{-}} \FunctionTok{unlist}\NormalTok{(output\_rcpp)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.220446e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output\_rcpp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $X1
##             [,1]       [,2]       [,3]        [,4]
## [1,] -0.36070042 -1.2632876 -0.2047036  0.54832401
## [2,] -0.05608254  0.6219094  1.8170912 -0.03317559
## 
## $X2
##           [,1]      [,2]      [,3]      [,4]
## [1,] 0.6264538 0.8356286 0.3295078 0.4874291
## [2,] 0.1836433 1.5952808 0.8204684 0.7383247
## 
## $X3
##           [,1]      [,2]      [,3]     [,4]
## [1,] 0.5344838 0.4336018 1.3902836 1.628125
## [2,] 1.2015872 4.9297132 0.4402254 2.092427
## 
## $X4
##            [,1]       [,2]       [,3]       [,4]
## [1,] -0.4676802 -0.1795710 -1.1101553 -0.7186105
## [2,] -1.6947599  0.4670498 -0.1978799 -0.3033716
## 
## $X5
##            [,1]      [,2]      [,3]      [,4]
## [1,] 0.39244438 0.6982752 0.1085754 0.2375871
## [2,] 0.03372487 2.5449208 0.6731684 0.5451234
\end{verbatim}

\subsection{Solving Linear Least Squares Systems}\label{solving-linear-least-squares-systems}

\begin{itemize}
\tightlist
\item
  It is often required to solve a linear least squares system \(A \cdot x = b\).
\item
  Solving using SVD decomposition:
\end{itemize}

\begin{verbatim}
A.bdcSvd(Eigen::ComputeThinU | Eigen::ComputeThinV).solve(b)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Solving using QR decomposition:
\end{itemize}

\begin{verbatim}
A.colPivHouseholderQr().solve(b)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Write R function in \texttt{R/functions.R} and run in \texttt{main/main.R}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# R/functions.R}
\NormalTok{solve\_least\_squares }\OtherTok{\textless{}{-}}
  \ControlFlowTok{function}\NormalTok{(A, B) \{}
\NormalTok{    x }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(A, B)}
    \FunctionTok{return}\NormalTok{(x)}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{4} \SpecialCharTok{*} \DecValTok{4}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{)}
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{4} \SpecialCharTok{*} \DecValTok{4}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{)}
\NormalTok{output }\OtherTok{\textless{}{-}} \FunctionTok{solve\_least\_squares}\NormalTok{(A, B)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Write C++ function in \texttt{src/functions.cpp} and call in \texttt{main/main.R}:
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// solve least squares using SVD decomposition
// [[Rcpp::export]]
Eigen::MatrixXd solve_least_squares_svd(
  Eigen::MatrixXd A,
  Eigen::MatrixXd B
) {
  Eigen::MatrixXd x = A.bdcSvd(Eigen::ComputeThinU | Eigen::ComputeThinV).solve(B);
  return(x);
}
// solve least squares using QR decomposition
// [[Rcpp::export]]
Eigen::MatrixXd solve_least_squares_qr(
    Eigen::MatrixXd A,
    Eigen::MatrixXd B
) {
  Eigen::MatrixXd x = A.colPivHouseholderQr().solve(B);
  return(x);
}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{output\_svd }\OtherTok{\textless{}{-}} \FunctionTok{solve\_least\_squares\_svd}\NormalTok{(A, B)}
\NormalTok{output\_qr }\OtherTok{\textless{}{-}} \FunctionTok{solve\_least\_squares\_qr}\NormalTok{(A, B)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(output }\SpecialCharTok{{-}}\NormalTok{ output\_svd))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.881784e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(output }\SpecialCharTok{{-}}\NormalTok{ output\_qr))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.387779e-15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output\_svd}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]       [,2]       [,3]       [,4]
## [1,]  0.65530863 -1.2441297 -1.0799835  0.5926519
## [2,] -1.34801870  0.1453720  0.7313845 -2.2353988
## [3,]  1.38750763 -0.3405502 -0.7649107  1.5987206
## [4,] -0.06376266 -0.4632165 -0.2296862  0.4681169
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output\_qr}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]       [,2]       [,3]       [,4]
## [1,]  0.65530863 -1.2441297 -1.0799835  0.5926519
## [2,] -1.34801870  0.1453720  0.7313845 -2.2353988
## [3,]  1.38750763 -0.3405502 -0.7649107  1.5987206
## [4,] -0.06376266 -0.4632165 -0.2296862  0.4681169
\end{verbatim}

\subsection{Accessing to Elements of a Matrix and Vector}\label{accessing-to-elements-of-a-matrix-and-vector}

\begin{itemize}
\item
  You can access to the size information and elements of a matrix and vector as follows:
\item
  Sizes: \texttt{A.rows()} for row numbers and \texttt{A.cols()} for column numbers.
\item
  Element: \texttt{A(i,\ j)} for (\(i + 1\), \(j + 1\))-th element.
\item
  Rows and columns: \texttt{A.row(i)} for \(i + 1\)-th row and \texttt{A.col(j)} for \(j + 1\)-th column.
\item
  Write R function in \texttt{R/functions.R} and run in \texttt{main/main.R}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# R/functions.R}
\NormalTok{access }\OtherTok{\textless{}{-}} 
  \ControlFlowTok{function}\NormalTok{(A, i, j) \{}
\NormalTok{    I }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(A)}
\NormalTok{    J }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(A)}
\NormalTok{    a\_ij }\OtherTok{\textless{}{-}}\NormalTok{ A[i, j]}
\NormalTok{    a\_i }\OtherTok{\textless{}{-}}\NormalTok{ A[i, ]}
\NormalTok{    a\_j }\OtherTok{\textless{}{-}}\NormalTok{ A[, j]}
    \FunctionTok{return}\NormalTok{(}
      \FunctionTok{list}\NormalTok{(}
        \AttributeTok{I =}\NormalTok{ I,}
        \AttributeTok{J =}\NormalTok{ J,}
        \AttributeTok{a\_ij =}\NormalTok{ a\_ij,}
        \AttributeTok{a\_i =}\NormalTok{ a\_i,}
        \AttributeTok{a\_j =}\NormalTok{ a\_j}
\NormalTok{      )}
\NormalTok{    )}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{output }\OtherTok{\textless{}{-}} \FunctionTok{access}\NormalTok{(A, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Write C++ function in \texttt{src/functions.cpp} and call in \texttt{main/main.R}:
\end{itemize}

\begin{verbatim}
// src/functions.cpp
// [[Rcpp::export]]
Rcpp::List access_rcpp(
    Eigen::MatrixXd A, 
    int i, 
    int j
  ) {
    int I = A.rows();
    int J = A.cols();
    double a_ij = A(i - 1, j - 1);
    Eigen::VectorXd a_i = A.row(i - 1);
    Eigen::VectorXd a_j = A.col(j - 1);
    Rcpp::List output =
      Rcpp::List::create(
        Rcpp::Named("I") = I,
        Rcpp::Named("J") = J,
        Rcpp::Named("a_ij") = a_ij,
        Rcpp::Named("a_i") = a_i,
        Rcpp::Named("a_j") = a_j
      );
    return(output);
  }
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# main/main.R}
\NormalTok{output\_rcpp }\OtherTok{\textless{}{-}} \FunctionTok{access\_rcpp}\NormalTok{(A, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(output) }\SpecialCharTok{{-}} \FunctionTok{unlist}\NormalTok{(output\_rcpp)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output\_rcpp }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $I
## [1] 4
## 
## $J
## [1] 4
## 
## $a_ij
## [1] 0.3295078
## 
## $a_i
## [1] -0.6264538  0.3295078  0.5757814 -0.6212406
## 
## $a_j
## [1]  0.3295078 -0.8204684  0.4874291  0.7383247
\end{verbatim}

  \bibliography{PhDIO3.bib,packages.bib}

\end{document}
